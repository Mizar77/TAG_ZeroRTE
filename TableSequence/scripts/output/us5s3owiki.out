Warn: we adopt CRF implemented by allennlp, please install it first before using CRF.
{'main_dual': {'path_train': 'zero_rte/wiki/unseen_5_seed_3/train.jsonl', 'path_dev': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'save_dir': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/', 'num_iter': 5, 'data_name': 'wiki', 'split': 'unseen_5_seed_3', 'type': 'synthetic', 'model_size': 'large', 'with_train': False, 'by_rel': False, 'rl_version': 'all', 'rescale_train': False, 'score_only_ext': True, 'limit': 5000, 'g_encoder_name': 'generate', 'num_gen_per_label': 500, 'diverse': False}}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki/unseen_5_seed_3/generator/model', data_dir='outputs/wrapper/wiki/unseen_5_seed_3/generator/data', model_name='gpt2', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
Generating:   0%|          | 0/10 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  10%|█         | 1/10 [00:16<02:28, 16.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  20%|██        | 2/10 [00:31<02:06, 15.78s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  30%|███       | 3/10 [00:47<01:49, 15.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  40%|████      | 4/10 [01:01<01:30, 15.06s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  50%|█████     | 5/10 [01:17<01:17, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  60%|██████    | 6/10 [01:33<01:02, 15.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  70%|███████   | 7/10 [01:47<00:44, 14.95s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  80%|████████  | 8/10 [02:00<00:28, 14.40s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  90%|█████████ | 9/10 [02:13<00:14, 14.11s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating: 100%|██████████| 10/10 [02:29<00:00, 14.60s/it]Generating: 100%|██████████| 10/10 [02:29<00:00, 14.94s/it]
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
{'target': 600, 'success': 26, 'raw': 32}
{'target': 600, 'success': 50, 'raw': 64}
{'target': 600, 'success': 76, 'raw': 96}
{'target': 600, 'success': 101, 'raw': 128}
{'target': 600, 'success': 129, 'raw': 160}
{'target': 600, 'success': 155, 'raw': 192}
{'target': 600, 'success': 177, 'raw': 224}
{'target': 600, 'success': 199, 'raw': 256}
{'target': 600, 'success': 224, 'raw': 288}
{'target': 600, 'success': 247, 'raw': 320}
{'target': 600, 'success': 274, 'raw': 352}
{'target': 600, 'success': 297, 'raw': 384}
{'target': 600, 'success': 320, 'raw': 416}
{'target': 600, 'success': 343, 'raw': 448}
{'target': 600, 'success': 369, 'raw': 480}
{'target': 600, 'success': 391, 'raw': 512}
{'target': 600, 'success': 411, 'raw': 544}
{'target': 600, 'success': 433, 'raw': 576}
{'target': 600, 'success': 458, 'raw': 608}
{'target': 600, 'success': 486, 'raw': 640}
{'target': 600, 'success': 505, 'raw': 672}
{'target': 600, 'success': 530, 'raw': 704}
{'target': 600, 'success': 557, 'raw': 736}
{'target': 600, 'success': 581, 'raw': 768}
{'target': 600, 'success': 609, 'raw': 800}
{'prompt': 'Relation : country .', 'success_rate': 0.76125, 'errors': {''}}
{'target': 600, 'success': 25, 'raw': 32}
{'target': 600, 'success': 55, 'raw': 64}
{'target': 600, 'success': 81, 'raw': 96}
{'target': 600, 'success': 106, 'raw': 128}
{'target': 600, 'success': 131, 'raw': 160}
{'target': 600, 'success': 156, 'raw': 192}
{'target': 600, 'success': 181, 'raw': 224}
{'target': 600, 'success': 202, 'raw': 256}
{'target': 600, 'success': 225, 'raw': 288}
{'target': 600, 'success': 246, 'raw': 320}
{'target': 600, 'success': 273, 'raw': 352}
{'target': 600, 'success': 293, 'raw': 384}
{'target': 600, 'success': 318, 'raw': 416}
{'target': 600, 'success': 339, 'raw': 448}
{'target': 600, 'success': 362, 'raw': 480}
{'target': 600, 'success': 384, 'raw': 512}
{'target': 600, 'success': 410, 'raw': 544}
{'target': 600, 'success': 438, 'raw': 576}
{'target': 600, 'success': 463, 'raw': 608}
{'target': 600, 'success': 488, 'raw': 640}
{'target': 600, 'success': 515, 'raw': 672}
{'target': 600, 'success': 543, 'raw': 704}
{'target': 600, 'success': 566, 'raw': 736}
{'target': 600, 'success': 588, 'raw': 768}
{'target': 600, 'success': 613, 'raw': 800}
{'prompt': 'Relation : part of .', 'success_rate': 0.76625, 'errors': {'', "('Brest', 'part of', '', 'Fauci s son , Jean , also commanded the troops at Brest .')"}}
{'target': 600, 'success': 25, 'raw': 32}
{'target': 600, 'success': 45, 'raw': 64}
{'target': 600, 'success': 72, 'raw': 96}
{'target': 600, 'success': 94, 'raw': 128}
{'target': 600, 'success': 116, 'raw': 160}
{'target': 600, 'success': 141, 'raw': 192}
{'target': 600, 'success': 161, 'raw': 224}
{'target': 600, 'success': 186, 'raw': 256}
{'target': 600, 'success': 210, 'raw': 288}
{'target': 600, 'success': 232, 'raw': 320}
{'target': 600, 'success': 260, 'raw': 352}
{'target': 600, 'success': 280, 'raw': 384}
{'target': 600, 'success': 303, 'raw': 416}
{'target': 600, 'success': 326, 'raw': 448}
{'target': 600, 'success': 352, 'raw': 480}
{'target': 600, 'success': 376, 'raw': 512}
{'target': 600, 'success': 398, 'raw': 544}
{'target': 600, 'success': 421, 'raw': 576}
{'target': 600, 'success': 445, 'raw': 608}
{'target': 600, 'success': 472, 'raw': 640}
{'target': 600, 'success': 498, 'raw': 672}
{'target': 600, 'success': 525, 'raw': 704}
{'target': 600, 'success': 547, 'raw': 736}
{'target': 600, 'success': 570, 'raw': 768}
{'target': 600, 'success': 595, 'raw': 800}
{'target': 600, 'success': 618, 'raw': 832}
{'prompt': 'Relation : platform .', 'success_rate': 0.7427884615384616, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 55, 'raw': 64}
{'target': 600, 'success': 81, 'raw': 96}
{'target': 600, 'success': 110, 'raw': 128}
{'target': 600, 'success': 136, 'raw': 160}
{'target': 600, 'success': 160, 'raw': 192}
{'target': 600, 'success': 188, 'raw': 224}
{'target': 600, 'success': 218, 'raw': 256}
{'target': 600, 'success': 244, 'raw': 288}
{'target': 600, 'success': 270, 'raw': 320}
{'target': 600, 'success': 298, 'raw': 352}
{'target': 600, 'success': 326, 'raw': 384}
{'target': 600, 'success': 352, 'raw': 416}
{'target': 600, 'success': 382, 'raw': 448}
{'target': 600, 'success': 413, 'raw': 480}
{'target': 600, 'success': 444, 'raw': 512}
{'target': 600, 'success': 475, 'raw': 544}
{'target': 600, 'success': 504, 'raw': 576}
{'target': 600, 'success': 531, 'raw': 608}
{'target': 600, 'success': 557, 'raw': 640}
{'target': 600, 'success': 584, 'raw': 672}
{'target': 600, 'success': 613, 'raw': 704}
{'prompt': 'Relation : publisher .', 'success_rate': 0.8707386363636364, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 26, 'raw': 32}
{'target': 600, 'success': 45, 'raw': 64}
{'target': 600, 'success': 70, 'raw': 96}
{'target': 600, 'success': 96, 'raw': 128}
{'target': 600, 'success': 123, 'raw': 160}
{'target': 600, 'success': 146, 'raw': 192}
{'target': 600, 'success': 171, 'raw': 224}
{'target': 600, 'success': 194, 'raw': 256}
{'target': 600, 'success': 216, 'raw': 288}
{'target': 600, 'success': 244, 'raw': 320}
{'target': 600, 'success': 270, 'raw': 352}
{'target': 600, 'success': 295, 'raw': 384}
{'target': 600, 'success': 316, 'raw': 416}
{'target': 600, 'success': 339, 'raw': 448}
{'target': 600, 'success': 363, 'raw': 480}
{'target': 600, 'success': 388, 'raw': 512}
{'target': 600, 'success': 409, 'raw': 544}
{'target': 600, 'success': 434, 'raw': 576}
{'target': 600, 'success': 457, 'raw': 608}
{'target': 600, 'success': 476, 'raw': 640}
{'target': 600, 'success': 499, 'raw': 672}
{'target': 600, 'success': 523, 'raw': 704}
{'target': 600, 'success': 546, 'raw': 736}
{'target': 600, 'success': 570, 'raw': 768}
{'target': 600, 'success': 591, 'raw': 800}
{'target': 600, 'success': 612, 'raw': 832}
{'prompt': 'Relation : sport .', 'success_rate': 0.7355769230769231, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 26, 'raw': 32}
{'target': 600, 'success': 49, 'raw': 64}
{'target': 600, 'success': 71, 'raw': 96}
{'target': 600, 'success': 90, 'raw': 128}
{'target': 600, 'success': 110, 'raw': 160}
{'target': 600, 'success': 134, 'raw': 192}
{'target': 600, 'success': 158, 'raw': 224}
{'target': 600, 'success': 181, 'raw': 256}
{'target': 600, 'success': 198, 'raw': 288}
{'target': 600, 'success': 225, 'raw': 320}
{'target': 600, 'success': 250, 'raw': 352}
{'target': 600, 'success': 272, 'raw': 384}
{'target': 600, 'success': 295, 'raw': 416}
{'target': 600, 'success': 318, 'raw': 448}
{'target': 600, 'success': 342, 'raw': 480}
{'target': 600, 'success': 364, 'raw': 512}
{'target': 600, 'success': 390, 'raw': 544}
{'target': 600, 'success': 413, 'raw': 576}
{'target': 600, 'success': 437, 'raw': 608}
{'target': 600, 'success': 458, 'raw': 640}
{'target': 600, 'success': 483, 'raw': 672}
{'target': 600, 'success': 507, 'raw': 704}
{'target': 600, 'success': 531, 'raw': 736}
{'target': 600, 'success': 557, 'raw': 768}
{'target': 600, 'success': 582, 'raw': 800}
{'target': 600, 'success': 609, 'raw': 832}
{'prompt': 'Relation : continent .', 'success_rate': 0.7319711538461539, 'errors': {''}}
{'target': 600, 'success': 24, 'raw': 32}
{'target': 600, 'success': 48, 'raw': 64}
{'target': 600, 'success': 77, 'raw': 96}
{'target': 600, 'success': 108, 'raw': 128}
{'target': 600, 'success': 138, 'raw': 160}
{'target': 600, 'success': 162, 'raw': 192}
{'target': 600, 'success': 193, 'raw': 224}
{'target': 600, 'success': 222, 'raw': 256}
{'target': 600, 'success': 250, 'raw': 288}
{'target': 600, 'success': 278, 'raw': 320}
{'target': 600, 'success': 305, 'raw': 352}
{'target': 600, 'success': 332, 'raw': 384}
{'target': 600, 'success': 358, 'raw': 416}
{'target': 600, 'success': 385, 'raw': 448}
{'target': 600, 'success': 413, 'raw': 480}
{'target': 600, 'success': 440, 'raw': 512}
{'target': 600, 'success': 468, 'raw': 544}
{'target': 600, 'success': 494, 'raw': 576}
{'target': 600, 'success': 522, 'raw': 608}
{'target': 600, 'success': 552, 'raw': 640}
{'target': 600, 'success': 582, 'raw': 672}
{'target': 600, 'success': 609, 'raw': 704}
{'prompt': 'Relation : owned by .', 'success_rate': 0.8650568181818182, 'errors': {''}}
{'target': 600, 'success': 32, 'raw': 32}
{'target': 600, 'success': 62, 'raw': 64}
{'target': 600, 'success': 87, 'raw': 96}
{'target': 600, 'success': 116, 'raw': 128}
{'target': 600, 'success': 144, 'raw': 160}
{'target': 600, 'success': 174, 'raw': 192}
{'target': 600, 'success': 203, 'raw': 224}
{'target': 600, 'success': 231, 'raw': 256}
{'target': 600, 'success': 260, 'raw': 288}
{'target': 600, 'success': 289, 'raw': 320}
{'target': 600, 'success': 320, 'raw': 352}
{'target': 600, 'success': 350, 'raw': 384}
{'target': 600, 'success': 378, 'raw': 416}
{'target': 600, 'success': 408, 'raw': 448}
{'target': 600, 'success': 435, 'raw': 480}
{'target': 600, 'success': 464, 'raw': 512}
{'target': 600, 'success': 492, 'raw': 544}
{'target': 600, 'success': 522, 'raw': 576}
{'target': 600, 'success': 552, 'raw': 608}
{'target': 600, 'success': 576, 'raw': 640}
{'target': 600, 'success': 606, 'raw': 672}
{'prompt': 'Relation : performer .', 'success_rate': 0.9017857142857143, 'errors': {'', 'too many values to unpack (expected 2)', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 28, 'raw': 32}
{'target': 600, 'success': 59, 'raw': 64}
{'target': 600, 'success': 85, 'raw': 96}
{'target': 600, 'success': 112, 'raw': 128}
{'target': 600, 'success': 140, 'raw': 160}
{'target': 600, 'success': 171, 'raw': 192}
{'target': 600, 'success': 201, 'raw': 224}
{'target': 600, 'success': 231, 'raw': 256}
{'target': 600, 'success': 259, 'raw': 288}
{'target': 600, 'success': 289, 'raw': 320}
{'target': 600, 'success': 320, 'raw': 352}
{'target': 600, 'success': 350, 'raw': 384}
{'target': 600, 'success': 380, 'raw': 416}
{'target': 600, 'success': 410, 'raw': 448}
{'target': 600, 'success': 440, 'raw': 480}
{'target': 600, 'success': 470, 'raw': 512}
{'target': 600, 'success': 499, 'raw': 544}
{'target': 600, 'success': 529, 'raw': 576}
{'target': 600, 'success': 560, 'raw': 608}
{'target': 600, 'success': 592, 'raw': 640}
{'target': 600, 'success': 620, 'raw': 672}
{'prompt': 'Relation : producer .', 'success_rate': 0.9226190476190477, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 26, 'raw': 32}
{'target': 600, 'success': 49, 'raw': 64}
{'target': 600, 'success': 75, 'raw': 96}
{'target': 600, 'success': 101, 'raw': 128}
{'target': 600, 'success': 124, 'raw': 160}
{'target': 600, 'success': 149, 'raw': 192}
{'target': 600, 'success': 173, 'raw': 224}
{'target': 600, 'success': 194, 'raw': 256}
{'target': 600, 'success': 219, 'raw': 288}
{'target': 600, 'success': 244, 'raw': 320}
{'target': 600, 'success': 274, 'raw': 352}
{'target': 600, 'success': 299, 'raw': 384}
{'target': 600, 'success': 323, 'raw': 416}
{'target': 600, 'success': 349, 'raw': 448}
{'target': 600, 'success': 375, 'raw': 480}
{'target': 600, 'success': 400, 'raw': 512}
{'target': 600, 'success': 429, 'raw': 544}
{'target': 600, 'success': 454, 'raw': 576}
{'target': 600, 'success': 481, 'raw': 608}
{'target': 600, 'success': 506, 'raw': 640}
{'target': 600, 'success': 530, 'raw': 672}
{'target': 600, 'success': 558, 'raw': 704}
{'target': 600, 'success': 585, 'raw': 736}
{'target': 600, 'success': 612, 'raw': 768}
{'prompt': 'Relation : replaces .', 'success_rate': 0.796875, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/0.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/0_ext.jsonl'}}
estimate vocab size: 12158
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 12258, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_synthetic_large/unseen_5_seed_3/extractor/data/estimate.txt
Extractor Estimating: 0it [00:00, ?it/s]/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1190: UserWarning: operator() sees varying value in profiling, ignoring and this should be handled by GUARD logic (Triggered internally at ../torch/csrc/jit/codegen/cuda/parser.cpp:3668.)
  return forward_call(*input, **kwargs)
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1190: UserWarning: operator() profile_node %91 : int[] = prim::profile_ivalue[profile_failed="varying profile values"](%89)
 does not have profile information (Triggered internally at ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
Extractor Estimating: 1it [00:14, 14.70s/it]Extractor Estimating: 2it [00:17,  7.70s/it]Extractor Estimating: 3it [00:18,  4.48s/it]Extractor Estimating: 4it [00:18,  2.94s/it]Extractor Estimating: 5it [00:19,  2.09s/it]Extractor Estimating: 6it [00:19,  1.57s/it]Extractor Estimating: 7it [00:20,  1.25s/it]Extractor Estimating: 8it [00:21,  1.04s/it]Extractor Estimating: 9it [00:21,  1.09it/s]Extractor Estimating: 10it [00:22,  1.22it/s]Extractor Estimating: 11it [00:22,  1.34it/s]Extractor Estimating: 12it [00:23,  1.40it/s]Extractor Estimating: 13it [00:25,  1.21s/it]Extractor Estimating: 14it [00:26,  1.04s/it]Extractor Estimating: 15it [00:27,  1.10it/s]Extractor Estimating: 16it [00:27,  1.23it/s]Extractor Estimating: 17it [00:28,  1.35it/s]Extractor Estimating: 18it [00:28,  1.39it/s]Extractor Estimating: 19it [00:29,  1.47it/s]Extractor Estimating: 20it [00:30,  1.52it/s]Extractor Estimating: 21it [00:30,  1.57it/s]Extractor Estimating: 22it [00:31,  1.60it/s]Extractor Estimating: 23it [00:31,  1.62it/s]Extractor Estimating: 24it [00:32,  1.64it/s]Extractor Estimating: 25it [00:33,  1.62it/s]Extractor Estimating: 26it [00:33,  1.62it/s]Extractor Estimating: 27it [00:34,  1.52it/s]Extractor Estimating: 28it [00:35,  1.59it/s]Extractor Estimating: 29it [00:35,  1.61it/s]Extractor Estimating: 30it [00:36,  1.66it/s]Extractor Estimating: 31it [00:36,  1.65it/s]Extractor Estimating: 32it [00:37,  1.69it/s]Extractor Estimating: 33it [00:37,  1.70it/s]Extractor Estimating: 34it [00:38,  1.70it/s]Extractor Estimating: 35it [00:39,  1.66it/s]Extractor Estimating: 36it [00:39,  1.65it/s]Extractor Estimating: 37it [00:40,  1.61it/s]Extractor Estimating: 38it [00:41,  1.62it/s]Extractor Estimating: 39it [00:41,  1.58it/s]Extractor Estimating: 40it [00:42,  1.58it/s]Extractor Estimating: 41it [00:43,  1.55it/s]Extractor Estimating: 42it [00:43,  1.55it/s]Extractor Estimating: 43it [00:44,  1.55it/s]Extractor Estimating: 44it [00:44,  1.58it/s]Extractor Estimating: 45it [00:45,  1.59it/s]Extractor Estimating: 46it [00:46,  1.57it/s]Extractor Estimating: 47it [00:46,  1.59it/s]Extractor Estimating: 48it [00:47,  1.57it/s]Extractor Estimating: 49it [00:48,  1.60it/s]Extractor Estimating: 50it [00:48,  1.66it/s]Extractor Estimating: 51it [00:49,  1.61it/s]Extractor Estimating: 52it [00:49,  1.65it/s]Extractor Estimating: 53it [00:50,  1.69it/s]Extractor Estimating: 54it [00:51,  1.66it/s]Extractor Estimating: 55it [00:51,  1.74it/s]Extractor Estimating: 56it [00:52,  1.73it/s]Extractor Estimating: 57it [00:52,  1.55it/s]Extractor Estimating: 58it [00:53,  1.59it/s]Extractor Estimating: 59it [00:54,  1.65it/s]Extractor Estimating: 60it [00:56,  1.12s/it]Extractor Estimating: 61it [00:57,  1.03it/s]Extractor Estimating: 62it [00:57,  1.13it/s]Extractor Estimating: 63it [00:58,  1.28it/s]Extractor Estimating: 64it [00:58,  1.37it/s]Extractor Estimating: 65it [00:59,  1.49it/s]Extractor Estimating: 66it [01:00,  1.53it/s]Extractor Estimating: 67it [01:00,  1.57it/s]Extractor Estimating: 68it [01:01,  1.62it/s]Extractor Estimating: 69it [01:01,  1.65it/s]Extractor Estimating: 70it [01:02,  1.67it/s]Extractor Estimating: 71it [01:02,  1.67it/s]Extractor Estimating: 72it [01:03,  1.72it/s]Extractor Estimating: 73it [01:04,  1.76it/s]Extractor Estimating: 74it [01:04,  1.74it/s]Extractor Estimating: 75it [01:05,  1.74it/s]Extractor Estimating: 76it [01:05,  1.68it/s]Extractor Estimating: 77it [01:06,  1.64it/s]Extractor Estimating: 78it [01:07,  1.66it/s]Extractor Estimating: 79it [01:07,  1.66it/s]Extractor Estimating: 80it [01:08,  1.64it/s]Extractor Estimating: 81it [01:08,  1.58it/s]Extractor Estimating: 82it [01:09,  1.62it/s]Extractor Estimating: 83it [01:10,  1.62it/s]Extractor Estimating: 84it [01:10,  1.58it/s]Extractor Estimating: 85it [01:11,  1.58it/s]Extractor Estimating: 86it [01:12,  1.57it/s]Extractor Estimating: 87it [01:12,  1.61it/s]Extractor Estimating: 88it [01:13,  1.58it/s]Extractor Estimating: 89it [01:14,  1.55it/s]Extractor Estimating: 90it [01:14,  1.57it/s]Extractor Estimating: 91it [01:15,  1.55it/s]Extractor Estimating: 92it [01:16,  1.54it/s]Extractor Estimating: 93it [01:16,  1.52it/s]Extractor Estimating: 94it [01:17,  1.51it/s]Extractor Estimating: 95it [01:17,  1.53it/s]Extractor Estimating: 96it [01:18,  1.52it/s]Extractor Estimating: 97it [01:19,  1.55it/s]Extractor Estimating: 98it [01:19,  1.58it/s]Extractor Estimating: 99it [01:20,  1.53it/s]Extractor Estimating: 100it [01:21,  1.57it/s]Extractor Estimating: 101it [01:21,  1.63it/s]Extractor Estimating: 102it [01:22,  1.65it/s]Extractor Estimating: 103it [01:23,  1.51it/s]Extractor Estimating: 104it [01:23,  1.57it/s]Extractor Estimating: 105it [01:24,  1.61it/s]Extractor Estimating: 106it [01:24,  1.61it/s]Extractor Estimating: 107it [01:25,  1.64it/s]Extractor Estimating: 108it [01:26,  1.67it/s]Extractor Estimating: 109it [01:26,  1.70it/s]Extractor Estimating: 110it [01:27,  1.69it/s]Extractor Estimating: 111it [01:27,  1.66it/s]Extractor Estimating: 112it [01:28,  1.60it/s]Extractor Estimating: 113it [01:29,  1.56it/s]Extractor Estimating: 114it [01:29,  1.59it/s]Extractor Estimating: 115it [01:30,  1.63it/s]Extractor Estimating: 116it [01:30,  1.68it/s]Extractor Estimating: 117it [01:31,  1.70it/s]Extractor Estimating: 118it [01:32,  1.73it/s]Extractor Estimating: 119it [01:32,  1.72it/s]Extractor Estimating: 120it [01:33,  1.69it/s]Extractor Estimating: 121it [01:33,  1.68it/s]Extractor Estimating: 122it [01:34,  1.70it/s]Extractor Estimating: 123it [01:35,  1.69it/s]Extractor Estimating: 124it [01:35,  1.63it/s]Extractor Estimating: 125it [01:36,  1.65it/s]Extractor Estimating: 126it [01:36,  1.67it/s]Extractor Estimating: 127it [01:37,  1.67it/s]Extractor Estimating: 128it [01:38,  1.69it/s]Extractor Estimating: 129it [01:38,  1.67it/s]Extractor Estimating: 130it [01:39,  1.70it/s]Extractor Estimating: 131it [01:39,  1.70it/s]Extractor Estimating: 132it [01:40,  1.70it/s]Extractor Estimating: 133it [01:40,  1.71it/s]Extractor Estimating: 134it [01:41,  1.75it/s]Extractor Estimating: 135it [01:42,  1.72it/s]Extractor Estimating: 136it [01:42,  1.76it/s]Extractor Estimating: 137it [01:43,  1.69it/s]Extractor Estimating: 138it [01:43,  1.64it/s]Extractor Estimating: 139it [01:44,  1.65it/s]Extractor Estimating: 140it [01:45,  1.70it/s]Extractor Estimating: 141it [01:45,  1.71it/s]Extractor Estimating: 142it [01:46,  1.67it/s]Extractor Estimating: 143it [01:46,  1.69it/s]Extractor Estimating: 144it [01:47,  1.68it/s]Extractor Estimating: 145it [01:48,  1.66it/s]Extractor Estimating: 146it [01:48,  1.68it/s]Extractor Estimating: 147it [01:49,  1.75it/s]Extractor Estimating: 148it [01:49,  1.71it/s]Extractor Estimating: 149it [01:50,  1.66it/s]Extractor Estimating: 150it [01:51,  1.67it/s]Extractor Estimating: 151it [01:51,  1.69it/s]Extractor Estimating: 152it [01:52,  1.67it/s]Extractor Estimating: 153it [01:52,  1.69it/s]Extractor Estimating: 154it [01:53,  1.74it/s]Extractor Estimating: 155it [01:53,  1.71it/s]Extractor Estimating: 156it [01:54,  1.72it/s]Extractor Estimating: 157it [01:55,  1.64it/s]Extractor Estimating: 158it [01:55,  1.62it/s]Extractor Estimating: 159it [01:56,  1.62it/s]Extractor Estimating: 160it [01:57,  1.63it/s]Extractor Estimating: 161it [01:57,  1.58it/s]Extractor Estimating: 162it [01:58,  1.57it/s]Extractor Estimating: 163it [01:59,  1.57it/s]Extractor Estimating: 164it [01:59,  1.59it/s]Extractor Estimating: 165it [02:00,  1.58it/s]Extractor Estimating: 166it [02:00,  1.62it/s]Extractor Estimating: 167it [02:01,  1.66it/s]Extractor Estimating: 168it [02:02,  1.64it/s]Extractor Estimating: 169it [02:02,  1.63it/s]Extractor Estimating: 170it [02:03,  1.65it/s]Extractor Estimating: 171it [02:03,  1.65it/s]Extractor Estimating: 172it [02:04,  1.60it/s]Extractor Estimating: 173it [02:05,  1.66it/s]Extractor Estimating: 174it [02:05,  1.63it/s]Extractor Estimating: 175it [02:06,  1.62it/s]Extractor Estimating: 176it [02:06,  1.65it/s]Extractor Estimating: 177it [02:07,  1.64it/s]Extractor Estimating: 178it [02:08,  1.60it/s]Extractor Estimating: 179it [02:08,  1.60it/s]Extractor Estimating: 180it [02:09,  1.56it/s]Extractor Estimating: 181it [02:10,  1.57it/s]Extractor Estimating: 182it [02:10,  1.58it/s]Extractor Estimating: 183it [02:11,  1.58it/s]Extractor Estimating: 184it [02:11,  1.63it/s]Extractor Estimating: 185it [02:12,  1.59it/s]Extractor Estimating: 186it [02:13,  1.59it/s]Extractor Estimating: 187it [02:13,  1.60it/s]Extractor Estimating: 188it [02:14,  1.49it/s]Extractor Estimating: 189it [02:15,  1.52it/s]Extractor Estimating: 190it [02:15,  1.58it/s]Extractor Estimating: 191it [02:16,  1.56it/s]Extractor Estimating: 192it [02:17,  1.55it/s]Extractor Estimating: 193it [02:17,  1.60it/s]Extractor Estimating: 194it [02:18,  1.64it/s]Extractor Estimating: 195it [02:18,  1.64it/s]Extractor Estimating: 196it [02:19,  1.62it/s]Extractor Estimating: 197it [02:20,  1.64it/s]Extractor Estimating: 198it [02:20,  1.62it/s]Extractor Estimating: 199it [02:21,  1.57it/s]Extractor Estimating: 200it [02:22,  1.58it/s]Extractor Estimating: 201it [02:22,  1.58it/s]Extractor Estimating: 202it [02:23,  1.55it/s]Extractor Estimating: 203it [02:24,  1.58it/s]Extractor Estimating: 204it [02:24,  1.55it/s]Extractor Estimating: 205it [02:25,  1.57it/s]Extractor Estimating: 206it [02:25,  1.54it/s]Extractor Estimating: 207it [02:26,  1.57it/s]Extractor Estimating: 208it [02:27,  1.60it/s]Extractor Estimating: 209it [02:27,  1.61it/s]Extractor Estimating: 210it [02:28,  1.63it/s]Extractor Estimating: 211it [02:29,  1.55it/s]Extractor Estimating: 212it [02:29,  1.54it/s]Extractor Estimating: 213it [02:30,  1.51it/s]Extractor Estimating: 214it [02:31,  1.52it/s]Extractor Estimating: 215it [02:31,  1.52it/s]Extractor Estimating: 216it [02:32,  1.54it/s]Extractor Estimating: 217it [02:33,  1.53it/s]Extractor Estimating: 218it [02:33,  1.58it/s]Extractor Estimating: 219it [02:34,  1.58it/s]Extractor Estimating: 220it [02:34,  1.56it/s]Extractor Estimating: 221it [02:35,  1.58it/s]Extractor Estimating: 222it [02:36,  1.57it/s]Extractor Estimating: 223it [02:36,  1.56it/s]Extractor Estimating: 224it [02:37,  1.62it/s]Extractor Estimating: 225it [02:38,  1.59it/s]Extractor Estimating: 226it [02:38,  1.61it/s]Extractor Estimating: 227it [02:39,  1.58it/s]Extractor Estimating: 228it [02:40,  1.55it/s]Extractor Estimating: 229it [02:40,  1.55it/s]Extractor Estimating: 230it [02:41,  1.60it/s]Extractor Estimating: 231it [02:41,  1.61it/s]Extractor Estimating: 232it [02:42,  1.65it/s]Extractor Estimating: 233it [02:43,  1.65it/s]Extractor Estimating: 234it [02:43,  1.63it/s]Extractor Estimating: 235it [02:44,  1.56it/s]Extractor Estimating: 236it [02:45,  1.51it/s]Extractor Estimating: 237it [02:45,  1.51it/s]Extractor Estimating: 238it [02:46,  1.55it/s]Extractor Estimating: 239it [02:47,  1.54it/s]Extractor Estimating: 240it [02:47,  1.59it/s]Extractor Estimating: 241it [02:48,  1.62it/s]Extractor Estimating: 242it [02:48,  1.61it/s]Extractor Estimating: 243it [02:49,  1.57it/s]Extractor Estimating: 244it [02:50,  1.59it/s]Extractor Estimating: 245it [02:50,  1.59it/s]Extractor Estimating: 246it [02:51,  1.57it/s]Extractor Estimating: 247it [02:51,  1.58it/s]Extractor Estimating: 248it [02:52,  1.57it/s]Extractor Estimating: 249it [02:53,  1.57it/s]Extractor Estimating: 250it [02:53,  1.60it/s]Extractor Estimating: 250it [02:53,  1.44it/s]
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/0_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_5_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/0.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.2, 'with_train': False, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
{'num_pseudo': 1000, 'num_train': 4000}
num of filtered data: 1037 mean pseudo reward: 0.9485400981732951
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/0.jsonl', 'path_dev': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl'}
train vocab size: 23080
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 23180, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/data/train.txt
{"train_model: args: ModelArguments(model_class='JointModel', model_read_ckpt='outputs/wrapper/wiki_synthetic_large/unseen_5_seed_3/extractor/model', model_write_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/model', pretrained_wv='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/data/train.txt', label_config=None, batch_size=24, evaluate_interval=500, max_steps=10000, max_epoches=20, decay_rate=0.05, token_emb_dim=100, char_encoder='lstm', char_emb_dim=30, cased=False, hidden_dim=200, num_layers=3, crf=None, loss_reduction='sum', maxlen=None, dropout=0.5, optimizer='adam', lr=0.001, vocab_size=23180, vocab_file=None, ner_tag_vocab_size=64, re_tag_vocab_size=250, lm_emb_dim=1024, lm_emb_path='albert-large-v2', head_emb_dim=384, tag_form='iob2', warm_steps=1000, grad_period=1, device='cuda', seed=42)"}
warm up: learning rate was adjusted to 1e-06
warm up: learning rate was adjusted to 1.1e-05
warm up: learning rate was adjusted to 2.1000000000000002e-05
warm up: learning rate was adjusted to 3.1e-05
warm up: learning rate was adjusted to 4.1e-05
warm up: learning rate was adjusted to 5.1000000000000006e-05
warm up: learning rate was adjusted to 6.1e-05
warm up: learning rate was adjusted to 7.1e-05
warm up: learning rate was adjusted to 8.1e-05
warm up: learning rate was adjusted to 9.1e-05
g_step 100, step 12, avg_time 1.285, loss:403.3316
warm up: learning rate was adjusted to 0.000101
warm up: learning rate was adjusted to 0.000111
warm up: learning rate was adjusted to 0.000121
warm up: learning rate was adjusted to 0.000131
warm up: learning rate was adjusted to 0.000141
warm up: learning rate was adjusted to 0.00015099999999999998
warm up: learning rate was adjusted to 0.000161
warm up: learning rate was adjusted to 0.000171
warm up: learning rate was adjusted to 0.00018099999999999998
warm up: learning rate was adjusted to 0.000191
g_step 200, step 24, avg_time 0.990, loss:308.6364
warm up: learning rate was adjusted to 0.000201
warm up: learning rate was adjusted to 0.000211
warm up: learning rate was adjusted to 0.000221
warm up: learning rate was adjusted to 0.000231
warm up: learning rate was adjusted to 0.000241
warm up: learning rate was adjusted to 0.000251
warm up: learning rate was adjusted to 0.000261
warm up: learning rate was adjusted to 0.00027100000000000003
warm up: learning rate was adjusted to 0.00028100000000000005
warm up: learning rate was adjusted to 0.00029099999999999997
g_step 300, step 36, avg_time 0.991, loss:263.7576
warm up: learning rate was adjusted to 0.000301
warm up: learning rate was adjusted to 0.000311
warm up: learning rate was adjusted to 0.000321
warm up: learning rate was adjusted to 0.000331
warm up: learning rate was adjusted to 0.00034100000000000005
warm up: learning rate was adjusted to 0.000351
warm up: learning rate was adjusted to 0.000361
warm up: learning rate was adjusted to 0.000371
warm up: learning rate was adjusted to 0.000381
warm up: learning rate was adjusted to 0.000391
g_step 400, step 4, avg_time 0.981, loss:216.8735
warm up: learning rate was adjusted to 0.00040100000000000004
warm up: learning rate was adjusted to 0.000411
warm up: learning rate was adjusted to 0.000421
warm up: learning rate was adjusted to 0.000431
warm up: learning rate was adjusted to 0.000441
warm up: learning rate was adjusted to 0.000451
warm up: learning rate was adjusted to 0.00046100000000000004
warm up: learning rate was adjusted to 0.000471
warm up: learning rate was adjusted to 0.000481
warm up: learning rate was adjusted to 0.000491
g_step 500, step 16, avg_time 0.987, loss:194.4211
>> valid entity prec:0.4542, rec:0.3780, f1:0.4126
>> valid relation prec:0.1791, rec:0.0978, f1:0.1265
>> valid relation with NER prec:0.1791, rec:0.0978, f1:0.1265
new max entity f1 on valid!
new max relation f1 on valid!
new max relation f1 with NER on valid!
new max averaged entity f1 and relation f1 on valid!
new max averaged entity f1 and relation f1 with NER on valid!
warm up: learning rate was adjusted to 0.000501
warm up: learning rate was adjusted to 0.0005110000000000001
warm up: learning rate was adjusted to 0.000521
warm up: learning rate was adjusted to 0.000531
warm up: learning rate was adjusted to 0.000541
warm up: learning rate was adjusted to 0.0005510000000000001
warm up: learning rate was adjusted to 0.0005610000000000001
warm up: learning rate was adjusted to 0.0005710000000000001
warm up: learning rate was adjusted to 0.0005809999999999999
warm up: learning rate was adjusted to 0.0005909999999999999
g_step 600, step 28, avg_time 4.614, loss:176.2566
warm up: learning rate was adjusted to 0.000601
warm up: learning rate was adjusted to 0.000611
warm up: learning rate was adjusted to 0.000621
warm up: learning rate was adjusted to 0.000631
warm up: learning rate was adjusted to 0.000641
warm up: learning rate was adjusted to 0.000651
warm up: learning rate was adjusted to 0.000661
warm up: learning rate was adjusted to 0.000671
warm up: learning rate was adjusted to 0.0006810000000000001
warm up: learning rate was adjusted to 0.0006910000000000001
g_step 700, step 40, avg_time 1.002, loss:155.1374
warm up: learning rate was adjusted to 0.000701
warm up: learning rate was adjusted to 0.0007109999999999999
warm up: learning rate was adjusted to 0.000721
warm up: learning rate was adjusted to 0.000731
warm up: learning rate was adjusted to 0.000741
warm up: learning rate was adjusted to 0.000751
warm up: learning rate was adjusted to 0.000761
warm up: learning rate was adjusted to 0.000771
warm up: learning rate was adjusted to 0.000781
warm up: learning rate was adjusted to 0.000791
g_step 800, step 8, avg_time 0.986, loss:153.0955
warm up: learning rate was adjusted to 0.0008010000000000001
warm up: learning rate was adjusted to 0.0008110000000000001
warm up: learning rate was adjusted to 0.0008210000000000001
warm up: learning rate was adjusted to 0.000831
warm up: learning rate was adjusted to 0.000841
warm up: learning rate was adjusted to 0.000851
warm up: learning rate was adjusted to 0.000861
warm up: learning rate was adjusted to 0.000871
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/data', model_name='outputs/wrapper/wiki/unseen_5_seed_3/generator/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/data', model_name='outputs/wrapper/wiki/unseen_5_seed_3/generator/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/data', model_name='outputs/wrapper/wiki/unseen_5_seed_3/generator/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
08/29/2023 08:21:44 - WARNING - transformer_base.run_clm_rl -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True
08/29/2023 08:21:44 - INFO - transformer_base.run_clm_rl -   Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=2,
greater_is_better=False,
group_by_length=False,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_on_each_node=True,
logging_dir=runs/Aug29_08-21-44_ctolab07.scc.idea,
logging_first_step=False,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
output_dir=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
08/29/2023 08:21:45 - WARNING - datasets.builder -   Using custom data configuration default-9a3d966f567520bc
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1113: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/xuting/.cache/huggingface/datasets/json/default-9a3d966f567520bc/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...
0 tables [00:00, ? tables/s]                            0 tables [00:00, ? tables/s]                            [INFO|configuration_utils.py:515] 2023-08-29 08:21:47,341 >> loading configuration file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 08:21:47,342 >> Model config GPT2Config {
  "_name_or_path": "gpt2",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 08:21:47,342 >> loading configuration file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 08:21:47,343 >> Model config GPT2Config {
  "_name_or_path": "gpt2",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 08:21:47,416 >> Didn't find file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:21:47,443 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:21:47,443 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:21:47,444 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:21:47,444 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:21:47,444 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:21:47,444 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/tokenizer_config.json
[INFO|modeling_utils.py:1150] 2023-08-29 08:21:47,815 >> loading weights file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 08:21:50,998 >> All model checkpoint weights were used when initializing Model.

[INFO|modeling_utils.py:1345] 2023-08-29 08:21:51,014 >> All the weights of Model were initialized from the model checkpoint at outputs/wrapper/wiki/unseen_5_seed_3/generator/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Model for predictions without further training.
Dataset json downloaded and prepared to /home/xuting/.cache/huggingface/datasets/json/default-9a3d966f567520bc/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.
PreTrainedTokenizerFast(name_or_path='outputs/wrapper/wiki/unseen_5_seed_3/generator/model', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'})
08/29/2023 08:21:51 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.tokenize_function at 0x152680b00830> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
  0%|          | 0/2 [00:00<?, ?ba/s] 50%|█████     | 1/2 [00:00<00:00,  1.29ba/s]100%|██████████| 2/2 [00:00<00:00,  2.53ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:04,  3.43ba/s] 13%|█▎        | 2/15 [00:00<00:03,  4.12ba/s] 20%|██        | 3/15 [00:00<00:02,  4.37ba/s] 27%|██▋       | 4/15 [00:00<00:02,  4.53ba/s] 33%|███▎      | 5/15 [00:01<00:02,  4.58ba/s] 40%|████      | 6/15 [00:01<00:01,  4.62ba/s] 47%|████▋     | 7/15 [00:01<00:01,  4.68ba/s] 53%|█████▎    | 8/15 [00:01<00:01,  4.69ba/s] 60%|██████    | 9/15 [00:01<00:01,  4.71ba/s] 67%|██████▋   | 10/15 [00:02<00:01,  4.73ba/s] 73%|███████▎  | 11/15 [00:02<00:00,  4.72ba/s] 80%|████████  | 12/15 [00:02<00:00,  4.73ba/s] 87%|████████▋ | 13/15 [00:02<00:00,  3.97ba/s] 93%|█████████▎| 14/15 [00:03<00:00,  4.17ba/s]100%|██████████| 15/15 [00:03<00:00,  4.71ba/s]
  0%|          | 0/2 [00:00<?, ?ba/s] 50%|█████     | 1/2 [00:00<00:00,  5.57ba/s]100%|██████████| 2/2 [00:00<00:00, 10.73ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:02,  5.55ba/s] 20%|██        | 3/15 [00:00<00:01,  8.32ba/s] 27%|██▋       | 4/15 [00:00<00:01,  8.83ba/s] 40%|████      | 6/15 [00:00<00:00,  9.42ba/s] 53%|█████▎    | 8/15 [00:00<00:00,  9.69ba/s] 60%|██████    | 9/15 [00:00<00:00,  9.25ba/s] 67%|██████▋   | 10/15 [00:01<00:00,  9.40ba/s] 80%|████████  | 12/15 [00:01<00:00,  9.67ba/s] 93%|█████████▎| 14/15 [00:01<00:00,  9.84ba/s]100%|██████████| 15/15 [00:01<00:00,  9.97ba/s]
[INFO|trainer.py:414] 2023-08-29 08:21:57,627 >> Using amp fp16 backend
[INFO|trainer.py:1147] 2023-08-29 08:21:57,694 >> ***** Running training *****
[INFO|trainer.py:1148] 2023-08-29 08:21:57,694 >>   Num examples = 1037
[INFO|trainer.py:1149] 2023-08-29 08:21:57,695 >>   Num Epochs = 5
[INFO|trainer.py:1150] 2023-08-29 08:21:57,695 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1151] 2023-08-29 08:21:57,695 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1152] 2023-08-29 08:21:57,695 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1153] 2023-08-29 08:21:57,695 >>   Total optimization steps = 80
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:00<00:23,  3.30it/s]  2%|▎         | 2/80 [00:00<00:23,  3.39it/s]  4%|▍         | 3/80 [00:00<00:22,  3.42it/s]  5%|▌         | 4/80 [00:01<00:22,  3.43it/s]  6%|▋         | 5/80 [00:01<00:21,  3.44it/s]  8%|▊         | 6/80 [00:01<00:21,  3.45it/s]  9%|▉         | 7/80 [00:02<00:21,  3.43it/s] 10%|█         | 8/80 [00:02<00:21,  3.43it/s] 11%|█▏        | 9/80 [00:02<00:20,  3.41it/s] 12%|█▎        | 10/80 [00:02<00:20,  3.41it/s] 14%|█▍        | 11/80 [00:03<00:20,  3.41it/s] 15%|█▌        | 12/80 [00:03<00:19,  3.40it/s] 16%|█▋        | 13/80 [00:03<00:19,  3.40it/s] 18%|█▊        | 14/80 [00:04<00:19,  3.40it/s] 19%|█▉        | 15/80 [00:04<00:19,  3.34it/s] 20%|██        | 16/80 [00:04<00:19,  3.36it/s][INFO|trainer.py:2140] 2023-08-29 08:22:02,444 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 08:22:02,444 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 08:22:02,444 >>   Batch size = 8

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.44it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.35it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.45it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.49it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 45.80it/s][A
  2%|▏         | 32/1759 [00:00<00:38, 45.23it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 45.02it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 44.88it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 45.05it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.19it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.31it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.42it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.33it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.19it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 45.08it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 45.02it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.86it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.87it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 45.12it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.15it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.28it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.15it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.14it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 44.99it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 44.90it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 44.74it/s][A
  8%|▊         | 137/1759 [00:03<00:36, 44.84it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.06it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.09it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.34it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.20it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 45.26it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 45.05it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 45.06it/s][A
 10%|█         | 177/1759 [00:03<00:35, 45.01it/s][A
 10%|█         | 182/1759 [00:04<00:35, 44.98it/s][A
 11%|█         | 187/1759 [00:04<00:34, 45.13it/s][A
 11%|█         | 192/1759 [00:04<00:34, 45.34it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.32it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 45.37it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 45.32it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 45.16it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 45.11it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 45.01it/s][A
 13%|█▎        | 227/1759 [00:05<00:34, 45.01it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 45.04it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.26it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.34it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.34it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 45.25it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 45.14it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 45.06it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 44.93it/s][A
 15%|█▌        | 272/1759 [00:06<00:33, 44.95it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.03it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.17it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.26it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.35it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 45.19it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 45.15it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 44.96it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 45.02it/s][A
 18%|█▊        | 317/1759 [00:07<00:32, 44.97it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 45.03it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.12it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 45.26it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 45.33it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 45.25it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 45.14it/s][A
 20%|██        | 352/1759 [00:07<00:31, 44.99it/s][A
 20%|██        | 357/1759 [00:07<00:31, 44.96it/s][A
 21%|██        | 362/1759 [00:08<00:31, 44.85it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.04it/s][A
 21%|██        | 372/1759 [00:08<00:30, 45.06it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.15it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 45.30it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 45.26it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 45.20it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 45.00it/s][A
 23%|██▎       | 402/1759 [00:08<00:30, 45.00it/s][A
 23%|██▎       | 407/1759 [00:08<00:30, 45.00it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.15it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.19it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.18it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 44.61it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 44.85it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 44.91it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 44.91it/s][A
 25%|██▌       | 447/1759 [00:09<00:29, 44.75it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 44.85it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 45.06it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.14it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.01it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 45.20it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 45.29it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 45.09it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 45.07it/s][A
 28%|██▊       | 492/1759 [00:10<00:28, 44.95it/s][A
 28%|██▊       | 497/1759 [00:10<00:28, 44.98it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.16it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 44.98it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 45.00it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 45.08it/s][A
 30%|██▉       | 522/1759 [00:11<00:29, 41.62it/s][A
 30%|██▉       | 527/1759 [00:11<00:28, 42.68it/s][A
 30%|███       | 532/1759 [00:11<00:28, 43.48it/s][A
 31%|███       | 537/1759 [00:11<00:27, 44.01it/s][A
 31%|███       | 542/1759 [00:12<00:27, 44.31it/s][A
 31%|███       | 547/1759 [00:12<00:27, 44.53it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 44.78it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 44.85it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 44.61it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 44.72it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 44.81it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 45.12it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 45.13it/s][A
 33%|███▎      | 587/1759 [00:13<00:25, 45.18it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.17it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.18it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 44.95it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 44.76it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 44.81it/s][A
 35%|███▌      | 617/1759 [00:13<00:25, 44.89it/s][A
 35%|███▌      | 622/1759 [00:13<00:25, 45.00it/s][A
 36%|███▌      | 627/1759 [00:13<00:25, 45.02it/s][A
 36%|███▌      | 632/1759 [00:14<00:24, 45.08it/s][A
 36%|███▌      | 637/1759 [00:14<00:24, 45.24it/s][A
 36%|███▋      | 642/1759 [00:14<00:24, 45.16it/s][A
 37%|███▋      | 647/1759 [00:14<00:24, 45.08it/s][A
 37%|███▋      | 652/1759 [00:14<00:24, 44.87it/s][A
 37%|███▋      | 657/1759 [00:14<00:26, 41.00it/s][A
 38%|███▊      | 662/1759 [00:14<00:25, 42.23it/s][A
 38%|███▊      | 667/1759 [00:14<00:25, 43.15it/s][A
 38%|███▊      | 672/1759 [00:14<00:24, 43.85it/s][A
 38%|███▊      | 677/1759 [00:15<00:24, 44.38it/s][A
 39%|███▉      | 682/1759 [00:15<00:24, 44.71it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 44.98it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 45.12it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 44.62it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 44.59it/s][A
 40%|████      | 707/1759 [00:15<00:23, 44.76it/s][A
 40%|████      | 712/1759 [00:15<00:23, 44.96it/s][A
 41%|████      | 717/1759 [00:15<00:23, 45.03it/s][A
 41%|████      | 722/1759 [00:16<00:22, 45.19it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 45.30it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 45.39it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 45.23it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 45.05it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 44.83it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 44.95it/s][A
 43%|████▎     | 757/1759 [00:16<00:22, 45.03it/s][A
 43%|████▎     | 762/1759 [00:16<00:22, 45.03it/s][A
 44%|████▎     | 767/1759 [00:17<00:21, 45.18it/s][A
 44%|████▍     | 772/1759 [00:17<00:21, 45.31it/s][A
 44%|████▍     | 777/1759 [00:17<00:21, 45.21it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 45.18it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 44.95it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 44.84it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 44.91it/s][A
 46%|████▌     | 802/1759 [00:17<00:21, 44.95it/s][A
 46%|████▌     | 807/1759 [00:17<00:21, 45.06it/s][A
 46%|████▌     | 812/1759 [00:18<00:20, 45.10it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 45.25it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 45.23it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 45.11it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 44.87it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 44.86it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 44.87it/s][A
 48%|████▊     | 847/1759 [00:18<00:20, 45.01it/s][A
 48%|████▊     | 852/1759 [00:18<00:20, 45.03it/s][A
 49%|████▊     | 857/1759 [00:19<00:19, 45.15it/s][A
 49%|████▉     | 862/1759 [00:19<00:19, 45.14it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 45.13it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 45.12it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 44.94it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 44.86it/s][A
 50%|█████     | 887/1759 [00:19<00:21, 40.91it/s][A
 51%|█████     | 892/1759 [00:19<00:20, 42.22it/s][A
 51%|█████     | 897/1759 [00:19<00:19, 43.23it/s][A
 51%|█████▏    | 902/1759 [00:20<00:19, 43.94it/s][A
 52%|█████▏    | 907/1759 [00:20<00:19, 44.35it/s][A
 52%|█████▏    | 912/1759 [00:20<00:18, 44.79it/s][A
 52%|█████▏    | 917/1759 [00:20<00:18, 44.84it/s][A
 52%|█████▏    | 922/1759 [00:20<00:18, 44.89it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 44.49it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 44.45it/s][A
 53%|█████▎    | 937/1759 [00:20<00:18, 44.66it/s][A
 54%|█████▎    | 942/1759 [00:20<00:18, 44.90it/s][A
 54%|█████▍    | 947/1759 [00:21<00:18, 44.98it/s][A
 54%|█████▍    | 952/1759 [00:21<00:17, 45.15it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 45.28it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 45.27it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 45.20it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 44.83it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 44.57it/s][A
 56%|█████▌    | 982/1759 [00:21<00:17, 44.73it/s][A
 56%|█████▌    | 987/1759 [00:21<00:17, 44.94it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 45.09it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 45.28it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 45.19it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.24it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 45.13it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 44.79it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:16, 44.68it/s][A
 58%|█████▊    | 1027/1759 [00:22<00:16, 44.76it/s][A
 59%|█████▊    | 1032/1759 [00:22<00:16, 44.91it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:16, 45.09it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:15, 45.23it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:15, 45.35it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:15, 45.26it/s][A
 60%|██████    | 1057/1759 [00:23<00:15, 45.14it/s][A
 60%|██████    | 1062/1759 [00:23<00:15, 44.98it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 44.95it/s][A
 61%|██████    | 1072/1759 [00:23<00:15, 44.86it/s][A
 61%|██████    | 1077/1759 [00:23<00:15, 44.93it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:15, 45.00it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:14, 45.17it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 45.26it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 44.41it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 44.76it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 44.71it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 44.68it/s][A
 64%|██████▎   | 1117/1759 [00:24<00:14, 44.72it/s][A
 64%|██████▍   | 1122/1759 [00:24<00:14, 44.64it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 44.96it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:13, 45.17it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 45.28it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 45.19it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 45.17it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 45.08it/s][A
 66%|██████▌   | 1157/1759 [00:25<00:13, 44.56it/s][A
 66%|██████▌   | 1162/1759 [00:25<00:13, 44.61it/s][A
 66%|██████▋   | 1167/1759 [00:25<00:13, 44.65it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 44.91it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:12, 45.02it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:12, 45.16it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 45.17it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:12, 45.11it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 45.08it/s][A
 68%|██████▊   | 1202/1759 [00:26<00:12, 44.96it/s][A
 69%|██████▊   | 1207/1759 [00:26<00:12, 45.02it/s][A
 69%|██████▉   | 1212/1759 [00:26<00:12, 44.94it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 44.98it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:11, 44.98it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 45.15it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 45.17it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 45.03it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 44.96it/s][A
 71%|███████   | 1247/1759 [00:27<00:11, 44.81it/s][A
 71%|███████   | 1252/1759 [00:27<00:11, 44.94it/s][A
 71%|███████▏  | 1257/1759 [00:27<00:11, 44.86it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:11, 44.92it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:10, 45.01it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 45.05it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 45.17it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 44.99it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 44.87it/s][A
 73%|███████▎  | 1292/1759 [00:28<00:10, 44.72it/s][A
 74%|███████▎  | 1297/1759 [00:28<00:10, 44.86it/s][A
 74%|███████▍  | 1302/1759 [00:28<00:10, 44.86it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 44.98it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:09, 44.89it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:09, 45.05it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 45.11it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 45.10it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 44.89it/s][A
 76%|███████▌  | 1337/1759 [00:29<00:09, 44.96it/s][A
 76%|███████▋  | 1342/1759 [00:29<00:09, 44.95it/s][A
 77%|███████▋  | 1347/1759 [00:29<00:09, 45.03it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 45.05it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:08, 44.97it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 45.14it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 45.13it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:08, 45.02it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:08, 44.97it/s][A
 79%|███████▊  | 1382/1759 [00:30<00:08, 44.90it/s][A
 79%|███████▉  | 1387/1759 [00:30<00:08, 44.96it/s][A
 79%|███████▉  | 1392/1759 [00:30<00:08, 44.94it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 45.03it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:07, 45.06it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 45.04it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 45.05it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 45.08it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 44.93it/s][A
 81%|████████  | 1427/1759 [00:31<00:07, 43.96it/s][A
 81%|████████▏ | 1432/1759 [00:31<00:07, 44.29it/s][A
 82%|████████▏ | 1437/1759 [00:31<00:07, 44.65it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 44.67it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 44.79it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 44.83it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 44.95it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 44.98it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 44.70it/s][A
 84%|████████▎ | 1472/1759 [00:32<00:06, 44.81it/s][A
 84%|████████▍ | 1477/1759 [00:32<00:06, 44.91it/s][A
 84%|████████▍ | 1482/1759 [00:32<00:06, 45.02it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 45.04it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 44.99it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 45.07it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 45.05it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 45.00it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 44.79it/s][A
 86%|████████▌ | 1517/1759 [00:33<00:05, 44.74it/s][A
 87%|████████▋ | 1522/1759 [00:33<00:05, 44.92it/s][A
 87%|████████▋ | 1527/1759 [00:33<00:05, 44.97it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 45.13it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 45.02it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 45.10it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 45.11it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 44.97it/s][A
 89%|████████▊ | 1557/1759 [00:34<00:04, 44.87it/s][A
 89%|████████▉ | 1562/1759 [00:34<00:04, 43.62it/s][A
 89%|████████▉ | 1567/1759 [00:34<00:04, 44.09it/s][A
 89%|████████▉ | 1572/1759 [00:34<00:04, 44.43it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 44.69it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 44.78it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 44.90it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 44.83it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 44.83it/s][A
 91%|█████████ | 1602/1759 [00:35<00:03, 44.64it/s][A
 91%|█████████▏| 1607/1759 [00:35<00:03, 44.60it/s][A
 92%|█████████▏| 1612/1759 [00:35<00:03, 44.57it/s][A
 92%|█████████▏| 1617/1759 [00:35<00:03, 44.74it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 44.90it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 45.12it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 45.09it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 45.10it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 44.80it/s][A
 94%|█████████▎| 1647/1759 [00:36<00:02, 44.66it/s][A
 94%|█████████▍| 1652/1759 [00:36<00:02, 44.58it/s][A
 94%|█████████▍| 1657/1759 [00:36<00:02, 44.70it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 44.89it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 45.05it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 45.13it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 45.06it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 45.09it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 44.88it/s][A
 96%|█████████▌| 1692/1759 [00:37<00:01, 44.81it/s][A
 96%|█████████▋| 1697/1759 [00:37<00:01, 44.80it/s][A
 97%|█████████▋| 1702/1759 [00:37<00:01, 44.79it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 44.84it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 45.04it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 45.15it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 45.20it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 45.07it/s][A
 98%|█████████▊| 1732/1759 [00:38<00:00, 44.93it/s][A
 99%|█████████▊| 1737/1759 [00:38<00:00, 44.82it/s][A
 99%|█████████▉| 1742/1759 [00:38<00:00, 44.86it/s][A
 99%|█████████▉| 1747/1759 [00:38<00:00, 44.79it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 44.80it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 44.99it/s][A                                               
                                                   [A 20%|██        | 16/80 [00:43<00:19,  3.36it/s]
100%|██████████| 1759/1759 [00:39<00:00, 44.99it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 08:22:41,798 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-16
[INFO|configuration_utils.py:351] 2023-08-29 08:22:42,021 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-16/config.json
[INFO|modeling_utils.py:886] 2023-08-29 08:22:45,452 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-16/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 08:22:45,763 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-16/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 08:22:45,834 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-16/special_tokens_map.json
 21%|██▏       | 17/80 [00:54<15:51, 15.10s/it] 22%|██▎       | 18/80 [00:54<11:00, 10.66s/it] 24%|██▍       | 19/80 [00:54<07:40,  7.54s/it] 25%|██▌       | 20/80 [00:55<05:22,  5.37s/it] 26%|██▋       | 21/80 [00:55<03:46,  3.84s/it] 28%|██▊       | 22/80 [00:55<02:41,  2.78s/it] 29%|██▉       | 23/80 [00:56<01:55,  2.03s/it] 30%|███       | 24/80 [00:56<01:24,  1.51s/it] 31%|███▏      | 25/80 [00:56<01:03,  1.15s/it] 32%|███▎      | 26/80 [00:56<00:48,  1.12it/s] 34%|███▍      | 27/80 [00:57<00:37,  1.41it/s] 35%|███▌      | 28/80 [00:57<00:30,  1.71it/s] 36%|███▋      | 29/80 [00:57<00:25,  1.98it/s] 38%|███▊      | 30/80 [00:58<00:22,  2.26it/s] 39%|███▉      | 31/80 [00:58<00:19,  2.52it/s] 40%|████      | 32/80 [00:58<00:17,  2.73it/s][INFO|trainer.py:2140] 2023-08-29 08:22:56,416 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 08:22:56,416 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 08:22:56,416 >>   Batch size = 8
{'eval_loss': 0.8741165995597839, 'eval_runtime': 39.1924, 'eval_samples_per_second': 358.921, 'eval_steps_per_second': 44.881, 'epoch': 0.97}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 55.93it/s][A
  1%|          | 12/1759 [00:00<00:35, 48.96it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.20it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.34it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 45.86it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 45.53it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 45.30it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 45.02it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 45.04it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.08it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.34it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.38it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.33it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.25it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 45.11it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 45.00it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.25it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.67it/s][A
  6%|▌         | 97/1759 [00:02<00:37, 44.75it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.00it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.13it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.22it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.15it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 45.04it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 44.82it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 44.82it/s][A
  8%|▊         | 137/1759 [00:03<00:36, 44.90it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.07it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.26it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.25it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.31it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 45.32it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 45.19it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 45.15it/s][A
 10%|█         | 177/1759 [00:03<00:35, 45.06it/s][A
 10%|█         | 182/1759 [00:04<00:35, 44.97it/s][A
 11%|█         | 187/1759 [00:04<00:34, 45.04it/s][A
 11%|█         | 192/1759 [00:04<00:34, 45.15it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.25it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 45.22it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 45.13it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 45.04it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 44.97it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 44.81it/s][A
 13%|█▎        | 227/1759 [00:05<00:34, 44.87it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 44.95it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.06it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.10it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.23it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 45.09it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 45.13it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 44.89it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 44.98it/s][A
 15%|█▌        | 272/1759 [00:06<00:33, 45.03it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.00it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.12it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.11it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.24it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 45.19it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 45.12it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 44.98it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 44.92it/s][A
 18%|█▊        | 317/1759 [00:07<00:32, 44.93it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 44.96it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.02it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 45.14it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 45.21it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 45.19it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 45.18it/s][A
 20%|██        | 352/1759 [00:07<00:31, 45.15it/s][A
 20%|██        | 357/1759 [00:07<00:31, 45.12it/s][A
 21%|██        | 362/1759 [00:08<00:31, 44.51it/s][A
 21%|██        | 367/1759 [00:08<00:31, 44.67it/s][A
 21%|██        | 372/1759 [00:08<00:31, 44.68it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 44.86it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 44.96it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 45.13it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 44.99it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 45.06it/s][A
 23%|██▎       | 402/1759 [00:08<00:30, 44.99it/s][A
 23%|██▎       | 407/1759 [00:09<00:30, 44.93it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.06it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.09it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.06it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 45.11it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 45.22it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 45.11it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 45.04it/s][A
 25%|██▌       | 447/1759 [00:09<00:29, 45.01it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 44.84it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 44.98it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.01it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.18it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 45.17it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 45.08it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 45.18it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 45.00it/s][A
 28%|██▊       | 492/1759 [00:10<00:28, 45.03it/s][A
 28%|██▊       | 497/1759 [00:11<00:28, 44.34it/s][A
 29%|██▊       | 502/1759 [00:11<00:28, 44.54it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 44.74it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 44.85it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 45.10it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 45.08it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 45.14it/s][A
 30%|███       | 532/1759 [00:11<00:27, 45.06it/s][A
 31%|███       | 537/1759 [00:11<00:27, 44.78it/s][A
 31%|███       | 542/1759 [00:12<00:27, 44.80it/s][A
 31%|███       | 547/1759 [00:12<00:26, 44.92it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.05it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 45.14it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 45.13it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 45.08it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 45.04it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 45.00it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 44.89it/s][A
 33%|███▎      | 587/1759 [00:13<00:26, 44.89it/s][A
 34%|███▎      | 592/1759 [00:13<00:26, 44.80it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.00it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 45.11it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 45.24it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 45.17it/s][A
 35%|███▌      | 617/1759 [00:13<00:25, 45.18it/s][A
 35%|███▌      | 622/1759 [00:13<00:25, 44.97it/s][A
 36%|███▌      | 627/1759 [00:13<00:25, 45.00it/s][A
 36%|███▌      | 632/1759 [00:14<00:25, 44.96it/s][A
 36%|███▌      | 637/1759 [00:14<00:25, 44.86it/s][A
 36%|███▋      | 642/1759 [00:14<00:24, 44.96it/s][A
 37%|███▋      | 647/1759 [00:14<00:24, 45.01it/s][A
 37%|███▋      | 652/1759 [00:14<00:24, 45.08it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 45.19it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 45.14it/s][A
 38%|███▊      | 667/1759 [00:14<00:24, 45.06it/s][A
 38%|███▊      | 672/1759 [00:14<00:24, 45.08it/s][A
 38%|███▊      | 677/1759 [00:15<00:24, 44.90it/s][A
 39%|███▉      | 682/1759 [00:15<00:23, 44.94it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 45.01it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 45.05it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 45.11it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 45.20it/s][A
 40%|████      | 707/1759 [00:15<00:23, 45.06it/s][A
 40%|████      | 712/1759 [00:15<00:23, 45.04it/s][A
 41%|████      | 717/1759 [00:15<00:23, 44.98it/s][A
 41%|████      | 722/1759 [00:16<00:23, 44.88it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 44.96it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 44.96it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 45.07it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 45.20it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 45.15it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 45.14it/s][A
 43%|████▎     | 757/1759 [00:16<00:22, 45.13it/s][A
 43%|████▎     | 762/1759 [00:16<00:23, 42.98it/s][A
 44%|████▎     | 767/1759 [00:17<00:22, 43.67it/s][A
 44%|████▍     | 772/1759 [00:17<00:22, 44.15it/s][A
 44%|████▍     | 777/1759 [00:17<00:22, 44.50it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 44.79it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 44.90it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 44.87it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 44.94it/s][A
 46%|████▌     | 802/1759 [00:17<00:21, 44.70it/s][A
 46%|████▌     | 807/1759 [00:17<00:21, 44.71it/s][A
 46%|████▌     | 812/1759 [00:18<00:21, 44.75it/s][A
 46%|████▋     | 817/1759 [00:18<00:21, 44.84it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 44.80it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 45.05it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 45.15it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 45.17it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 44.98it/s][A
 48%|████▊     | 847/1759 [00:18<00:20, 44.93it/s][A
 48%|████▊     | 852/1759 [00:18<00:20, 44.81it/s][A
 49%|████▊     | 857/1759 [00:19<00:20, 44.86it/s][A
 49%|████▉     | 862/1759 [00:19<00:19, 44.99it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 45.12it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 45.19it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 45.24it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 45.15it/s][A
 50%|█████     | 887/1759 [00:19<00:19, 45.01it/s][A
 51%|█████     | 892/1759 [00:19<00:19, 44.93it/s][A
 51%|█████     | 897/1759 [00:19<00:21, 40.23it/s][A
 51%|█████▏    | 902/1759 [00:20<00:20, 41.65it/s][A
 52%|█████▏    | 907/1759 [00:20<00:19, 42.75it/s][A
 52%|█████▏    | 912/1759 [00:20<00:19, 43.60it/s][A
 52%|█████▏    | 917/1759 [00:20<00:19, 44.18it/s][A
 52%|█████▏    | 922/1759 [00:20<00:18, 44.60it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 44.81it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 44.72it/s][A
 53%|█████▎    | 937/1759 [00:20<00:18, 44.52it/s][A
 54%|█████▎    | 942/1759 [00:20<00:18, 44.43it/s][A
 54%|█████▍    | 947/1759 [00:21<00:18, 44.50it/s][A
 54%|█████▍    | 952/1759 [00:21<00:18, 44.80it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 45.10it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 45.23it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 45.28it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 45.37it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 45.05it/s][A
 56%|█████▌    | 982/1759 [00:21<00:17, 44.84it/s][A
 56%|█████▌    | 987/1759 [00:21<00:17, 44.72it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 44.63it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 44.83it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 45.06it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.16it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 45.36it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 45.27it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:16, 45.12it/s][A
 58%|█████▊    | 1027/1759 [00:22<00:16, 44.85it/s][A
 59%|█████▊    | 1032/1759 [00:22<00:17, 41.20it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:17, 42.43it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:16, 43.24it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:16, 43.89it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:15, 44.36it/s][A
 60%|██████    | 1057/1759 [00:23<00:15, 44.71it/s][A
 60%|██████    | 1062/1759 [00:23<00:15, 44.85it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 44.91it/s][A
 61%|██████    | 1072/1759 [00:23<00:15, 44.53it/s][A
 61%|██████    | 1077/1759 [00:23<00:15, 44.58it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:15, 44.84it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:14, 44.98it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 45.08it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 45.12it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 45.26it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 45.14it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 44.96it/s][A
 64%|██████▎   | 1117/1759 [00:24<00:14, 44.73it/s][A
 64%|██████▍   | 1122/1759 [00:24<00:14, 44.66it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 44.87it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:13, 45.09it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 45.18it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 45.21it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 45.23it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 45.15it/s][A
 66%|██████▌   | 1157/1759 [00:25<00:13, 45.03it/s][A
 66%|██████▌   | 1162/1759 [00:25<00:13, 44.87it/s][A
 66%|██████▋   | 1167/1759 [00:25<00:13, 44.72it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 44.75it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:12, 44.89it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:12, 44.96it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 45.12it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:12, 45.18it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 45.19it/s][A
 68%|██████▊   | 1202/1759 [00:26<00:12, 45.13it/s][A
 69%|██████▊   | 1207/1759 [00:26<00:12, 44.84it/s][A
 69%|██████▉   | 1212/1759 [00:26<00:12, 44.75it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 44.77it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:12, 43.23it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:12, 43.92it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 44.41it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 44.67it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 44.97it/s][A
 71%|███████   | 1247/1759 [00:27<00:11, 44.81it/s][A
 71%|███████   | 1252/1759 [00:27<00:11, 44.64it/s][A
 71%|███████▏  | 1257/1759 [00:27<00:11, 44.67it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:11, 44.48it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:11, 44.70it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 44.93it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 45.11it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 45.26it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 45.25it/s][A
 73%|███████▎  | 1292/1759 [00:28<00:10, 45.24it/s][A
 74%|███████▎  | 1297/1759 [00:28<00:10, 45.07it/s][A
 74%|███████▍  | 1302/1759 [00:28<00:10, 44.97it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 44.86it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:09, 44.81it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:09, 44.93it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 45.02it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 45.18it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 45.29it/s][A
 76%|███████▌  | 1337/1759 [00:29<00:09, 45.24it/s][A
 76%|███████▋  | 1342/1759 [00:29<00:09, 45.07it/s][A
 77%|███████▋  | 1347/1759 [00:29<00:09, 44.92it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 44.87it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:09, 40.67it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:09, 42.07it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:09, 39.42it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:09, 41.12it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:09, 42.32it/s][A
 79%|███████▊  | 1382/1759 [00:30<00:08, 43.19it/s][A
 79%|███████▉  | 1387/1759 [00:30<00:08, 43.83it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 44.27it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 44.34it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:08, 44.60it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 44.62it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 44.53it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 44.78it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 44.96it/s][A
 81%|████████  | 1427/1759 [00:31<00:07, 45.01it/s][A
 81%|████████▏ | 1432/1759 [00:31<00:07, 45.07it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 45.05it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 45.02it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 45.09it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 44.92it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 44.83it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 44.98it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 44.99it/s][A
 84%|████████▎ | 1472/1759 [00:32<00:06, 45.09it/s][A
 84%|████████▍ | 1477/1759 [00:32<00:06, 45.10it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 44.96it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 44.90it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:06, 43.93it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 44.12it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 44.37it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 44.51it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 44.63it/s][A
 86%|████████▌ | 1517/1759 [00:33<00:05, 44.84it/s][A
 87%|████████▋ | 1522/1759 [00:33<00:05, 44.96it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 44.99it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 44.87it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 44.91it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 44.91it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 44.86it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 44.90it/s][A
 89%|████████▊ | 1557/1759 [00:34<00:04, 44.97it/s][A
 89%|████████▉ | 1562/1759 [00:34<00:04, 45.07it/s][A
 89%|████████▉ | 1567/1759 [00:34<00:04, 45.16it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 45.20it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 45.02it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 44.99it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 44.93it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 44.87it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 44.91it/s][A
 91%|█████████ | 1602/1759 [00:35<00:03, 44.95it/s][A
 91%|█████████▏| 1607/1759 [00:35<00:03, 45.07it/s][A
 92%|█████████▏| 1612/1759 [00:35<00:03, 45.21it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 45.10it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 45.10it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 44.42it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 44.59it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 44.72it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 44.80it/s][A
 94%|█████████▎| 1647/1759 [00:36<00:02, 44.72it/s][A
 94%|█████████▍| 1652/1759 [00:36<00:02, 44.95it/s][A
 94%|█████████▍| 1657/1759 [00:36<00:02, 45.07it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 45.19it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 45.05it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 44.91it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 44.90it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 44.98it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 44.84it/s][A
 96%|█████████▌| 1692/1759 [00:37<00:01, 44.90it/s][A
 96%|█████████▋| 1697/1759 [00:37<00:01, 44.93it/s][A
 97%|█████████▋| 1702/1759 [00:37<00:01, 44.90it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 45.12it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 45.05it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 44.97it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 44.99it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 44.87it/s][A
 98%|█████████▊| 1732/1759 [00:38<00:00, 45.00it/s][A
 99%|█████████▊| 1737/1759 [00:38<00:00, 44.95it/s][A
 99%|█████████▉| 1742/1759 [00:38<00:00, 44.95it/s][A
 99%|█████████▉| 1747/1759 [00:38<00:00, 45.03it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 44.95it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 45.08it/s][A                                               
                                                   [A 40%|████      | 32/80 [01:38<00:17,  2.73it/s]
100%|██████████| 1759/1759 [00:39<00:00, 45.08it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 08:23:35,865 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-32
[INFO|configuration_utils.py:351] 2023-08-29 08:23:36,008 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-32/config.json
[INFO|modeling_utils.py:886] 2023-08-29 08:23:39,239 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-32/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 08:23:39,434 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-32/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 08:23:39,545 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-32/special_tokens_map.json
 41%|████▏     | 33/80 [01:48<11:50, 15.12s/it] 42%|████▎     | 34/80 [01:48<08:11, 10.68s/it] 44%|████▍     | 35/80 [01:49<05:43,  7.63s/it] 45%|████▌     | 36/80 [01:49<03:58,  5.43s/it] 46%|████▋     | 37/80 [01:49<02:47,  3.89s/it] 48%|████▊     | 38/80 [01:49<01:57,  2.81s/it] 49%|████▉     | 39/80 [01:50<01:24,  2.05s/it] 50%|█████     | 40/80 [01:50<01:01,  1.53s/it] 51%|█████▏    | 41/80 [01:50<00:45,  1.16s/it] 52%|█████▎    | 42/80 [01:51<00:34,  1.11it/s] 54%|█████▍    | 43/80 [01:51<00:26,  1.40it/s] 55%|█████▌    | 44/80 [01:51<00:21,  1.68it/s] 56%|█████▋    | 45/80 [01:52<00:17,  1.98it/s] 57%|█████▊    | 46/80 [01:52<00:15,  2.27it/s] 59%|█████▉    | 47/80 [01:52<00:13,  2.52it/s] 60%|██████    | 48/80 [01:52<00:11,  2.74it/s][INFO|trainer.py:2140] 2023-08-29 08:23:50,618 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 08:23:50,618 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 08:23:50,618 >>   Batch size = 8
{'eval_loss': 0.8763248324394226, 'eval_runtime': 39.2846, 'eval_samples_per_second': 358.079, 'eval_steps_per_second': 44.776, 'epoch': 1.97}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:30, 56.85it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.30it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.15it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.24it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 45.70it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 45.56it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 45.32it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 45.18it/s][A
  3%|▎         | 47/1759 [00:01<00:37, 45.28it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.37it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.48it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.39it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.22it/s][A
  4%|▍         | 72/1759 [00:01<00:38, 44.05it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 44.32it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 44.67it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.77it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.90it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 44.98it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.25it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.26it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 44.98it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.03it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 44.97it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 45.06it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 45.07it/s][A
  8%|▊         | 137/1759 [00:03<00:35, 45.16it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.21it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.28it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.17it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.14it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 44.90it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 44.98it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 44.97it/s][A
 10%|█         | 177/1759 [00:03<00:35, 45.00it/s][A
 10%|█         | 182/1759 [00:04<00:34, 45.11it/s][A
 11%|█         | 187/1759 [00:04<00:34, 45.36it/s][A
 11%|█         | 192/1759 [00:04<00:34, 45.28it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.28it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 45.11it/s][A
 12%|█▏        | 207/1759 [00:04<00:35, 44.06it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 44.43it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 44.57it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 44.69it/s][A
 13%|█▎        | 227/1759 [00:05<00:34, 44.91it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 44.92it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.13it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.16it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.15it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 45.11it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 45.20it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 45.07it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 45.09it/s][A
 15%|█▌        | 272/1759 [00:06<00:32, 45.11it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.10it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.15it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.14it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.13it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 45.02it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 45.13it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 45.04it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 45.08it/s][A
 18%|█▊        | 317/1759 [00:07<00:31, 45.08it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 45.10it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.13it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 45.09it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 45.13it/s][A
 19%|█▉        | 342/1759 [00:07<00:32, 43.69it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 44.21it/s][A
 20%|██        | 352/1759 [00:07<00:31, 44.54it/s][A
 20%|██        | 357/1759 [00:07<00:31, 44.65it/s][A
 21%|██        | 362/1759 [00:08<00:31, 44.82it/s][A
 21%|██        | 367/1759 [00:08<00:30, 44.94it/s][A
 21%|██        | 372/1759 [00:08<00:30, 44.90it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.00it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 44.81it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 44.86it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 45.03it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 45.07it/s][A
 23%|██▎       | 402/1759 [00:08<00:30, 45.15it/s][A
 23%|██▎       | 407/1759 [00:09<00:29, 45.10it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.19it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.19it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.18it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 44.99it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 44.84it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 44.88it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 45.18it/s][A
 25%|██▌       | 447/1759 [00:09<00:28, 45.25it/s][A
 26%|██▌       | 452/1759 [00:10<00:28, 45.21it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 45.17it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.19it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.08it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 44.99it/s][A
 27%|██▋       | 477/1759 [00:10<00:29, 44.01it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 44.35it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 44.74it/s][A
 28%|██▊       | 492/1759 [00:10<00:28, 44.83it/s][A
 28%|██▊       | 497/1759 [00:11<00:28, 45.00it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.10it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 45.10it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 44.95it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 44.81it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 44.78it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 44.99it/s][A
 30%|███       | 532/1759 [00:11<00:27, 45.07it/s][A
 31%|███       | 537/1759 [00:11<00:27, 45.15it/s][A
 31%|███       | 542/1759 [00:12<00:26, 45.20it/s][A
 31%|███       | 547/1759 [00:12<00:26, 45.18it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.16it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 45.09it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 44.88it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 44.85it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 44.92it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 45.10it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 45.12it/s][A
 33%|███▎      | 587/1759 [00:13<00:25, 45.26it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.18it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.13it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 45.08it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 44.87it/s][A
 35%|███▍      | 612/1759 [00:13<00:26, 43.22it/s][A
 35%|███▌      | 617/1759 [00:13<00:26, 43.88it/s][A
 35%|███▌      | 622/1759 [00:13<00:25, 44.33it/s][A
 36%|███▌      | 627/1759 [00:13<00:25, 44.65it/s][A
 36%|███▌      | 632/1759 [00:14<00:25, 44.91it/s][A
 36%|███▌      | 637/1759 [00:14<00:24, 44.93it/s][A
 36%|███▋      | 642/1759 [00:14<00:24, 45.11it/s][A
 37%|███▋      | 647/1759 [00:14<00:24, 45.00it/s][A
 37%|███▋      | 652/1759 [00:14<00:24, 44.74it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 44.81it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 44.98it/s][A
 38%|███▊      | 667/1759 [00:14<00:24, 45.06it/s][A
 38%|███▊      | 672/1759 [00:14<00:24, 45.14it/s][A
 38%|███▊      | 677/1759 [00:15<00:23, 45.25it/s][A
 39%|███▉      | 682/1759 [00:15<00:23, 45.30it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 45.29it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 45.18it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 44.94it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 44.96it/s][A
 40%|████      | 707/1759 [00:15<00:23, 45.04it/s][A
 40%|████      | 712/1759 [00:15<00:23, 45.14it/s][A
 41%|████      | 717/1759 [00:15<00:23, 45.21it/s][A
 41%|████      | 722/1759 [00:16<00:22, 45.18it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 45.13it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 45.12it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 45.05it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 44.93it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 44.84it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 45.01it/s][A
 43%|████▎     | 757/1759 [00:16<00:22, 45.14it/s][A
 43%|████▎     | 762/1759 [00:16<00:22, 45.12it/s][A
 44%|████▎     | 767/1759 [00:17<00:21, 45.16it/s][A
 44%|████▍     | 772/1759 [00:17<00:21, 45.21it/s][A
 44%|████▍     | 777/1759 [00:17<00:21, 45.19it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 45.08it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 45.02it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 44.88it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 44.90it/s][A
 46%|████▌     | 802/1759 [00:17<00:21, 45.03it/s][A
 46%|████▌     | 807/1759 [00:17<00:21, 45.18it/s][A
 46%|████▌     | 812/1759 [00:18<00:20, 45.16it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 45.16it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 45.08it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 45.07it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 44.91it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 44.68it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 44.91it/s][A
 48%|████▊     | 847/1759 [00:18<00:20, 45.08it/s][A
 48%|████▊     | 852/1759 [00:18<00:20, 45.18it/s][A
 49%|████▊     | 857/1759 [00:19<00:20, 44.23it/s][A
 49%|████▉     | 862/1759 [00:19<00:20, 44.60it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 44.71it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 44.66it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 44.70it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 44.73it/s][A
 50%|█████     | 887/1759 [00:19<00:19, 44.76it/s][A
 51%|█████     | 892/1759 [00:19<00:19, 45.02it/s][A
 51%|█████     | 897/1759 [00:19<00:19, 44.91it/s][A
 51%|█████▏    | 902/1759 [00:20<00:19, 44.99it/s][A
 52%|█████▏    | 907/1759 [00:20<00:18, 45.15it/s][A
 52%|█████▏    | 912/1759 [00:20<00:18, 45.26it/s][A
 52%|█████▏    | 917/1759 [00:20<00:18, 45.05it/s][A
 52%|█████▏    | 922/1759 [00:20<00:18, 44.97it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 44.84it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 44.86it/s][A
 53%|█████▎    | 937/1759 [00:20<00:18, 44.98it/s][A
 54%|█████▎    | 942/1759 [00:20<00:18, 45.04it/s][A
 54%|█████▍    | 947/1759 [00:21<00:17, 45.13it/s][A
 54%|█████▍    | 952/1759 [00:21<00:17, 45.20it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 45.12it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 45.02it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 44.95it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 44.91it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 44.97it/s][A
 56%|█████▌    | 982/1759 [00:21<00:17, 44.92it/s][A
 56%|█████▌    | 987/1759 [00:21<00:17, 45.05it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 45.11it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 45.23it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 45.23it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.01it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 44.85it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 44.84it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:16, 44.94it/s][A
 58%|█████▊    | 1027/1759 [00:22<00:16, 45.07it/s][A
 59%|█████▊    | 1032/1759 [00:22<00:16, 45.08it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:15, 45.22it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:15, 45.21it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:15, 45.30it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:15, 45.10it/s][A
 60%|██████    | 1057/1759 [00:23<00:15, 45.01it/s][A
 60%|██████    | 1062/1759 [00:23<00:15, 44.99it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 44.87it/s][A
 61%|██████    | 1072/1759 [00:23<00:15, 44.93it/s][A
 61%|██████    | 1077/1759 [00:23<00:15, 45.03it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:14, 45.15it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:15, 44.51it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 44.71it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 44.74it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 44.83it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 44.88it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 44.86it/s][A
 64%|██████▎   | 1117/1759 [00:24<00:14, 45.05it/s][A
 64%|██████▍   | 1122/1759 [00:24<00:14, 45.01it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 45.00it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:13, 45.03it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 45.10it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 44.89it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 44.80it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 44.78it/s][A
 66%|██████▌   | 1157/1759 [00:25<00:13, 44.94it/s][A
 66%|██████▌   | 1162/1759 [00:25<00:13, 44.96it/s][A
 66%|██████▋   | 1167/1759 [00:25<00:13, 44.89it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 44.96it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:12, 45.13it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:14, 40.86it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:13, 42.14it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:13, 43.14it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 43.77it/s][A
 68%|██████▊   | 1202/1759 [00:26<00:12, 44.24it/s][A
 69%|██████▊   | 1207/1759 [00:26<00:12, 44.52it/s][A
 69%|██████▉   | 1212/1759 [00:26<00:12, 44.62it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 44.69it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:12, 44.49it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 44.46it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 44.68it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 44.84it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 44.92it/s][A
 71%|███████   | 1247/1759 [00:27<00:11, 45.22it/s][A
 71%|███████   | 1252/1759 [00:27<00:11, 45.10it/s][A
 71%|███████▏  | 1257/1759 [00:27<00:11, 45.25it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:10, 45.20it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:10, 44.99it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 44.89it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 44.76it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 44.87it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 45.08it/s][A
 73%|███████▎  | 1292/1759 [00:28<00:10, 45.18it/s][A
 74%|███████▎  | 1297/1759 [00:28<00:10, 45.17it/s][A
 74%|███████▍  | 1302/1759 [00:28<00:10, 45.10it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 45.03it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:09, 44.94it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:10, 42.68it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:10, 43.22it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 43.92it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 44.35it/s][A
 76%|███████▌  | 1337/1759 [00:29<00:09, 44.70it/s][A
 76%|███████▋  | 1342/1759 [00:29<00:09, 44.85it/s][A
 77%|███████▋  | 1347/1759 [00:29<00:09, 44.90it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 44.77it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:09, 44.65it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 44.75it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 44.86it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:08, 45.05it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:08, 45.12it/s][A
 79%|███████▊  | 1382/1759 [00:30<00:08, 45.17it/s][A
 79%|███████▉  | 1387/1759 [00:30<00:08, 45.17it/s][A
 79%|███████▉  | 1392/1759 [00:30<00:08, 45.21it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 44.98it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:07, 44.85it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 44.71it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 44.73it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 45.03it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 45.06it/s][A
 81%|████████  | 1427/1759 [00:31<00:07, 45.26it/s][A
 81%|████████▏ | 1432/1759 [00:31<00:07, 45.23it/s][A
 82%|████████▏ | 1437/1759 [00:31<00:07, 45.18it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 45.00it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 44.81it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 44.79it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 44.81it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 44.93it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 44.99it/s][A
 84%|████████▎ | 1472/1759 [00:32<00:06, 45.19it/s][A
 84%|████████▍ | 1477/1759 [00:32<00:06, 45.18it/s][A
 84%|████████▍ | 1482/1759 [00:32<00:06, 45.23it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 45.02it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 44.86it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 44.80it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 44.72it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 44.77it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 44.92it/s][A
 86%|████████▌ | 1517/1759 [00:33<00:05, 45.08it/s][A
 87%|████████▋ | 1522/1759 [00:33<00:05, 45.16it/s][A
 87%|████████▋ | 1527/1759 [00:33<00:05, 45.12it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 45.04it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 44.81it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 44.84it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:05, 42.22it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 43.27it/s][A
 89%|████████▊ | 1557/1759 [00:34<00:04, 43.90it/s][A
 89%|████████▉ | 1562/1759 [00:34<00:04, 44.41it/s][A
 89%|████████▉ | 1567/1759 [00:34<00:04, 44.64it/s][A
 89%|████████▉ | 1572/1759 [00:34<00:04, 44.86it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 44.72it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 44.72it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 44.50it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 44.57it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 44.90it/s][A
 91%|█████████ | 1602/1759 [00:35<00:03, 44.92it/s][A
 91%|█████████▏| 1607/1759 [00:35<00:03, 45.08it/s][A
 92%|█████████▏| 1612/1759 [00:35<00:03, 45.19it/s][A
 92%|█████████▏| 1617/1759 [00:35<00:03, 45.18it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 45.20it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 44.99it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 44.87it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 44.84it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 44.91it/s][A
 94%|█████████▎| 1647/1759 [00:36<00:02, 45.00it/s][A
 94%|█████████▍| 1652/1759 [00:36<00:02, 45.11it/s][A
 94%|█████████▍| 1657/1759 [00:36<00:02, 45.22it/s][A
 94%|█████████▍| 1662/1759 [00:36<00:02, 45.12it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 45.09it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 44.92it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 44.86it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 44.77it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 44.88it/s][A
 96%|█████████▌| 1692/1759 [00:37<00:01, 44.98it/s][A
 96%|█████████▋| 1697/1759 [00:37<00:01, 45.11it/s][A
 97%|█████████▋| 1702/1759 [00:37<00:01, 45.24it/s][A
 97%|█████████▋| 1707/1759 [00:37<00:01, 45.17it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 45.07it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 44.97it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 44.92it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 44.84it/s][A
 98%|█████████▊| 1732/1759 [00:38<00:00, 44.86it/s][A
 99%|█████████▊| 1737/1759 [00:38<00:00, 45.00it/s][A
 99%|█████████▉| 1742/1759 [00:38<00:00, 45.09it/s][A
 99%|█████████▉| 1747/1759 [00:38<00:00, 45.16it/s][A
100%|█████████▉| 1752/1759 [00:38<00:00, 45.31it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 45.23it/s][A                                               
                                                   [A 60%|██████    | 48/80 [02:32<00:11,  2.74it/s]
100%|██████████| 1759/1759 [00:39<00:00, 45.23it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 08:24:29,876 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-48
[INFO|configuration_utils.py:351] 2023-08-29 08:24:29,991 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-48/config.json
[INFO|modeling_utils.py:886] 2023-08-29 08:24:32,983 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-48/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 08:24:33,085 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-48/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 08:24:33,130 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-48/special_tokens_map.json
 61%|██████▏   | 49/80 [02:41<07:41, 14.88s/it] 62%|██████▎   | 50/80 [02:41<05:15, 10.51s/it] 64%|██████▍   | 51/80 [02:42<03:35,  7.45s/it] 65%|██████▌   | 52/80 [02:42<02:28,  5.30s/it] 66%|██████▋   | 53/80 [02:42<01:42,  3.80s/it] 68%|██████▊   | 54/80 [02:43<01:11,  2.75s/it] 69%|██████▉   | 55/80 [02:43<00:50,  2.01s/it] 70%|███████   | 56/80 [02:43<00:35,  1.50s/it] 71%|███████▏  | 57/80 [02:44<00:26,  1.14s/it] 72%|███████▎  | 58/80 [02:44<00:19,  1.13it/s] 74%|███████▍  | 59/80 [02:44<00:14,  1.42it/s] 75%|███████▌  | 60/80 [02:44<00:11,  1.72it/s] 76%|███████▋  | 61/80 [02:45<00:09,  1.99it/s] 78%|███████▊  | 62/80 [02:45<00:07,  2.27it/s] 79%|███████▉  | 63/80 [02:45<00:06,  2.53it/s] 80%|████████  | 64/80 [02:46<00:05,  2.74it/s][INFO|trainer.py:2140] 2023-08-29 08:24:43,821 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 08:24:43,821 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 08:24:43,821 >>   Batch size = 8
{'eval_loss': 0.8785508275032043, 'eval_runtime': 39.1858, 'eval_samples_per_second': 358.982, 'eval_steps_per_second': 44.889, 'epoch': 2.97}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.31it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.22it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.46it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.75it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 46.10it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 45.55it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 45.27it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 45.02it/s][A
  3%|▎         | 47/1759 [00:01<00:37, 45.06it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.26it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.36it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.40it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.51it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.17it/s][A
  4%|▍         | 77/1759 [00:01<00:38, 43.89it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 44.57it/s][A
  5%|▍         | 87/1759 [00:01<00:38, 43.12it/s][A
  5%|▌         | 92/1759 [00:02<00:38, 43.84it/s][A
  6%|▌         | 97/1759 [00:02<00:37, 44.17it/s][A
  6%|▌         | 102/1759 [00:02<00:37, 44.65it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 44.85it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.04it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 44.94it/s][A
  7%|▋         | 122/1759 [00:02<00:48, 33.45it/s][A
  7%|▋         | 126/1759 [00:02<00:49, 33.06it/s][A
  7%|▋         | 131/1759 [00:03<00:45, 36.16it/s][A
  8%|▊         | 136/1759 [00:03<00:41, 38.70it/s][A
  8%|▊         | 141/1759 [00:03<00:39, 40.57it/s][A
  8%|▊         | 146/1759 [00:03<00:38, 41.97it/s][A
  9%|▊         | 151/1759 [00:03<00:37, 43.03it/s][A
  9%|▉         | 156/1759 [00:03<00:36, 43.73it/s][A
  9%|▉         | 161/1759 [00:03<00:36, 44.26it/s][A
  9%|▉         | 166/1759 [00:03<00:36, 44.22it/s][A
 10%|▉         | 171/1759 [00:03<00:35, 44.17it/s][A
 10%|█         | 176/1759 [00:04<00:35, 44.35it/s][A
 10%|█         | 181/1759 [00:04<00:35, 44.64it/s][A
 11%|█         | 186/1759 [00:04<00:35, 44.83it/s][A
 11%|█         | 191/1759 [00:04<00:34, 45.08it/s][A
 11%|█         | 196/1759 [00:04<00:34, 45.19it/s][A
 11%|█▏        | 201/1759 [00:04<00:34, 45.40it/s][A
 12%|█▏        | 206/1759 [00:04<00:34, 45.34it/s][A
 12%|█▏        | 211/1759 [00:04<00:34, 44.97it/s][A
 12%|█▏        | 216/1759 [00:04<00:35, 43.88it/s][A
 13%|█▎        | 221/1759 [00:05<00:34, 44.12it/s][A
 13%|█▎        | 226/1759 [00:05<00:34, 44.49it/s][A
 13%|█▎        | 231/1759 [00:05<00:34, 44.69it/s][A
 13%|█▎        | 236/1759 [00:05<00:33, 44.89it/s][A
 14%|█▎        | 241/1759 [00:05<00:33, 45.02it/s][A
 14%|█▍        | 246/1759 [00:05<00:33, 45.25it/s][A
 14%|█▍        | 251/1759 [00:05<00:33, 45.23it/s][A
 15%|█▍        | 256/1759 [00:05<00:33, 45.01it/s][A
 15%|█▍        | 261/1759 [00:05<00:33, 44.81it/s][A
 15%|█▌        | 266/1759 [00:06<00:33, 44.84it/s][A
 15%|█▌        | 271/1759 [00:06<00:33, 44.86it/s][A
 16%|█▌        | 276/1759 [00:06<00:32, 44.99it/s][A
 16%|█▌        | 281/1759 [00:06<00:32, 45.16it/s][A
 16%|█▋        | 286/1759 [00:06<00:32, 45.23it/s][A
 17%|█▋        | 291/1759 [00:06<00:32, 45.27it/s][A
 17%|█▋        | 296/1759 [00:06<00:32, 45.25it/s][A
 17%|█▋        | 301/1759 [00:06<00:32, 45.03it/s][A
 17%|█▋        | 306/1759 [00:06<00:32, 44.90it/s][A
 18%|█▊        | 311/1759 [00:07<00:32, 44.83it/s][A
 18%|█▊        | 316/1759 [00:07<00:32, 44.93it/s][A
 18%|█▊        | 321/1759 [00:07<00:31, 45.08it/s][A
 19%|█▊        | 326/1759 [00:07<00:31, 45.17it/s][A
 19%|█▉        | 331/1759 [00:07<00:31, 45.19it/s][A
 19%|█▉        | 336/1759 [00:07<00:31, 45.31it/s][A
 19%|█▉        | 341/1759 [00:07<00:31, 45.28it/s][A
 20%|█▉        | 346/1759 [00:07<00:31, 45.15it/s][A
 20%|█▉        | 351/1759 [00:07<00:31, 44.11it/s][A
 20%|██        | 356/1759 [00:08<00:31, 44.24it/s][A
 21%|██        | 361/1759 [00:08<00:31, 44.48it/s][A
 21%|██        | 366/1759 [00:08<00:31, 44.84it/s][A
 21%|██        | 371/1759 [00:08<00:30, 44.87it/s][A
 21%|██▏       | 376/1759 [00:08<00:30, 45.14it/s][A
 22%|██▏       | 381/1759 [00:08<00:30, 45.23it/s][A
 22%|██▏       | 386/1759 [00:08<00:30, 45.17it/s][A
 22%|██▏       | 391/1759 [00:08<00:30, 45.03it/s][A
 23%|██▎       | 396/1759 [00:08<00:30, 44.97it/s][A
 23%|██▎       | 401/1759 [00:09<00:30, 44.91it/s][A
 23%|██▎       | 406/1759 [00:09<00:30, 44.96it/s][A
 23%|██▎       | 411/1759 [00:09<00:29, 45.06it/s][A
 24%|██▎       | 416/1759 [00:09<00:29, 45.10it/s][A
 24%|██▍       | 421/1759 [00:09<00:29, 45.22it/s][A
 24%|██▍       | 426/1759 [00:09<00:29, 45.26it/s][A
 25%|██▍       | 431/1759 [00:09<00:29, 45.26it/s][A
 25%|██▍       | 436/1759 [00:09<00:29, 45.02it/s][A
 25%|██▌       | 441/1759 [00:09<00:29, 44.95it/s][A
 25%|██▌       | 446/1759 [00:10<00:29, 44.97it/s][A
 26%|██▌       | 451/1759 [00:10<00:29, 45.04it/s][A
 26%|██▌       | 456/1759 [00:10<00:28, 45.05it/s][A
 26%|██▌       | 461/1759 [00:10<00:28, 45.04it/s][A
 26%|██▋       | 466/1759 [00:10<00:28, 45.21it/s][A
 27%|██▋       | 471/1759 [00:10<00:28, 45.30it/s][A
 27%|██▋       | 476/1759 [00:10<00:28, 45.11it/s][A
 27%|██▋       | 481/1759 [00:10<00:28, 45.00it/s][A
 28%|██▊       | 486/1759 [00:10<00:29, 42.99it/s][A
 28%|██▊       | 491/1759 [00:11<00:29, 43.62it/s][A
 28%|██▊       | 496/1759 [00:11<00:28, 44.14it/s][A
 28%|██▊       | 501/1759 [00:11<00:28, 44.44it/s][A
 29%|██▉       | 506/1759 [00:11<00:28, 44.73it/s][A
 29%|██▉       | 511/1759 [00:11<00:27, 44.79it/s][A
 29%|██▉       | 516/1759 [00:11<00:27, 44.99it/s][A
 30%|██▉       | 521/1759 [00:11<00:27, 44.95it/s][A
 30%|██▉       | 526/1759 [00:11<00:27, 44.66it/s][A
 30%|███       | 531/1759 [00:11<00:27, 44.73it/s][A
 30%|███       | 536/1759 [00:12<00:27, 44.82it/s][A
 31%|███       | 541/1759 [00:12<00:27, 45.08it/s][A
 31%|███       | 546/1759 [00:12<00:26, 45.17it/s][A
 31%|███▏      | 551/1759 [00:12<00:26, 45.33it/s][A
 32%|███▏      | 556/1759 [00:12<00:26, 45.20it/s][A
 32%|███▏      | 561/1759 [00:12<00:26, 45.22it/s][A
 32%|███▏      | 566/1759 [00:12<00:26, 45.03it/s][A
 32%|███▏      | 571/1759 [00:12<00:26, 44.84it/s][A
 33%|███▎      | 576/1759 [00:12<00:26, 44.87it/s][A
 33%|███▎      | 581/1759 [00:13<00:26, 44.82it/s][A
 33%|███▎      | 586/1759 [00:13<00:26, 44.97it/s][A
 34%|███▎      | 591/1759 [00:13<00:25, 45.00it/s][A
 34%|███▍      | 596/1759 [00:13<00:25, 45.17it/s][A
 34%|███▍      | 601/1759 [00:13<00:25, 45.33it/s][A
 34%|███▍      | 606/1759 [00:13<00:25, 45.26it/s][A
 35%|███▍      | 611/1759 [00:13<00:25, 45.18it/s][A
 35%|███▌      | 616/1759 [00:13<00:25, 45.06it/s][A
 35%|███▌      | 621/1759 [00:13<00:26, 43.17it/s][A
 36%|███▌      | 626/1759 [00:14<00:25, 43.89it/s][A
 36%|███▌      | 631/1759 [00:14<00:25, 44.35it/s][A
 36%|███▌      | 636/1759 [00:14<00:25, 44.57it/s][A
 36%|███▋      | 641/1759 [00:14<00:24, 44.84it/s][A
 37%|███▋      | 646/1759 [00:14<00:24, 44.96it/s][A
 37%|███▋      | 651/1759 [00:14<00:24, 45.05it/s][A
 37%|███▋      | 656/1759 [00:14<00:24, 45.08it/s][A
 38%|███▊      | 661/1759 [00:14<00:24, 44.66it/s][A
 38%|███▊      | 666/1759 [00:14<00:24, 44.65it/s][A
 38%|███▊      | 671/1759 [00:15<00:24, 44.86it/s][A
 38%|███▊      | 676/1759 [00:15<00:24, 45.00it/s][A
 39%|███▊      | 681/1759 [00:15<00:23, 45.20it/s][A
 39%|███▉      | 686/1759 [00:15<00:23, 45.22it/s][A
 39%|███▉      | 691/1759 [00:15<00:23, 45.23it/s][A
 40%|███▉      | 696/1759 [00:15<00:23, 45.28it/s][A
 40%|███▉      | 701/1759 [00:15<00:23, 45.25it/s][A
 40%|████      | 706/1759 [00:15<00:23, 44.99it/s][A
 40%|████      | 711/1759 [00:15<00:23, 44.92it/s][A
 41%|████      | 716/1759 [00:16<00:23, 44.86it/s][A
 41%|████      | 721/1759 [00:16<00:23, 45.01it/s][A
 41%|████▏     | 726/1759 [00:16<00:22, 45.16it/s][A
 42%|████▏     | 731/1759 [00:16<00:22, 45.18it/s][A
 42%|████▏     | 736/1759 [00:16<00:22, 45.19it/s][A
 42%|████▏     | 741/1759 [00:16<00:22, 45.20it/s][A
 42%|████▏     | 746/1759 [00:16<00:22, 45.13it/s][A
 43%|████▎     | 751/1759 [00:16<00:22, 44.97it/s][A
 43%|████▎     | 756/1759 [00:16<00:22, 44.80it/s][A
 43%|████▎     | 761/1759 [00:17<00:22, 43.65it/s][A
 44%|████▎     | 766/1759 [00:17<00:22, 44.21it/s][A
 44%|████▍     | 771/1759 [00:17<00:22, 44.64it/s][A
 44%|████▍     | 776/1759 [00:17<00:21, 44.84it/s][A
 44%|████▍     | 781/1759 [00:17<00:21, 44.94it/s][A
 45%|████▍     | 786/1759 [00:17<00:21, 45.09it/s][A
 45%|████▍     | 791/1759 [00:17<00:21, 45.15it/s][A
 45%|████▌     | 796/1759 [00:17<00:21, 45.16it/s][A
 46%|████▌     | 801/1759 [00:17<00:21, 44.82it/s][A
 46%|████▌     | 806/1759 [00:18<00:21, 44.80it/s][A
 46%|████▌     | 811/1759 [00:18<00:21, 44.90it/s][A
 46%|████▋     | 816/1759 [00:18<00:20, 45.00it/s][A
 47%|████▋     | 821/1759 [00:18<00:20, 45.12it/s][A
 47%|████▋     | 826/1759 [00:18<00:20, 45.17it/s][A
 47%|████▋     | 831/1759 [00:18<00:20, 45.28it/s][A
 48%|████▊     | 836/1759 [00:18<00:20, 45.26it/s][A
 48%|████▊     | 841/1759 [00:18<00:20, 45.16it/s][A
 48%|████▊     | 846/1759 [00:18<00:20, 45.09it/s][A
 48%|████▊     | 851/1759 [00:19<00:20, 44.95it/s][A
 49%|████▊     | 856/1759 [00:19<00:20, 44.94it/s][A
 49%|████▉     | 861/1759 [00:19<00:19, 44.92it/s][A
 49%|████▉     | 866/1759 [00:19<00:19, 44.91it/s][A
 50%|████▉     | 871/1759 [00:19<00:19, 45.03it/s][A
 50%|████▉     | 876/1759 [00:19<00:19, 45.08it/s][A
 50%|█████     | 881/1759 [00:19<00:19, 45.21it/s][A
 50%|█████     | 886/1759 [00:19<00:19, 45.21it/s][A
 51%|█████     | 891/1759 [00:19<00:19, 45.16it/s][A
 51%|█████     | 896/1759 [00:20<00:19, 43.57it/s][A
 51%|█████     | 901/1759 [00:20<00:19, 44.02it/s][A
 52%|█████▏    | 906/1759 [00:20<00:19, 44.38it/s][A
 52%|█████▏    | 911/1759 [00:20<00:18, 44.69it/s][A
 52%|█████▏    | 916/1759 [00:20<00:18, 44.81it/s][A
 52%|█████▏    | 921/1759 [00:20<00:18, 45.05it/s][A
 53%|█████▎    | 926/1759 [00:20<00:18, 45.02it/s][A
 53%|█████▎    | 931/1759 [00:20<00:18, 45.08it/s][A
 53%|█████▎    | 936/1759 [00:20<00:18, 44.81it/s][A
 53%|█████▎    | 941/1759 [00:21<00:18, 44.80it/s][A
 54%|█████▍    | 946/1759 [00:21<00:18, 44.95it/s][A
 54%|█████▍    | 951/1759 [00:21<00:17, 44.89it/s][A
 54%|█████▍    | 956/1759 [00:21<00:17, 45.15it/s][A
 55%|█████▍    | 961/1759 [00:21<00:17, 45.13it/s][A
 55%|█████▍    | 966/1759 [00:21<00:17, 45.06it/s][A
 55%|█████▌    | 971/1759 [00:21<00:17, 45.18it/s][A
 55%|█████▌    | 976/1759 [00:21<00:17, 45.04it/s][A
 56%|█████▌    | 981/1759 [00:21<00:17, 44.94it/s][A
 56%|█████▌    | 986/1759 [00:22<00:17, 44.84it/s][A
 56%|█████▋    | 991/1759 [00:22<00:17, 44.94it/s][A
 57%|█████▋    | 996/1759 [00:22<00:16, 44.95it/s][A
 57%|█████▋    | 1001/1759 [00:22<00:16, 45.19it/s][A
 57%|█████▋    | 1006/1759 [00:22<00:16, 45.16it/s][A
 57%|█████▋    | 1011/1759 [00:22<00:16, 45.22it/s][A
 58%|█████▊    | 1016/1759 [00:22<00:16, 45.14it/s][A
 58%|█████▊    | 1021/1759 [00:22<00:16, 45.03it/s][A
 58%|█████▊    | 1026/1759 [00:23<00:16, 44.84it/s][A
 59%|█████▊    | 1031/1759 [00:23<00:17, 42.18it/s][A
 59%|█████▉    | 1036/1759 [00:23<00:16, 43.21it/s][A
 59%|█████▉    | 1041/1759 [00:23<00:16, 43.89it/s][A
 59%|█████▉    | 1046/1759 [00:23<00:16, 44.45it/s][A
 60%|█████▉    | 1051/1759 [00:23<00:15, 44.77it/s][A
 60%|██████    | 1056/1759 [00:23<00:15, 44.74it/s][A
 60%|██████    | 1061/1759 [00:23<00:15, 44.80it/s][A
 61%|██████    | 1066/1759 [00:23<00:15, 44.91it/s][A
 61%|██████    | 1071/1759 [00:23<00:15, 44.66it/s][A
 61%|██████    | 1076/1759 [00:24<00:15, 44.56it/s][A
 61%|██████▏   | 1081/1759 [00:24<00:15, 44.70it/s][A
 62%|██████▏   | 1086/1759 [00:24<00:15, 44.82it/s][A
 62%|██████▏   | 1091/1759 [00:24<00:14, 44.96it/s][A
 62%|██████▏   | 1096/1759 [00:24<00:14, 45.13it/s][A
 63%|██████▎   | 1101/1759 [00:24<00:14, 45.32it/s][A
 63%|██████▎   | 1106/1759 [00:24<00:14, 45.22it/s][A
 63%|██████▎   | 1111/1759 [00:24<00:14, 45.10it/s][A
 63%|██████▎   | 1116/1759 [00:24<00:14, 44.92it/s][A
 64%|██████▎   | 1121/1759 [00:25<00:14, 44.60it/s][A
 64%|██████▍   | 1126/1759 [00:25<00:14, 44.78it/s][A
 64%|██████▍   | 1131/1759 [00:25<00:14, 44.81it/s][A
 65%|██████▍   | 1136/1759 [00:25<00:13, 45.11it/s][A
 65%|██████▍   | 1141/1759 [00:25<00:13, 45.27it/s][A
 65%|██████▌   | 1146/1759 [00:25<00:13, 45.26it/s][A
 65%|██████▌   | 1151/1759 [00:25<00:13, 45.16it/s][A
 66%|██████▌   | 1156/1759 [00:25<00:13, 45.21it/s][A
 66%|██████▌   | 1161/1759 [00:25<00:13, 44.90it/s][A
 66%|██████▋   | 1166/1759 [00:26<00:13, 44.72it/s][A
 67%|██████▋   | 1171/1759 [00:26<00:13, 44.65it/s][A
 67%|██████▋   | 1176/1759 [00:26<00:13, 44.83it/s][A
 67%|██████▋   | 1181/1759 [00:26<00:12, 44.87it/s][A
 67%|██████▋   | 1186/1759 [00:26<00:12, 45.05it/s][A
 68%|██████▊   | 1191/1759 [00:26<00:12, 45.21it/s][A
 68%|██████▊   | 1196/1759 [00:26<00:12, 45.38it/s][A
 68%|██████▊   | 1201/1759 [00:26<00:12, 45.28it/s][A
 69%|██████▊   | 1206/1759 [00:26<00:12, 44.98it/s][A
 69%|██████▉   | 1211/1759 [00:27<00:12, 44.69it/s][A
 69%|██████▉   | 1216/1759 [00:27<00:12, 44.73it/s][A
 69%|██████▉   | 1221/1759 [00:27<00:12, 44.29it/s][A
 70%|██████▉   | 1226/1759 [00:27<00:11, 44.66it/s][A
 70%|██████▉   | 1231/1759 [00:27<00:11, 44.92it/s][A
 70%|███████   | 1236/1759 [00:27<00:11, 45.03it/s][A
 71%|███████   | 1241/1759 [00:27<00:11, 45.07it/s][A
 71%|███████   | 1246/1759 [00:27<00:11, 44.98it/s][A
 71%|███████   | 1251/1759 [00:28<00:11, 44.90it/s][A
 71%|███████▏  | 1256/1759 [00:28<00:11, 44.72it/s][A
 72%|███████▏  | 1261/1759 [00:28<00:11, 44.67it/s][A
 72%|███████▏  | 1266/1759 [00:28<00:11, 44.68it/s][A
 72%|███████▏  | 1271/1759 [00:28<00:10, 44.82it/s][A
 73%|███████▎  | 1276/1759 [00:28<00:10, 45.04it/s][A
 73%|███████▎  | 1281/1759 [00:28<00:10, 45.21it/s][A
 73%|███████▎  | 1286/1759 [00:28<00:10, 45.31it/s][A
 73%|███████▎  | 1291/1759 [00:28<00:10, 45.18it/s][A
 74%|███████▎  | 1296/1759 [00:29<00:10, 45.08it/s][A
 74%|███████▍  | 1301/1759 [00:29<00:10, 44.81it/s][A
 74%|███████▍  | 1306/1759 [00:29<00:10, 44.73it/s][A
 75%|███████▍  | 1311/1759 [00:29<00:09, 44.85it/s][A
 75%|███████▍  | 1316/1759 [00:29<00:09, 44.85it/s][A
 75%|███████▌  | 1321/1759 [00:29<00:09, 45.10it/s][A
 75%|███████▌  | 1326/1759 [00:29<00:09, 45.13it/s][A
 76%|███████▌  | 1331/1759 [00:29<00:09, 45.27it/s][A
 76%|███████▌  | 1336/1759 [00:29<00:09, 45.08it/s][A
 76%|███████▌  | 1341/1759 [00:30<00:09, 44.92it/s][A
 77%|███████▋  | 1346/1759 [00:30<00:09, 44.79it/s][A
 77%|███████▋  | 1351/1759 [00:30<00:09, 44.76it/s][A
 77%|███████▋  | 1356/1759 [00:30<00:08, 44.95it/s][A
 77%|███████▋  | 1361/1759 [00:30<00:08, 45.00it/s][A
 78%|███████▊  | 1366/1759 [00:30<00:08, 45.01it/s][A
 78%|███████▊  | 1371/1759 [00:30<00:08, 45.10it/s][A
 78%|███████▊  | 1376/1759 [00:30<00:08, 45.25it/s][A
 79%|███████▊  | 1381/1759 [00:30<00:08, 45.14it/s][A
 79%|███████▉  | 1386/1759 [00:31<00:08, 45.04it/s][A
 79%|███████▉  | 1391/1759 [00:31<00:08, 44.81it/s][A
 79%|███████▉  | 1396/1759 [00:31<00:08, 44.79it/s][A
 80%|███████▉  | 1401/1759 [00:31<00:07, 44.89it/s][A
 80%|███████▉  | 1406/1759 [00:31<00:07, 44.95it/s][A
 80%|████████  | 1411/1759 [00:31<00:07, 45.10it/s][A
 81%|████████  | 1416/1759 [00:31<00:07, 45.09it/s][A
 81%|████████  | 1421/1759 [00:31<00:07, 45.13it/s][A
 81%|████████  | 1426/1759 [00:31<00:07, 45.15it/s][A
 81%|████████▏ | 1431/1759 [00:32<00:07, 44.96it/s][A
 82%|████████▏ | 1436/1759 [00:32<00:07, 44.88it/s][A
 82%|████████▏ | 1441/1759 [00:32<00:07, 44.76it/s][A
 82%|████████▏ | 1446/1759 [00:32<00:06, 44.80it/s][A
 82%|████████▏ | 1451/1759 [00:32<00:07, 43.38it/s][A
 83%|████████▎ | 1456/1759 [00:32<00:06, 43.95it/s][A
 83%|████████▎ | 1461/1759 [00:32<00:06, 44.46it/s][A
 83%|████████▎ | 1466/1759 [00:32<00:06, 44.72it/s][A
 84%|████████▎ | 1471/1759 [00:32<00:06, 44.73it/s][A
 84%|████████▍ | 1476/1759 [00:33<00:06, 44.82it/s][A
 84%|████████▍ | 1481/1759 [00:33<00:06, 44.70it/s][A
 84%|████████▍ | 1486/1759 [00:33<00:06, 44.68it/s][A
 85%|████████▍ | 1491/1759 [00:33<00:06, 44.62it/s][A
 85%|████████▌ | 1496/1759 [00:33<00:05, 44.73it/s][A
 85%|████████▌ | 1501/1759 [00:33<00:05, 44.99it/s][A
 86%|████████▌ | 1506/1759 [00:33<00:05, 45.25it/s][A
 86%|████████▌ | 1511/1759 [00:33<00:05, 45.27it/s][A
 86%|████████▌ | 1516/1759 [00:33<00:05, 45.27it/s][A
 86%|████████▋ | 1521/1759 [00:34<00:05, 45.15it/s][A
 87%|████████▋ | 1526/1759 [00:34<00:05, 44.97it/s][A
 87%|████████▋ | 1531/1759 [00:34<00:05, 44.93it/s][A
 87%|████████▋ | 1536/1759 [00:34<00:04, 44.74it/s][A
 88%|████████▊ | 1541/1759 [00:34<00:04, 44.79it/s][A
 88%|████████▊ | 1546/1759 [00:34<00:04, 44.97it/s][A
 88%|████████▊ | 1551/1759 [00:34<00:04, 44.91it/s][A
 88%|████████▊ | 1556/1759 [00:34<00:04, 45.21it/s][A
 89%|████████▊ | 1561/1759 [00:34<00:04, 45.18it/s][A
 89%|████████▉ | 1566/1759 [00:35<00:04, 45.25it/s][A
 89%|████████▉ | 1571/1759 [00:35<00:04, 45.24it/s][A
 90%|████████▉ | 1576/1759 [00:35<00:04, 45.14it/s][A
 90%|████████▉ | 1581/1759 [00:35<00:03, 45.01it/s][A
 90%|█████████ | 1586/1759 [00:35<00:03, 44.94it/s][A
 90%|█████████ | 1591/1759 [00:35<00:03, 44.98it/s][A
 91%|█████████ | 1596/1759 [00:35<00:03, 45.14it/s][A
 91%|█████████ | 1601/1759 [00:35<00:03, 45.21it/s][A
 91%|█████████▏| 1606/1759 [00:35<00:03, 45.06it/s][A
 92%|█████████▏| 1611/1759 [00:36<00:03, 45.19it/s][A
 92%|█████████▏| 1616/1759 [00:36<00:03, 45.13it/s][A
 92%|█████████▏| 1621/1759 [00:36<00:03, 45.03it/s][A
 92%|█████████▏| 1626/1759 [00:36<00:02, 44.88it/s][A
 93%|█████████▎| 1631/1759 [00:36<00:02, 44.89it/s][A
 93%|█████████▎| 1636/1759 [00:36<00:02, 45.04it/s][A
 93%|█████████▎| 1641/1759 [00:36<00:02, 45.05it/s][A
 94%|█████████▎| 1646/1759 [00:36<00:02, 45.05it/s][A
 94%|█████████▍| 1651/1759 [00:36<00:02, 45.13it/s][A
 94%|█████████▍| 1656/1759 [00:37<00:02, 45.10it/s][A
 94%|█████████▍| 1661/1759 [00:37<00:02, 45.10it/s][A
 95%|█████████▍| 1666/1759 [00:37<00:02, 45.01it/s][A
 95%|█████████▍| 1671/1759 [00:37<00:01, 44.82it/s][A
 95%|█████████▌| 1676/1759 [00:37<00:01, 44.96it/s][A
 96%|█████████▌| 1681/1759 [00:37<00:01, 41.87it/s][A
 96%|█████████▌| 1686/1759 [00:37<00:01, 42.95it/s][A
 96%|█████████▌| 1691/1759 [00:37<00:01, 43.68it/s][A
 96%|█████████▋| 1696/1759 [00:37<00:01, 44.23it/s][A
 97%|█████████▋| 1701/1759 [00:38<00:01, 44.60it/s][A
 97%|█████████▋| 1706/1759 [00:38<00:01, 44.66it/s][A
 97%|█████████▋| 1711/1759 [00:38<00:01, 44.76it/s][A
 98%|█████████▊| 1716/1759 [00:38<00:00, 44.71it/s][A
 98%|█████████▊| 1721/1759 [00:38<00:00, 44.46it/s][A
 98%|█████████▊| 1726/1759 [00:38<00:00, 44.67it/s][A
 98%|█████████▊| 1731/1759 [00:38<00:00, 44.78it/s][A
 99%|█████████▊| 1736/1759 [00:38<00:00, 45.02it/s][A
 99%|█████████▉| 1741/1759 [00:38<00:00, 45.05it/s][A
 99%|█████████▉| 1746/1759 [00:39<00:00, 45.24it/s][A
100%|█████████▉| 1751/1759 [00:39<00:00, 45.26it/s][A
100%|█████████▉| 1756/1759 [00:39<00:00, 45.16it/s][A                                               
                                                   [A 80%|████████  | 64/80 [03:25<00:05,  2.74it/s]
100%|██████████| 1759/1759 [00:39<00:00, 45.16it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 08:25:23,353 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-64
[INFO|configuration_utils.py:351] 2023-08-29 08:25:23,806 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-64/config.json
[INFO|modeling_utils.py:886] 2023-08-29 08:25:27,840 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-64/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 08:25:28,066 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-64/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 08:25:28,187 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-64/special_tokens_map.json
 81%|████████▏ | 65/80 [03:38<04:00, 16.01s/it] 82%|████████▎ | 66/80 [03:38<02:38, 11.30s/it] 84%|████████▍ | 67/80 [03:39<01:43,  8.00s/it] 85%|████████▌ | 68/80 [03:39<01:08,  5.69s/it] 86%|████████▋ | 69/80 [03:39<00:44,  4.07s/it] 88%|████████▊ | 70/80 [03:40<00:29,  2.94s/it] 89%|████████▉ | 71/80 [03:40<00:19,  2.14s/it] 90%|█████████ | 72/80 [03:40<00:12,  1.59s/it] 91%|█████████▏| 73/80 [03:40<00:08,  1.20s/it] 92%|█████████▎| 74/80 [03:41<00:05,  1.08it/s] 94%|█████████▍| 75/80 [03:41<00:03,  1.35it/s] 95%|█████████▌| 76/80 [03:41<00:02,  1.65it/s] 96%|█████████▋| 77/80 [03:42<00:01,  1.93it/s] 98%|█████████▊| 78/80 [03:42<00:00,  2.23it/s] 99%|█████████▉| 79/80 [03:42<00:00,  2.49it/s]100%|██████████| 80/80 [03:43<00:00,  2.72it/s][INFO|trainer.py:2140] 2023-08-29 08:25:40,734 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 08:25:40,734 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 08:25:40,734 >>   Batch size = 8
{'eval_loss': 0.8864798545837402, 'eval_runtime': 39.3566, 'eval_samples_per_second': 357.424, 'eval_steps_per_second': 44.694, 'epoch': 3.97}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.24it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.65it/s][A
  1%|          | 18/1759 [00:00<00:36, 47.56it/s][A
  1%|▏         | 23/1759 [00:00<00:37, 46.69it/s][A
  2%|▏         | 28/1759 [00:00<00:37, 46.18it/s][A
  2%|▏         | 33/1759 [00:00<00:37, 45.69it/s][A
  2%|▏         | 38/1759 [00:00<00:37, 45.47it/s][A
  2%|▏         | 43/1759 [00:00<00:38, 45.16it/s][A
  3%|▎         | 48/1759 [00:01<00:37, 45.20it/s][A
  3%|▎         | 53/1759 [00:01<00:37, 45.30it/s][A
  3%|▎         | 58/1759 [00:01<00:37, 45.36it/s][A
  4%|▎         | 63/1759 [00:01<00:37, 45.47it/s][A
  4%|▍         | 68/1759 [00:01<00:37, 45.41it/s][A
  4%|▍         | 73/1759 [00:01<00:37, 45.39it/s][A
  4%|▍         | 78/1759 [00:01<00:37, 45.34it/s][A
  5%|▍         | 83/1759 [00:01<00:37, 45.25it/s][A
  5%|▌         | 88/1759 [00:01<00:37, 44.51it/s][A
  5%|▌         | 93/1759 [00:02<00:37, 44.79it/s][A
  6%|▌         | 98/1759 [00:02<00:36, 44.96it/s][A
  6%|▌         | 103/1759 [00:02<00:36, 45.11it/s][A
  6%|▌         | 108/1759 [00:02<00:36, 45.11it/s][A
  6%|▋         | 113/1759 [00:02<00:36, 45.22it/s][A
  7%|▋         | 118/1759 [00:02<00:36, 45.23it/s][A
  7%|▋         | 123/1759 [00:02<00:36, 45.23it/s][A
  7%|▋         | 128/1759 [00:02<00:36, 45.05it/s][A
  8%|▊         | 133/1759 [00:02<00:36, 44.98it/s][A
  8%|▊         | 138/1759 [00:03<00:35, 45.12it/s][A
  8%|▊         | 143/1759 [00:03<00:35, 45.24it/s][A
  8%|▊         | 148/1759 [00:03<00:35, 45.15it/s][A
  9%|▊         | 153/1759 [00:03<00:35, 45.29it/s][A
  9%|▉         | 158/1759 [00:03<00:35, 45.29it/s][A
  9%|▉         | 163/1759 [00:03<00:35, 45.23it/s][A
 10%|▉         | 168/1759 [00:03<00:35, 45.04it/s][A
 10%|▉         | 173/1759 [00:03<00:35, 45.07it/s][A
 10%|█         | 178/1759 [00:03<00:35, 45.09it/s][A
 10%|█         | 183/1759 [00:04<00:34, 45.14it/s][A
 11%|█         | 188/1759 [00:04<00:34, 45.23it/s][A
 11%|█         | 193/1759 [00:04<00:34, 45.16it/s][A
 11%|█▏        | 198/1759 [00:04<00:34, 45.31it/s][A
 12%|█▏        | 203/1759 [00:04<00:34, 45.32it/s][A
 12%|█▏        | 208/1759 [00:04<00:34, 45.33it/s][A
 12%|█▏        | 213/1759 [00:04<00:34, 45.16it/s][A
 12%|█▏        | 218/1759 [00:04<00:35, 43.59it/s][A
 13%|█▎        | 223/1759 [00:04<00:35, 43.60it/s][A
 13%|█▎        | 228/1759 [00:05<00:34, 44.20it/s][A
 13%|█▎        | 233/1759 [00:05<00:34, 44.48it/s][A
 14%|█▎        | 238/1759 [00:05<00:33, 44.78it/s][A
 14%|█▍        | 243/1759 [00:05<00:33, 44.97it/s][A
 14%|█▍        | 248/1759 [00:05<00:33, 45.09it/s][A
 14%|█▍        | 253/1759 [00:05<00:33, 45.18it/s][A
 15%|█▍        | 258/1759 [00:05<00:33, 45.05it/s][A
 15%|█▍        | 263/1759 [00:05<00:34, 43.34it/s][A
 15%|█▌        | 268/1759 [00:06<00:40, 36.41it/s][A
 16%|█▌        | 273/1759 [00:06<00:38, 39.07it/s][A
 16%|█▌        | 278/1759 [00:06<00:36, 40.82it/s][A
 16%|█▌        | 283/1759 [00:06<00:34, 42.17it/s][A
 16%|█▋        | 288/1759 [00:06<00:34, 43.15it/s][A
 17%|█▋        | 293/1759 [00:06<00:33, 43.91it/s][A
 17%|█▋        | 298/1759 [00:06<00:32, 44.36it/s][A
 17%|█▋        | 303/1759 [00:06<00:32, 44.70it/s][A
 18%|█▊        | 308/1759 [00:06<00:32, 44.77it/s][A
 18%|█▊        | 313/1759 [00:07<00:32, 44.47it/s][A
 18%|█▊        | 318/1759 [00:07<00:32, 44.48it/s][A
 18%|█▊        | 323/1759 [00:07<00:32, 44.64it/s][A
 19%|█▊        | 328/1759 [00:07<00:31, 44.84it/s][A
 19%|█▉        | 333/1759 [00:07<00:31, 45.10it/s][A
 19%|█▉        | 338/1759 [00:07<00:31, 45.30it/s][A
 19%|█▉        | 343/1759 [00:07<00:31, 45.35it/s][A
 20%|█▉        | 348/1759 [00:07<00:31, 45.46it/s][A
 20%|██        | 353/1759 [00:07<00:31, 45.32it/s][A
 20%|██        | 358/1759 [00:08<00:31, 44.33it/s][A
 21%|██        | 363/1759 [00:08<00:31, 44.34it/s][A
 21%|██        | 368/1759 [00:08<00:31, 44.51it/s][A
 21%|██        | 373/1759 [00:08<00:30, 44.72it/s][A
 21%|██▏       | 378/1759 [00:08<00:30, 44.92it/s][A
 22%|██▏       | 383/1759 [00:08<00:30, 45.13it/s][A
 22%|██▏       | 388/1759 [00:08<00:30, 45.19it/s][A
 22%|██▏       | 393/1759 [00:08<00:30, 45.37it/s][A
 23%|██▎       | 398/1759 [00:08<00:30, 45.36it/s][A
 23%|██▎       | 403/1759 [00:09<00:30, 45.15it/s][A
 23%|██▎       | 408/1759 [00:09<00:29, 45.15it/s][A
 23%|██▎       | 413/1759 [00:09<00:29, 45.10it/s][A
 24%|██▍       | 418/1759 [00:09<00:29, 44.88it/s][A
 24%|██▍       | 423/1759 [00:09<00:29, 45.05it/s][A
 24%|██▍       | 428/1759 [00:09<00:29, 45.17it/s][A
 25%|██▍       | 433/1759 [00:09<00:29, 45.24it/s][A
 25%|██▍       | 438/1759 [00:09<00:29, 45.39it/s][A
 25%|██▌       | 443/1759 [00:09<00:29, 45.26it/s][A
 25%|██▌       | 448/1759 [00:09<00:29, 45.13it/s][A
 26%|██▌       | 453/1759 [00:10<00:28, 45.05it/s][A
 26%|██▌       | 458/1759 [00:10<00:28, 45.09it/s][A
 26%|██▋       | 463/1759 [00:10<00:28, 45.08it/s][A
 27%|██▋       | 468/1759 [00:10<00:28, 44.99it/s][A
 27%|██▋       | 473/1759 [00:10<00:28, 45.09it/s][A
 27%|██▋       | 478/1759 [00:10<00:28, 45.17it/s][A
 27%|██▋       | 483/1759 [00:10<00:28, 45.34it/s][A
 28%|██▊       | 488/1759 [00:10<00:28, 45.28it/s][A
 28%|██▊       | 493/1759 [00:11<00:28, 45.10it/s][A
 28%|██▊       | 498/1759 [00:11<00:28, 44.62it/s][A
 29%|██▊       | 503/1759 [00:11<00:28, 44.70it/s][A
 29%|██▉       | 508/1759 [00:11<00:27, 44.90it/s][A
 29%|██▉       | 513/1759 [00:11<00:27, 44.90it/s][A
 29%|██▉       | 518/1759 [00:11<00:27, 44.97it/s][A
 30%|██▉       | 523/1759 [00:11<00:27, 45.17it/s][A
 30%|███       | 528/1759 [00:11<00:27, 45.29it/s][A
 30%|███       | 533/1759 [00:11<00:27, 45.23it/s][A
 31%|███       | 538/1759 [00:11<00:27, 45.10it/s][A
 31%|███       | 543/1759 [00:12<00:27, 45.03it/s][A
 31%|███       | 548/1759 [00:12<00:26, 45.05it/s][A
 31%|███▏      | 553/1759 [00:12<00:26, 45.14it/s][A
 32%|███▏      | 558/1759 [00:12<00:26, 45.03it/s][A
 32%|███▏      | 563/1759 [00:12<00:26, 45.07it/s][A
 32%|███▏      | 568/1759 [00:12<00:26, 45.22it/s][A
 33%|███▎      | 573/1759 [00:12<00:26, 45.31it/s][A
 33%|███▎      | 578/1759 [00:12<00:26, 45.22it/s][A
 33%|███▎      | 583/1759 [00:12<00:26, 45.12it/s][A
 33%|███▎      | 588/1759 [00:13<00:25, 45.08it/s][A
 34%|███▎      | 593/1759 [00:13<00:25, 45.11it/s][A
 34%|███▍      | 598/1759 [00:13<00:25, 45.11it/s][A
 34%|███▍      | 603/1759 [00:13<00:25, 44.95it/s][A
 35%|███▍      | 608/1759 [00:13<00:25, 45.06it/s][A
 35%|███▍      | 613/1759 [00:13<00:25, 45.08it/s][A
 35%|███▌      | 618/1759 [00:13<00:25, 45.25it/s][A
 35%|███▌      | 623/1759 [00:13<00:25, 45.18it/s][A
 36%|███▌      | 628/1759 [00:13<00:25, 45.20it/s][A
 36%|███▌      | 633/1759 [00:14<00:24, 45.07it/s][A
 36%|███▋      | 638/1759 [00:14<00:24, 45.13it/s][A
 37%|███▋      | 643/1759 [00:14<00:24, 45.12it/s][A
 37%|███▋      | 648/1759 [00:14<00:24, 44.98it/s][A
 37%|███▋      | 653/1759 [00:14<00:24, 45.04it/s][A
 37%|███▋      | 658/1759 [00:14<00:24, 45.21it/s][A
 38%|███▊      | 663/1759 [00:14<00:24, 45.22it/s][A
 38%|███▊      | 668/1759 [00:14<00:24, 45.14it/s][A
 38%|███▊      | 673/1759 [00:14<00:24, 45.10it/s][A
 39%|███▊      | 678/1759 [00:15<00:23, 45.09it/s][A
 39%|███▉      | 683/1759 [00:15<00:23, 45.19it/s][A
 39%|███▉      | 688/1759 [00:15<00:23, 45.06it/s][A
 39%|███▉      | 693/1759 [00:15<00:23, 44.98it/s][A
 40%|███▉      | 698/1759 [00:15<00:23, 45.03it/s][A
 40%|███▉      | 703/1759 [00:15<00:23, 45.17it/s][A
 40%|████      | 708/1759 [00:15<00:23, 45.16it/s][A
 41%|████      | 713/1759 [00:15<00:23, 45.18it/s][A
 41%|████      | 718/1759 [00:15<00:23, 45.10it/s][A
 41%|████      | 723/1759 [00:16<00:22, 45.07it/s][A
 41%|████▏     | 728/1759 [00:16<00:22, 45.14it/s][A
 42%|████▏     | 733/1759 [00:16<00:22, 45.04it/s][A
 42%|████▏     | 738/1759 [00:16<00:23, 43.08it/s][A
 42%|████▏     | 743/1759 [00:16<00:23, 43.81it/s][A
 43%|████▎     | 748/1759 [00:16<00:22, 44.30it/s][A
 43%|████▎     | 753/1759 [00:16<00:22, 44.54it/s][A
 43%|████▎     | 758/1759 [00:16<00:22, 44.79it/s][A
 43%|████▎     | 763/1759 [00:16<00:22, 44.78it/s][A
 44%|████▎     | 768/1759 [00:17<00:22, 44.92it/s][A
 44%|████▍     | 773/1759 [00:17<00:21, 44.98it/s][A
 44%|████▍     | 778/1759 [00:17<00:21, 44.65it/s][A
 45%|████▍     | 783/1759 [00:17<00:21, 44.87it/s][A
 45%|████▍     | 788/1759 [00:17<00:21, 45.04it/s][A
 45%|████▌     | 793/1759 [00:17<00:21, 45.15it/s][A
 45%|████▌     | 798/1759 [00:17<00:21, 45.20it/s][A
 46%|████▌     | 803/1759 [00:17<00:21, 45.21it/s][A
 46%|████▌     | 808/1759 [00:17<00:21, 45.24it/s][A
 46%|████▌     | 813/1759 [00:18<00:20, 45.25it/s][A
 47%|████▋     | 818/1759 [00:18<00:20, 45.05it/s][A
 47%|████▋     | 823/1759 [00:18<00:20, 44.87it/s][A
 47%|████▋     | 828/1759 [00:18<00:20, 44.92it/s][A
 47%|████▋     | 833/1759 [00:18<00:20, 45.04it/s][A
 48%|████▊     | 838/1759 [00:18<00:20, 45.18it/s][A
 48%|████▊     | 843/1759 [00:18<00:20, 45.24it/s][A
 48%|████▊     | 848/1759 [00:18<00:20, 45.29it/s][A
 48%|████▊     | 853/1759 [00:18<00:20, 45.26it/s][A
 49%|████▉     | 858/1759 [00:19<00:19, 45.21it/s][A
 49%|████▉     | 863/1759 [00:19<00:19, 45.11it/s][A
 49%|████▉     | 868/1759 [00:19<00:19, 44.83it/s][A
 50%|████▉     | 873/1759 [00:19<00:19, 44.47it/s][A
 50%|████▉     | 878/1759 [00:19<00:19, 44.84it/s][A
 50%|█████     | 883/1759 [00:19<00:19, 45.00it/s][A
 50%|█████     | 888/1759 [00:19<00:19, 45.16it/s][A
 51%|█████     | 893/1759 [00:19<00:19, 45.13it/s][A
 51%|█████     | 898/1759 [00:19<00:19, 45.16it/s][A
 51%|█████▏    | 903/1759 [00:20<00:18, 45.12it/s][A
 52%|█████▏    | 908/1759 [00:20<00:18, 44.95it/s][A
 52%|█████▏    | 913/1759 [00:20<00:18, 44.90it/s][A
 52%|█████▏    | 918/1759 [00:20<00:18, 44.67it/s][A
 52%|█████▏    | 923/1759 [00:20<00:18, 44.89it/s][A
 53%|█████▎    | 928/1759 [00:20<00:18, 45.09it/s][A
 53%|█████▎    | 933/1759 [00:20<00:18, 45.23it/s][A
 53%|█████▎    | 938/1759 [00:20<00:18, 45.16it/s][A
 54%|█████▎    | 943/1759 [00:20<00:18, 45.22it/s][A
 54%|█████▍    | 948/1759 [00:21<00:17, 45.13it/s][A
 54%|█████▍    | 953/1759 [00:21<00:17, 45.12it/s][A
 54%|█████▍    | 958/1759 [00:21<00:17, 45.05it/s][A
 55%|█████▍    | 963/1759 [00:21<00:17, 44.92it/s][A
 55%|█████▌    | 968/1759 [00:21<00:17, 45.14it/s][A
 55%|█████▌    | 973/1759 [00:21<00:17, 45.14it/s][A
 56%|█████▌    | 978/1759 [00:21<00:17, 45.30it/s][A
 56%|█████▌    | 983/1759 [00:21<00:17, 45.15it/s][A
 56%|█████▌    | 988/1759 [00:21<00:17, 45.20it/s][A
 56%|█████▋    | 993/1759 [00:22<00:16, 45.12it/s][A
 57%|█████▋    | 998/1759 [00:22<00:16, 45.05it/s][A
 57%|█████▋    | 1003/1759 [00:22<00:16, 44.99it/s][A
 57%|█████▋    | 1008/1759 [00:22<00:16, 44.92it/s][A
 58%|█████▊    | 1013/1759 [00:22<00:16, 43.93it/s][A
 58%|█████▊    | 1018/1759 [00:22<00:16, 44.51it/s][A
 58%|█████▊    | 1023/1759 [00:22<00:16, 44.79it/s][A
 58%|█████▊    | 1028/1759 [00:22<00:16, 44.89it/s][A
 59%|█████▊    | 1033/1759 [00:22<00:16, 44.90it/s][A
 59%|█████▉    | 1038/1759 [00:23<00:16, 44.92it/s][A
 59%|█████▉    | 1043/1759 [00:23<00:15, 44.94it/s][A
 60%|█████▉    | 1048/1759 [00:23<00:15, 44.85it/s][A
 60%|█████▉    | 1053/1759 [00:23<00:15, 44.79it/s][A
 60%|██████    | 1058/1759 [00:23<00:15, 44.84it/s][A
 60%|██████    | 1063/1759 [00:23<00:15, 45.09it/s][A
 61%|██████    | 1068/1759 [00:23<00:15, 45.19it/s][A
 61%|██████    | 1073/1759 [00:23<00:15, 45.24it/s][A
 61%|██████▏   | 1078/1759 [00:23<00:15, 45.15it/s][A
 62%|██████▏   | 1083/1759 [00:24<00:14, 45.17it/s][A
 62%|██████▏   | 1088/1759 [00:24<00:14, 45.11it/s][A
 62%|██████▏   | 1093/1759 [00:24<00:14, 44.94it/s][A
 62%|██████▏   | 1098/1759 [00:24<00:14, 44.88it/s][A
 63%|██████▎   | 1103/1759 [00:24<00:14, 44.88it/s][A
 63%|██████▎   | 1108/1759 [00:24<00:14, 45.05it/s][A
 63%|██████▎   | 1113/1759 [00:24<00:14, 45.20it/s][A
 64%|██████▎   | 1118/1759 [00:24<00:14, 45.18it/s][A
 64%|██████▍   | 1123/1759 [00:24<00:14, 45.16it/s][A
 64%|██████▍   | 1128/1759 [00:25<00:13, 45.19it/s][A
 64%|██████▍   | 1133/1759 [00:25<00:13, 45.09it/s][A
 65%|██████▍   | 1138/1759 [00:25<00:13, 44.90it/s][A
 65%|██████▍   | 1143/1759 [00:25<00:13, 44.81it/s][A
 65%|██████▌   | 1148/1759 [00:25<00:13, 43.79it/s][A
 66%|██████▌   | 1153/1759 [00:25<00:13, 44.35it/s][A
 66%|██████▌   | 1158/1759 [00:25<00:13, 44.65it/s][A
 66%|██████▌   | 1163/1759 [00:25<00:13, 44.85it/s][A
 66%|██████▋   | 1168/1759 [00:26<00:13, 45.01it/s][A
 67%|██████▋   | 1173/1759 [00:26<00:13, 45.07it/s][A
 67%|██████▋   | 1178/1759 [00:26<00:12, 44.95it/s][A
 67%|██████▋   | 1183/1759 [00:26<00:12, 44.73it/s][A
 68%|██████▊   | 1188/1759 [00:26<00:12, 44.75it/s][A
 68%|██████▊   | 1193/1759 [00:26<00:12, 44.81it/s][A
 68%|██████▊   | 1198/1759 [00:26<00:12, 44.98it/s][A
 68%|██████▊   | 1203/1759 [00:26<00:12, 45.07it/s][A
 69%|██████▊   | 1208/1759 [00:26<00:12, 45.23it/s][A
 69%|██████▉   | 1213/1759 [00:26<00:12, 45.29it/s][A
 69%|██████▉   | 1218/1759 [00:27<00:11, 45.25it/s][A
 70%|██████▉   | 1223/1759 [00:27<00:11, 45.04it/s][A
 70%|██████▉   | 1228/1759 [00:27<00:11, 44.89it/s][A
 70%|███████   | 1233/1759 [00:27<00:11, 44.90it/s][A
 70%|███████   | 1238/1759 [00:27<00:11, 44.88it/s][A
 71%|███████   | 1243/1759 [00:27<00:11, 45.05it/s][A
 71%|███████   | 1248/1759 [00:27<00:11, 45.09it/s][A
 71%|███████   | 1253/1759 [00:27<00:11, 45.18it/s][A
 72%|███████▏  | 1258/1759 [00:27<00:11, 45.28it/s][A
 72%|███████▏  | 1263/1759 [00:28<00:10, 45.19it/s][A
 72%|███████▏  | 1268/1759 [00:28<00:10, 45.06it/s][A
 72%|███████▏  | 1273/1759 [00:28<00:10, 44.98it/s][A
 73%|███████▎  | 1278/1759 [00:28<00:10, 44.81it/s][A
 73%|███████▎  | 1283/1759 [00:28<00:10, 43.78it/s][A
 73%|███████▎  | 1288/1759 [00:28<00:10, 44.47it/s][A
 74%|███████▎  | 1293/1759 [00:28<00:10, 44.73it/s][A
 74%|███████▍  | 1298/1759 [00:28<00:10, 44.93it/s][A
 74%|███████▍  | 1303/1759 [00:29<00:10, 45.07it/s][A
 74%|███████▍  | 1308/1759 [00:29<00:10, 45.02it/s][A
 75%|███████▍  | 1313/1759 [00:29<00:09, 44.96it/s][A
 75%|███████▍  | 1318/1759 [00:29<00:09, 44.81it/s][A
 75%|███████▌  | 1323/1759 [00:29<00:09, 44.80it/s][A
 75%|███████▌  | 1328/1759 [00:29<00:09, 44.80it/s][A
 76%|███████▌  | 1333/1759 [00:29<00:09, 44.97it/s][A
 76%|███████▌  | 1338/1759 [00:29<00:09, 45.01it/s][A
 76%|███████▋  | 1343/1759 [00:29<00:09, 45.09it/s][A
 77%|███████▋  | 1348/1759 [00:30<00:09, 45.28it/s][A
 77%|███████▋  | 1353/1759 [00:30<00:08, 45.20it/s][A
 77%|███████▋  | 1358/1759 [00:30<00:08, 45.13it/s][A
 77%|███████▋  | 1363/1759 [00:30<00:08, 44.85it/s][A
 78%|███████▊  | 1368/1759 [00:30<00:08, 44.85it/s][A
 78%|███████▊  | 1373/1759 [00:30<00:08, 44.91it/s][A
 78%|███████▊  | 1378/1759 [00:30<00:08, 44.95it/s][A
 79%|███████▊  | 1383/1759 [00:30<00:08, 45.13it/s][A
 79%|███████▉  | 1388/1759 [00:30<00:08, 45.13it/s][A
 79%|███████▉  | 1393/1759 [00:31<00:08, 45.28it/s][A
 79%|███████▉  | 1398/1759 [00:31<00:07, 45.24it/s][A
 80%|███████▉  | 1403/1759 [00:31<00:07, 45.18it/s][A
 80%|████████  | 1408/1759 [00:31<00:07, 44.87it/s][A
 80%|████████  | 1413/1759 [00:31<00:07, 44.88it/s][A
 81%|████████  | 1418/1759 [00:31<00:07, 43.08it/s][A
 81%|████████  | 1423/1759 [00:31<00:07, 43.85it/s][A
 81%|████████  | 1428/1759 [00:31<00:07, 44.35it/s][A
 81%|████████▏ | 1433/1759 [00:31<00:07, 44.74it/s][A
 82%|████████▏ | 1438/1759 [00:32<00:07, 44.93it/s][A
 82%|████████▏ | 1443/1759 [00:32<00:07, 44.99it/s][A
 82%|████████▏ | 1448/1759 [00:32<00:06, 44.84it/s][A
 83%|████████▎ | 1453/1759 [00:32<00:06, 44.77it/s][A
 83%|████████▎ | 1458/1759 [00:32<00:06, 44.57it/s][A
 83%|████████▎ | 1463/1759 [00:32<00:06, 44.60it/s][A
 83%|████████▎ | 1468/1759 [00:32<00:06, 44.88it/s][A
 84%|████████▎ | 1473/1759 [00:32<00:06, 45.04it/s][A
 84%|████████▍ | 1478/1759 [00:32<00:06, 45.22it/s][A
 84%|████████▍ | 1483/1759 [00:33<00:06, 45.41it/s][A
 85%|████████▍ | 1488/1759 [00:33<00:05, 45.35it/s][A
 85%|████████▍ | 1493/1759 [00:33<00:05, 45.11it/s][A
 85%|████████▌ | 1498/1759 [00:33<00:05, 44.92it/s][A
 85%|████████▌ | 1503/1759 [00:33<00:05, 44.83it/s][A
 86%|████████▌ | 1508/1759 [00:33<00:05, 44.86it/s][A
 86%|████████▌ | 1513/1759 [00:33<00:05, 44.95it/s][A
 86%|████████▋ | 1518/1759 [00:33<00:05, 45.09it/s][A
 87%|████████▋ | 1523/1759 [00:33<00:05, 45.24it/s][A
 87%|████████▋ | 1528/1759 [00:34<00:05, 45.43it/s][A
 87%|████████▋ | 1533/1759 [00:34<00:04, 45.35it/s][A
 87%|████████▋ | 1538/1759 [00:34<00:04, 45.07it/s][A
 88%|████████▊ | 1543/1759 [00:34<00:04, 44.98it/s][A
 88%|████████▊ | 1548/1759 [00:34<00:04, 44.82it/s][A
 88%|████████▊ | 1553/1759 [00:34<00:04, 44.48it/s][A
 89%|████████▊ | 1558/1759 [00:34<00:04, 44.77it/s][A
 89%|████████▉ | 1563/1759 [00:34<00:04, 44.87it/s][A
 89%|████████▉ | 1568/1759 [00:34<00:04, 45.16it/s][A
 89%|████████▉ | 1573/1759 [00:35<00:04, 45.22it/s][A
 90%|████████▉ | 1578/1759 [00:35<00:03, 45.35it/s][A
 90%|████████▉ | 1583/1759 [00:35<00:03, 45.14it/s][A
 90%|█████████ | 1588/1759 [00:35<00:03, 45.04it/s][A
 91%|█████████ | 1593/1759 [00:35<00:03, 44.95it/s][A
 91%|█████████ | 1598/1759 [00:35<00:03, 44.87it/s][A
 91%|█████████ | 1603/1759 [00:35<00:03, 45.03it/s][A
 91%|█████████▏| 1608/1759 [00:35<00:03, 45.03it/s][A
 92%|█████████▏| 1613/1759 [00:35<00:03, 45.16it/s][A
 92%|█████████▏| 1618/1759 [00:36<00:03, 45.20it/s][A
 92%|█████████▏| 1623/1759 [00:36<00:03, 45.33it/s][A
 93%|█████████▎| 1628/1759 [00:36<00:02, 45.10it/s][A
 93%|█████████▎| 1633/1759 [00:36<00:02, 45.03it/s][A
 93%|█████████▎| 1638/1759 [00:36<00:02, 44.94it/s][A
 93%|█████████▎| 1643/1759 [00:36<00:02, 44.88it/s][A
 94%|█████████▎| 1648/1759 [00:36<00:02, 44.96it/s][A
 94%|█████████▍| 1653/1759 [00:36<00:02, 44.93it/s][A
 94%|█████████▍| 1658/1759 [00:36<00:02, 45.16it/s][A
 95%|█████████▍| 1663/1759 [00:37<00:02, 45.25it/s][A
 95%|█████████▍| 1668/1759 [00:37<00:02, 45.26it/s][A
 95%|█████████▌| 1673/1759 [00:37<00:01, 45.16it/s][A
 95%|█████████▌| 1678/1759 [00:37<00:01, 44.99it/s][A
 96%|█████████▌| 1683/1759 [00:37<00:01, 44.97it/s][A
 96%|█████████▌| 1688/1759 [00:37<00:01, 44.86it/s][A
 96%|█████████▌| 1693/1759 [00:37<00:01, 44.08it/s][A
 97%|█████████▋| 1698/1759 [00:37<00:01, 44.50it/s][A
 97%|█████████▋| 1703/1759 [00:37<00:01, 44.77it/s][A
 97%|█████████▋| 1708/1759 [00:38<00:01, 45.00it/s][A
 97%|█████████▋| 1713/1759 [00:38<00:01, 45.03it/s][A
 98%|█████████▊| 1718/1759 [00:38<00:00, 45.05it/s][A
 98%|█████████▊| 1723/1759 [00:38<00:00, 44.91it/s][A
 98%|█████████▊| 1728/1759 [00:38<00:00, 44.85it/s][A
 99%|█████████▊| 1733/1759 [00:38<00:00, 44.67it/s][A
 99%|█████████▉| 1738/1759 [00:38<00:00, 44.72it/s][A
 99%|█████████▉| 1743/1759 [00:38<00:00, 44.85it/s][A
 99%|█████████▉| 1748/1759 [00:38<00:00, 45.10it/s][A
100%|█████████▉| 1753/1759 [00:39<00:00, 45.24it/s][A
100%|█████████▉| 1758/1759 [00:39<00:00, 45.28it/s][A                                               
                                                   [A100%|██████████| 80/80 [04:22<00:00,  2.72it/s]
100%|██████████| 1759/1759 [00:39<00:00, 45.28it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 08:26:20,098 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-80
[INFO|configuration_utils.py:351] 2023-08-29 08:26:20,339 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-80/config.json
[INFO|modeling_utils.py:886] 2023-08-29 08:26:23,513 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-80/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 08:26:23,715 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-80/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 08:26:23,809 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-80/special_tokens_map.json
[INFO|trainer.py:1343] 2023-08-29 08:26:31,856 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:1352] 2023-08-29 08:26:31,891 >> Loading best model from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-16 (score: 0.8741165995597839).
                                               100%|██████████| 80/80 [04:41<00:00,  2.72it/s]100%|██████████| 80/80 [04:41<00:00,  3.52s/it]
[INFO|trainer.py:1894] 2023-08-29 08:26:39,346 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model
[INFO|configuration_utils.py:351] 2023-08-29 08:26:39,465 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/config.json
[INFO|modeling_utils.py:886] 2023-08-29 08:26:42,502 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 08:26:42,626 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 08:26:42,697 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/special_tokens_map.json
[INFO|trainer_pt_utils.py:908] 2023-08-29 08:26:43,152 >> ***** train metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:26:43,152 >>   epoch                    =       4.97
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:26:43,152 >>   train_loss               =      0.583
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:26:43,152 >>   train_runtime            = 0:04:41.62
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:26:43,152 >>   train_samples            =       1037
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:26:43,152 >>   train_samples_per_second =     18.411
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:26:43,152 >>   train_steps_per_second   =      0.284
{'eval_loss': 0.8885968327522278, 'eval_runtime': 39.1624, 'eval_samples_per_second': 359.197, 'eval_steps_per_second': 44.916, 'epoch': 4.97}
{'train_runtime': 281.6214, 'train_samples_per_second': 18.411, 'train_steps_per_second': 0.284, 'train_loss': 0.5830095767974853, 'epoch': 4.97}
08/29/2023 08:26:43 - INFO - transformer_base.run_clm_rl -   *** Evaluate ***
[INFO|trainer.py:2140] 2023-08-29 08:26:43,370 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 08:26:43,370 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 08:26:43,370 >>   Batch size = 8
  0%|          | 0/1759 [00:00<?, ?it/s]  0%|          | 6/1759 [00:00<00:31, 55.53it/s]  1%|          | 12/1759 [00:00<00:35, 49.45it/s]  1%|          | 17/1759 [00:00<00:36, 47.90it/s]  1%|▏         | 22/1759 [00:00<00:36, 47.22it/s]  2%|▏         | 27/1759 [00:00<00:37, 46.56it/s]  2%|▏         | 32/1759 [00:00<00:37, 46.25it/s]  2%|▏         | 37/1759 [00:00<00:37, 46.05it/s]  2%|▏         | 42/1759 [00:00<00:37, 45.79it/s]  3%|▎         | 47/1759 [00:01<00:37, 45.17it/s]  3%|▎         | 52/1759 [00:01<00:38, 44.82it/s]  3%|▎         | 57/1759 [00:01<00:37, 44.95it/s]  4%|▎         | 62/1759 [00:01<00:37, 45.04it/s]  4%|▍         | 67/1759 [00:01<00:37, 45.20it/s]  4%|▍         | 72/1759 [00:01<00:37, 45.34it/s]  4%|▍         | 77/1759 [00:01<00:36, 45.47it/s]  5%|▍         | 82/1759 [00:01<00:36, 45.49it/s]  5%|▍         | 87/1759 [00:01<00:36, 45.35it/s]  5%|▌         | 92/1759 [00:02<00:36, 45.06it/s]  6%|▌         | 97/1759 [00:02<00:37, 44.80it/s]  6%|▌         | 102/1759 [00:02<00:42, 39.09it/s]  6%|▌         | 107/1759 [00:02<00:40, 40.83it/s]  6%|▋         | 112/1759 [00:02<00:39, 42.08it/s]  7%|▋         | 117/1759 [00:02<00:38, 43.14it/s]  7%|▋         | 122/1759 [00:02<00:37, 43.80it/s]  7%|▋         | 127/1759 [00:02<00:36, 44.40it/s]  8%|▊         | 132/1759 [00:02<00:36, 44.70it/s]  8%|▊         | 137/1759 [00:03<00:36, 44.93it/s]  8%|▊         | 142/1759 [00:03<00:36, 44.58it/s]  8%|▊         | 147/1759 [00:03<00:57, 27.79it/s]  9%|▊         | 152/1759 [00:03<00:50, 31.53it/s]  9%|▉         | 157/1759 [00:03<00:46, 34.77it/s]  9%|▉         | 162/1759 [00:03<00:42, 37.50it/s]  9%|▉         | 167/1759 [00:03<00:40, 39.62it/s] 10%|▉         | 172/1759 [00:04<00:38, 41.24it/s] 10%|█         | 177/1759 [00:04<00:37, 42.42it/s] 10%|█         | 182/1759 [00:04<00:36, 43.37it/s] 11%|█         | 187/1759 [00:04<00:36, 43.55it/s] 11%|█         | 192/1759 [00:04<00:35, 43.68it/s] 11%|█         | 197/1759 [00:04<00:35, 43.96it/s] 11%|█▏        | 202/1759 [00:04<00:35, 44.32it/s] 12%|█▏        | 207/1759 [00:04<00:34, 44.72it/s] 12%|█▏        | 212/1759 [00:04<00:34, 44.91it/s] 12%|█▏        | 217/1759 [00:05<00:34, 45.09it/s] 13%|█▎        | 222/1759 [00:05<00:33, 45.28it/s] 13%|█▎        | 227/1759 [00:05<00:34, 44.95it/s] 13%|█▎        | 232/1759 [00:05<00:34, 44.91it/s] 13%|█▎        | 237/1759 [00:05<00:34, 44.75it/s] 14%|█▍        | 242/1759 [00:05<00:33, 44.66it/s] 14%|█▍        | 247/1759 [00:05<00:33, 44.74it/s] 14%|█▍        | 252/1759 [00:05<00:33, 44.93it/s] 15%|█▍        | 257/1759 [00:05<00:33, 45.09it/s] 15%|█▍        | 262/1759 [00:06<00:33, 45.24it/s] 15%|█▌        | 267/1759 [00:06<00:32, 45.35it/s] 15%|█▌        | 272/1759 [00:06<00:32, 45.33it/s] 16%|█▌        | 277/1759 [00:06<00:32, 45.12it/s] 16%|█▌        | 282/1759 [00:06<00:32, 45.02it/s] 16%|█▋        | 287/1759 [00:06<00:32, 44.90it/s] 17%|█▋        | 292/1759 [00:06<00:32, 44.94it/s] 17%|█▋        | 297/1759 [00:06<00:32, 45.03it/s] 17%|█▋        | 302/1759 [00:06<00:32, 45.17it/s] 17%|█▋        | 307/1759 [00:07<00:32, 45.24it/s] 18%|█▊        | 312/1759 [00:07<00:31, 45.38it/s] 18%|█▊        | 317/1759 [00:07<00:31, 45.33it/s] 18%|█▊        | 322/1759 [00:07<00:31, 45.06it/s] 19%|█▊        | 327/1759 [00:07<00:31, 45.02it/s] 19%|█▉        | 332/1759 [00:07<00:31, 44.93it/s] 19%|█▉        | 337/1759 [00:07<00:31, 44.96it/s] 19%|█▉        | 342/1759 [00:07<00:31, 44.97it/s] 20%|█▉        | 347/1759 [00:07<00:31, 45.13it/s] 20%|██        | 352/1759 [00:08<00:31, 45.30it/s] 20%|██        | 357/1759 [00:08<00:30, 45.23it/s] 21%|██        | 362/1759 [00:08<00:30, 45.32it/s] 21%|██        | 367/1759 [00:08<00:31, 44.43it/s] 21%|██        | 372/1759 [00:08<00:31, 44.59it/s] 21%|██▏       | 377/1759 [00:08<00:30, 44.75it/s] 22%|██▏       | 382/1759 [00:08<00:30, 44.79it/s] 22%|██▏       | 387/1759 [00:08<00:30, 44.93it/s] 22%|██▏       | 392/1759 [00:08<00:30, 44.97it/s] 23%|██▎       | 397/1759 [00:09<00:30, 45.13it/s] 23%|██▎       | 402/1759 [00:09<00:30, 45.16it/s] 23%|██▎       | 407/1759 [00:09<00:29, 45.10it/s] 23%|██▎       | 412/1759 [00:09<00:29, 45.06it/s] 24%|██▎       | 417/1759 [00:09<00:29, 45.00it/s] 24%|██▍       | 422/1759 [00:09<00:29, 45.04it/s] 24%|██▍       | 427/1759 [00:09<00:29, 45.00it/s] 25%|██▍       | 432/1759 [00:09<00:29, 45.04it/s] 25%|██▍       | 437/1759 [00:09<00:29, 45.06it/s] 25%|██▌       | 442/1759 [00:10<00:29, 45.16it/s] 25%|██▌       | 447/1759 [00:10<00:29, 45.18it/s] 26%|██▌       | 452/1759 [00:10<00:28, 45.14it/s] 26%|██▌       | 457/1759 [00:10<00:28, 45.04it/s] 26%|██▋       | 462/1759 [00:10<00:28, 45.02it/s] 27%|██▋       | 467/1759 [00:10<00:28, 45.03it/s] 27%|██▋       | 472/1759 [00:10<00:28, 45.09it/s] 27%|██▋       | 477/1759 [00:10<00:28, 44.92it/s] 27%|██▋       | 482/1759 [00:10<00:28, 45.01it/s] 28%|██▊       | 487/1759 [00:11<00:28, 45.04it/s] 28%|██▊       | 492/1759 [00:11<00:28, 45.17it/s] 28%|██▊       | 497/1759 [00:11<00:27, 45.18it/s] 29%|██▊       | 502/1759 [00:11<00:28, 44.45it/s] 29%|██▉       | 507/1759 [00:11<00:28, 44.62it/s] 29%|██▉       | 512/1759 [00:11<00:27, 44.75it/s] 29%|██▉       | 517/1759 [00:11<00:27, 44.80it/s] 30%|██▉       | 522/1759 [00:11<00:27, 44.87it/s] 30%|██▉       | 527/1759 [00:11<00:27, 44.97it/s] 30%|███       | 532/1759 [00:12<00:27, 45.06it/s] 31%|███       | 537/1759 [00:12<00:27, 44.99it/s] 31%|███       | 542/1759 [00:12<00:27, 44.93it/s] 31%|███       | 547/1759 [00:12<00:26, 44.95it/s] 31%|███▏      | 552/1759 [00:12<00:26, 44.97it/s] 32%|███▏      | 557/1759 [00:12<00:26, 45.04it/s] 32%|███▏      | 562/1759 [00:12<00:26, 44.99it/s] 32%|███▏      | 567/1759 [00:12<00:26, 45.02it/s] 33%|███▎      | 572/1759 [00:12<00:26, 45.06it/s] 33%|███▎      | 577/1759 [00:13<00:26, 45.09it/s] 33%|███▎      | 582/1759 [00:13<00:26, 45.11it/s] 33%|███▎      | 587/1759 [00:13<00:25, 45.15it/s] 34%|███▎      | 592/1759 [00:13<00:25, 45.20it/s] 34%|███▍      | 597/1759 [00:13<00:25, 45.25it/s] 34%|███▍      | 602/1759 [00:13<00:25, 45.09it/s] 35%|███▍      | 607/1759 [00:13<00:25, 45.18it/s] 35%|███▍      | 612/1759 [00:13<00:25, 45.18it/s] 35%|███▌      | 617/1759 [00:13<00:25, 45.23it/s] 35%|███▌      | 622/1759 [00:14<00:25, 45.29it/s] 36%|███▌      | 627/1759 [00:14<00:25, 45.22it/s] 36%|███▌      | 632/1759 [00:14<00:24, 45.23it/s] 36%|███▌      | 637/1759 [00:14<00:24, 45.20it/s] 36%|███▋      | 642/1759 [00:14<00:24, 45.25it/s] 37%|███▋      | 647/1759 [00:14<00:24, 45.17it/s] 37%|███▋      | 652/1759 [00:14<00:24, 45.14it/s] 37%|███▋      | 657/1759 [00:14<00:24, 45.20it/s] 38%|███▊      | 662/1759 [00:14<00:24, 45.27it/s] 38%|███▊      | 667/1759 [00:15<00:24, 45.28it/s] 38%|███▊      | 672/1759 [00:15<00:24, 45.25it/s] 38%|███▊      | 677/1759 [00:15<00:24, 44.20it/s] 39%|███▉      | 682/1759 [00:15<00:24, 44.59it/s] 39%|███▉      | 687/1759 [00:15<00:23, 44.84it/s] 39%|███▉      | 692/1759 [00:15<00:23, 44.87it/s] 40%|███▉      | 697/1759 [00:15<00:23, 44.99it/s] 40%|███▉      | 702/1759 [00:15<00:23, 45.04it/s] 40%|████      | 707/1759 [00:15<00:23, 45.20it/s] 40%|████      | 712/1759 [00:16<00:23, 45.13it/s] 41%|████      | 717/1759 [00:16<00:23, 45.10it/s] 41%|████      | 722/1759 [00:16<00:22, 45.12it/s] 41%|████▏     | 727/1759 [00:16<00:22, 45.26it/s] 42%|████▏     | 732/1759 [00:16<00:22, 45.26it/s] 42%|████▏     | 737/1759 [00:16<00:22, 45.20it/s] 42%|████▏     | 742/1759 [00:16<00:22, 45.15it/s] 42%|████▏     | 747/1759 [00:16<00:22, 45.27it/s] 43%|████▎     | 752/1759 [00:16<00:22, 45.29it/s] 43%|████▎     | 757/1759 [00:17<00:22, 45.26it/s] 43%|████▎     | 762/1759 [00:17<00:22, 45.19it/s] 44%|████▎     | 767/1759 [00:17<00:21, 45.14it/s] 44%|████▍     | 772/1759 [00:17<00:21, 45.31it/s] 44%|████▍     | 777/1759 [00:17<00:21, 45.26it/s] 44%|████▍     | 782/1759 [00:17<00:21, 45.18it/s] 45%|████▍     | 787/1759 [00:17<00:21, 45.14it/s] 45%|████▌     | 792/1759 [00:17<00:21, 45.28it/s] 45%|████▌     | 797/1759 [00:17<00:21, 45.26it/s] 46%|████▌     | 802/1759 [00:18<00:21, 45.25it/s] 46%|████▌     | 807/1759 [00:18<00:21, 45.24it/s] 46%|████▌     | 812/1759 [00:18<00:20, 45.16it/s] 46%|████▋     | 817/1759 [00:18<00:21, 43.92it/s] 47%|████▋     | 822/1759 [00:18<00:21, 44.38it/s] 47%|████▋     | 827/1759 [00:18<00:20, 44.56it/s] 47%|████▋     | 832/1759 [00:18<00:20, 44.77it/s] 48%|████▊     | 837/1759 [00:18<00:20, 44.94it/s] 48%|████▊     | 842/1759 [00:18<00:20, 45.06it/s] 48%|████▊     | 847/1759 [00:19<00:20, 45.08it/s] 48%|████▊     | 852/1759 [00:19<00:20, 45.15it/s] 49%|████▊     | 857/1759 [00:19<00:20, 44.94it/s] 49%|████▉     | 862/1759 [00:19<00:19, 45.01it/s] 49%|████▉     | 867/1759 [00:19<00:19, 45.08it/s] 50%|████▉     | 872/1759 [00:19<00:19, 45.19it/s] 50%|████▉     | 877/1759 [00:19<00:19, 45.27it/s] 50%|█████     | 882/1759 [00:19<00:19, 45.26it/s] 50%|█████     | 887/1759 [00:19<00:19, 45.31it/s] 51%|█████     | 892/1759 [00:20<00:19, 45.14it/s] 51%|█████     | 897/1759 [00:20<00:19, 45.19it/s] 51%|█████▏    | 902/1759 [00:20<00:19, 45.07it/s] 52%|█████▏    | 907/1759 [00:20<00:18, 45.10it/s] 52%|█████▏    | 912/1759 [00:20<00:18, 45.07it/s] 52%|█████▏    | 917/1759 [00:20<00:18, 45.23it/s] 52%|█████▏    | 922/1759 [00:20<00:18, 45.24it/s] 53%|█████▎    | 927/1759 [00:20<00:18, 45.26it/s] 53%|█████▎    | 932/1759 [00:20<00:18, 45.29it/s] 53%|█████▎    | 937/1759 [00:21<00:18, 45.22it/s] 54%|█████▎    | 942/1759 [00:21<00:18, 45.16it/s] 54%|█████▍    | 947/1759 [00:21<00:18, 45.05it/s] 54%|█████▍    | 952/1759 [00:21<00:18, 43.88it/s] 54%|█████▍    | 957/1759 [00:21<00:18, 44.36it/s] 55%|█████▍    | 962/1759 [00:21<00:17, 44.76it/s] 55%|█████▍    | 967/1759 [00:21<00:17, 44.86it/s] 55%|█████▌    | 972/1759 [00:21<00:17, 45.01it/s] 56%|█████▌    | 977/1759 [00:21<00:17, 45.04it/s] 56%|█████▌    | 982/1759 [00:22<00:17, 45.13it/s] 56%|█████▌    | 987/1759 [00:22<00:17, 45.07it/s] 56%|█████▋    | 992/1759 [00:22<00:17, 44.74it/s] 57%|█████▋    | 997/1759 [00:22<00:16, 44.83it/s] 57%|█████▋    | 1002/1759 [00:22<00:16, 45.06it/s] 57%|█████▋    | 1007/1759 [00:22<00:16, 45.30it/s] 58%|█████▊    | 1012/1759 [00:22<00:16, 45.39it/s] 58%|█████▊    | 1017/1759 [00:22<00:16, 45.36it/s] 58%|█████▊    | 1022/1759 [00:22<00:16, 45.35it/s] 58%|█████▊    | 1027/1759 [00:23<00:16, 45.26it/s] 59%|█████▊    | 1032/1759 [00:23<00:16, 45.09it/s] 59%|█████▉    | 1037/1759 [00:23<00:16, 44.80it/s] 59%|█████▉    | 1042/1759 [00:23<00:16, 44.80it/s] 60%|█████▉    | 1047/1759 [00:23<00:15, 44.90it/s] 60%|█████▉    | 1052/1759 [00:23<00:15, 45.10it/s] 60%|██████    | 1057/1759 [00:23<00:15, 45.18it/s] 60%|██████    | 1062/1759 [00:23<00:15, 45.34it/s] 61%|██████    | 1067/1759 [00:23<00:15, 45.39it/s] 61%|██████    | 1072/1759 [00:24<00:15, 45.43it/s] 61%|██████    | 1077/1759 [00:24<00:15, 45.24it/s] 62%|██████▏   | 1082/1759 [00:24<00:14, 45.21it/s] 62%|██████▏   | 1087/1759 [00:24<00:14, 45.07it/s] 62%|██████▏   | 1092/1759 [00:24<00:15, 44.26it/s] 62%|██████▏   | 1097/1759 [00:24<00:14, 44.51it/s] 63%|██████▎   | 1102/1759 [00:24<00:14, 44.82it/s] 63%|██████▎   | 1107/1759 [00:24<00:14, 45.02it/s] 63%|██████▎   | 1112/1759 [00:24<00:14, 45.16it/s] 64%|██████▎   | 1117/1759 [00:25<00:14, 45.12it/s] 64%|██████▍   | 1122/1759 [00:25<00:14, 45.09it/s] 64%|██████▍   | 1127/1759 [00:25<00:14, 45.08it/s] 64%|██████▍   | 1132/1759 [00:25<00:13, 44.98it/s] 65%|██████▍   | 1137/1759 [00:25<00:13, 44.89it/s] 65%|██████▍   | 1142/1759 [00:25<00:13, 45.04it/s] 65%|██████▌   | 1147/1759 [00:25<00:13, 45.19it/s] 65%|██████▌   | 1152/1759 [00:25<00:13, 45.20it/s] 66%|██████▌   | 1157/1759 [00:25<00:13, 45.12it/s] 66%|██████▌   | 1162/1759 [00:26<00:13, 45.23it/s] 66%|██████▋   | 1167/1759 [00:26<00:13, 45.20it/s] 67%|██████▋   | 1172/1759 [00:26<00:13, 45.08it/s] 67%|██████▋   | 1177/1759 [00:26<00:12, 44.90it/s] 67%|██████▋   | 1182/1759 [00:26<00:12, 44.92it/s] 67%|██████▋   | 1187/1759 [00:26<00:12, 45.06it/s] 68%|██████▊   | 1192/1759 [00:26<00:12, 45.18it/s] 68%|██████▊   | 1197/1759 [00:26<00:12, 45.25it/s] 68%|██████▊   | 1202/1759 [00:26<00:12, 45.32it/s] 69%|██████▊   | 1207/1759 [00:27<00:12, 45.30it/s] 69%|██████▉   | 1212/1759 [00:27<00:12, 45.27it/s] 69%|██████▉   | 1217/1759 [00:27<00:12, 45.11it/s] 69%|██████▉   | 1222/1759 [00:27<00:11, 45.00it/s] 70%|██████▉   | 1227/1759 [00:27<00:11, 44.98it/s] 70%|███████   | 1232/1759 [00:27<00:12, 42.54it/s] 70%|███████   | 1237/1759 [00:27<00:12, 43.49it/s] 71%|███████   | 1242/1759 [00:27<00:11, 44.09it/s] 71%|███████   | 1247/1759 [00:27<00:11, 44.60it/s] 71%|███████   | 1252/1759 [00:28<00:11, 44.86it/s] 71%|███████▏  | 1257/1759 [00:28<00:11, 44.99it/s] 72%|███████▏  | 1262/1759 [00:28<00:11, 44.95it/s] 72%|███████▏  | 1267/1759 [00:28<00:10, 44.83it/s] 72%|███████▏  | 1272/1759 [00:28<00:10, 44.69it/s] 73%|███████▎  | 1277/1759 [00:28<00:10, 44.68it/s] 73%|███████▎  | 1282/1759 [00:28<00:10, 44.94it/s] 73%|███████▎  | 1287/1759 [00:28<00:10, 45.03it/s] 73%|███████▎  | 1292/1759 [00:28<00:10, 45.26it/s] 74%|███████▎  | 1297/1759 [00:29<00:10, 45.33it/s] 74%|███████▍  | 1302/1759 [00:29<00:10, 45.33it/s] 74%|███████▍  | 1307/1759 [00:29<00:09, 45.20it/s] 75%|███████▍  | 1312/1759 [00:29<00:09, 45.03it/s] 75%|███████▍  | 1317/1759 [00:29<00:09, 44.79it/s] 75%|███████▌  | 1322/1759 [00:29<00:09, 44.76it/s] 75%|███████▌  | 1327/1759 [00:29<00:09, 44.92it/s] 76%|███████▌  | 1332/1759 [00:29<00:09, 45.12it/s] 76%|███████▌  | 1337/1759 [00:29<00:09, 45.27it/s] 76%|███████▋  | 1342/1759 [00:30<00:09, 45.33it/s] 77%|███████▋  | 1347/1759 [00:30<00:09, 45.34it/s] 77%|███████▋  | 1352/1759 [00:30<00:08, 45.24it/s] 77%|███████▋  | 1357/1759 [00:30<00:08, 45.06it/s] 77%|███████▋  | 1362/1759 [00:30<00:08, 44.89it/s] 78%|███████▊  | 1367/1759 [00:30<00:09, 42.49it/s] 78%|███████▊  | 1372/1759 [00:30<00:08, 43.32it/s] 78%|███████▊  | 1377/1759 [00:30<00:08, 44.03it/s] 79%|███████▊  | 1382/1759 [00:30<00:08, 44.45it/s] 79%|███████▉  | 1387/1759 [00:31<00:08, 44.74it/s] 79%|███████▉  | 1392/1759 [00:31<00:08, 45.00it/s] 79%|███████▉  | 1397/1759 [00:31<00:08, 45.13it/s] 80%|███████▉  | 1402/1759 [00:31<00:07, 45.14it/s] 80%|███████▉  | 1407/1759 [00:31<00:07, 44.72it/s] 80%|████████  | 1412/1759 [00:31<00:07, 44.75it/s] 81%|████████  | 1417/1759 [00:31<00:07, 44.85it/s] 81%|████████  | 1422/1759 [00:31<00:07, 45.01it/s] 81%|████████  | 1427/1759 [00:31<00:07, 45.14it/s] 81%|████████▏ | 1432/1759 [00:32<00:07, 45.27it/s] 82%|████████▏ | 1437/1759 [00:32<00:07, 45.32it/s] 82%|████████▏ | 1442/1759 [00:32<00:06, 45.42it/s] 82%|████████▏ | 1447/1759 [00:32<00:06, 45.16it/s] 83%|████████▎ | 1452/1759 [00:32<00:06, 44.98it/s] 83%|████████▎ | 1457/1759 [00:32<00:06, 44.99it/s] 83%|████████▎ | 1462/1759 [00:32<00:06, 44.77it/s] 83%|████████▎ | 1467/1759 [00:32<00:06, 45.02it/s] 84%|████████▎ | 1472/1759 [00:32<00:06, 45.07it/s] 84%|████████▍ | 1477/1759 [00:33<00:06, 45.17it/s] 84%|████████▍ | 1482/1759 [00:33<00:06, 45.26it/s] 85%|████████▍ | 1487/1759 [00:33<00:06, 45.18it/s] 85%|████████▍ | 1492/1759 [00:33<00:05, 45.05it/s] 85%|████████▌ | 1497/1759 [00:33<00:05, 44.93it/s] 85%|████████▌ | 1502/1759 [00:33<00:05, 44.95it/s] 86%|████████▌ | 1507/1759 [00:33<00:05, 44.97it/s] 86%|████████▌ | 1512/1759 [00:33<00:05, 45.04it/s] 86%|████████▌ | 1517/1759 [00:33<00:05, 45.17it/s] 87%|████████▋ | 1522/1759 [00:34<00:05, 45.24it/s] 87%|████████▋ | 1527/1759 [00:34<00:05, 45.23it/s] 87%|████████▋ | 1532/1759 [00:34<00:05, 45.20it/s] 87%|████████▋ | 1537/1759 [00:34<00:04, 45.06it/s] 88%|████████▊ | 1542/1759 [00:34<00:04, 44.96it/s] 88%|████████▊ | 1547/1759 [00:34<00:04, 44.99it/s] 88%|████████▊ | 1552/1759 [00:34<00:04, 44.91it/s] 89%|████████▊ | 1557/1759 [00:34<00:04, 45.01it/s] 89%|████████▉ | 1562/1759 [00:34<00:04, 45.19it/s] 89%|████████▉ | 1567/1759 [00:35<00:04, 45.25it/s] 89%|████████▉ | 1572/1759 [00:35<00:04, 45.18it/s] 90%|████████▉ | 1577/1759 [00:35<00:04, 45.24it/s] 90%|████████▉ | 1582/1759 [00:35<00:03, 45.17it/s] 90%|█████████ | 1587/1759 [00:35<00:03, 45.10it/s] 91%|█████████ | 1592/1759 [00:35<00:03, 45.04it/s] 91%|█████████ | 1597/1759 [00:35<00:03, 43.81it/s] 91%|█████████ | 1602/1759 [00:35<00:03, 44.29it/s] 91%|█████████▏| 1607/1759 [00:35<00:03, 44.52it/s] 92%|█████████▏| 1612/1759 [00:36<00:03, 44.81it/s] 92%|█████████▏| 1617/1759 [00:36<00:03, 44.83it/s] 92%|█████████▏| 1622/1759 [00:36<00:03, 44.85it/s] 92%|█████████▏| 1627/1759 [00:36<00:02, 44.97it/s] 93%|█████████▎| 1632/1759 [00:36<00:02, 44.88it/s] 93%|█████████▎| 1637/1759 [00:36<00:02, 44.80it/s] 93%|█████████▎| 1642/1759 [00:36<00:02, 44.87it/s] 94%|█████████▎| 1647/1759 [00:36<00:02, 45.03it/s] 94%|█████████▍| 1652/1759 [00:36<00:02, 45.18it/s] 94%|█████████▍| 1657/1759 [00:37<00:02, 45.14it/s] 94%|█████████▍| 1662/1759 [00:37<00:02, 45.15it/s] 95%|█████████▍| 1667/1759 [00:37<00:02, 45.02it/s] 95%|█████████▌| 1672/1759 [00:37<00:01, 45.04it/s] 95%|█████████▌| 1677/1759 [00:37<00:01, 44.93it/s] 96%|█████████▌| 1682/1759 [00:37<00:01, 44.81it/s] 96%|█████████▌| 1687/1759 [00:37<00:01, 44.98it/s] 96%|█████████▌| 1692/1759 [00:37<00:01, 40.67it/s] 96%|█████████▋| 1697/1759 [00:37<00:01, 42.01it/s] 97%|█████████▋| 1702/1759 [00:38<00:01, 43.02it/s] 97%|█████████▋| 1707/1759 [00:38<00:01, 43.72it/s] 97%|█████████▋| 1712/1759 [00:38<00:01, 44.27it/s] 98%|█████████▊| 1717/1759 [00:38<00:00, 44.70it/s] 98%|█████████▊| 1722/1759 [00:38<00:00, 44.75it/s] 98%|█████████▊| 1727/1759 [00:38<00:00, 44.75it/s] 98%|█████████▊| 1732/1759 [00:38<00:00, 44.51it/s] 99%|█████████▊| 1737/1759 [00:38<00:00, 44.50it/s] 99%|█████████▉| 1742/1759 [00:38<00:00, 44.59it/s] 99%|█████████▉| 1747/1759 [00:39<00:00, 44.84it/s]100%|█████████▉| 1752/1759 [00:39<00:00, 45.14it/s]100%|█████████▉| 1757/1759 [00:39<00:00, 45.30it/s]100%|██████████| 1759/1759 [00:39<00:00, 44.70it/s]
[INFO|trainer_pt_utils.py:908] 2023-08-29 08:27:22,742 >> ***** eval metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:27:22,742 >>   epoch                   =       4.97
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:27:22,742 >>   eval_loss               =     0.8741
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:27:22,742 >>   eval_runtime            = 0:00:39.37
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:27:22,742 >>   eval_samples            =      14067
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:27:22,742 >>   eval_samples_per_second =    357.287
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:27:22,742 >>   eval_steps_per_second   =     44.677
[INFO|trainer_pt_utils.py:913] 2023-08-29 08:27:22,742 >>   perplexity              =     2.3968
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:37,646 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:37,676 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:37,676 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:37,676 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:37,676 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 08:27:38,463 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 08:27:38,464 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:27:39,082 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 08:27:40,224 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:27:40,224 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:43,135 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:43,155 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:43,156 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:43,156 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:27:43,156 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 08:27:43,867 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 08:27:43,868 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:27:44,154 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 08:27:44,367 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:27:44,367 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-48
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-32
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-16
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-80
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/checkpoint-64
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl', 'labels': ['country', 'part of', 'platform', 'publisher', 'sport'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_in_all_single_is_eval_True.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_out_filter_all_single_is_eval_True.jsonl'}}
predict vocab size: 22024
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 22124, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.51it/s]Extractor Predicting: 2it [00:01,  1.57it/s]Extractor Predicting: 3it [00:01,  1.56it/s]Extractor Predicting: 4it [00:02,  1.63it/s]Extractor Predicting: 5it [00:03,  1.65it/s]Extractor Predicting: 6it [00:03,  1.66it/s]Extractor Predicting: 7it [00:04,  1.67it/s]Extractor Predicting: 8it [00:04,  1.65it/s]Extractor Predicting: 9it [00:05,  1.64it/s]Extractor Predicting: 10it [00:06,  1.59it/s]Extractor Predicting: 11it [00:06,  1.56it/s]Extractor Predicting: 12it [00:07,  1.54it/s]Extractor Predicting: 13it [00:08,  1.52it/s]Extractor Predicting: 14it [00:08,  1.50it/s]Extractor Predicting: 15it [00:09,  1.47it/s]Extractor Predicting: 16it [00:10,  1.47it/s]Extractor Predicting: 17it [00:10,  1.46it/s]Extractor Predicting: 18it [00:11,  1.46it/s]Extractor Predicting: 19it [00:12,  1.48it/s]Extractor Predicting: 20it [00:12,  1.48it/s]Extractor Predicting: 21it [00:13,  1.47it/s]Extractor Predicting: 22it [00:14,  1.47it/s]Extractor Predicting: 23it [00:15,  1.45it/s]Extractor Predicting: 24it [00:15,  1.48it/s]Extractor Predicting: 25it [00:16,  1.52it/s]Extractor Predicting: 26it [00:17,  1.51it/s]Extractor Predicting: 27it [00:17,  1.51it/s]Extractor Predicting: 28it [00:18,  1.57it/s]Extractor Predicting: 29it [00:18,  1.61it/s]Extractor Predicting: 30it [00:19,  1.61it/s]Extractor Predicting: 31it [00:20,  1.63it/s]Extractor Predicting: 32it [00:20,  1.59it/s]Extractor Predicting: 33it [00:21,  1.61it/s]Extractor Predicting: 34it [00:21,  1.62it/s]Extractor Predicting: 35it [00:22,  1.64it/s]Extractor Predicting: 36it [00:23,  1.62it/s]Extractor Predicting: 37it [00:23,  1.63it/s]Extractor Predicting: 38it [00:24,  1.65it/s]Extractor Predicting: 39it [00:24,  1.63it/s]Extractor Predicting: 40it [00:25,  1.64it/s]Extractor Predicting: 41it [00:26,  1.56it/s]Extractor Predicting: 42it [00:26,  1.60it/s]Extractor Predicting: 43it [00:27,  1.63it/s]Extractor Predicting: 44it [00:28,  1.64it/s]Extractor Predicting: 45it [00:28,  1.65it/s]Extractor Predicting: 46it [00:29,  1.66it/s]Extractor Predicting: 47it [00:29,  1.66it/s]Extractor Predicting: 48it [00:30,  1.63it/s]Extractor Predicting: 49it [00:31,  1.68it/s]Extractor Predicting: 50it [00:31,  1.65it/s]Extractor Predicting: 51it [00:32,  1.67it/s]Extractor Predicting: 52it [00:32,  1.67it/s]Extractor Predicting: 53it [00:33,  1.68it/s]Extractor Predicting: 54it [00:34,  1.70it/s]Extractor Predicting: 55it [00:34,  1.69it/s]Extractor Predicting: 56it [00:35,  1.68it/s]Extractor Predicting: 57it [00:35,  1.65it/s]Extractor Predicting: 58it [00:36,  1.62it/s]Extractor Predicting: 59it [00:37,  1.61it/s]Extractor Predicting: 60it [00:37,  1.64it/s]Extractor Predicting: 61it [00:38,  1.65it/s]Extractor Predicting: 62it [00:38,  1.62it/s]Extractor Predicting: 63it [00:39,  1.63it/s]Extractor Predicting: 64it [00:40,  1.62it/s]Extractor Predicting: 65it [00:40,  1.60it/s]Extractor Predicting: 66it [00:41,  1.56it/s]Extractor Predicting: 67it [00:42,  1.41it/s]Extractor Predicting: 68it [00:43,  1.42it/s]Extractor Predicting: 69it [00:43,  1.50it/s]Extractor Predicting: 70it [00:44,  1.56it/s]Extractor Predicting: 71it [00:44,  1.58it/s]Extractor Predicting: 72it [00:45,  1.56it/s]Extractor Predicting: 73it [00:46,  1.55it/s]Extractor Predicting: 74it [00:46,  1.55it/s]Extractor Predicting: 75it [00:47,  1.54it/s]Extractor Predicting: 76it [00:48,  1.53it/s]Extractor Predicting: 77it [00:48,  1.53it/s]Extractor Predicting: 78it [00:49,  1.61it/s]Extractor Predicting: 79it [00:49,  1.58it/s]Extractor Predicting: 80it [00:50,  1.59it/s]Extractor Predicting: 81it [00:51,  1.59it/s]Extractor Predicting: 82it [00:51,  1.60it/s]Extractor Predicting: 83it [00:52,  1.62it/s]Extractor Predicting: 84it [00:53,  1.67it/s]Extractor Predicting: 85it [00:53,  1.65it/s]Extractor Predicting: 86it [00:54,  1.62it/s]Extractor Predicting: 87it [00:54,  1.61it/s]Extractor Predicting: 88it [00:55,  1.52it/s]Extractor Predicting: 89it [00:56,  1.58it/s]Extractor Predicting: 90it [00:56,  1.58it/s]Extractor Predicting: 91it [00:57,  1.61it/s]Extractor Predicting: 92it [00:58,  1.56it/s]Extractor Predicting: 93it [00:58,  1.52it/s]Extractor Predicting: 94it [00:59,  1.55it/s]Extractor Predicting: 95it [01:00,  1.61it/s]Extractor Predicting: 96it [01:00,  1.63it/s]Extractor Predicting: 97it [01:01,  1.69it/s]Extractor Predicting: 98it [01:01,  1.73it/s]Extractor Predicting: 99it [01:02,  1.68it/s]Extractor Predicting: 100it [01:02,  1.77it/s]Extractor Predicting: 101it [01:03,  1.72it/s]Extractor Predicting: 102it [01:04,  1.69it/s]Extractor Predicting: 103it [01:04,  1.70it/s]Extractor Predicting: 104it [01:05,  1.71it/s]Extractor Predicting: 105it [01:05,  1.74it/s]Extractor Predicting: 106it [01:06,  1.72it/s]Extractor Predicting: 107it [01:07,  1.68it/s]Extractor Predicting: 108it [01:07,  1.67it/s]Extractor Predicting: 109it [01:08,  1.67it/s]Extractor Predicting: 110it [01:08,  1.67it/s]Extractor Predicting: 111it [01:09,  1.70it/s]Extractor Predicting: 112it [01:09,  1.71it/s]Extractor Predicting: 113it [01:10,  1.72it/s]Extractor Predicting: 114it [01:11,  1.75it/s]Extractor Predicting: 115it [01:11,  1.74it/s]Extractor Predicting: 116it [01:12,  1.74it/s]Extractor Predicting: 117it [01:12,  1.73it/s]Extractor Predicting: 118it [01:13,  1.74it/s]Extractor Predicting: 119it [01:13,  1.74it/s]Extractor Predicting: 120it [01:14,  1.78it/s]Extractor Predicting: 121it [01:15,  1.75it/s]Extractor Predicting: 122it [01:15,  1.71it/s]Extractor Predicting: 123it [01:16,  1.70it/s]Extractor Predicting: 124it [01:16,  1.69it/s]Extractor Predicting: 125it [01:17,  1.69it/s]Extractor Predicting: 126it [01:18,  1.70it/s]Extractor Predicting: 127it [01:18,  1.76it/s]Extractor Predicting: 128it [01:19,  1.75it/s]Extractor Predicting: 129it [01:19,  1.76it/s]Extractor Predicting: 130it [01:20,  1.75it/s]Extractor Predicting: 131it [01:20,  1.73it/s]Extractor Predicting: 132it [01:21,  1.76it/s]Extractor Predicting: 133it [01:22,  1.71it/s]Extractor Predicting: 134it [01:22,  1.73it/s]Extractor Predicting: 135it [01:23,  1.73it/s]Extractor Predicting: 136it [01:23,  1.72it/s]Extractor Predicting: 137it [01:24,  1.72it/s]Extractor Predicting: 138it [01:24,  1.71it/s]Extractor Predicting: 139it [01:25,  1.70it/s]Extractor Predicting: 140it [01:26,  1.69it/s]Extractor Predicting: 141it [01:26,  1.71it/s]Extractor Predicting: 142it [01:27,  1.74it/s]Extractor Predicting: 143it [01:27,  1.75it/s]Extractor Predicting: 144it [01:28,  1.75it/s]Extractor Predicting: 145it [01:29,  1.69it/s]Extractor Predicting: 146it [01:29,  1.67it/s]Extractor Predicting: 147it [01:30,  1.68it/s]Extractor Predicting: 148it [01:30,  1.66it/s]Extractor Predicting: 149it [01:31,  1.65it/s]Extractor Predicting: 150it [01:32,  1.66it/s]Extractor Predicting: 151it [01:32,  1.59it/s]Extractor Predicting: 152it [01:33,  1.55it/s]Extractor Predicting: 153it [01:34,  1.51it/s]Extractor Predicting: 154it [01:34,  1.47it/s]Extractor Predicting: 155it [01:35,  1.49it/s]Extractor Predicting: 156it [01:36,  1.49it/s]Extractor Predicting: 157it [01:36,  1.54it/s]Extractor Predicting: 158it [01:37,  1.53it/s]Extractor Predicting: 159it [01:38,  1.55it/s]Extractor Predicting: 160it [01:38,  1.59it/s]Extractor Predicting: 161it [01:39,  1.61it/s]Extractor Predicting: 162it [01:39,  1.60it/s]Extractor Predicting: 163it [01:40,  1.59it/s]Extractor Predicting: 164it [01:41,  1.62it/s]Extractor Predicting: 165it [01:41,  1.61it/s]Extractor Predicting: 166it [01:42,  1.58it/s]Extractor Predicting: 167it [01:43,  1.59it/s]Extractor Predicting: 168it [01:43,  1.58it/s]Extractor Predicting: 169it [01:44,  1.61it/s]Extractor Predicting: 170it [01:44,  1.64it/s]Extractor Predicting: 171it [01:45,  1.66it/s]Extractor Predicting: 172it [01:46,  1.64it/s]Extractor Predicting: 173it [01:46,  1.68it/s]Extractor Predicting: 174it [01:47,  1.67it/s]Extractor Predicting: 175it [01:47,  1.64it/s]Extractor Predicting: 176it [01:48,  1.61it/s]Extractor Predicting: 177it [01:49,  1.59it/s]Extractor Predicting: 178it [01:49,  1.66it/s]Extractor Predicting: 179it [01:50,  1.78it/s]Extractor Predicting: 180it [01:50,  1.87it/s]Extractor Predicting: 181it [01:51,  1.85it/s]Extractor Predicting: 182it [01:51,  1.85it/s]Extractor Predicting: 183it [01:52,  1.72it/s]Extractor Predicting: 184it [01:53,  1.64it/s]Extractor Predicting: 185it [01:54,  1.44it/s]Extractor Predicting: 186it [01:54,  1.48it/s]Extractor Predicting: 187it [01:55,  1.50it/s]Extractor Predicting: 188it [01:55,  1.51it/s]Extractor Predicting: 189it [01:56,  1.54it/s]Extractor Predicting: 190it [01:57,  1.54it/s]Extractor Predicting: 191it [01:57,  1.54it/s]Extractor Predicting: 192it [01:58,  1.55it/s]Extractor Predicting: 193it [01:59,  1.63it/s]Extractor Predicting: 194it [01:59,  1.65it/s]Extractor Predicting: 195it [02:00,  1.68it/s]Extractor Predicting: 196it [02:00,  1.65it/s]Extractor Predicting: 197it [02:01,  1.64it/s]Extractor Predicting: 198it [02:02,  1.59it/s]Extractor Predicting: 199it [02:02,  1.59it/s]Extractor Predicting: 200it [02:03,  1.62it/s]Extractor Predicting: 201it [02:03,  1.62it/s]Extractor Predicting: 202it [02:04,  1.61it/s]Extractor Predicting: 203it [02:05,  1.61it/s]Extractor Predicting: 204it [02:05,  1.63it/s]Extractor Predicting: 205it [02:06,  1.65it/s]Extractor Predicting: 206it [02:07,  1.65it/s]Extractor Predicting: 207it [02:07,  1.64it/s]Extractor Predicting: 208it [02:08,  1.65it/s]Extractor Predicting: 209it [02:08,  1.63it/s]Extractor Predicting: 210it [02:09,  1.65it/s]Extractor Predicting: 211it [02:10,  1.63it/s]Extractor Predicting: 212it [02:10,  1.59it/s]Extractor Predicting: 213it [02:11,  1.58it/s]Extractor Predicting: 214it [02:12,  1.58it/s]Extractor Predicting: 215it [02:12,  1.61it/s]Extractor Predicting: 216it [02:13,  1.60it/s]Extractor Predicting: 217it [02:13,  1.64it/s]Extractor Predicting: 218it [02:14,  1.66it/s]Extractor Predicting: 219it [02:15,  1.65it/s]Extractor Predicting: 220it [02:15,  1.66it/s]Extractor Predicting: 221it [02:16,  1.66it/s]Extractor Predicting: 222it [02:16,  1.66it/s]Extractor Predicting: 223it [02:17,  1.63it/s]Extractor Predicting: 224it [02:18,  1.59it/s]Extractor Predicting: 225it [02:18,  1.59it/s]Extractor Predicting: 226it [02:19,  1.60it/s]Extractor Predicting: 227it [02:19,  1.61it/s]Extractor Predicting: 228it [02:20,  1.58it/s]Extractor Predicting: 229it [02:21,  1.59it/s]Extractor Predicting: 230it [02:21,  1.58it/s]Extractor Predicting: 231it [02:22,  1.57it/s]Extractor Predicting: 232it [02:23,  1.61it/s]Extractor Predicting: 233it [02:23,  1.57it/s]Extractor Predicting: 234it [02:24,  1.55it/s]Extractor Predicting: 235it [02:25,  1.58it/s]Extractor Predicting: 236it [02:25,  1.58it/s]Extractor Predicting: 237it [02:26,  1.59it/s]Extractor Predicting: 238it [02:26,  1.56it/s]Extractor Predicting: 239it [02:27,  1.59it/s]Extractor Predicting: 240it [02:28,  1.60it/s]Extractor Predicting: 241it [02:28,  1.61it/s]Extractor Predicting: 242it [02:29,  1.58it/s]Extractor Predicting: 243it [02:30,  1.60it/s]Extractor Predicting: 244it [02:30,  1.60it/s]Extractor Predicting: 245it [02:31,  1.56it/s]Extractor Predicting: 246it [02:31,  1.60it/s]Extractor Predicting: 247it [02:32,  1.63it/s]Extractor Predicting: 248it [02:33,  1.58it/s]Extractor Predicting: 249it [02:33,  1.58it/s]Extractor Predicting: 250it [02:34,  1.63it/s]Extractor Predicting: 251it [02:35,  1.65it/s]Extractor Predicting: 252it [02:35,  1.69it/s]Extractor Predicting: 253it [02:36,  1.68it/s]Extractor Predicting: 254it [02:36,  1.68it/s]Extractor Predicting: 255it [02:37,  1.65it/s]Extractor Predicting: 256it [02:38,  1.64it/s]Extractor Predicting: 257it [02:38,  1.64it/s]Extractor Predicting: 258it [02:39,  1.64it/s]Extractor Predicting: 259it [02:39,  1.63it/s]Extractor Predicting: 260it [02:40,  1.64it/s]Extractor Predicting: 261it [02:41,  1.67it/s]Extractor Predicting: 262it [02:41,  1.71it/s]Extractor Predicting: 263it [02:42,  1.70it/s]Extractor Predicting: 264it [02:42,  1.69it/s]Extractor Predicting: 265it [02:43,  1.68it/s]Extractor Predicting: 266it [02:44,  1.68it/s]Extractor Predicting: 267it [02:44,  1.66it/s]Extractor Predicting: 268it [02:45,  1.63it/s]Extractor Predicting: 269it [02:45,  1.64it/s]Extractor Predicting: 270it [02:46,  1.59it/s]Extractor Predicting: 271it [02:47,  1.62it/s]Extractor Predicting: 272it [02:47,  1.65it/s]Extractor Predicting: 273it [02:48,  1.65it/s]Extractor Predicting: 274it [02:48,  1.66it/s]Extractor Predicting: 275it [02:49,  1.63it/s]Extractor Predicting: 276it [02:50,  1.66it/s]Extractor Predicting: 277it [02:50,  1.66it/s]Extractor Predicting: 278it [02:51,  1.66it/s]Extractor Predicting: 279it [02:51,  1.63it/s]Extractor Predicting: 280it [02:52,  1.61it/s]Extractor Predicting: 281it [02:53,  1.60it/s]Extractor Predicting: 282it [02:53,  1.59it/s]Extractor Predicting: 283it [02:54,  1.59it/s]Extractor Predicting: 284it [02:55,  1.64it/s]Extractor Predicting: 285it [02:55,  1.61it/s]Extractor Predicting: 286it [02:56,  1.59it/s]Extractor Predicting: 287it [02:57,  1.57it/s]Extractor Predicting: 288it [02:57,  1.59it/s]Extractor Predicting: 289it [02:58,  1.55it/s]Extractor Predicting: 290it [02:58,  1.55it/s]Extractor Predicting: 291it [02:59,  1.57it/s]Extractor Predicting: 292it [03:00,  1.56it/s]Extractor Predicting: 293it [03:00,  1.57it/s]Extractor Predicting: 294it [03:01,  1.59it/s]Extractor Predicting: 295it [03:02,  1.59it/s]Extractor Predicting: 296it [03:02,  1.59it/s]Extractor Predicting: 297it [03:03,  1.58it/s]Extractor Predicting: 298it [03:03,  1.62it/s]Extractor Predicting: 299it [03:04,  1.59it/s]Extractor Predicting: 300it [03:05,  1.55it/s]Extractor Predicting: 301it [03:05,  1.55it/s]Extractor Predicting: 302it [03:06,  1.58it/s]Extractor Predicting: 303it [03:07,  1.60it/s]Extractor Predicting: 304it [03:07,  1.61it/s]Extractor Predicting: 305it [03:08,  1.63it/s]Extractor Predicting: 306it [03:09,  1.60it/s]Extractor Predicting: 307it [03:09,  1.62it/s]Extractor Predicting: 308it [03:10,  1.64it/s]Extractor Predicting: 309it [03:10,  1.61it/s]Extractor Predicting: 310it [03:11,  1.55it/s]Extractor Predicting: 311it [03:12,  1.50it/s]Extractor Predicting: 312it [03:12,  1.48it/s]Extractor Predicting: 313it [03:13,  1.46it/s]Extractor Predicting: 314it [03:14,  1.44it/s]Extractor Predicting: 315it [03:15,  1.42it/s]Extractor Predicting: 316it [03:15,  1.41it/s]Extractor Predicting: 317it [03:16,  1.42it/s]Extractor Predicting: 318it [03:17,  1.42it/s]Extractor Predicting: 319it [03:17,  1.42it/s]Extractor Predicting: 320it [03:18,  1.42it/s]Extractor Predicting: 321it [03:19,  1.26it/s]Extractor Predicting: 322it [03:20,  1.29it/s]Extractor Predicting: 323it [03:21,  1.33it/s]Extractor Predicting: 324it [03:21,  1.37it/s]Extractor Predicting: 325it [03:22,  1.38it/s]Extractor Predicting: 326it [03:23,  1.40it/s]Extractor Predicting: 327it [03:23,  1.47it/s]Extractor Predicting: 328it [03:24,  1.49it/s]Extractor Predicting: 329it [03:25,  1.52it/s]Extractor Predicting: 330it [03:25,  1.57it/s]Extractor Predicting: 331it [03:26,  1.59it/s]Extractor Predicting: 332it [03:26,  1.62it/s]Extractor Predicting: 333it [03:27,  1.59it/s]Extractor Predicting: 334it [03:28,  1.57it/s]Extractor Predicting: 335it [03:28,  1.58it/s]Extractor Predicting: 336it [03:29,  1.55it/s]Extractor Predicting: 337it [03:29,  1.60it/s]Extractor Predicting: 338it [03:30,  1.60it/s]Extractor Predicting: 339it [03:31,  1.60it/s]Extractor Predicting: 340it [03:31,  1.57it/s]Extractor Predicting: 341it [03:32,  1.53it/s]Extractor Predicting: 342it [03:33,  1.54it/s]Extractor Predicting: 343it [03:33,  1.54it/s]Extractor Predicting: 344it [03:34,  1.51it/s]Extractor Predicting: 345it [03:35,  1.50it/s]Extractor Predicting: 346it [03:35,  1.47it/s]Extractor Predicting: 347it [03:36,  1.47it/s]Extractor Predicting: 348it [03:37,  1.48it/s]Extractor Predicting: 349it [03:37,  1.50it/s]Extractor Predicting: 350it [03:38,  1.48it/s]Extractor Predicting: 351it [03:39,  1.50it/s]Extractor Predicting: 352it [03:39,  1.51it/s]Extractor Predicting: 353it [03:40,  1.50it/s]Extractor Predicting: 354it [03:41,  1.48it/s]Extractor Predicting: 355it [03:41,  1.51it/s]Extractor Predicting: 356it [03:42,  1.52it/s]Extractor Predicting: 357it [03:43,  1.54it/s]Extractor Predicting: 358it [03:43,  1.53it/s]Extractor Predicting: 359it [03:44,  1.51it/s]Extractor Predicting: 360it [03:45,  1.54it/s]Extractor Predicting: 361it [03:45,  1.56it/s]Extractor Predicting: 362it [03:46,  1.56it/s]Extractor Predicting: 363it [03:47,  1.56it/s]Extractor Predicting: 364it [03:47,  1.55it/s]Extractor Predicting: 365it [03:48,  1.61it/s]Extractor Predicting: 366it [03:48,  1.58it/s]Extractor Predicting: 367it [03:49,  1.57it/s]Extractor Predicting: 368it [03:50,  1.56it/s]Extractor Predicting: 369it [03:50,  1.55it/s]Extractor Predicting: 370it [03:51,  1.58it/s]Extractor Predicting: 371it [03:52,  1.56it/s]Extractor Predicting: 372it [03:52,  1.56it/s]Extractor Predicting: 373it [03:53,  1.54it/s]Extractor Predicting: 374it [03:54,  1.57it/s]Extractor Predicting: 375it [03:54,  1.58it/s]Extractor Predicting: 376it [03:55,  1.61it/s]Extractor Predicting: 377it [03:55,  1.60it/s]Extractor Predicting: 378it [03:56,  1.58it/s]Extractor Predicting: 379it [03:57,  1.55it/s]Extractor Predicting: 380it [03:57,  1.55it/s]Extractor Predicting: 381it [03:58,  1.56it/s]Extractor Predicting: 382it [03:59,  1.56it/s]Extractor Predicting: 383it [03:59,  1.57it/s]Extractor Predicting: 384it [04:00,  1.57it/s]Extractor Predicting: 385it [04:01,  1.59it/s]Extractor Predicting: 386it [04:01,  1.59it/s]Extractor Predicting: 387it [04:02,  1.57it/s]Extractor Predicting: 388it [04:03,  1.56it/s]Extractor Predicting: 389it [04:03,  1.60it/s]Extractor Predicting: 390it [04:04,  1.61it/s]Extractor Predicting: 391it [04:04,  1.61it/s]Extractor Predicting: 392it [04:05,  1.64it/s]Extractor Predicting: 393it [04:06,  1.63it/s]Extractor Predicting: 394it [04:06,  1.62it/s]Extractor Predicting: 395it [04:07,  1.63it/s]Extractor Predicting: 396it [04:07,  1.60it/s]Extractor Predicting: 397it [04:08,  1.61it/s]Extractor Predicting: 398it [04:09,  1.64it/s]Extractor Predicting: 399it [04:09,  1.64it/s]Extractor Predicting: 400it [04:10,  1.60it/s]Extractor Predicting: 401it [04:11,  1.56it/s]Extractor Predicting: 402it [04:11,  1.52it/s]Extractor Predicting: 403it [04:12,  1.54it/s]Extractor Predicting: 404it [04:13,  1.58it/s]Extractor Predicting: 405it [04:13,  1.58it/s]Extractor Predicting: 406it [04:14,  1.59it/s]Extractor Predicting: 407it [04:14,  1.62it/s]Extractor Predicting: 408it [04:15,  1.67it/s]Extractor Predicting: 409it [04:15,  1.70it/s]Extractor Predicting: 410it [04:16,  1.70it/s]Extractor Predicting: 411it [04:17,  1.70it/s]Extractor Predicting: 412it [04:17,  1.72it/s]Extractor Predicting: 413it [04:18,  1.76it/s]Extractor Predicting: 414it [04:18,  1.78it/s]Extractor Predicting: 415it [04:19,  1.69it/s]Extractor Predicting: 416it [04:20,  1.60it/s]Extractor Predicting: 417it [04:20,  1.53it/s]Extractor Predicting: 418it [04:21,  1.50it/s]Extractor Predicting: 419it [04:22,  1.47it/s]Extractor Predicting: 420it [04:22,  1.47it/s]Extractor Predicting: 421it [04:23,  1.45it/s]Extractor Predicting: 422it [04:24,  1.68it/s]Extractor Predicting: 422it [04:24,  1.60it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:23,172 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:23,194 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:23,194 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:23,194 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:23,194 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 08:32:23,838 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 08:32:23,839 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:32:24,447 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 08:32:25,537 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:32:25,537 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:28,531 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:28,573 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:28,573 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:28,573 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:32:28,573 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 08:32:29,390 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 08:32:29,391 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:32:30,069 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 08:32:30,334 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:32:30,334 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_out_filter_all_single_is_eval_True.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_in_all_single_is_eval_True.jsonl",
  "precision": 0.19645085262720088,
  "recall": 0.10073221013720055,
  "score": 0.1331766917293233,
  "mode": "all_single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/results_all_single_is_eval_True.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_in_single_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_out_filter_single_is_eval_False.jsonl'}}
predict vocab size: 13679
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 13779, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.55it/s]Extractor Predicting: 2it [00:01,  1.54it/s]Extractor Predicting: 3it [00:01,  1.56it/s]Extractor Predicting: 4it [00:02,  1.59it/s]Extractor Predicting: 5it [00:03,  1.56it/s]Extractor Predicting: 6it [00:03,  1.60it/s]Extractor Predicting: 7it [00:04,  1.62it/s]Extractor Predicting: 8it [00:05,  1.61it/s]Extractor Predicting: 9it [00:05,  1.59it/s]Extractor Predicting: 10it [00:06,  1.60it/s]Extractor Predicting: 11it [00:06,  1.61it/s]Extractor Predicting: 12it [00:07,  1.60it/s]Extractor Predicting: 13it [00:08,  1.61it/s]Extractor Predicting: 14it [00:08,  1.59it/s]Extractor Predicting: 15it [00:09,  1.61it/s]Extractor Predicting: 16it [00:09,  1.65it/s]Extractor Predicting: 17it [00:10,  1.64it/s]Extractor Predicting: 18it [00:11,  1.62it/s]Extractor Predicting: 19it [00:11,  1.61it/s]Extractor Predicting: 20it [00:12,  1.62it/s]Extractor Predicting: 21it [00:13,  1.62it/s]Extractor Predicting: 22it [00:13,  1.60it/s]Extractor Predicting: 23it [00:14,  1.58it/s]Extractor Predicting: 24it [00:14,  1.60it/s]Extractor Predicting: 25it [00:15,  1.62it/s]Extractor Predicting: 26it [00:16,  1.61it/s]Extractor Predicting: 27it [00:16,  1.63it/s]Extractor Predicting: 28it [00:17,  1.60it/s]Extractor Predicting: 29it [00:18,  1.62it/s]Extractor Predicting: 30it [00:18,  1.61it/s]Extractor Predicting: 31it [00:19,  1.47it/s]Extractor Predicting: 32it [00:20,  1.51it/s]Extractor Predicting: 33it [00:20,  1.54it/s]Extractor Predicting: 34it [00:21,  1.55it/s]Extractor Predicting: 35it [00:22,  1.55it/s]Extractor Predicting: 36it [00:22,  1.56it/s]Extractor Predicting: 37it [00:23,  1.57it/s]Extractor Predicting: 38it [00:23,  1.58it/s]Extractor Predicting: 39it [00:24,  1.57it/s]Extractor Predicting: 40it [00:25,  1.58it/s]Extractor Predicting: 41it [00:25,  1.57it/s]Extractor Predicting: 42it [00:26,  1.59it/s]Extractor Predicting: 43it [00:27,  1.63it/s]Extractor Predicting: 44it [00:27,  1.62it/s]Extractor Predicting: 45it [00:28,  1.59it/s]Extractor Predicting: 46it [00:29,  1.53it/s]Extractor Predicting: 47it [00:29,  1.54it/s]Extractor Predicting: 48it [00:30,  1.56it/s]Extractor Predicting: 49it [00:30,  1.55it/s]Extractor Predicting: 50it [00:31,  1.55it/s]Extractor Predicting: 51it [00:32,  1.54it/s]Extractor Predicting: 52it [00:32,  1.53it/s]Extractor Predicting: 53it [00:33,  1.55it/s]Extractor Predicting: 54it [00:34,  1.52it/s]Extractor Predicting: 55it [00:34,  1.52it/s]Extractor Predicting: 56it [00:35,  1.52it/s]Extractor Predicting: 57it [00:36,  1.52it/s]Extractor Predicting: 58it [00:36,  1.52it/s]Extractor Predicting: 59it [00:37,  1.52it/s]Extractor Predicting: 60it [00:38,  1.55it/s]Extractor Predicting: 61it [00:38,  1.55it/s]Extractor Predicting: 62it [00:39,  1.54it/s]Extractor Predicting: 63it [00:40,  1.53it/s]Extractor Predicting: 64it [00:40,  1.58it/s]Extractor Predicting: 65it [00:41,  1.62it/s]Extractor Predicting: 66it [00:41,  1.62it/s]Extractor Predicting: 67it [00:42,  1.61it/s]Extractor Predicting: 68it [00:43,  1.61it/s]Extractor Predicting: 69it [00:43,  1.62it/s]Extractor Predicting: 70it [00:44,  1.59it/s]Extractor Predicting: 71it [00:45,  1.58it/s]Extractor Predicting: 72it [00:45,  1.59it/s]Extractor Predicting: 73it [00:46,  1.59it/s]Extractor Predicting: 74it [00:46,  1.59it/s]Extractor Predicting: 75it [00:47,  1.59it/s]Extractor Predicting: 76it [00:48,  1.58it/s]Extractor Predicting: 77it [00:48,  1.63it/s]Extractor Predicting: 78it [00:49,  1.63it/s]Extractor Predicting: 79it [00:49,  1.62it/s]Extractor Predicting: 80it [00:50,  1.61it/s]Extractor Predicting: 81it [00:51,  1.64it/s]Extractor Predicting: 82it [00:51,  1.61it/s]Extractor Predicting: 83it [00:52,  1.58it/s]Extractor Predicting: 84it [00:53,  1.58it/s]Extractor Predicting: 85it [00:53,  1.57it/s]Extractor Predicting: 86it [00:54,  1.57it/s]Extractor Predicting: 87it [00:55,  1.61it/s]Extractor Predicting: 88it [00:55,  1.56it/s]Extractor Predicting: 89it [00:56,  1.56it/s]Extractor Predicting: 90it [00:56,  1.56it/s]Extractor Predicting: 91it [00:57,  1.59it/s]Extractor Predicting: 92it [00:58,  1.63it/s]Extractor Predicting: 93it [00:58,  1.63it/s]Extractor Predicting: 94it [00:59,  1.64it/s]Extractor Predicting: 95it [00:59,  1.62it/s]Extractor Predicting: 96it [01:00,  1.61it/s]Extractor Predicting: 97it [01:01,  1.64it/s]Extractor Predicting: 98it [01:01,  1.64it/s]Extractor Predicting: 99it [01:02,  1.65it/s]Extractor Predicting: 100it [01:03,  1.63it/s]Extractor Predicting: 101it [01:03,  1.59it/s]Extractor Predicting: 102it [01:04,  1.58it/s]Extractor Predicting: 103it [01:05,  1.57it/s]Extractor Predicting: 104it [01:05,  1.46it/s]Extractor Predicting: 105it [01:06,  1.49it/s]Extractor Predicting: 106it [01:07,  1.51it/s]Extractor Predicting: 107it [01:07,  1.56it/s]Extractor Predicting: 108it [01:08,  1.60it/s]Extractor Predicting: 109it [01:08,  1.60it/s]Extractor Predicting: 110it [01:09,  1.63it/s]Extractor Predicting: 111it [01:10,  1.63it/s]Extractor Predicting: 112it [01:10,  1.61it/s]Extractor Predicting: 113it [01:11,  1.60it/s]Extractor Predicting: 114it [01:11,  1.62it/s]Extractor Predicting: 115it [01:12,  1.62it/s]Extractor Predicting: 116it [01:13,  1.62it/s]Extractor Predicting: 117it [01:13,  1.67it/s]Extractor Predicting: 118it [01:14,  1.64it/s]Extractor Predicting: 119it [01:14,  1.64it/s]Extractor Predicting: 120it [01:15,  1.68it/s]Extractor Predicting: 121it [01:16,  1.68it/s]Extractor Predicting: 122it [01:16,  1.65it/s]Extractor Predicting: 123it [01:17,  1.65it/s]Extractor Predicting: 124it [01:18,  1.63it/s]Extractor Predicting: 125it [01:18,  1.58it/s]Extractor Predicting: 126it [01:19,  1.59it/s]Extractor Predicting: 127it [01:19,  1.62it/s]Extractor Predicting: 128it [01:20,  1.63it/s]Extractor Predicting: 129it [01:21,  1.64it/s]Extractor Predicting: 130it [01:21,  1.62it/s]Extractor Predicting: 131it [01:22,  1.59it/s]Extractor Predicting: 132it [01:23,  1.60it/s]Extractor Predicting: 133it [01:23,  1.61it/s]Extractor Predicting: 134it [01:24,  1.59it/s]Extractor Predicting: 135it [01:24,  1.61it/s]Extractor Predicting: 136it [01:25,  1.64it/s]Extractor Predicting: 137it [01:26,  1.65it/s]Extractor Predicting: 138it [01:26,  1.62it/s]Extractor Predicting: 139it [01:27,  1.61it/s]Extractor Predicting: 140it [01:27,  1.65it/s]Extractor Predicting: 141it [01:28,  1.67it/s]Extractor Predicting: 142it [01:29,  1.69it/s]Extractor Predicting: 143it [01:29,  1.72it/s]Extractor Predicting: 144it [01:30,  1.68it/s]Extractor Predicting: 145it [01:30,  1.69it/s]Extractor Predicting: 146it [01:31,  1.68it/s]Extractor Predicting: 147it [01:32,  1.68it/s]Extractor Predicting: 148it [01:32,  1.67it/s]Extractor Predicting: 149it [01:33,  1.68it/s]Extractor Predicting: 150it [01:33,  1.68it/s]Extractor Predicting: 151it [01:34,  1.68it/s]Extractor Predicting: 152it [01:34,  1.71it/s]Extractor Predicting: 153it [01:35,  1.68it/s]Extractor Predicting: 154it [01:36,  1.67it/s]Extractor Predicting: 155it [01:36,  1.67it/s]Extractor Predicting: 156it [01:37,  1.66it/s]Extractor Predicting: 157it [01:38,  1.65it/s]Extractor Predicting: 158it [01:38,  1.67it/s]Extractor Predicting: 159it [01:39,  1.70it/s]Extractor Predicting: 160it [01:39,  1.72it/s]Extractor Predicting: 161it [01:40,  1.65it/s]Extractor Predicting: 162it [01:41,  1.61it/s]Extractor Predicting: 163it [01:41,  1.62it/s]Extractor Predicting: 164it [01:42,  1.66it/s]Extractor Predicting: 165it [01:42,  1.65it/s]Extractor Predicting: 166it [01:43,  1.58it/s]Extractor Predicting: 167it [01:44,  1.56it/s]Extractor Predicting: 168it [01:44,  1.57it/s]Extractor Predicting: 169it [01:45,  1.57it/s]Extractor Predicting: 170it [01:46,  1.54it/s]Extractor Predicting: 170it [01:46,  1.60it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:27,465 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:27,473 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:27,473 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:27,473 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:27,473 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 08:34:28,187 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 08:34:28,189 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:34:28,772 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 08:34:29,856 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:34:29,856 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:32,885 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:32,888 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:32,888 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:32,888 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:34:32,888 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 08:34:33,680 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 08:34:33,681 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:34:34,300 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 08:34:34,572 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:34:34,572 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_out_filter_single_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_in_single_is_eval_False.jsonl",
  "precision": 0.27684159845931633,
  "recall": 0.1411042944785276,
  "score": 0.18693107932379713,
  "mode": "single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/results_single_is_eval_False.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_in_multi_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_out_filter_multi_is_eval_False.jsonl'}}
predict vocab size: 3869
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 3969, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.57it/s]Extractor Predicting: 2it [00:01,  1.55it/s]Extractor Predicting: 3it [00:01,  1.56it/s]Extractor Predicting: 4it [00:02,  1.53it/s]Extractor Predicting: 5it [00:03,  1.55it/s]Extractor Predicting: 6it [00:03,  1.50it/s]Extractor Predicting: 7it [00:04,  1.48it/s]Extractor Predicting: 8it [00:05,  1.51it/s]Extractor Predicting: 9it [00:05,  1.54it/s]Extractor Predicting: 10it [00:06,  1.54it/s]Extractor Predicting: 11it [00:07,  1.50it/s]Extractor Predicting: 12it [00:07,  1.56it/s]Extractor Predicting: 13it [00:08,  1.57it/s]Extractor Predicting: 14it [00:09,  1.56it/s]Extractor Predicting: 15it [00:09,  1.57it/s]Extractor Predicting: 16it [00:10,  1.57it/s]Extractor Predicting: 17it [00:11,  1.55it/s]Extractor Predicting: 18it [00:11,  1.55it/s]Extractor Predicting: 19it [00:12,  1.55it/s]Extractor Predicting: 20it [00:13,  1.51it/s]Extractor Predicting: 21it [00:13,  1.54it/s]Extractor Predicting: 22it [00:14,  1.55it/s]Extractor Predicting: 23it [00:14,  1.55it/s]Extractor Predicting: 24it [00:15,  1.54it/s]Extractor Predicting: 25it [00:16,  1.58it/s]Extractor Predicting: 26it [00:16,  1.58it/s]Extractor Predicting: 27it [00:17,  1.56it/s]Extractor Predicting: 28it [00:18,  1.58it/s]Extractor Predicting: 29it [00:18,  1.57it/s]Extractor Predicting: 30it [00:19,  1.55it/s]Extractor Predicting: 31it [00:20,  1.56it/s]Extractor Predicting: 32it [00:20,  1.56it/s]Extractor Predicting: 33it [00:21,  1.50it/s]Extractor Predicting: 33it [00:21,  1.54it/s]
[INFO|configuration_utils.py:515] 2023-08-29 08:34:58,485 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 08:34:58,486 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki/unseen_5_seed_3/generator/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 08:34:58,546 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 08:34:58,548 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki/unseen_5_seed_3/generator/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|modeling_utils.py:1150] 2023-08-29 08:34:58,568 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 08:35:07,824 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.

[INFO|modeling_utils.py:1345] 2023-08-29 08:35:07,847 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.
[INFO|configuration_utils.py:515] 2023-08-29 08:35:07,987 >> loading configuration file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 08:35:07,988 >> Model config GPT2Config {
  "_name_or_path": "gpt2",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 08:35:08,044 >> Didn't find file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:35:08,097 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:35:08,097 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:35:08,097 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:35:08,097 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:35:08,097 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 08:35:08,098 >> loading file outputs/wrapper/wiki/unseen_5_seed_3/generator/model/tokenizer_config.json
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_out_filter_multi_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/pred_in_multi_is_eval_False.jsonl",
  "precision": 0.477088948787062,
  "recall": 0.09409888357256778,
  "score": 0.15719360568383658,
  "mode": "multi",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/results_multi_is_eval_False.json"
}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/data', model_name='outputs/wrapper/wiki/unseen_5_seed_3/generator/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
Generating:   0%|          | 0/10 [00:00<?, ?it/s][WARNING|generation_utils.py:914] 2023-08-29 08:35:08,441 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:08,962 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:09,574 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:10,125 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:10,648 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:11,139 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:11,716 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:12,333 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:12,923 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:13,596 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:14,183 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:14,757 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:15,382 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:15,935 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:16,518 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:17,060 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:17,688 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:18,227 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:18,833 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:19,370 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:19,951 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:20,548 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:21,100 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:21,674 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  10%|█         | 1/10 [00:13<02:04, 13.87s/it][WARNING|generation_utils.py:914] 2023-08-29 08:35:22,310 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:22,908 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:23,541 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:24,227 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:24,820 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:25,447 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:26,110 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:26,780 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:27,405 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:27,985 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:28,682 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:29,217 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:29,860 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:30,529 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:31,083 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:31,705 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:32,339 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:32,918 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:33,487 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:34,133 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:34,797 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:35,418 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:35,969 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  20%|██        | 2/10 [00:28<01:53, 14.13s/it][WARNING|generation_utils.py:914] 2023-08-29 08:35:36,686 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:37,236 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:37,871 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:38,378 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:38,866 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:39,420 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:39,936 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:40,409 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:40,982 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:41,485 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:42,082 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:42,589 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:43,086 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:43,579 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:44,202 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:44,668 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:45,147 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:45,643 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:46,138 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:46,649 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:47,142 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:47,656 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:48,143 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  30%|███       | 3/10 [00:40<01:32, 13.16s/it][WARNING|generation_utils.py:914] 2023-08-29 08:35:48,628 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:49,189 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:49,750 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:50,312 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:51,041 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:51,637 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:52,179 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:52,870 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:53,497 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:54,143 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:54,794 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:55,538 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:56,103 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:56,675 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:57,383 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:58,025 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:58,607 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:59,141 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:35:59,732 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:00,303 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:00,941 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:01,554 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  40%|████      | 4/10 [00:53<01:19, 13.28s/it][WARNING|generation_utils.py:914] 2023-08-29 08:36:02,119 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:02,675 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:03,331 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:03,868 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:04,477 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:05,106 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:05,696 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:06,276 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:06,880 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:07,477 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:08,093 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:08,692 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:09,314 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:09,927 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:10,599 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:11,107 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:11,658 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:12,211 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:12,848 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:13,535 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:14,175 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:14,764 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:15,431 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:15,946 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:16,583 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:17,147 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:17,805 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:18,378 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  50%|█████     | 5/10 [01:10<01:12, 14.57s/it][WARNING|generation_utils.py:914] 2023-08-29 08:36:18,949 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:19,467 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:20,039 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:20,670 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:21,301 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:21,852 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:22,379 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:23,032 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:23,619 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:24,224 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:24,766 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:25,351 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:25,937 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:26,481 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:27,006 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:27,698 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:28,394 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:28,985 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:29,557 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:30,132 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:30,683 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:31,229 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:31,801 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:32,363 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  60%|██████    | 6/10 [01:24<00:57, 14.42s/it][WARNING|generation_utils.py:914] 2023-08-29 08:36:33,081 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:33,656 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:34,287 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:34,921 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:35,569 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:36,156 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:36,729 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:37,245 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:37,865 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:38,446 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:39,024 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:39,628 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:40,219 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:41,003 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:41,678 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:42,239 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:42,831 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:43,387 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:44,016 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:44,545 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:45,086 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  70%|███████   | 7/10 [01:37<00:41, 13.87s/it][WARNING|generation_utils.py:914] 2023-08-29 08:36:45,799 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:46,328 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:46,927 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:47,555 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:48,155 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:48,775 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:49,322 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:49,847 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:50,411 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:51,016 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:51,588 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:52,189 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:52,863 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:53,472 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:54,004 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:54,679 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:55,299 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:55,906 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:56,504 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:57,159 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:57,713 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  80%|████████  | 8/10 [01:49<00:26, 13.45s/it][WARNING|generation_utils.py:914] 2023-08-29 08:36:58,375 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:58,925 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:36:59,472 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:00,061 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:00,701 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:01,289 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:01,901 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:02,539 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:03,127 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:03,737 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:04,422 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:05,042 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:05,625 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:06,170 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:06,733 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:07,331 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:07,960 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:08,522 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:09,166 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:09,774 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:10,343 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  90%|█████████ | 9/10 [02:02<00:13, 13.17s/it][WARNING|generation_utils.py:914] 2023-08-29 08:37:10,924 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:11,522 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:12,110 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:12,685 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:13,375 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:13,903 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:14,492 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:15,044 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:15,673 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:16,284 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:16,984 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:18,134 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:18,691 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:19,282 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:19,903 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:20,430 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:21,050 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:21,614 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:22,148 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:22,841 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:23,394 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 08:37:23,986 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating: 100%|██████████| 10/10 [02:16<00:00, 13.34s/it]Generating: 100%|██████████| 10/10 [02:16<00:00, 13.62s/it]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:30,102 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:30,124 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:30,125 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:30,125 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:30,125 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 08:37:30,574 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 08:37:30,575 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:37:30,887 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 08:37:32,041 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:37:32,041 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:33,605 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:33,629 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:33,630 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:33,630 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:37:33,630 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 08:37:34,053 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 08:37:34,054 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:37:34,337 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 08:37:34,529 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:37:34,529 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{'target': 600, 'success': 27, 'raw': 32}
{'target': 600, 'success': 50, 'raw': 64}
{'target': 600, 'success': 76, 'raw': 96}
{'target': 600, 'success': 103, 'raw': 128}
{'target': 600, 'success': 125, 'raw': 160}
{'target': 600, 'success': 149, 'raw': 192}
{'target': 600, 'success': 174, 'raw': 224}
{'target': 600, 'success': 193, 'raw': 256}
{'target': 600, 'success': 221, 'raw': 288}
{'target': 600, 'success': 246, 'raw': 320}
{'target': 600, 'success': 271, 'raw': 352}
{'target': 600, 'success': 298, 'raw': 384}
{'target': 600, 'success': 326, 'raw': 416}
{'target': 600, 'success': 350, 'raw': 448}
{'target': 600, 'success': 376, 'raw': 480}
{'target': 600, 'success': 402, 'raw': 512}
{'target': 600, 'success': 427, 'raw': 544}
{'target': 600, 'success': 452, 'raw': 576}
{'target': 600, 'success': 478, 'raw': 608}
{'target': 600, 'success': 502, 'raw': 640}
{'target': 600, 'success': 524, 'raw': 672}
{'target': 600, 'success': 549, 'raw': 704}
{'target': 600, 'success': 575, 'raw': 736}
{'target': 600, 'success': 600, 'raw': 768}
{'prompt': 'Relation : country .', 'success_rate': 0.78125, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 27, 'raw': 32}
{'target': 600, 'success': 54, 'raw': 64}
{'target': 600, 'success': 82, 'raw': 96}
{'target': 600, 'success': 108, 'raw': 128}
{'target': 600, 'success': 138, 'raw': 160}
{'target': 600, 'success': 161, 'raw': 192}
{'target': 600, 'success': 188, 'raw': 224}
{'target': 600, 'success': 213, 'raw': 256}
{'target': 600, 'success': 241, 'raw': 288}
{'target': 600, 'success': 270, 'raw': 320}
{'target': 600, 'success': 296, 'raw': 352}
{'target': 600, 'success': 322, 'raw': 384}
{'target': 600, 'success': 348, 'raw': 416}
{'target': 600, 'success': 376, 'raw': 448}
{'target': 600, 'success': 406, 'raw': 480}
{'target': 600, 'success': 434, 'raw': 512}
{'target': 600, 'success': 465, 'raw': 544}
{'target': 600, 'success': 487, 'raw': 576}
{'target': 600, 'success': 515, 'raw': 608}
{'target': 600, 'success': 543, 'raw': 640}
{'target': 600, 'success': 573, 'raw': 672}
{'target': 600, 'success': 599, 'raw': 704}
{'target': 600, 'success': 629, 'raw': 736}
{'prompt': 'Relation : part of .', 'success_rate': 0.8546195652173914, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 26, 'raw': 32}
{'target': 600, 'success': 52, 'raw': 64}
{'target': 600, 'success': 81, 'raw': 96}
{'target': 600, 'success': 104, 'raw': 128}
{'target': 600, 'success': 135, 'raw': 160}
{'target': 600, 'success': 162, 'raw': 192}
{'target': 600, 'success': 189, 'raw': 224}
{'target': 600, 'success': 217, 'raw': 256}
{'target': 600, 'success': 243, 'raw': 288}
{'target': 600, 'success': 268, 'raw': 320}
{'target': 600, 'success': 295, 'raw': 352}
{'target': 600, 'success': 323, 'raw': 384}
{'target': 600, 'success': 347, 'raw': 416}
{'target': 600, 'success': 372, 'raw': 448}
{'target': 600, 'success': 402, 'raw': 480}
{'target': 600, 'success': 429, 'raw': 512}
{'target': 600, 'success': 455, 'raw': 544}
{'target': 600, 'success': 483, 'raw': 576}
{'target': 600, 'success': 512, 'raw': 608}
{'target': 600, 'success': 540, 'raw': 640}
{'target': 600, 'success': 565, 'raw': 672}
{'target': 600, 'success': 590, 'raw': 704}
{'target': 600, 'success': 618, 'raw': 736}
{'prompt': 'Relation : platform .', 'success_rate': 0.8396739130434783, 'errors': {'', 'not enough values to unpack (expected 2, got 1)', "('The game', 'platform', '', 'The game is an action game developed by Epic Games , founded by longtime game designer Mike Hannon .')"}}
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 57, 'raw': 64}
{'target': 600, 'success': 83, 'raw': 96}
{'target': 600, 'success': 110, 'raw': 128}
{'target': 600, 'success': 137, 'raw': 160}
{'target': 600, 'success': 167, 'raw': 192}
{'target': 600, 'success': 192, 'raw': 224}
{'target': 600, 'success': 222, 'raw': 256}
{'target': 600, 'success': 253, 'raw': 288}
{'target': 600, 'success': 277, 'raw': 320}
{'target': 600, 'success': 306, 'raw': 352}
{'target': 600, 'success': 334, 'raw': 384}
{'target': 600, 'success': 364, 'raw': 416}
{'target': 600, 'success': 393, 'raw': 448}
{'target': 600, 'success': 423, 'raw': 480}
{'target': 600, 'success': 451, 'raw': 512}
{'target': 600, 'success': 481, 'raw': 544}
{'target': 600, 'success': 508, 'raw': 576}
{'target': 600, 'success': 538, 'raw': 608}
{'target': 600, 'success': 566, 'raw': 640}
{'target': 600, 'success': 592, 'raw': 672}
{'target': 600, 'success': 621, 'raw': 704}
{'prompt': 'Relation : publisher .', 'success_rate': 0.8821022727272727, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
['Relation : sport . Context : Following his promotion to the first tier of the FIFA World Cup squad in 2004 he was sent to Brazil for two matchdays to compete in the 2006 FIFA World Cup qualifiers . Head Entity : Paul Bissonnette , Tail Entity : FIFA World Cup .\n']
{'target': 600, 'success': 23, 'raw': 32}
{'target': 600, 'success': 46, 'raw': 64}
{'target': 600, 'success': 65, 'raw': 96}
{'target': 600, 'success': 90, 'raw': 128}
{'target': 600, 'success': 110, 'raw': 160}
{'target': 600, 'success': 130, 'raw': 192}
{'target': 600, 'success': 152, 'raw': 224}
{'target': 600, 'success': 171, 'raw': 256}
{'target': 600, 'success': 188, 'raw': 288}
{'target': 600, 'success': 212, 'raw': 320}
{'target': 600, 'success': 237, 'raw': 352}
{'target': 600, 'success': 259, 'raw': 384}
{'target': 600, 'success': 284, 'raw': 416}
{'target': 600, 'success': 307, 'raw': 448}
{'target': 600, 'success': 333, 'raw': 480}
{'target': 600, 'success': 351, 'raw': 512}
{'target': 600, 'success': 373, 'raw': 544}
{'target': 600, 'success': 393, 'raw': 576}
{'target': 600, 'success': 417, 'raw': 608}
{'target': 600, 'success': 437, 'raw': 640}
{'target': 600, 'success': 456, 'raw': 672}
{'target': 600, 'success': 476, 'raw': 704}
{'target': 600, 'success': 494, 'raw': 736}
{'target': 600, 'success': 518, 'raw': 768}
{'target': 600, 'success': 545, 'raw': 800}
{'target': 600, 'success': 572, 'raw': 832}
{'target': 600, 'success': 594, 'raw': 864}
{'target': 600, 'success': 621, 'raw': 896}
{'prompt': 'Relation : sport .', 'success_rate': 0.6930803571428571, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 26, 'raw': 32}
{'target': 600, 'success': 51, 'raw': 64}
{'target': 600, 'success': 79, 'raw': 96}
{'target': 600, 'success': 108, 'raw': 128}
{'target': 600, 'success': 131, 'raw': 160}
{'target': 600, 'success': 154, 'raw': 192}
{'target': 600, 'success': 179, 'raw': 224}
{'target': 600, 'success': 204, 'raw': 256}
{'target': 600, 'success': 231, 'raw': 288}
{'target': 600, 'success': 256, 'raw': 320}
{'target': 600, 'success': 280, 'raw': 352}
{'target': 600, 'success': 303, 'raw': 384}
{'target': 600, 'success': 328, 'raw': 416}
{'target': 600, 'success': 354, 'raw': 448}
{'target': 600, 'success': 379, 'raw': 480}
{'target': 600, 'success': 404, 'raw': 512}
{'target': 600, 'success': 426, 'raw': 544}
{'target': 600, 'success': 451, 'raw': 576}
{'target': 600, 'success': 480, 'raw': 608}
{'target': 600, 'success': 502, 'raw': 640}
{'target': 600, 'success': 527, 'raw': 672}
{'target': 600, 'success': 551, 'raw': 704}
{'target': 600, 'success': 578, 'raw': 736}
{'target': 600, 'success': 604, 'raw': 768}
{'prompt': 'Relation : continent .', 'success_rate': 0.7864583333333334, 'errors': {''}}
{'target': 600, 'success': 28, 'raw': 32}
{'target': 600, 'success': 54, 'raw': 64}
{'target': 600, 'success': 85, 'raw': 96}
{'target': 600, 'success': 115, 'raw': 128}
{'target': 600, 'success': 144, 'raw': 160}
{'target': 600, 'success': 176, 'raw': 192}
{'target': 600, 'success': 206, 'raw': 224}
{'target': 600, 'success': 233, 'raw': 256}
{'target': 600, 'success': 263, 'raw': 288}
{'target': 600, 'success': 292, 'raw': 320}
{'target': 600, 'success': 319, 'raw': 352}
{'target': 600, 'success': 350, 'raw': 384}
{'target': 600, 'success': 376, 'raw': 416}
{'target': 600, 'success': 407, 'raw': 448}
{'target': 600, 'success': 433, 'raw': 480}
{'target': 600, 'success': 459, 'raw': 512}
{'target': 600, 'success': 491, 'raw': 544}
{'target': 600, 'success': 521, 'raw': 576}
{'target': 600, 'success': 549, 'raw': 608}
{'target': 600, 'success': 578, 'raw': 640}
{'target': 600, 'success': 607, 'raw': 672}
{'prompt': 'Relation : owned by .', 'success_rate': 0.9032738095238095, 'errors': {'', 'too many values to unpack (expected 2)'}}
{'target': 600, 'success': 28, 'raw': 32}
{'target': 600, 'success': 58, 'raw': 64}
{'target': 600, 'success': 88, 'raw': 96}
{'target': 600, 'success': 118, 'raw': 128}
{'target': 600, 'success': 149, 'raw': 160}
{'target': 600, 'success': 180, 'raw': 192}
{'target': 600, 'success': 209, 'raw': 224}
{'target': 600, 'success': 237, 'raw': 256}
{'target': 600, 'success': 268, 'raw': 288}
{'target': 600, 'success': 296, 'raw': 320}
{'target': 600, 'success': 325, 'raw': 352}
{'target': 600, 'success': 354, 'raw': 384}
{'target': 600, 'success': 383, 'raw': 416}
{'target': 600, 'success': 412, 'raw': 448}
{'target': 600, 'success': 444, 'raw': 480}
{'target': 600, 'success': 475, 'raw': 512}
{'target': 600, 'success': 500, 'raw': 544}
{'target': 600, 'success': 531, 'raw': 576}
{'target': 600, 'success': 562, 'raw': 608}
{'target': 600, 'success': 591, 'raw': 640}
{'target': 600, 'success': 621, 'raw': 672}
{'prompt': 'Relation : performer .', 'success_rate': 0.9241071428571429, 'errors': {''}}
{'target': 600, 'success': 30, 'raw': 32}
{'target': 600, 'success': 62, 'raw': 64}
{'target': 600, 'success': 90, 'raw': 96}
{'target': 600, 'success': 119, 'raw': 128}
{'target': 600, 'success': 147, 'raw': 160}
{'target': 600, 'success': 173, 'raw': 192}
{'target': 600, 'success': 205, 'raw': 224}
{'target': 600, 'success': 235, 'raw': 256}
{'target': 600, 'success': 261, 'raw': 288}
{'target': 600, 'success': 293, 'raw': 320}
{'target': 600, 'success': 323, 'raw': 352}
{'target': 600, 'success': 353, 'raw': 384}
{'target': 600, 'success': 385, 'raw': 416}
{'target': 600, 'success': 415, 'raw': 448}
{'target': 600, 'success': 444, 'raw': 480}
{'target': 600, 'success': 473, 'raw': 512}
{'target': 600, 'success': 499, 'raw': 544}
{'target': 600, 'success': 528, 'raw': 576}
{'target': 600, 'success': 558, 'raw': 608}
{'target': 600, 'success': 585, 'raw': 640}
{'target': 600, 'success': 614, 'raw': 672}
{'prompt': 'Relation : producer .', 'success_rate': 0.9136904761904762, 'errors': {''}}
['Relation : replaces . Context : Later in the year ( 1141 ) , he married Alixandra , daughter of the Duke of Orleans , sister of King James III , the 1st of her née Bodegas . Head Entity : Alixandra , Tail Entity : Prince of Orleans .\n']
{'target': 600, 'success': 27, 'raw': 32}
{'target': 600, 'success': 53, 'raw': 64}
{'target': 600, 'success': 81, 'raw': 96}
{'target': 600, 'success': 111, 'raw': 128}
{'target': 600, 'success': 140, 'raw': 160}
{'target': 600, 'success': 168, 'raw': 192}
{'target': 600, 'success': 194, 'raw': 224}
{'target': 600, 'success': 219, 'raw': 256}
{'target': 600, 'success': 249, 'raw': 288}
{'target': 600, 'success': 277, 'raw': 320}
{'target': 600, 'success': 306, 'raw': 352}
{'target': 600, 'success': 332, 'raw': 384}
{'target': 600, 'success': 363, 'raw': 416}
{'target': 600, 'success': 390, 'raw': 448}
{'target': 600, 'success': 417, 'raw': 480}
{'target': 600, 'success': 447, 'raw': 512}
{'target': 600, 'success': 476, 'raw': 544}
{'target': 600, 'success': 502, 'raw': 576}
{'target': 600, 'success': 532, 'raw': 608}
{'target': 600, 'success': 558, 'raw': 640}
{'target': 600, 'success': 587, 'raw': 672}
{'target': 600, 'success': 613, 'raw': 704}
{'prompt': 'Relation : replaces .', 'success_rate': 0.8707386363636364, 'errors': {'', 'not enough values to unpack (expected 2, got 1)', "('Opera dParis', 'replaces', '', 'In the 1920s , he studied opera at the Conservatoire and later at the Opera dParis after the death of his wife .')"}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/1.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/1_ext.jsonl'}}
estimate vocab size: 8866
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 8966, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/data/estimate.txt
Extractor Estimating: 0it [00:00, ?it/s]Extractor Estimating: 1it [00:00,  1.74it/s]Extractor Estimating: 2it [00:01,  1.66it/s]Extractor Estimating: 3it [00:01,  1.75it/s]Extractor Estimating: 4it [00:02,  1.78it/s]Extractor Estimating: 5it [00:02,  1.87it/s]Extractor Estimating: 6it [00:03,  1.86it/s]Extractor Estimating: 7it [00:03,  1.73it/s]Extractor Estimating: 8it [00:04,  1.74it/s]Extractor Estimating: 9it [00:05,  1.63it/s]Extractor Estimating: 10it [00:05,  1.64it/s]Extractor Estimating: 11it [00:06,  1.68it/s]Extractor Estimating: 12it [00:07,  1.67it/s]Extractor Estimating: 13it [00:07,  1.73it/s]Extractor Estimating: 14it [00:08,  1.66it/s]Extractor Estimating: 15it [00:08,  1.71it/s]Extractor Estimating: 16it [00:09,  1.69it/s]Extractor Estimating: 17it [00:09,  1.71it/s]Extractor Estimating: 18it [00:10,  1.70it/s]Extractor Estimating: 19it [00:11,  1.76it/s]Extractor Estimating: 20it [00:11,  1.63it/s]Extractor Estimating: 21it [00:12,  1.66it/s]Extractor Estimating: 22it [00:12,  1.63it/s]Extractor Estimating: 23it [00:13,  1.68it/s]Extractor Estimating: 24it [00:14,  1.71it/s]Extractor Estimating: 25it [00:14,  1.67it/s]Extractor Estimating: 26it [00:15,  1.70it/s]Extractor Estimating: 27it [00:15,  1.66it/s]Extractor Estimating: 28it [00:16,  1.67it/s]Extractor Estimating: 29it [00:17,  1.62it/s]Extractor Estimating: 30it [00:17,  1.62it/s]Extractor Estimating: 31it [00:18,  1.61it/s]Extractor Estimating: 32it [00:18,  1.65it/s]Extractor Estimating: 33it [00:19,  1.67it/s]Extractor Estimating: 34it [00:20,  1.65it/s]Extractor Estimating: 35it [00:20,  1.67it/s]Extractor Estimating: 36it [00:21,  1.65it/s]Extractor Estimating: 37it [00:22,  1.62it/s]Extractor Estimating: 38it [00:22,  1.63it/s]Extractor Estimating: 39it [00:23,  1.59it/s]Extractor Estimating: 40it [00:23,  1.61it/s]Extractor Estimating: 41it [00:24,  1.63it/s]Extractor Estimating: 42it [00:25,  1.67it/s]Extractor Estimating: 43it [00:25,  1.68it/s]Extractor Estimating: 44it [00:26,  1.65it/s]Extractor Estimating: 45it [00:26,  1.65it/s]Extractor Estimating: 46it [00:27,  1.64it/s]Extractor Estimating: 47it [00:28,  1.66it/s]Extractor Estimating: 48it [00:28,  1.67it/s]Extractor Estimating: 49it [00:29,  1.70it/s]Extractor Estimating: 50it [00:29,  1.71it/s]Extractor Estimating: 51it [00:30,  1.76it/s]Extractor Estimating: 52it [00:30,  1.72it/s]Extractor Estimating: 53it [00:31,  1.77it/s]Extractor Estimating: 54it [00:32,  1.80it/s]Extractor Estimating: 55it [00:32,  1.78it/s]Extractor Estimating: 56it [00:33,  1.83it/s]Extractor Estimating: 57it [00:33,  1.86it/s]Extractor Estimating: 58it [00:34,  1.82it/s]Extractor Estimating: 59it [00:34,  1.83it/s]Extractor Estimating: 60it [00:35,  1.80it/s]Extractor Estimating: 61it [00:35,  1.83it/s]Extractor Estimating: 62it [00:36,  1.85it/s]Extractor Estimating: 63it [00:36,  1.86it/s]Extractor Estimating: 64it [00:37,  1.84it/s]Extractor Estimating: 65it [00:38,  1.75it/s]Extractor Estimating: 66it [00:38,  1.77it/s]Extractor Estimating: 67it [00:39,  1.86it/s]Extractor Estimating: 68it [00:39,  1.88it/s]Extractor Estimating: 69it [00:40,  1.85it/s]Extractor Estimating: 70it [00:40,  1.84it/s]Extractor Estimating: 71it [00:41,  1.85it/s]Extractor Estimating: 72it [00:41,  1.83it/s]Extractor Estimating: 73it [00:42,  1.91it/s]Extractor Estimating: 74it [00:42,  1.89it/s]Extractor Estimating: 75it [00:43,  1.89it/s]Extractor Estimating: 76it [00:44,  1.79it/s]Extractor Estimating: 77it [00:44,  1.75it/s]Extractor Estimating: 78it [00:45,  1.73it/s]Extractor Estimating: 79it [00:45,  1.69it/s]Extractor Estimating: 80it [00:46,  1.67it/s]Extractor Estimating: 81it [00:47,  1.67it/s]Extractor Estimating: 82it [00:47,  1.67it/s]Extractor Estimating: 83it [00:48,  1.65it/s]Extractor Estimating: 84it [00:48,  1.61it/s]Extractor Estimating: 85it [00:49,  1.67it/s]Extractor Estimating: 86it [00:50,  1.63it/s]Extractor Estimating: 87it [00:50,  1.64it/s]Extractor Estimating: 88it [00:51,  1.66it/s]Extractor Estimating: 89it [00:51,  1.62it/s]Extractor Estimating: 90it [00:52,  1.64it/s]Extractor Estimating: 91it [00:53,  1.61it/s]Extractor Estimating: 92it [00:53,  1.62it/s]Extractor Estimating: 93it [00:54,  1.62it/s]Extractor Estimating: 94it [00:55,  1.61it/s]Extractor Estimating: 95it [00:55,  1.64it/s]Extractor Estimating: 96it [00:56,  1.49it/s]Extractor Estimating: 97it [00:57,  1.53it/s]Extractor Estimating: 98it [00:57,  1.59it/s]Extractor Estimating: 99it [00:58,  1.59it/s]Extractor Estimating: 100it [00:58,  1.60it/s]Extractor Estimating: 101it [00:59,  1.66it/s]Extractor Estimating: 102it [01:00,  1.66it/s]Extractor Estimating: 103it [01:00,  1.69it/s]Extractor Estimating: 104it [01:01,  1.69it/s]Extractor Estimating: 105it [01:01,  1.69it/s]Extractor Estimating: 106it [01:02,  1.72it/s]Extractor Estimating: 107it [01:02,  1.80it/s]Extractor Estimating: 108it [01:03,  1.70it/s]Extractor Estimating: 109it [01:04,  1.67it/s]Extractor Estimating: 110it [01:04,  1.67it/s]Extractor Estimating: 111it [01:05,  1.68it/s]Extractor Estimating: 112it [01:05,  1.70it/s]Extractor Estimating: 113it [01:06,  1.73it/s]Extractor Estimating: 114it [01:06,  1.75it/s]Extractor Estimating: 115it [01:07,  1.76it/s]Extractor Estimating: 116it [01:08,  1.75it/s]Extractor Estimating: 117it [01:08,  1.75it/s]Extractor Estimating: 118it [01:09,  1.66it/s]Extractor Estimating: 119it [01:09,  1.69it/s]Extractor Estimating: 120it [01:10,  1.71it/s]Extractor Estimating: 121it [01:11,  1.72it/s]Extractor Estimating: 122it [01:11,  1.73it/s]Extractor Estimating: 123it [01:12,  1.72it/s]Extractor Estimating: 124it [01:12,  1.71it/s]Extractor Estimating: 125it [01:13,  1.74it/s]Extractor Estimating: 126it [01:13,  1.77it/s]Extractor Estimating: 127it [01:14,  1.72it/s]Extractor Estimating: 128it [01:15,  1.75it/s]Extractor Estimating: 129it [01:15,  1.75it/s]Extractor Estimating: 130it [01:16,  1.77it/s]Extractor Estimating: 131it [01:16,  1.80it/s]Extractor Estimating: 132it [01:17,  1.81it/s]Extractor Estimating: 133it [01:17,  1.74it/s]Extractor Estimating: 134it [01:18,  1.78it/s]Extractor Estimating: 135it [01:19,  1.74it/s]Extractor Estimating: 136it [01:19,  1.68it/s]Extractor Estimating: 137it [01:20,  1.72it/s]Extractor Estimating: 138it [01:20,  1.71it/s]Extractor Estimating: 139it [01:21,  1.70it/s]Extractor Estimating: 140it [01:21,  1.73it/s]Extractor Estimating: 141it [01:22,  1.67it/s]Extractor Estimating: 142it [01:23,  1.64it/s]Extractor Estimating: 143it [01:23,  1.67it/s]Extractor Estimating: 144it [01:24,  1.70it/s]Extractor Estimating: 145it [01:25,  1.69it/s]Extractor Estimating: 146it [01:25,  1.66it/s]Extractor Estimating: 147it [01:26,  1.69it/s]Extractor Estimating: 148it [01:26,  1.71it/s]Extractor Estimating: 149it [01:27,  1.73it/s]Extractor Estimating: 150it [01:27,  1.67it/s]Extractor Estimating: 151it [01:28,  1.71it/s]Extractor Estimating: 152it [01:29,  1.68it/s]Extractor Estimating: 153it [01:29,  1.68it/s]Extractor Estimating: 154it [01:30,  1.67it/s]Extractor Estimating: 155it [01:30,  1.65it/s]Extractor Estimating: 156it [01:31,  1.65it/s]Extractor Estimating: 157it [01:32,  1.68it/s]Extractor Estimating: 158it [01:32,  1.69it/s]Extractor Estimating: 159it [01:33,  1.67it/s]Extractor Estimating: 160it [01:33,  1.70it/s]Extractor Estimating: 161it [01:34,  1.70it/s]Extractor Estimating: 162it [01:35,  1.68it/s]Extractor Estimating: 163it [01:35,  1.66it/s]Extractor Estimating: 164it [01:36,  1.69it/s]Extractor Estimating: 165it [01:36,  1.67it/s]Extractor Estimating: 166it [01:37,  1.72it/s]Extractor Estimating: 167it [01:38,  1.70it/s]Extractor Estimating: 168it [01:38,  1.72it/s]Extractor Estimating: 169it [01:39,  1.74it/s]Extractor Estimating: 170it [01:39,  1.72it/s]Extractor Estimating: 171it [01:40,  1.70it/s]Extractor Estimating: 172it [01:40,  1.73it/s]Extractor Estimating: 173it [01:41,  1.76it/s]Extractor Estimating: 174it [01:42,  1.74it/s]Extractor Estimating: 175it [01:42,  1.73it/s]Extractor Estimating: 176it [01:43,  1.74it/s]Extractor Estimating: 177it [01:43,  1.74it/s]Extractor Estimating: 178it [01:44,  1.70it/s]Extractor Estimating: 179it [01:45,  1.69it/s]Extractor Estimating: 180it [01:45,  1.68it/s]Extractor Estimating: 181it [01:46,  1.62it/s]Extractor Estimating: 182it [01:46,  1.65it/s]Extractor Estimating: 183it [01:47,  1.66it/s]Extractor Estimating: 184it [01:48,  1.68it/s]Extractor Estimating: 185it [01:48,  1.67it/s]Extractor Estimating: 186it [01:49,  1.65it/s]Extractor Estimating: 187it [01:49,  1.66it/s]Extractor Estimating: 188it [01:50,  1.62it/s]Extractor Estimating: 189it [01:51,  1.59it/s]Extractor Estimating: 190it [01:51,  1.62it/s]Extractor Estimating: 191it [01:52,  1.63it/s]Extractor Estimating: 192it [01:52,  1.71it/s]Extractor Estimating: 193it [01:53,  1.71it/s]Extractor Estimating: 194it [01:54,  1.71it/s]Extractor Estimating: 195it [01:54,  1.67it/s]Extractor Estimating: 196it [01:55,  1.67it/s]Extractor Estimating: 197it [01:55,  1.65it/s]Extractor Estimating: 198it [01:56,  1.48it/s]Extractor Estimating: 199it [01:57,  1.54it/s]Extractor Estimating: 200it [01:57,  1.56it/s]Extractor Estimating: 201it [01:58,  1.59it/s]Extractor Estimating: 202it [01:59,  1.64it/s]Extractor Estimating: 203it [01:59,  1.64it/s]Extractor Estimating: 204it [02:00,  1.66it/s]Extractor Estimating: 205it [02:00,  1.65it/s]Extractor Estimating: 206it [02:01,  1.64it/s]Extractor Estimating: 207it [02:02,  1.64it/s]Extractor Estimating: 208it [02:02,  1.63it/s]Extractor Estimating: 209it [02:03,  1.66it/s]Extractor Estimating: 210it [02:04,  1.65it/s]Extractor Estimating: 211it [02:04,  1.68it/s]Extractor Estimating: 212it [02:05,  1.61it/s]Extractor Estimating: 213it [02:05,  1.57it/s]Extractor Estimating: 214it [02:06,  1.61it/s]Extractor Estimating: 215it [02:07,  1.60it/s]Extractor Estimating: 216it [02:07,  1.66it/s]Extractor Estimating: 217it [02:08,  1.63it/s]Extractor Estimating: 218it [02:08,  1.62it/s]Extractor Estimating: 219it [02:09,  1.65it/s]Extractor Estimating: 220it [02:10,  1.60it/s]Extractor Estimating: 221it [02:10,  1.59it/s]Extractor Estimating: 222it [02:11,  1.59it/s]Extractor Estimating: 223it [02:12,  1.63it/s]Extractor Estimating: 224it [02:12,  1.65it/s]Extractor Estimating: 225it [02:13,  1.64it/s]Extractor Estimating: 226it [02:13,  1.65it/s]Extractor Estimating: 227it [02:14,  1.66it/s]Extractor Estimating: 228it [02:15,  1.66it/s]Extractor Estimating: 229it [02:15,  1.60it/s]Extractor Estimating: 230it [02:16,  1.67it/s]Extractor Estimating: 231it [02:16,  1.63it/s]Extractor Estimating: 232it [02:17,  1.67it/s]Extractor Estimating: 233it [02:18,  1.64it/s]Extractor Estimating: 234it [02:18,  1.61it/s]Extractor Estimating: 235it [02:19,  1.60it/s]Extractor Estimating: 236it [02:20,  1.57it/s]Extractor Estimating: 237it [02:20,  1.60it/s]Extractor Estimating: 238it [02:21,  1.61it/s]Extractor Estimating: 239it [02:21,  1.65it/s]Extractor Estimating: 240it [02:22,  1.62it/s]Extractor Estimating: 241it [02:23,  1.66it/s]Extractor Estimating: 242it [02:23,  1.71it/s]Extractor Estimating: 243it [02:24,  1.68it/s]Extractor Estimating: 244it [02:24,  1.66it/s]Extractor Estimating: 245it [02:25,  1.69it/s]Extractor Estimating: 246it [02:26,  1.67it/s]Extractor Estimating: 247it [02:26,  1.65it/s]Extractor Estimating: 248it [02:27,  1.65it/s]Extractor Estimating: 249it [02:27,  1.65it/s]Extractor Estimating: 250it [02:28,  1.77it/s]Extractor Estimating: 250it [02:28,  1.69it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:23,668 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:23,697 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:23,697 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:23,697 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:23,697 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 08:40:24,465 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 08:40:24,466 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:40:25,076 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 08:40:26,232 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:40:26,233 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:29,261 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:29,277 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:29,277 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:29,277 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 08:40:29,277 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 08:40:30,015 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 08:40:30,017 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 08:40:30,761 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 08:40:30,949 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 08:40:30,949 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1113: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[INFO|training_args.py:725] 2023-08-29 09:26:09,275 >> PyTorch: setting up devices
[INFO|training_args.py:625] 2023-08-29 09:26:09,637 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/1_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_5_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/1.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.4, 'with_train': False, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
{'num_pseudo': 2000, 'num_train': 3000}
num of filtered data: 2018 mean pseudo reward: 0.9611657459675683
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/1.jsonl', 'path_dev': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl'}
train vocab size: 23390
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 23490, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/data/train.txt
{"train_model: args: ModelArguments(model_class='JointModel', model_read_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/model', model_write_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/model', pretrained_wv='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/data/train.txt', label_config=None, batch_size=24, evaluate_interval=500, max_steps=10000, max_epoches=20, decay_rate=0.05, token_emb_dim=100, char_encoder='lstm', char_emb_dim=30, cased=False, hidden_dim=200, num_layers=3, crf=None, loss_reduction='sum', maxlen=None, dropout=0.5, optimizer='adam', lr=0.001, vocab_size=23490, vocab_file=None, ner_tag_vocab_size=64, re_tag_vocab_size=250, lm_emb_dim=1024, lm_emb_path='albert-large-v2', head_emb_dim=384, tag_form='iob2', warm_steps=1000, grad_period=1, device='cuda', seed=42)"}
warm up: learning rate was adjusted to 1e-06
warm up: learning rate was adjusted to 1.1e-05
warm up: learning rate was adjusted to 2.1000000000000002e-05
warm up: learning rate was adjusted to 3.1e-05
warm up: learning rate was adjusted to 4.1e-05
warm up: learning rate was adjusted to 5.1000000000000006e-05
warm up: learning rate was adjusted to 6.1e-05
warm up: learning rate was adjusted to 7.1e-05
warm up: learning rate was adjusted to 8.1e-05
warm up: learning rate was adjusted to 9.1e-05
g_step 100, step 15, avg_time 0.963, loss:531.4470
warm up: learning rate was adjusted to 0.000101
warm up: learning rate was adjusted to 0.000111
warm up: learning rate was adjusted to 0.000121
warm up: learning rate was adjusted to 0.000131
warm up: learning rate was adjusted to 0.000141
warm up: learning rate was adjusted to 0.00015099999999999998
warm up: learning rate was adjusted to 0.000161
warm up: learning rate was adjusted to 0.000171
warm up: learning rate was adjusted to 0.00018099999999999998
warm up: learning rate was adjusted to 0.000191
g_step 200, step 30, avg_time 0.967, loss:471.0459
warm up: learning rate was adjusted to 0.000201
warm up: learning rate was adjusted to 0.000211
warm up: learning rate was adjusted to 0.000221
warm up: learning rate was adjusted to 0.000231
warm up: learning rate was adjusted to 0.000241
warm up: learning rate was adjusted to 0.000251
warm up: learning rate was adjusted to 0.000261
warm up: learning rate was adjusted to 0.00027100000000000003
warm up: learning rate was adjusted to 0.00028100000000000005
warm up: learning rate was adjusted to 0.00029099999999999997
g_step 300, step 45, avg_time 0.967, loss:422.9869
warm up: learning rate was adjusted to 0.000301
warm up: learning rate was adjusted to 0.000311
warm up: learning rate was adjusted to 0.000321
warm up: learning rate was adjusted to 0.000331
warm up: learning rate was adjusted to 0.00034100000000000005
warm up: learning rate was adjusted to 0.000351
warm up: learning rate was adjusted to 0.000361
warm up: learning rate was adjusted to 0.000371
warm up: learning rate was adjusted to 0.000381
warm up: learning rate was adjusted to 0.000391
g_step 400, step 60, avg_time 0.963, loss:408.3630
warm up: learning rate was adjusted to 0.00040100000000000004
warm up: learning rate was adjusted to 0.000411
warm up: learning rate was adjusted to 0.000421
warm up: learning rate was adjusted to 0.000431
warm up: learning rate was adjusted to 0.000441
warm up: learning rate was adjusted to 0.000451
warm up: learning rate was adjusted to 0.00046100000000000004
warm up: learning rate was adjusted to 0.000471
warm up: learning rate was adjusted to 0.000481
warm up: learning rate was adjusted to 0.000491
g_step 500, step 75, avg_time 0.962, loss:361.9718
>> valid entity prec:0.4698, rec:0.3923, f1:0.4276
>> valid relation prec:0.2291, rec:0.1113, f1:0.1498
>> valid relation with NER prec:0.2291, rec:0.1113, f1:0.1498
new max entity f1 on valid!
new max relation f1 on valid!
new max relation f1 with NER on valid!
new max averaged entity f1 and relation f1 on valid!
new max averaged entity f1 and relation f1 with NER on valid!
warm up: learning rate was adjusted to 0.000501
warm up: learning rate was adjusted to 0.0005110000000000001
warm up: learning rate was adjusted to 0.000521
warm up: learning rate was adjusted to 0.000531
warm up: learning rate was adjusted to 0.000541
warm up: learning rate was adjusted to 0.0005510000000000001
warm up: learning rate was adjusted to 0.0005610000000000001
warm up: learning rate was adjusted to 0.0005710000000000001
warm up: learning rate was adjusted to 0.0005809999999999999
warm up: learning rate was adjusted to 0.0005909999999999999
g_step 600, step 5, avg_time 4.598, loss:342.1301
warm up: learning rate was adjusted to 0.000601
warm up: learning rate was adjusted to 0.000611
warm up: learning rate was adjusted to 0.000621
warm up: learning rate was adjusted to 0.000631
warm up: learning rate was adjusted to 0.000641
warm up: learning rate was adjusted to 0.000651
warm up: learning rate was adjusted to 0.000661
warm up: learning rate was adjusted to 0.000671
warm up: learning rate was adjusted to 0.0006810000000000001
warm up: learning rate was adjusted to 0.0006910000000000001
g_step 700, step 20, avg_time 0.967, loss:320.0733
warm up: learning rate was adjusted to 0.000701
warm up: learning rate was adjusted to 0.0007109999999999999
warm up: learning rate was adjusted to 0.000721
warm up: learning rate was adjusted to 0.000731
warm up: learning rate was adjusted to 0.000741
warm up: learning rate was adjusted to 0.000751
warm up: learning rate was adjusted to 0.000761
warm up: learning rate was adjusted to 0.000771
warm up: learning rate was adjusted to 0.000781
warm up: learning rate was adjusted to 0.000791
g_step 800, step 35, avg_time 0.961, loss:303.4196
warm up: learning rate was adjusted to 0.0008010000000000001
warm up: learning rate was adjusted to 0.0008110000000000001
warm up: learning rate was adjusted to 0.0008210000000000001
warm up: learning rate was adjusted to 0.000831
warm up: learning rate was adjusted to 0.000841
warm up: learning rate was adjusted to 0.000851
warm up: learning rate was adjusted to 0.000861
warm up: learning rate was adjusted to 0.000871
warm up: learning rate was adjusted to 0.0008810000000000001
warm up: learning rate was adjusted to 0.000891
g_step 900, step 50, avg_time 0.964, loss:295.4257
warm up: learning rate was adjusted to 0.000901
warm up: learning rate was adjusted to 0.000911
warm up: learning rate was adjusted to 0.000921
warm up: learning rate was adjusted to 0.0009310000000000001
warm up: learning rate was adjusted to 0.0009410000000000001
warm up: learning rate was adjusted to 0.000951
warm up: learning rate was adjusted to 0.0009609999999999999
warm up: learning rate was adjusted to 0.000971
warm up: learning rate was adjusted to 0.0009809999999999999
warm up: learning rate was adjusted to 0.000991
g_step 1000, step 65, avg_time 0.965, loss:293.0536
learning rate was adjusted to 0.0009523809523809524
>> valid entity prec:0.4427, rec:0.3934, f1:0.4166
>> valid relation prec:0.2045, rec:0.1104, f1:0.1434
>> valid relation with NER prec:0.2045, rec:0.1104, f1:0.1434
g_step 1100, step 80, avg_time 4.614, loss:281.5557
g_step 1200, step 10, avg_time 0.966, loss:259.0193
g_step 1300, step 25, avg_time 0.970, loss:254.3522
g_step 1400, step 40, avg_time 0.971, loss:228.6128
g_step 1500, step 55, avg_time 0.959, loss:217.3944
>> valid entity prec:0.4439, rec:0.3824, f1:0.4109
>> valid relation prec:0.1943, rec:0.1093, f1:0.1399
>> valid relation with NER prec:0.1943, rec:0.1093, f1:0.1399
g_step 1600, step 70, avg_time 4.603, loss:209.2000
g_step 1700, step 85, avg_time 0.962, loss:196.6385
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
08/29/2023 09:26:09 - WARNING - transformer_base.run_clm_rl -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True
08/29/2023 09:26:09 - INFO - transformer_base.run_clm_rl -   Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=2,
greater_is_better=False,
group_by_length=False,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_on_each_node=True,
logging_dir=runs/Aug29_09-26-09_ctolab07.scc.idea,
logging_first_step=False,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
output_dir=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
08/29/2023 09:26:11 - WARNING - datasets.builder -   Using custom data configuration default-b169b8df3ef8f750
Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/xuting/.cache/huggingface/datasets/json/default-b169b8df3ef8f750/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...
0 tables [00:00, ? tables/s]                            0 tables [00:00, ? tables/s]                            [INFO|configuration_utils.py:515] 2023-08-29 09:26:13,041 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 09:26:13,042 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki/unseen_5_seed_3/generator/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 09:26:13,042 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 09:26:13,043 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki/unseen_5_seed_3/generator/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 09:26:13,115 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:26:13,152 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:26:13,152 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:26:13,152 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:26:13,152 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:26:13,152 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:26:13,152 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/tokenizer_config.json
[INFO|modeling_utils.py:1150] 2023-08-29 09:26:13,500 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 09:26:16,807 >> All model checkpoint weights were used when initializing Model.

[INFO|modeling_utils.py:1345] 2023-08-29 09:26:16,808 >> All the weights of Model were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Model for predictions without further training.
Dataset json downloaded and prepared to /home/xuting/.cache/huggingface/datasets/json/default-b169b8df3ef8f750/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.
PreTrainedTokenizerFast(name_or_path='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'})
  0%|          | 0/3 [00:00<?, ?ba/s] 33%|███▎      | 1/3 [00:00<00:00,  3.06ba/s] 67%|██████▋   | 2/3 [00:00<00:00,  3.73ba/s]100%|██████████| 3/3 [00:00<00:00,  5.33ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:03,  3.79ba/s] 13%|█▎        | 2/15 [00:00<00:02,  4.34ba/s] 20%|██        | 3/15 [00:00<00:02,  4.53ba/s] 27%|██▋       | 4/15 [00:00<00:02,  4.62ba/s] 33%|███▎      | 5/15 [00:01<00:02,  4.69ba/s] 40%|████      | 6/15 [00:01<00:01,  4.71ba/s] 47%|████▋     | 7/15 [00:01<00:01,  4.73ba/s] 53%|█████▎    | 8/15 [00:01<00:01,  4.75ba/s] 60%|██████    | 9/15 [00:01<00:01,  4.77ba/s] 67%|██████▋   | 10/15 [00:02<00:01,  4.76ba/s] 73%|███████▎  | 11/15 [00:02<00:00,  4.76ba/s] 80%|████████  | 12/15 [00:02<00:00,  4.77ba/s] 87%|████████▋ | 13/15 [00:02<00:00,  4.76ba/s] 93%|█████████▎| 14/15 [00:02<00:00,  4.78ba/s]100%|██████████| 15/15 [00:03<00:00,  4.99ba/s]
  0%|          | 0/3 [00:00<?, ?ba/s] 33%|███▎      | 1/3 [00:00<00:00,  5.61ba/s]100%|██████████| 3/3 [00:00<00:00, 11.82ba/s]100%|██████████| 3/3 [00:00<00:00, 10.63ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:02,  5.43ba/s] 20%|██        | 3/15 [00:00<00:01,  8.33ba/s] 33%|███▎      | 5/15 [00:00<00:01,  9.22ba/s] 40%|████      | 6/15 [00:00<00:00,  9.37ba/s] 53%|█████▎    | 8/15 [00:00<00:00,  9.75ba/s] 60%|██████    | 9/15 [00:00<00:00,  9.24ba/s] 73%|███████▎  | 11/15 [00:01<00:00,  9.63ba/s] 80%|████████  | 12/15 [00:01<00:00,  9.70ba/s] 87%|████████▋ | 13/15 [00:01<00:00,  9.77ba/s]100%|██████████| 15/15 [00:01<00:00, 12.17ba/s]100%|██████████| 15/15 [00:01<00:00, 10.01ba/s]
[INFO|trainer.py:414] 2023-08-29 09:26:23,109 >> Using amp fp16 backend
[INFO|trainer.py:1147] 2023-08-29 09:26:23,188 >> ***** Running training *****
[INFO|trainer.py:1148] 2023-08-29 09:26:23,188 >>   Num examples = 2019
[INFO|trainer.py:1149] 2023-08-29 09:26:23,188 >>   Num Epochs = 5
[INFO|trainer.py:1150] 2023-08-29 09:26:23,188 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1151] 2023-08-29 09:26:23,188 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1152] 2023-08-29 09:26:23,188 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1153] 2023-08-29 09:26:23,188 >>   Total optimization steps = 160
  0%|          | 0/160 [00:00<?, ?it/s]  1%|          | 1/160 [00:00<00:47,  3.32it/s]  1%|▏         | 2/160 [00:00<00:46,  3.40it/s]  2%|▏         | 3/160 [00:00<00:45,  3.43it/s]  2%|▎         | 4/160 [00:01<00:45,  3.44it/s]  3%|▎         | 5/160 [00:01<00:44,  3.45it/s]  4%|▍         | 6/160 [00:01<00:44,  3.45it/s]  4%|▍         | 7/160 [00:02<00:44,  3.45it/s]  5%|▌         | 8/160 [00:02<00:43,  3.46it/s]  6%|▌         | 9/160 [00:02<00:43,  3.46it/s]  6%|▋         | 10/160 [00:02<00:43,  3.46it/s]  7%|▋         | 11/160 [00:03<00:43,  3.46it/s]  8%|▊         | 12/160 [00:03<00:42,  3.46it/s]  8%|▊         | 13/160 [00:03<00:42,  3.46it/s]  9%|▉         | 14/160 [00:04<00:42,  3.46it/s]  9%|▉         | 15/160 [00:04<00:42,  3.41it/s] 10%|█         | 16/160 [00:04<00:42,  3.42it/s] 11%|█         | 17/160 [00:04<00:41,  3.44it/s] 11%|█▏        | 18/160 [00:05<00:41,  3.45it/s] 12%|█▏        | 19/160 [00:05<00:40,  3.45it/s] 12%|█▎        | 20/160 [00:05<00:40,  3.45it/s] 13%|█▎        | 21/160 [00:06<00:40,  3.45it/s] 14%|█▍        | 22/160 [00:06<00:39,  3.46it/s] 14%|█▍        | 23/160 [00:06<00:39,  3.46it/s] 15%|█▌        | 24/160 [00:06<00:39,  3.46it/s] 16%|█▌        | 25/160 [00:07<00:39,  3.46it/s] 16%|█▋        | 26/160 [00:07<00:38,  3.46it/s] 17%|█▋        | 27/160 [00:07<00:38,  3.46it/s] 18%|█▊        | 28/160 [00:08<00:38,  3.46it/s] 18%|█▊        | 29/160 [00:08<00:37,  3.46it/s] 19%|█▉        | 30/160 [00:08<00:37,  3.46it/s] 19%|█▉        | 31/160 [00:08<00:37,  3.46it/s] 20%|██        | 32/160 [00:09<00:33,  3.87it/s][INFO|trainer.py:2140] 2023-08-29 09:26:32,375 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 09:26:32,375 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 09:26:32,375 >>   Batch size = 8

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.45it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.51it/s][A
  1%|          | 18/1759 [00:00<00:36, 47.79it/s][A
  1%|▏         | 23/1759 [00:00<00:37, 46.76it/s][A
  2%|▏         | 28/1759 [00:00<00:37, 46.23it/s][A
  2%|▏         | 33/1759 [00:00<00:37, 45.89it/s][A
  2%|▏         | 38/1759 [00:00<00:37, 45.58it/s][A
  2%|▏         | 43/1759 [00:00<00:37, 45.20it/s][A
  3%|▎         | 48/1759 [00:01<00:37, 45.05it/s][A
  3%|▎         | 53/1759 [00:01<00:37, 45.08it/s][A
  3%|▎         | 58/1759 [00:01<00:37, 45.19it/s][A
  4%|▎         | 63/1759 [00:01<00:37, 45.27it/s][A
  4%|▍         | 68/1759 [00:01<00:37, 45.36it/s][A
  4%|▍         | 73/1759 [00:01<00:37, 45.34it/s][A
  4%|▍         | 78/1759 [00:01<00:37, 45.24it/s][A
  5%|▍         | 83/1759 [00:01<00:37, 45.23it/s][A
  5%|▌         | 88/1759 [00:01<00:37, 44.97it/s][A
  5%|▌         | 93/1759 [00:02<00:37, 44.96it/s][A
  6%|▌         | 98/1759 [00:02<00:36, 44.98it/s][A
  6%|▌         | 103/1759 [00:02<00:36, 45.12it/s][A
  6%|▌         | 108/1759 [00:02<00:36, 45.34it/s][A
  6%|▋         | 113/1759 [00:02<00:36, 45.30it/s][A
  7%|▋         | 118/1759 [00:02<00:36, 45.36it/s][A
  7%|▋         | 123/1759 [00:02<00:36, 45.27it/s][A
  7%|▋         | 128/1759 [00:02<00:36, 45.13it/s][A
  8%|▊         | 133/1759 [00:02<00:36, 44.99it/s][A
  8%|▊         | 138/1759 [00:03<00:36, 44.84it/s][A
  8%|▊         | 143/1759 [00:03<00:35, 44.90it/s][A
  8%|▊         | 148/1759 [00:03<00:35, 45.01it/s][A
  9%|▊         | 153/1759 [00:03<00:35, 45.17it/s][A
  9%|▉         | 158/1759 [00:03<00:35, 45.28it/s][A
  9%|▉         | 163/1759 [00:03<00:35, 45.41it/s][A
 10%|▉         | 168/1759 [00:03<00:35, 45.33it/s][A
 10%|▉         | 173/1759 [00:03<00:35, 45.18it/s][A
 10%|█         | 178/1759 [00:03<00:35, 45.11it/s][A
 10%|█         | 183/1759 [00:04<00:35, 45.03it/s][A
 11%|█         | 188/1759 [00:04<00:34, 45.13it/s][A
 11%|█         | 193/1759 [00:04<00:34, 45.05it/s][A
 11%|█▏        | 198/1759 [00:04<00:34, 45.13it/s][A
 12%|█▏        | 203/1759 [00:04<00:34, 45.17it/s][A
 12%|█▏        | 208/1759 [00:04<00:34, 45.28it/s][A
 12%|█▏        | 213/1759 [00:04<00:34, 45.25it/s][A
 12%|█▏        | 218/1759 [00:04<00:34, 45.13it/s][A
 13%|█▎        | 223/1759 [00:04<00:34, 44.97it/s][A
 13%|█▎        | 228/1759 [00:05<00:34, 44.90it/s][A
 13%|█▎        | 233/1759 [00:05<00:34, 43.80it/s][A
 14%|█▎        | 238/1759 [00:05<00:34, 44.27it/s][A
 14%|█▍        | 243/1759 [00:05<00:33, 44.61it/s][A
 14%|█▍        | 248/1759 [00:05<00:33, 44.91it/s][A
 14%|█▍        | 253/1759 [00:05<00:33, 44.97it/s][A
 15%|█▍        | 258/1759 [00:05<00:33, 44.96it/s][A
 15%|█▍        | 263/1759 [00:05<00:33, 45.05it/s][A
 15%|█▌        | 268/1759 [00:05<00:33, 44.91it/s][A
 16%|█▌        | 273/1759 [00:06<00:33, 44.76it/s][A
 16%|█▌        | 278/1759 [00:06<00:33, 44.78it/s][A
 16%|█▌        | 283/1759 [00:06<00:32, 44.87it/s][A
 16%|█▋        | 288/1759 [00:06<00:32, 45.08it/s][A
 17%|█▋        | 293/1759 [00:06<00:32, 45.17it/s][A
 17%|█▋        | 298/1759 [00:06<00:32, 45.32it/s][A
 17%|█▋        | 303/1759 [00:06<00:32, 45.28it/s][A
 18%|█▊        | 308/1759 [00:06<00:32, 45.14it/s][A
 18%|█▊        | 313/1759 [00:06<00:32, 44.99it/s][A
 18%|█▊        | 318/1759 [00:07<00:32, 44.98it/s][A
 18%|█▊        | 323/1759 [00:07<00:31, 44.92it/s][A
 19%|█▊        | 328/1759 [00:07<00:31, 44.96it/s][A
 19%|█▉        | 333/1759 [00:07<00:31, 45.08it/s][A
 19%|█▉        | 338/1759 [00:07<00:31, 45.16it/s][A
 19%|█▉        | 343/1759 [00:07<00:31, 45.36it/s][A
 20%|█▉        | 348/1759 [00:07<00:31, 45.30it/s][A
 20%|██        | 353/1759 [00:07<00:31, 45.18it/s][A
 20%|██        | 358/1759 [00:07<00:31, 45.18it/s][A
 21%|██        | 363/1759 [00:08<00:31, 44.99it/s][A
 21%|██        | 368/1759 [00:08<00:30, 45.01it/s][A
 21%|██        | 373/1759 [00:08<00:30, 44.93it/s][A
 21%|██▏       | 378/1759 [00:08<00:30, 44.98it/s][A
 22%|██▏       | 383/1759 [00:08<00:30, 45.16it/s][A
 22%|██▏       | 388/1759 [00:08<00:30, 45.24it/s][A
 22%|██▏       | 393/1759 [00:08<00:30, 45.21it/s][A
 23%|██▎       | 398/1759 [00:08<00:30, 45.09it/s][A
 23%|██▎       | 403/1759 [00:08<00:30, 44.95it/s][A
 23%|██▎       | 408/1759 [00:09<00:30, 44.95it/s][A
 23%|██▎       | 413/1759 [00:09<00:30, 44.86it/s][A
 24%|██▍       | 418/1759 [00:09<00:29, 44.93it/s][A
 24%|██▍       | 423/1759 [00:09<00:29, 45.10it/s][A
 24%|██▍       | 428/1759 [00:09<00:29, 45.20it/s][A
 25%|██▍       | 433/1759 [00:09<00:29, 45.24it/s][A
 25%|██▍       | 438/1759 [00:09<00:29, 45.18it/s][A
 25%|██▌       | 443/1759 [00:09<00:29, 45.05it/s][A
 25%|██▌       | 448/1759 [00:09<00:29, 45.05it/s][A
 26%|██▌       | 453/1759 [00:10<00:29, 44.93it/s][A
 26%|██▌       | 458/1759 [00:10<00:28, 44.87it/s][A
 26%|██▋       | 463/1759 [00:10<00:29, 43.74it/s][A
 27%|██▋       | 468/1759 [00:10<00:29, 44.18it/s][A
 27%|██▋       | 473/1759 [00:10<00:28, 44.68it/s][A
 27%|██▋       | 478/1759 [00:10<00:28, 44.88it/s][A
 27%|██▋       | 483/1759 [00:10<00:28, 44.91it/s][A
 28%|██▊       | 488/1759 [00:10<00:28, 44.96it/s][A
 28%|██▊       | 493/1759 [00:10<00:28, 44.97it/s][A
 28%|██▊       | 498/1759 [00:11<00:28, 44.81it/s][A
 29%|██▊       | 503/1759 [00:11<00:28, 44.70it/s][A
 29%|██▉       | 508/1759 [00:11<00:27, 44.83it/s][A
 29%|██▉       | 513/1759 [00:11<00:27, 44.94it/s][A
 29%|██▉       | 518/1759 [00:11<00:27, 45.15it/s][A
 30%|██▉       | 523/1759 [00:11<00:27, 45.16it/s][A
 30%|███       | 528/1759 [00:11<00:27, 45.24it/s][A
 30%|███       | 533/1759 [00:11<00:27, 45.25it/s][A
 31%|███       | 538/1759 [00:11<00:27, 45.10it/s][A
 31%|███       | 543/1759 [00:12<00:27, 44.89it/s][A
 31%|███       | 548/1759 [00:12<00:27, 44.80it/s][A
 31%|███▏      | 553/1759 [00:12<00:26, 44.87it/s][A
 32%|███▏      | 558/1759 [00:12<00:30, 39.58it/s][A
 32%|███▏      | 563/1759 [00:12<00:29, 41.18it/s][A
 32%|███▏      | 568/1759 [00:12<00:28, 42.36it/s][A
 33%|███▎      | 573/1759 [00:12<00:27, 43.30it/s][A
 33%|███▎      | 578/1759 [00:12<00:26, 43.87it/s][A
 33%|███▎      | 583/1759 [00:12<00:26, 44.31it/s][A
 33%|███▎      | 588/1759 [00:13<00:26, 44.63it/s][A
 34%|███▎      | 593/1759 [00:13<00:25, 44.88it/s][A
 34%|███▍      | 598/1759 [00:13<00:26, 44.59it/s][A
 34%|███▍      | 603/1759 [00:13<00:25, 44.50it/s][A
 35%|███▍      | 608/1759 [00:13<00:25, 44.64it/s][A
 35%|███▍      | 613/1759 [00:13<00:25, 44.86it/s][A
 35%|███▌      | 618/1759 [00:13<00:25, 44.97it/s][A
 35%|███▌      | 623/1759 [00:13<00:25, 45.20it/s][A
 36%|███▌      | 628/1759 [00:13<00:24, 45.27it/s][A
 36%|███▌      | 633/1759 [00:14<00:24, 45.32it/s][A
 36%|███▋      | 638/1759 [00:14<00:24, 45.27it/s][A
 37%|███▋      | 643/1759 [00:14<00:24, 45.04it/s][A
 37%|███▋      | 648/1759 [00:14<00:24, 44.93it/s][A
 37%|███▋      | 653/1759 [00:14<00:24, 44.90it/s][A
 37%|███▋      | 658/1759 [00:14<00:24, 44.98it/s][A
 38%|███▊      | 663/1759 [00:14<00:24, 45.08it/s][A
 38%|███▊      | 668/1759 [00:14<00:24, 45.17it/s][A
 38%|███▊      | 673/1759 [00:14<00:24, 45.19it/s][A
 39%|███▊      | 678/1759 [00:15<00:23, 45.21it/s][A
 39%|███▉      | 683/1759 [00:15<00:23, 45.06it/s][A
 39%|███▉      | 688/1759 [00:15<00:23, 44.90it/s][A
 39%|███▉      | 693/1759 [00:15<00:25, 41.18it/s][A
 40%|███▉      | 698/1759 [00:15<00:25, 42.17it/s][A
 40%|███▉      | 703/1759 [00:15<00:24, 43.25it/s][A
 40%|████      | 708/1759 [00:15<00:23, 43.94it/s][A
 41%|████      | 713/1759 [00:15<00:23, 44.38it/s][A
 41%|████      | 718/1759 [00:15<00:23, 44.76it/s][A
 41%|████      | 723/1759 [00:16<00:23, 44.88it/s][A
 41%|████▏     | 728/1759 [00:16<00:22, 45.02it/s][A
 42%|████▏     | 733/1759 [00:16<00:22, 44.75it/s][A
 42%|████▏     | 738/1759 [00:16<00:22, 44.53it/s][A
 42%|████▏     | 743/1759 [00:16<00:22, 44.72it/s][A
 43%|████▎     | 748/1759 [00:16<00:22, 44.91it/s][A
 43%|████▎     | 753/1759 [00:16<00:22, 44.97it/s][A
 43%|████▎     | 758/1759 [00:16<00:22, 45.09it/s][A
 43%|████▎     | 763/1759 [00:16<00:22, 45.21it/s][A
 44%|████▎     | 768/1759 [00:17<00:21, 45.19it/s][A
 44%|████▍     | 773/1759 [00:17<00:21, 45.24it/s][A
 44%|████▍     | 778/1759 [00:17<00:21, 45.06it/s][A
 45%|████▍     | 783/1759 [00:17<00:21, 44.99it/s][A
 45%|████▍     | 788/1759 [00:17<00:21, 44.97it/s][A
 45%|████▌     | 793/1759 [00:17<00:21, 44.93it/s][A
 45%|████▌     | 798/1759 [00:17<00:21, 44.92it/s][A
 46%|████▌     | 803/1759 [00:17<00:21, 45.04it/s][A
 46%|████▌     | 808/1759 [00:17<00:21, 45.11it/s][A
 46%|████▌     | 813/1759 [00:18<00:20, 45.16it/s][A
 47%|████▋     | 818/1759 [00:18<00:20, 45.12it/s][A
 47%|████▋     | 823/1759 [00:18<00:20, 45.07it/s][A
 47%|████▋     | 828/1759 [00:18<00:20, 45.06it/s][A
 47%|████▋     | 833/1759 [00:18<00:20, 44.94it/s][A
 48%|████▊     | 838/1759 [00:18<00:20, 44.93it/s][A
 48%|████▊     | 843/1759 [00:18<00:20, 44.89it/s][A
 48%|████▊     | 848/1759 [00:18<00:20, 44.92it/s][A
 48%|████▊     | 853/1759 [00:18<00:20, 45.14it/s][A
 49%|████▉     | 858/1759 [00:19<00:19, 45.17it/s][A
 49%|████▉     | 863/1759 [00:19<00:19, 45.19it/s][A
 49%|████▉     | 868/1759 [00:19<00:19, 45.03it/s][A
 50%|████▉     | 873/1759 [00:19<00:19, 44.98it/s][A
 50%|████▉     | 878/1759 [00:19<00:19, 44.88it/s][A
 50%|█████     | 883/1759 [00:19<00:19, 44.93it/s][A
 50%|█████     | 888/1759 [00:19<00:19, 44.79it/s][A
 51%|█████     | 893/1759 [00:19<00:19, 44.87it/s][A
 51%|█████     | 898/1759 [00:19<00:19, 45.03it/s][A
 51%|█████▏    | 903/1759 [00:20<00:18, 45.08it/s][A
 52%|█████▏    | 908/1759 [00:20<00:18, 45.14it/s][A
 52%|█████▏    | 913/1759 [00:20<00:18, 45.07it/s][A
 52%|█████▏    | 918/1759 [00:20<00:18, 44.95it/s][A
 52%|█████▏    | 923/1759 [00:20<00:20, 40.08it/s][A
 53%|█████▎    | 928/1759 [00:20<00:19, 41.61it/s][A
 53%|█████▎    | 933/1759 [00:20<00:19, 42.71it/s][A
 53%|█████▎    | 938/1759 [00:20<00:18, 43.39it/s][A
 54%|█████▎    | 943/1759 [00:21<00:18, 43.95it/s][A
 54%|█████▍    | 948/1759 [00:21<00:18, 44.37it/s][A
 54%|█████▍    | 953/1759 [00:21<00:18, 44.68it/s][A
 54%|█████▍    | 958/1759 [00:21<00:17, 44.85it/s][A
 55%|█████▍    | 963/1759 [00:21<00:17, 44.57it/s][A
 55%|█████▌    | 968/1759 [00:21<00:17, 44.53it/s][A
 55%|█████▌    | 973/1759 [00:21<00:17, 44.70it/s][A
 56%|█████▌    | 978/1759 [00:21<00:17, 44.79it/s][A
 56%|█████▌    | 983/1759 [00:21<00:17, 44.93it/s][A
 56%|█████▌    | 988/1759 [00:22<00:17, 45.10it/s][A
 56%|█████▋    | 993/1759 [00:22<00:16, 45.13it/s][A
 57%|█████▋    | 998/1759 [00:22<00:16, 45.26it/s][A
 57%|█████▋    | 1003/1759 [00:22<00:16, 45.18it/s][A
 57%|█████▋    | 1008/1759 [00:22<00:16, 45.04it/s][A
 58%|█████▊    | 1013/1759 [00:22<00:17, 43.62it/s][A
 58%|█████▊    | 1018/1759 [00:22<00:16, 44.16it/s][A
 58%|█████▊    | 1023/1759 [00:22<00:16, 44.47it/s][A
 58%|█████▊    | 1028/1759 [00:22<00:16, 44.69it/s][A
 59%|█████▊    | 1033/1759 [00:23<00:16, 44.80it/s][A
 59%|█████▉    | 1038/1759 [00:23<00:16, 45.06it/s][A
 59%|█████▉    | 1043/1759 [00:23<00:15, 45.04it/s][A
 60%|█████▉    | 1048/1759 [00:23<00:15, 45.08it/s][A
 60%|█████▉    | 1053/1759 [00:23<00:15, 44.82it/s][A
 60%|██████    | 1058/1759 [00:23<00:15, 44.72it/s][A
 60%|██████    | 1063/1759 [00:23<00:15, 44.91it/s][A
 61%|██████    | 1068/1759 [00:23<00:15, 44.88it/s][A
 61%|██████    | 1073/1759 [00:23<00:15, 44.74it/s][A
 61%|██████▏   | 1078/1759 [00:24<00:15, 44.97it/s][A
 62%|██████▏   | 1083/1759 [00:24<00:15, 45.02it/s][A
 62%|██████▏   | 1088/1759 [00:24<00:14, 45.13it/s][A
 62%|██████▏   | 1093/1759 [00:24<00:14, 44.94it/s][A
 62%|██████▏   | 1098/1759 [00:24<00:14, 44.90it/s][A
 63%|██████▎   | 1103/1759 [00:24<00:14, 44.86it/s][A
 63%|██████▎   | 1108/1759 [00:24<00:14, 44.86it/s][A
 63%|██████▎   | 1113/1759 [00:24<00:14, 44.99it/s][A
 64%|██████▎   | 1118/1759 [00:24<00:14, 45.02it/s][A
 64%|██████▍   | 1123/1759 [00:25<00:14, 45.05it/s][A
 64%|██████▍   | 1128/1759 [00:25<00:13, 45.11it/s][A
 64%|██████▍   | 1133/1759 [00:25<00:13, 45.13it/s][A
 65%|██████▍   | 1138/1759 [00:25<00:13, 45.08it/s][A
 65%|██████▍   | 1143/1759 [00:25<00:13, 44.90it/s][A
 65%|██████▌   | 1148/1759 [00:25<00:13, 44.29it/s][A
 66%|██████▌   | 1153/1759 [00:25<00:13, 44.57it/s][A
 66%|██████▌   | 1158/1759 [00:25<00:13, 44.82it/s][A
 66%|██████▌   | 1163/1759 [00:25<00:13, 44.90it/s][A
 66%|██████▋   | 1168/1759 [00:26<00:13, 44.92it/s][A
 67%|██████▋   | 1173/1759 [00:26<00:13, 45.02it/s][A
 67%|██████▋   | 1178/1759 [00:26<00:12, 45.04it/s][A
 67%|██████▋   | 1183/1759 [00:26<00:12, 45.00it/s][A
 68%|██████▊   | 1188/1759 [00:26<00:12, 44.83it/s][A
 68%|██████▊   | 1193/1759 [00:26<00:12, 44.76it/s][A
 68%|██████▊   | 1198/1759 [00:26<00:12, 44.91it/s][A
 68%|██████▊   | 1203/1759 [00:26<00:12, 44.99it/s][A
 69%|██████▊   | 1208/1759 [00:26<00:12, 45.06it/s][A
 69%|██████▉   | 1213/1759 [00:27<00:12, 45.12it/s][A
 69%|██████▉   | 1218/1759 [00:27<00:12, 45.05it/s][A
 70%|██████▉   | 1223/1759 [00:27<00:11, 45.12it/s][A
 70%|██████▉   | 1228/1759 [00:27<00:11, 44.96it/s][A
 70%|███████   | 1233/1759 [00:27<00:11, 44.87it/s][A
 70%|███████   | 1238/1759 [00:27<00:11, 44.91it/s][A
 71%|███████   | 1243/1759 [00:27<00:11, 43.96it/s][A
 71%|███████   | 1248/1759 [00:27<00:11, 44.38it/s][A
 71%|███████   | 1253/1759 [00:27<00:11, 44.66it/s][A
 72%|███████▏  | 1258/1759 [00:28<00:11, 44.75it/s][A
 72%|███████▏  | 1263/1759 [00:28<00:11, 44.84it/s][A
 72%|███████▏  | 1268/1759 [00:28<00:10, 44.95it/s][A
 72%|███████▏  | 1273/1759 [00:28<00:10, 44.80it/s][A
 73%|███████▎  | 1278/1759 [00:28<00:10, 44.72it/s][A
 73%|███████▎  | 1283/1759 [00:28<00:10, 44.70it/s][A
 73%|███████▎  | 1288/1759 [00:28<00:10, 44.78it/s][A
 74%|███████▎  | 1293/1759 [00:28<00:10, 44.95it/s][A
 74%|███████▍  | 1298/1759 [00:28<00:10, 45.09it/s][A
 74%|███████▍  | 1303/1759 [00:29<00:10, 45.09it/s][A
 74%|███████▍  | 1308/1759 [00:29<00:09, 45.11it/s][A
 75%|███████▍  | 1313/1759 [00:29<00:09, 45.02it/s][A
 75%|███████▍  | 1318/1759 [00:29<00:09, 44.96it/s][A
 75%|███████▌  | 1323/1759 [00:29<00:09, 44.76it/s][A
 75%|███████▌  | 1328/1759 [00:29<00:09, 44.76it/s][A
 76%|███████▌  | 1333/1759 [00:29<00:09, 44.81it/s][A
 76%|███████▌  | 1338/1759 [00:29<00:09, 44.93it/s][A
 76%|███████▋  | 1343/1759 [00:29<00:09, 45.12it/s][A
 77%|███████▋  | 1348/1759 [00:30<00:09, 45.06it/s][A
 77%|███████▋  | 1353/1759 [00:30<00:09, 45.10it/s][A
 77%|███████▋  | 1358/1759 [00:30<00:08, 45.00it/s][A
 77%|███████▋  | 1363/1759 [00:30<00:08, 44.86it/s][A
 78%|███████▊  | 1368/1759 [00:30<00:08, 44.80it/s][A
 78%|███████▊  | 1373/1759 [00:30<00:08, 44.68it/s][A
 78%|███████▊  | 1378/1759 [00:30<00:08, 43.55it/s][A
 79%|███████▊  | 1383/1759 [00:30<00:08, 44.09it/s][A
 79%|███████▉  | 1388/1759 [00:30<00:08, 44.41it/s][A
 79%|███████▉  | 1393/1759 [00:31<00:08, 44.60it/s][A
 79%|███████▉  | 1398/1759 [00:31<00:08, 44.85it/s][A
 80%|███████▉  | 1403/1759 [00:31<00:07, 44.90it/s][A
 80%|████████  | 1408/1759 [00:31<00:07, 44.93it/s][A
 80%|████████  | 1413/1759 [00:31<00:07, 44.95it/s][A
 81%|████████  | 1418/1759 [00:31<00:07, 44.75it/s][A
 81%|████████  | 1423/1759 [00:31<00:07, 44.80it/s][A
 81%|████████  | 1428/1759 [00:31<00:07, 44.95it/s][A
 81%|████████▏ | 1433/1759 [00:31<00:07, 45.01it/s][A
 82%|████████▏ | 1438/1759 [00:32<00:07, 45.09it/s][A
 82%|████████▏ | 1443/1759 [00:32<00:07, 44.96it/s][A
 82%|████████▏ | 1448/1759 [00:32<00:06, 45.00it/s][A
 83%|████████▎ | 1453/1759 [00:32<00:06, 44.96it/s][A
 83%|████████▎ | 1458/1759 [00:32<00:06, 44.84it/s][A
 83%|████████▎ | 1463/1759 [00:32<00:06, 44.83it/s][A
 83%|████████▎ | 1468/1759 [00:32<00:06, 44.71it/s][A
 84%|████████▎ | 1473/1759 [00:32<00:06, 44.17it/s][A
 84%|████████▍ | 1478/1759 [00:32<00:06, 44.59it/s][A
 84%|████████▍ | 1483/1759 [00:33<00:06, 44.72it/s][A
 85%|████████▍ | 1488/1759 [00:33<00:06, 44.78it/s][A
 85%|████████▍ | 1493/1759 [00:33<00:05, 44.84it/s][A
 85%|████████▌ | 1498/1759 [00:33<00:05, 44.82it/s][A
 85%|████████▌ | 1503/1759 [00:33<00:05, 44.82it/s][A
 86%|████████▌ | 1508/1759 [00:33<00:05, 44.78it/s][A
 86%|████████▌ | 1513/1759 [00:33<00:05, 44.61it/s][A
 86%|████████▋ | 1518/1759 [00:33<00:05, 44.79it/s][A
 87%|████████▋ | 1523/1759 [00:33<00:05, 44.91it/s][A
 87%|████████▋ | 1528/1759 [00:34<00:05, 44.99it/s][A
 87%|████████▋ | 1533/1759 [00:34<00:05, 45.10it/s][A
 87%|████████▋ | 1538/1759 [00:34<00:04, 45.11it/s][A
 88%|████████▊ | 1543/1759 [00:34<00:04, 44.97it/s][A
 88%|████████▊ | 1548/1759 [00:34<00:04, 44.93it/s][A
 88%|████████▊ | 1553/1759 [00:34<00:04, 44.75it/s][A
 89%|████████▊ | 1558/1759 [00:34<00:04, 43.23it/s][A
 89%|████████▉ | 1563/1759 [00:34<00:04, 44.05it/s][A
 89%|████████▉ | 1568/1759 [00:34<00:04, 44.39it/s][A
 89%|████████▉ | 1573/1759 [00:35<00:04, 44.66it/s][A
 90%|████████▉ | 1578/1759 [00:35<00:04, 44.86it/s][A
 90%|████████▉ | 1583/1759 [00:35<00:03, 45.01it/s][A
 90%|█████████ | 1588/1759 [00:35<00:03, 44.94it/s][A
 91%|█████████ | 1593/1759 [00:35<00:03, 44.95it/s][A
 91%|█████████ | 1598/1759 [00:35<00:03, 44.81it/s][A
 91%|█████████ | 1603/1759 [00:35<00:03, 44.64it/s][A
 91%|█████████▏| 1608/1759 [00:35<00:03, 43.08it/s][A
 92%|█████████▏| 1613/1759 [00:35<00:03, 43.70it/s][A
 92%|█████████▏| 1618/1759 [00:36<00:03, 44.15it/s][A
 92%|█████████▏| 1623/1759 [00:36<00:03, 44.46it/s][A
 93%|█████████▎| 1628/1759 [00:36<00:02, 44.69it/s][A
 93%|█████████▎| 1633/1759 [00:36<00:02, 44.87it/s][A
 93%|█████████▎| 1638/1759 [00:36<00:02, 45.00it/s][A
 93%|█████████▎| 1643/1759 [00:36<00:02, 44.87it/s][A
 94%|█████████▎| 1648/1759 [00:36<00:02, 44.69it/s][A
 94%|█████████▍| 1653/1759 [00:36<00:02, 44.71it/s][A
 94%|█████████▍| 1658/1759 [00:37<00:04, 22.75it/s][A
 95%|█████████▍| 1663/1759 [00:37<00:03, 26.86it/s][A
 95%|█████████▍| 1668/1759 [00:37<00:02, 30.68it/s][A
 95%|█████████▌| 1673/1759 [00:37<00:02, 34.00it/s][A
 95%|█████████▌| 1678/1759 [00:37<00:02, 36.81it/s][A
 96%|█████████▌| 1683/1759 [00:37<00:01, 39.03it/s][A
 96%|█████████▌| 1688/1759 [00:38<00:01, 40.84it/s][A
 96%|█████████▌| 1693/1759 [00:38<00:01, 41.99it/s][A
 97%|█████████▋| 1698/1759 [00:38<00:01, 42.70it/s][A
 97%|█████████▋| 1703/1759 [00:38<00:01, 43.05it/s][A
 97%|█████████▋| 1708/1759 [00:38<00:01, 43.37it/s][A
 97%|█████████▋| 1713/1759 [00:38<00:01, 43.77it/s][A
 98%|█████████▊| 1718/1759 [00:38<00:00, 44.21it/s][A
 98%|█████████▊| 1723/1759 [00:38<00:00, 44.51it/s][A
 98%|█████████▊| 1728/1759 [00:38<00:00, 44.79it/s][A
 99%|█████████▊| 1733/1759 [00:39<00:00, 44.99it/s][A
 99%|█████████▉| 1738/1759 [00:39<00:00, 45.04it/s][A
 99%|█████████▉| 1743/1759 [00:39<00:00, 44.98it/s][A
 99%|█████████▉| 1748/1759 [00:39<00:00, 44.95it/s][A
100%|█████████▉| 1753/1759 [00:39<00:00, 44.88it/s][A
100%|█████████▉| 1758/1759 [00:39<00:00, 44.81it/s][A
                                                   [A                                                
100%|██████████| 1759/1759 [00:39<00:00, 44.81it/s][A 20%|██        | 32/160 [00:48<00:33,  3.87it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 09:27:12,289 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-32
[INFO|configuration_utils.py:351] 2023-08-29 09:27:12,443 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-32/config.json
[INFO|modeling_utils.py:886] 2023-08-29 09:27:15,023 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-32/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 09:27:15,152 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-32/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 09:27:15,212 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-32/special_tokens_map.json
 21%|██        | 33/160 [00:58<31:29, 14.88s/it] 21%|██▏       | 34/160 [00:58<22:04, 10.51s/it] 22%|██▏       | 35/160 [00:58<15:30,  7.45s/it] 22%|██▎       | 36/160 [00:59<10:57,  5.30s/it] 23%|██▎       | 37/160 [00:59<07:47,  3.80s/it] 24%|██▍       | 38/160 [00:59<05:35,  2.75s/it] 24%|██▍       | 39/160 [00:59<04:03,  2.01s/it] 25%|██▌       | 40/160 [01:00<02:59,  1.50s/it] 26%|██▌       | 41/160 [01:00<02:15,  1.14s/it] 26%|██▋       | 42/160 [01:00<01:44,  1.13it/s] 27%|██▋       | 43/160 [01:01<01:22,  1.42it/s] 28%|██▊       | 44/160 [01:01<01:07,  1.72it/s] 28%|██▊       | 45/160 [01:01<00:57,  2.00it/s] 29%|██▉       | 46/160 [01:02<00:49,  2.29it/s] 29%|██▉       | 47/160 [01:02<00:44,  2.55it/s] 30%|███       | 48/160 [01:02<00:40,  2.77it/s] 31%|███       | 49/160 [01:02<00:37,  2.94it/s] 31%|███▏      | 50/160 [01:03<00:35,  3.08it/s] 32%|███▏      | 51/160 [01:03<00:34,  3.18it/s] 32%|███▎      | 52/160 [01:03<00:33,  3.26it/s] 33%|███▎      | 53/160 [01:04<00:32,  3.32it/s] 34%|███▍      | 54/160 [01:04<00:31,  3.36it/s] 34%|███▍      | 55/160 [01:04<00:31,  3.39it/s] 35%|███▌      | 56/160 [01:04<00:31,  3.35it/s] 36%|███▌      | 57/160 [01:05<00:30,  3.38it/s] 36%|███▋      | 58/160 [01:05<00:30,  3.40it/s] 37%|███▋      | 59/160 [01:05<00:29,  3.42it/s] 38%|███▊      | 60/160 [01:06<00:29,  3.43it/s] 38%|███▊      | 61/160 [01:06<00:28,  3.43it/s] 39%|███▉      | 62/160 [01:06<00:28,  3.44it/s] 39%|███▉      | 63/160 [01:06<00:28,  3.44it/s] 40%|████      | 64/160 [01:07<00:24,  3.85it/s][INFO|trainer.py:2140] 2023-08-29 09:27:30,338 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 09:27:30,338 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 09:27:30,338 >>   Batch size = 8
{'eval_loss': 0.9000823497772217, 'eval_runtime': 39.609, 'eval_samples_per_second': 355.146, 'eval_steps_per_second': 44.409, 'epoch': 1.0}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 55.98it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.44it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.94it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.82it/s][A
  2%|▏         | 27/1759 [00:00<00:38, 44.93it/s][A
  2%|▏         | 32/1759 [00:00<00:38, 45.09it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 45.02it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 44.83it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 44.78it/s][A
  3%|▎         | 52/1759 [00:01<00:38, 44.85it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.08it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.21it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.22it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.21it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 45.16it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 45.08it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.90it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.77it/s][A
  6%|▌         | 97/1759 [00:02<00:37, 44.89it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.07it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.26it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.12it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.16it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 45.10it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 45.12it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 44.94it/s][A
  8%|▊         | 137/1759 [00:03<00:36, 44.88it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 44.92it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.09it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.23it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.22it/s][A
  9%|▉         | 162/1759 [00:03<00:36, 43.67it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 44.24it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 44.50it/s][A
 10%|█         | 177/1759 [00:03<00:35, 44.65it/s][A
 10%|█         | 182/1759 [00:04<00:35, 44.68it/s][A
 11%|█         | 187/1759 [00:04<00:35, 44.81it/s][A
 11%|█         | 192/1759 [00:04<00:34, 44.98it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.04it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 44.85it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 44.84it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 45.03it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 45.01it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 45.02it/s][A
 13%|█▎        | 227/1759 [00:05<00:34, 45.00it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 45.05it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.10it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.12it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.00it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 44.97it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 45.02it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 45.13it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 45.13it/s][A
 15%|█▌        | 272/1759 [00:06<00:32, 45.10it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.12it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.17it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.13it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.07it/s][A
 17%|█▋        | 297/1759 [00:06<00:34, 42.83it/s][A
 17%|█▋        | 302/1759 [00:06<00:33, 43.60it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 44.20it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 44.48it/s][A
 18%|█▊        | 317/1759 [00:07<00:32, 44.75it/s][A
 18%|█▊        | 322/1759 [00:07<00:32, 44.86it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 44.88it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 44.98it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 44.78it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 44.83it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 44.92it/s][A
 20%|██        | 352/1759 [00:07<00:31, 45.08it/s][A
 20%|██        | 357/1759 [00:07<00:31, 45.21it/s][A
 21%|██        | 362/1759 [00:08<00:30, 45.30it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.16it/s][A
 21%|██        | 372/1759 [00:08<00:30, 44.95it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 44.94it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 44.81it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 44.81it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 44.91it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 44.86it/s][A
 23%|██▎       | 402/1759 [00:08<00:29, 45.25it/s][A
 23%|██▎       | 407/1759 [00:09<00:29, 45.18it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.02it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.00it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 44.97it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 44.73it/s][A
 25%|██▍       | 432/1759 [00:09<00:30, 43.79it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 44.28it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 44.64it/s][A
 25%|██▌       | 447/1759 [00:09<00:29, 44.83it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 44.97it/s][A
 26%|██▌       | 457/1759 [00:10<00:29, 44.88it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 44.83it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 44.82it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 44.74it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 44.83it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 44.77it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 44.91it/s][A
 28%|██▊       | 492/1759 [00:10<00:28, 45.10it/s][A
 28%|██▊       | 497/1759 [00:11<00:27, 45.14it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.03it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 44.90it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 44.90it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 44.97it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 44.81it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 44.97it/s][A
 30%|███       | 532/1759 [00:11<00:27, 45.03it/s][A
 31%|███       | 537/1759 [00:11<00:27, 45.21it/s][A
 31%|███       | 542/1759 [00:12<00:26, 45.23it/s][A
 31%|███       | 547/1759 [00:12<00:26, 45.11it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.02it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 44.95it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 44.94it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 44.77it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 44.88it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 45.01it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 45.12it/s][A
 33%|███▎      | 587/1759 [00:13<00:25, 45.27it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.13it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.19it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 45.02it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 44.98it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 44.98it/s][A
 35%|███▌      | 617/1759 [00:13<00:26, 43.63it/s][A
 35%|███▌      | 622/1759 [00:13<00:25, 44.13it/s][A
 36%|███▌      | 627/1759 [00:13<00:25, 44.58it/s][A
 36%|███▌      | 632/1759 [00:14<00:25, 44.74it/s][A
 36%|███▌      | 637/1759 [00:14<00:24, 44.95it/s][A
 36%|███▋      | 642/1759 [00:14<00:24, 44.97it/s][A
 37%|███▋      | 647/1759 [00:14<00:24, 44.92it/s][A
 37%|███▋      | 652/1759 [00:14<00:24, 44.91it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 44.77it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 44.77it/s][A
 38%|███▊      | 667/1759 [00:14<00:24, 44.84it/s][A
 38%|███▊      | 672/1759 [00:14<00:24, 44.91it/s][A
 38%|███▊      | 677/1759 [00:15<00:23, 45.14it/s][A
 39%|███▉      | 682/1759 [00:15<00:23, 45.17it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 45.05it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 44.96it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 44.93it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 44.86it/s][A
 40%|████      | 707/1759 [00:15<00:23, 44.82it/s][A
 40%|████      | 712/1759 [00:15<00:23, 44.87it/s][A
 41%|████      | 717/1759 [00:15<00:23, 44.98it/s][A
 41%|████      | 722/1759 [00:16<00:22, 45.18it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 45.16it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 45.16it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 45.14it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 45.08it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 45.05it/s][A
 43%|████▎     | 752/1759 [00:16<00:24, 40.55it/s][A
 43%|████▎     | 757/1759 [00:16<00:23, 41.99it/s][A
 43%|████▎     | 762/1759 [00:16<00:23, 43.05it/s][A
 44%|████▎     | 767/1759 [00:17<00:22, 43.72it/s][A
 44%|████▍     | 772/1759 [00:17<00:22, 44.27it/s][A
 44%|████▍     | 777/1759 [00:17<00:22, 44.56it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 44.74it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 44.73it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 44.45it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 44.33it/s][A
 46%|████▌     | 802/1759 [00:17<00:21, 44.54it/s][A
 46%|████▌     | 807/1759 [00:17<00:21, 44.67it/s][A
 46%|████▌     | 812/1759 [00:18<00:21, 44.97it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 45.13it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 45.20it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 45.29it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 45.11it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 44.82it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 44.60it/s][A
 48%|████▊     | 847/1759 [00:18<00:20, 44.65it/s][A
 48%|████▊     | 852/1759 [00:18<00:20, 44.74it/s][A
 49%|████▊     | 857/1759 [00:19<00:20, 45.00it/s][A
 49%|████▉     | 862/1759 [00:19<00:19, 45.15it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 45.20it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 45.27it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 45.14it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 44.84it/s][A
 50%|█████     | 887/1759 [00:19<00:20, 41.91it/s][A
 51%|█████     | 892/1759 [00:19<00:20, 42.88it/s][A
 51%|█████     | 897/1759 [00:20<00:19, 43.65it/s][A
 51%|█████▏    | 902/1759 [00:20<00:19, 44.09it/s][A
 52%|█████▏    | 907/1759 [00:20<00:19, 44.43it/s][A
 52%|█████▏    | 912/1759 [00:20<00:18, 44.64it/s][A
 52%|█████▏    | 917/1759 [00:20<00:18, 44.87it/s][A
 52%|█████▏    | 922/1759 [00:20<00:18, 45.00it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 44.56it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 44.69it/s][A
 53%|█████▎    | 937/1759 [00:20<00:18, 44.85it/s][A
 54%|█████▎    | 942/1759 [00:21<00:18, 44.97it/s][A
 54%|█████▍    | 947/1759 [00:21<00:18, 44.99it/s][A
 54%|█████▍    | 952/1759 [00:21<00:17, 45.00it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 44.99it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 45.12it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 44.94it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 44.79it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 44.74it/s][A
 56%|█████▌    | 982/1759 [00:21<00:17, 44.84it/s][A
 56%|█████▌    | 987/1759 [00:22<00:17, 44.95it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 45.10it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 45.15it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 45.12it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.26it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 45.00it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 44.95it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:16, 44.68it/s][A
 58%|█████▊    | 1027/1759 [00:22<00:16, 44.71it/s][A
 59%|█████▊    | 1032/1759 [00:23<00:16, 44.92it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:16, 44.97it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:15, 45.03it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:15, 45.08it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:15, 45.08it/s][A
 60%|██████    | 1057/1759 [00:23<00:15, 45.11it/s][A
 60%|██████    | 1062/1759 [00:23<00:15, 45.01it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 44.86it/s][A
 61%|██████    | 1072/1759 [00:23<00:15, 44.78it/s][A
 61%|██████    | 1077/1759 [00:24<00:16, 42.37it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:15, 43.29it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:15, 43.90it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 44.49it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 44.47it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 44.67it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 44.69it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 44.73it/s][A
 64%|██████▎   | 1117/1759 [00:24<00:14, 44.53it/s][A
 64%|██████▍   | 1122/1759 [00:25<00:14, 44.66it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 44.79it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:13, 44.99it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 44.74it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 45.23it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 45.17it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 45.17it/s][A
 66%|██████▌   | 1157/1759 [00:25<00:13, 45.10it/s][A
 66%|██████▌   | 1162/1759 [00:25<00:13, 44.85it/s][A
 66%|██████▋   | 1167/1759 [00:26<00:13, 44.84it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 44.87it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:12, 45.01it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:12, 44.98it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 44.94it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:12, 45.06it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 45.02it/s][A
 68%|██████▊   | 1202/1759 [00:26<00:12, 44.98it/s][A
 69%|██████▊   | 1207/1759 [00:26<00:12, 44.83it/s][A
 69%|██████▉   | 1212/1759 [00:27<00:12, 44.80it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 44.92it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:11, 44.94it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 44.90it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 44.87it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 45.06it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 44.99it/s][A
 71%|███████   | 1247/1759 [00:27<00:11, 44.85it/s][A
 71%|███████   | 1252/1759 [00:27<00:11, 44.78it/s][A
 71%|███████▏  | 1257/1759 [00:28<00:11, 44.77it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:11, 44.90it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:10, 44.90it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 44.96it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 45.00it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 44.97it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 44.96it/s][A
 73%|███████▎  | 1292/1759 [00:28<00:10, 44.82it/s][A
 74%|███████▎  | 1297/1759 [00:28<00:10, 44.84it/s][A
 74%|███████▍  | 1302/1759 [00:29<00:10, 44.82it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 42.38it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:10, 43.25it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:10, 43.95it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 44.34it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 44.59it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 44.55it/s][A
 76%|███████▌  | 1337/1759 [00:29<00:09, 44.64it/s][A
 76%|███████▋  | 1342/1759 [00:29<00:09, 44.67it/s][A
 77%|███████▋  | 1347/1759 [00:30<00:09, 44.49it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 44.54it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:08, 44.75it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 44.95it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 45.03it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:08, 45.16it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:08, 45.03it/s][A
 79%|███████▊  | 1382/1759 [00:30<00:08, 44.91it/s][A
 79%|███████▉  | 1387/1759 [00:30<00:08, 44.89it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 44.82it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 41.09it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:08, 42.25it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:08, 43.09it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 43.74it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 44.13it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 44.51it/s][A
 81%|████████  | 1427/1759 [00:31<00:07, 44.72it/s][A
 81%|████████▏ | 1432/1759 [00:31<00:07, 44.85it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 44.60it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 44.64it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 44.78it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 44.82it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 44.98it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 44.98it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 45.01it/s][A
 84%|████████▎ | 1472/1759 [00:32<00:06, 45.15it/s][A
 84%|████████▍ | 1477/1759 [00:32<00:06, 44.90it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 44.79it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 44.77it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 44.78it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 44.87it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 44.95it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 45.09it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 45.12it/s][A
 86%|████████▌ | 1517/1759 [00:33<00:05, 45.13it/s][A
 87%|████████▋ | 1522/1759 [00:33<00:05, 45.03it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 44.82it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 42.79it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:05, 43.56it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 44.07it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 44.37it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 44.62it/s][A
 89%|████████▊ | 1557/1759 [00:34<00:04, 44.77it/s][A
 89%|████████▉ | 1562/1759 [00:34<00:04, 44.95it/s][A
 89%|████████▉ | 1567/1759 [00:34<00:04, 44.89it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 44.59it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 44.70it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 44.71it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 44.92it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 45.01it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 45.06it/s][A
 91%|█████████ | 1602/1759 [00:35<00:03, 45.05it/s][A
 91%|█████████▏| 1607/1759 [00:35<00:03, 45.05it/s][A
 92%|█████████▏| 1612/1759 [00:36<00:03, 44.95it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 44.79it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 44.75it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 44.78it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 44.90it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 45.02it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 45.09it/s][A
 94%|█████████▎| 1647/1759 [00:36<00:02, 43.92it/s][A
 94%|█████████▍| 1652/1759 [00:36<00:02, 44.54it/s][A
 94%|█████████▍| 1657/1759 [00:37<00:02, 44.70it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 44.70it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 44.65it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 44.76it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 44.96it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 44.94it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 44.95it/s][A
 96%|█████████▌| 1692/1759 [00:37<00:01, 44.95it/s][A
 96%|█████████▋| 1697/1759 [00:37<00:01, 44.95it/s][A
 97%|█████████▋| 1702/1759 [00:38<00:01, 44.96it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 44.72it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 44.75it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 44.85it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 44.89it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 44.91it/s][A
 98%|█████████▊| 1732/1759 [00:38<00:00, 45.11it/s][A
 99%|█████████▊| 1737/1759 [00:38<00:00, 45.02it/s][A
 99%|█████████▉| 1742/1759 [00:38<00:00, 44.93it/s][A
 99%|█████████▉| 1747/1759 [00:39<00:00, 38.17it/s][A
100%|█████████▉| 1751/1759 [00:39<00:00, 36.01it/s][A
100%|█████████▉| 1755/1759 [00:39<00:00, 32.32it/s][A
                                                   [A                                                
100%|██████████| 1759/1759 [00:39<00:00, 32.32it/s][A 40%|████      | 64/160 [01:46<00:24,  3.85it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 09:28:09,918 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-64
[INFO|configuration_utils.py:351] 2023-08-29 09:28:10,080 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-64/config.json
[INFO|modeling_utils.py:886] 2023-08-29 09:28:13,583 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-64/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 09:28:13,848 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-64/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 09:28:13,934 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-64/special_tokens_map.json
 41%|████      | 65/160 [01:56<23:47, 15.03s/it] 41%|████▏     | 66/160 [01:56<16:37, 10.61s/it] 42%|████▏     | 67/160 [01:57<11:39,  7.52s/it] 42%|████▎     | 68/160 [01:57<08:12,  5.35s/it] 43%|████▎     | 69/160 [01:57<05:48,  3.83s/it] 44%|████▍     | 70/160 [01:58<04:09,  2.77s/it] 44%|████▍     | 71/160 [01:58<03:00,  2.03s/it] 45%|████▌     | 72/160 [01:58<02:12,  1.51s/it] 46%|████▌     | 73/160 [01:59<01:39,  1.14s/it] 46%|████▋     | 74/160 [01:59<01:16,  1.13it/s] 47%|████▋     | 75/160 [01:59<01:00,  1.41it/s] 48%|████▊     | 76/160 [01:59<00:49,  1.71it/s] 48%|████▊     | 77/160 [02:00<00:41,  1.98it/s] 49%|████▉     | 78/160 [02:00<00:36,  2.26it/s] 49%|████▉     | 79/160 [02:00<00:32,  2.52it/s] 50%|█████     | 80/160 [02:01<00:29,  2.73it/s] 51%|█████     | 81/160 [02:01<00:27,  2.90it/s] 51%|█████▏    | 82/160 [02:01<00:25,  3.04it/s] 52%|█████▏    | 83/160 [02:01<00:24,  3.14it/s] 52%|█████▎    | 84/160 [02:02<00:23,  3.21it/s] 53%|█████▎    | 85/160 [02:02<00:22,  3.27it/s] 54%|█████▍    | 86/160 [02:02<00:22,  3.31it/s] 54%|█████▍    | 87/160 [02:03<00:21,  3.33it/s] 55%|█████▌    | 88/160 [02:03<00:21,  3.28it/s] 56%|█████▌    | 89/160 [02:03<00:21,  3.32it/s] 56%|█████▋    | 90/160 [02:04<00:20,  3.34it/s] 57%|█████▋    | 91/160 [02:04<00:20,  3.36it/s] 57%|█████▊    | 92/160 [02:04<00:20,  3.37it/s] 58%|█████▊    | 93/160 [02:04<00:19,  3.38it/s] 59%|█████▉    | 94/160 [02:05<00:19,  3.39it/s] 59%|█████▉    | 95/160 [02:05<00:19,  3.39it/s] 60%|██████    | 96/160 [02:05<00:16,  3.79it/s][INFO|trainer.py:2140] 2023-08-29 09:28:28,900 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 09:28:28,900 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 09:28:28,900 >>   Batch size = 8
{'eval_loss': 0.9054571986198425, 'eval_runtime': 39.4682, 'eval_samples_per_second': 356.414, 'eval_steps_per_second': 44.568, 'epoch': 2.0}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.06it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.15it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.78it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.64it/s][A
  2%|▏         | 27/1759 [00:00<00:38, 44.71it/s][A
  2%|▏         | 32/1759 [00:00<00:38, 44.83it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 44.88it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 44.63it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 44.70it/s][A
  3%|▎         | 52/1759 [00:01<00:38, 44.89it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.07it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.14it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.09it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.24it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 45.16it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 45.16it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.92it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.86it/s][A
  6%|▌         | 97/1759 [00:02<00:37, 44.92it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.03it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.07it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.12it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.23it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 45.24it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 45.18it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 45.11it/s][A
  8%|▊         | 137/1759 [00:03<00:35, 45.06it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.03it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.02it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.05it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.04it/s][A
  9%|▉         | 162/1759 [00:03<00:37, 42.33it/s][A
  9%|▉         | 167/1759 [00:03<00:36, 43.24it/s][A
 10%|▉         | 172/1759 [00:03<00:36, 43.85it/s][A
 10%|█         | 177/1759 [00:03<00:35, 44.38it/s][A
 10%|█         | 182/1759 [00:04<00:35, 44.59it/s][A
 11%|█         | 187/1759 [00:04<00:35, 44.80it/s][A
 11%|█         | 192/1759 [00:04<00:34, 44.88it/s][A
 11%|█         | 197/1759 [00:04<00:34, 44.90it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 44.72it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 44.73it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 44.89it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 44.98it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 45.07it/s][A
 13%|█▎        | 227/1759 [00:05<00:33, 45.14it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 45.24it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.26it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.02it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 44.97it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 44.87it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 44.95it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 45.09it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 45.16it/s][A
 15%|█▌        | 272/1759 [00:06<00:32, 45.21it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.10it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.11it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.02it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 44.87it/s][A
 17%|█▋        | 297/1759 [00:06<00:34, 43.00it/s][A
 17%|█▋        | 302/1759 [00:06<00:33, 43.73it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 44.24it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 44.59it/s][A
 18%|█▊        | 317/1759 [00:07<00:32, 44.76it/s][A
 18%|█▊        | 322/1759 [00:07<00:32, 44.90it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.04it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 44.91it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 44.72it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 44.74it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 45.00it/s][A
 20%|██        | 352/1759 [00:07<00:31, 45.09it/s][A
 20%|██        | 357/1759 [00:07<00:31, 45.17it/s][A
 21%|██        | 362/1759 [00:08<00:30, 45.19it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.21it/s][A
 21%|██        | 372/1759 [00:08<00:30, 45.19it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.04it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 44.87it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 44.86it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 44.95it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 45.06it/s][A
 23%|██▎       | 402/1759 [00:08<00:30, 45.09it/s][A
 23%|██▎       | 407/1759 [00:09<00:29, 45.25it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.16it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.11it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 44.90it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 44.86it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 44.87it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 44.80it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 44.89it/s][A
 25%|██▌       | 447/1759 [00:09<00:29, 44.97it/s][A
 26%|██▌       | 452/1759 [00:10<00:28, 45.16it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 45.20it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.01it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 44.99it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 44.76it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 44.77it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 44.86it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 45.01it/s][A
 28%|██▊       | 492/1759 [00:10<00:28, 45.00it/s][A
 28%|██▊       | 497/1759 [00:11<00:27, 45.14it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 44.99it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 45.22it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 45.11it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 44.42it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 44.54it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 44.59it/s][A
 30%|███       | 532/1759 [00:11<00:27, 44.71it/s][A
 31%|███       | 537/1759 [00:11<00:27, 44.83it/s][A
 31%|███       | 542/1759 [00:12<00:26, 45.11it/s][A
 31%|███       | 547/1759 [00:12<00:26, 45.11it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.20it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 44.98it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 44.95it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 44.88it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 44.78it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 44.91it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 44.94it/s][A
 33%|███▎      | 587/1759 [00:13<00:25, 45.13it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.15it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.26it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 45.13it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 44.94it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 44.93it/s][A
 35%|███▌      | 617/1759 [00:13<00:25, 44.75it/s][A
 35%|███▌      | 622/1759 [00:13<00:25, 44.80it/s][A
 36%|███▌      | 627/1759 [00:13<00:25, 44.92it/s][A
 36%|███▌      | 632/1759 [00:14<00:25, 45.03it/s][A
 36%|███▌      | 637/1759 [00:14<00:24, 45.08it/s][A
 36%|███▋      | 642/1759 [00:14<00:24, 45.18it/s][A
 37%|███▋      | 647/1759 [00:14<00:24, 45.23it/s][A
 37%|███▋      | 652/1759 [00:14<00:25, 43.76it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 44.11it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 44.38it/s][A
 38%|███▊      | 667/1759 [00:14<00:24, 44.59it/s][A
 38%|███▊      | 672/1759 [00:14<00:24, 44.64it/s][A
 38%|███▊      | 677/1759 [00:15<00:24, 44.63it/s][A
 39%|███▉      | 682/1759 [00:15<00:23, 44.88it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 45.02it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 44.89it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 45.05it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 45.01it/s][A
 40%|████      | 707/1759 [00:15<00:23, 45.06it/s][A
 40%|████      | 712/1759 [00:15<00:23, 45.10it/s][A
 41%|████      | 717/1759 [00:15<00:23, 45.04it/s][A
 41%|████      | 722/1759 [00:16<00:23, 44.91it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 45.01it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 44.91it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 44.89it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 44.92it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 44.85it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 44.91it/s][A
 43%|████▎     | 757/1759 [00:16<00:22, 44.94it/s][A
 43%|████▎     | 762/1759 [00:16<00:22, 45.02it/s][A
 44%|████▎     | 767/1759 [00:17<00:22, 44.90it/s][A
 44%|████▍     | 772/1759 [00:17<00:21, 44.91it/s][A
 44%|████▍     | 777/1759 [00:17<00:21, 44.98it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 44.93it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 44.39it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 44.66it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 44.72it/s][A
 46%|████▌     | 802/1759 [00:17<00:21, 44.88it/s][A
 46%|████▌     | 807/1759 [00:17<00:21, 44.84it/s][A
 46%|████▌     | 812/1759 [00:18<00:21, 44.89it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 44.93it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 44.96it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 44.82it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 44.82it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 44.79it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 44.94it/s][A
 48%|████▊     | 847/1759 [00:18<00:20, 44.98it/s][A
 48%|████▊     | 852/1759 [00:18<00:20, 45.06it/s][A
 49%|████▊     | 857/1759 [00:19<00:19, 45.17it/s][A
 49%|████▉     | 862/1759 [00:19<00:19, 45.06it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 45.02it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 44.92it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 44.91it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 44.87it/s][A
 50%|█████     | 887/1759 [00:19<00:19, 44.93it/s][A
 51%|█████     | 892/1759 [00:19<00:19, 44.97it/s][A
 51%|█████     | 897/1759 [00:19<00:19, 44.97it/s][A
 51%|█████▏    | 902/1759 [00:20<00:19, 44.96it/s][A
 52%|█████▏    | 907/1759 [00:20<00:18, 44.99it/s][A
 52%|█████▏    | 912/1759 [00:20<00:18, 44.96it/s][A
 52%|█████▏    | 917/1759 [00:20<00:18, 44.91it/s][A
 52%|█████▏    | 922/1759 [00:20<00:20, 41.74it/s][A
 53%|█████▎    | 927/1759 [00:20<00:19, 42.80it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 43.58it/s][A
 53%|█████▎    | 937/1759 [00:20<00:18, 43.99it/s][A
 54%|█████▎    | 942/1759 [00:20<00:18, 44.35it/s][A
 54%|█████▍    | 947/1759 [00:21<00:18, 44.58it/s][A
 54%|█████▍    | 952/1759 [00:21<00:18, 44.66it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 44.68it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 44.46it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 44.54it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 44.65it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 44.79it/s][A
 56%|█████▌    | 982/1759 [00:21<00:17, 45.04it/s][A
 56%|█████▌    | 987/1759 [00:21<00:17, 45.13it/s][A
 56%|█████▋    | 992/1759 [00:22<00:16, 45.16it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 45.07it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 44.97it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 44.78it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 44.66it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 44.72it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:16, 44.83it/s][A
 58%|█████▊    | 1027/1759 [00:22<00:16, 45.13it/s][A
 59%|█████▊    | 1032/1759 [00:22<00:16, 45.26it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:16, 45.10it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:15, 45.12it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:15, 44.97it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:15, 44.85it/s][A
 60%|██████    | 1057/1759 [00:23<00:16, 42.09it/s][A
 60%|██████    | 1062/1759 [00:23<00:16, 42.99it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 43.72it/s][A
 61%|██████    | 1072/1759 [00:23<00:15, 44.13it/s][A
 61%|██████    | 1077/1759 [00:24<00:15, 44.56it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:15, 44.58it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:14, 44.83it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 44.95it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 44.65it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 44.64it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 44.74it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 44.96it/s][A
 64%|██████▎   | 1117/1759 [00:24<00:14, 45.17it/s][A
 64%|██████▍   | 1122/1759 [00:25<00:14, 45.10it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 45.08it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:13, 45.10it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 44.86it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 44.73it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 44.73it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 44.79it/s][A
 66%|██████▌   | 1157/1759 [00:25<00:13, 44.99it/s][A
 66%|██████▌   | 1162/1759 [00:25<00:13, 45.20it/s][A
 66%|██████▋   | 1167/1759 [00:26<00:13, 45.22it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 45.11it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:12, 45.07it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:12, 45.02it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 44.97it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:14, 40.05it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:13, 41.58it/s][A
 68%|██████▊   | 1202/1759 [00:26<00:13, 42.70it/s][A
 69%|██████▊   | 1207/1759 [00:26<00:12, 43.45it/s][A
 69%|██████▉   | 1212/1759 [00:27<00:12, 44.17it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 44.55it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:11, 44.76it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 44.73it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 44.39it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 44.24it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 44.41it/s][A
 71%|███████   | 1247/1759 [00:27<00:11, 44.58it/s][A
 71%|███████   | 1252/1759 [00:27<00:11, 44.80it/s][A
 71%|███████▏  | 1257/1759 [00:28<00:11, 44.92it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:11, 44.96it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:10, 45.11it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 45.14it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 45.05it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 44.93it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 44.83it/s][A
 73%|███████▎  | 1292/1759 [00:28<00:10, 44.88it/s][A
 74%|███████▎  | 1297/1759 [00:28<00:10, 44.88it/s][A
 74%|███████▍  | 1302/1759 [00:29<00:10, 44.98it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 44.95it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:09, 45.12it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:09, 45.00it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 45.00it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:10, 41.37it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:10, 42.58it/s][A
 76%|███████▌  | 1337/1759 [00:29<00:09, 43.31it/s][A
 76%|███████▋  | 1342/1759 [00:29<00:09, 43.90it/s][A
 77%|███████▋  | 1347/1759 [00:30<00:09, 44.20it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 44.43it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:08, 44.72it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 44.80it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 44.57it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:08, 44.49it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:08, 44.68it/s][A
 79%|███████▊  | 1382/1759 [00:30<00:08, 44.86it/s][A
 79%|███████▉  | 1387/1759 [00:30<00:08, 44.94it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 45.00it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 45.02it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:07, 45.18it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 45.11it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 44.87it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 44.91it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 44.79it/s][A
 81%|████████  | 1427/1759 [00:31<00:07, 44.81it/s][A
 81%|████████▏ | 1432/1759 [00:31<00:07, 44.89it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 44.98it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 45.04it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 45.05it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 45.05it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 44.83it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 44.21it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 44.47it/s][A
 84%|████████▎ | 1472/1759 [00:32<00:06, 44.60it/s][A
 84%|████████▍ | 1477/1759 [00:32<00:06, 44.62it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 44.83it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 44.95it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 44.94it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 44.97it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 44.75it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 44.68it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 44.78it/s][A
 86%|████████▌ | 1517/1759 [00:33<00:05, 44.95it/s][A
 87%|████████▋ | 1522/1759 [00:33<00:05, 44.96it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 45.02it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 45.11it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 44.96it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 45.02it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 44.71it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 44.69it/s][A
 89%|████████▊ | 1557/1759 [00:34<00:04, 44.81it/s][A
 89%|████████▉ | 1562/1759 [00:34<00:04, 44.83it/s][A
 89%|████████▉ | 1567/1759 [00:34<00:04, 44.95it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 45.00it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 45.05it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 45.07it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 44.85it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 44.86it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 44.35it/s][A
 91%|█████████ | 1602/1759 [00:35<00:03, 44.61it/s][A
 91%|█████████▏| 1607/1759 [00:35<00:03, 44.81it/s][A
 92%|█████████▏| 1612/1759 [00:35<00:03, 44.79it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 44.97it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 44.92it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 44.88it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 44.89it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 44.75it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 44.78it/s][A
 94%|█████████▎| 1647/1759 [00:36<00:02, 44.86it/s][A
 94%|█████████▍| 1652/1759 [00:36<00:02, 44.98it/s][A
 94%|█████████▍| 1657/1759 [00:36<00:02, 45.03it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 45.05it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 45.05it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 44.95it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 44.80it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 44.80it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 44.87it/s][A
 96%|█████████▌| 1692/1759 [00:37<00:01, 44.85it/s][A
 96%|█████████▋| 1697/1759 [00:37<00:01, 44.94it/s][A
 97%|█████████▋| 1702/1759 [00:37<00:01, 45.02it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 45.10it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 43.94it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 44.62it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 44.62it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 44.67it/s][A
 98%|█████████▊| 1732/1759 [00:38<00:00, 43.67it/s][A
 99%|█████████▊| 1737/1759 [00:38<00:00, 44.18it/s][A
 99%|█████████▉| 1742/1759 [00:38<00:00, 44.39it/s][A
 99%|█████████▉| 1747/1759 [00:39<00:00, 44.60it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 44.82it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 44.81it/s][A
                                                   [A                                                
100%|██████████| 1759/1759 [00:39<00:00, 44.81it/s][A 60%|██████    | 96/160 [02:45<00:16,  3.79it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 09:29:08,256 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-96
[INFO|configuration_utils.py:351] 2023-08-29 09:29:08,376 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-96/config.json
[INFO|modeling_utils.py:886] 2023-08-29 09:29:11,149 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-96/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 09:29:11,324 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-96/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 09:29:11,378 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-96/special_tokens_map.json
 61%|██████    | 97/160 [02:55<15:59, 15.23s/it] 61%|██████▏   | 98/160 [02:56<11:06, 10.76s/it] 62%|██████▏   | 99/160 [02:56<07:44,  7.62s/it] 62%|██████▎   | 100/160 [02:56<05:25,  5.42s/it] 63%|██████▎   | 101/160 [02:57<03:49,  3.88s/it] 64%|██████▍   | 102/160 [02:57<02:42,  2.81s/it] 64%|██████▍   | 103/160 [02:57<01:56,  2.05s/it] 65%|██████▌   | 104/160 [02:57<01:25,  1.52s/it] 66%|██████▌   | 105/160 [02:58<01:03,  1.16s/it] 66%|██████▋   | 106/160 [02:58<00:48,  1.12it/s] 67%|██████▋   | 107/160 [02:58<00:37,  1.40it/s] 68%|██████▊   | 108/160 [02:59<00:30,  1.70it/s] 68%|██████▊   | 109/160 [02:59<00:25,  1.97it/s] 69%|██████▉   | 110/160 [02:59<00:22,  2.25it/s] 69%|██████▉   | 111/160 [03:00<00:19,  2.51it/s] 70%|███████   | 112/160 [03:00<00:17,  2.72it/s] 71%|███████   | 113/160 [03:00<00:16,  2.90it/s] 71%|███████▏  | 114/160 [03:00<00:15,  3.03it/s] 72%|███████▏  | 115/160 [03:01<00:14,  3.13it/s] 72%|███████▎  | 116/160 [03:01<00:13,  3.21it/s] 73%|███████▎  | 117/160 [03:01<00:13,  3.27it/s] 74%|███████▍  | 118/160 [03:02<00:12,  3.31it/s] 74%|███████▍  | 119/160 [03:02<00:12,  3.33it/s] 75%|███████▌  | 120/160 [03:02<00:12,  3.30it/s] 76%|███████▌  | 121/160 [03:02<00:11,  3.33it/s] 76%|███████▋  | 122/160 [03:03<00:11,  3.35it/s] 77%|███████▋  | 123/160 [03:03<00:10,  3.37it/s] 78%|███████▊  | 124/160 [03:03<00:10,  3.38it/s] 78%|███████▊  | 125/160 [03:04<00:10,  3.38it/s] 79%|███████▉  | 126/160 [03:04<00:10,  3.39it/s] 79%|███████▉  | 127/160 [03:04<00:09,  3.39it/s] 80%|████████  | 128/160 [03:04<00:08,  3.78it/s][INFO|trainer.py:2140] 2023-08-29 09:29:28,133 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 09:29:28,133 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 09:29:28,133 >>   Batch size = 8
{'eval_loss': 0.9223339557647705, 'eval_runtime': 39.2969, 'eval_samples_per_second': 357.967, 'eval_steps_per_second': 44.762, 'epoch': 3.0}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:30, 56.61it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.60it/s][A
  1%|          | 18/1759 [00:00<00:36, 47.69it/s][A
  1%|▏         | 23/1759 [00:00<00:37, 46.83it/s][A
  2%|▏         | 28/1759 [00:00<00:38, 45.22it/s][A
  2%|▏         | 33/1759 [00:00<00:38, 45.14it/s][A
  2%|▏         | 38/1759 [00:00<00:38, 44.99it/s][A
  2%|▏         | 43/1759 [00:00<00:38, 44.59it/s][A
  3%|▎         | 48/1759 [00:01<00:38, 44.71it/s][A
  3%|▎         | 53/1759 [00:01<00:38, 44.82it/s][A
  3%|▎         | 58/1759 [00:01<00:37, 45.12it/s][A
  4%|▎         | 63/1759 [00:01<00:37, 45.16it/s][A
  4%|▍         | 68/1759 [00:01<00:37, 45.28it/s][A
  4%|▍         | 73/1759 [00:01<00:37, 45.35it/s][A
  4%|▍         | 78/1759 [00:01<00:37, 45.36it/s][A
  5%|▍         | 83/1759 [00:01<00:37, 45.12it/s][A
  5%|▌         | 88/1759 [00:01<00:37, 44.98it/s][A
  5%|▌         | 93/1759 [00:02<00:37, 44.86it/s][A
  6%|▌         | 98/1759 [00:02<00:37, 44.86it/s][A
  6%|▌         | 103/1759 [00:02<00:36, 45.08it/s][A
  6%|▌         | 108/1759 [00:02<00:36, 45.11it/s][A
  6%|▋         | 113/1759 [00:02<00:36, 45.26it/s][A
  7%|▋         | 118/1759 [00:02<00:36, 45.34it/s][A
  7%|▋         | 123/1759 [00:02<00:36, 45.38it/s][A
  7%|▋         | 128/1759 [00:02<00:36, 45.14it/s][A
  8%|▊         | 133/1759 [00:02<00:36, 44.96it/s][A
  8%|▊         | 138/1759 [00:03<00:36, 44.81it/s][A
  8%|▊         | 143/1759 [00:03<00:36, 44.83it/s][A
  8%|▊         | 148/1759 [00:03<00:35, 45.01it/s][A
  9%|▊         | 153/1759 [00:03<00:35, 44.99it/s][A
  9%|▉         | 158/1759 [00:03<00:35, 45.16it/s][A
  9%|▉         | 163/1759 [00:03<00:35, 44.46it/s][A
 10%|▉         | 168/1759 [00:03<00:35, 44.82it/s][A
 10%|▉         | 173/1759 [00:03<00:35, 44.94it/s][A
 10%|█         | 178/1759 [00:03<00:35, 44.91it/s][A
 10%|█         | 183/1759 [00:04<00:35, 44.88it/s][A
 11%|█         | 188/1759 [00:04<00:34, 44.89it/s][A
 11%|█         | 193/1759 [00:04<00:34, 44.93it/s][A
 11%|█▏        | 198/1759 [00:04<00:34, 45.04it/s][A
 12%|█▏        | 203/1759 [00:04<00:34, 45.06it/s][A
 12%|█▏        | 208/1759 [00:04<00:34, 45.19it/s][A
 12%|█▏        | 213/1759 [00:04<00:34, 45.22it/s][A
 12%|█▏        | 218/1759 [00:04<00:34, 45.29it/s][A
 13%|█▎        | 223/1759 [00:04<00:34, 45.11it/s][A
 13%|█▎        | 228/1759 [00:05<00:34, 44.99it/s][A
 13%|█▎        | 233/1759 [00:05<00:33, 44.91it/s][A
 14%|█▎        | 238/1759 [00:05<00:33, 44.88it/s][A
 14%|█▍        | 243/1759 [00:05<00:33, 44.99it/s][A
 14%|█▍        | 248/1759 [00:05<00:33, 45.01it/s][A
 14%|█▍        | 253/1759 [00:05<00:33, 45.16it/s][A
 15%|█▍        | 258/1759 [00:05<00:33, 45.28it/s][A
 15%|█▍        | 263/1759 [00:05<00:33, 45.14it/s][A
 15%|█▌        | 268/1759 [00:05<00:33, 45.11it/s][A
 16%|█▌        | 273/1759 [00:06<00:33, 44.96it/s][A
 16%|█▌        | 278/1759 [00:06<00:32, 44.91it/s][A
 16%|█▌        | 283/1759 [00:06<00:32, 44.93it/s][A
 16%|█▋        | 288/1759 [00:06<00:32, 44.94it/s][A
 17%|█▋        | 293/1759 [00:06<00:32, 45.08it/s][A
 17%|█▋        | 298/1759 [00:06<00:32, 44.53it/s][A
 17%|█▋        | 303/1759 [00:06<00:32, 44.83it/s][A
 18%|█▊        | 308/1759 [00:06<00:32, 44.85it/s][A
 18%|█▊        | 313/1759 [00:06<00:32, 44.85it/s][A
 18%|█▊        | 318/1759 [00:07<00:32, 44.82it/s][A
 18%|█▊        | 323/1759 [00:07<00:32, 44.75it/s][A
 19%|█▊        | 328/1759 [00:07<00:31, 44.89it/s][A
 19%|█▉        | 333/1759 [00:07<00:31, 44.96it/s][A
 19%|█▉        | 338/1759 [00:07<00:31, 45.08it/s][A
 19%|█▉        | 343/1759 [00:07<00:31, 45.09it/s][A
 20%|█▉        | 348/1759 [00:07<00:31, 45.24it/s][A
 20%|██        | 353/1759 [00:07<00:31, 45.13it/s][A
 20%|██        | 358/1759 [00:07<00:31, 45.02it/s][A
 21%|██        | 363/1759 [00:08<00:31, 44.92it/s][A
 21%|██        | 368/1759 [00:08<00:31, 44.80it/s][A
 21%|██        | 373/1759 [00:08<00:30, 44.96it/s][A
 21%|██▏       | 378/1759 [00:08<00:30, 45.00it/s][A
 22%|██▏       | 383/1759 [00:08<00:30, 45.12it/s][A
 22%|██▏       | 388/1759 [00:08<00:30, 45.18it/s][A
 22%|██▏       | 393/1759 [00:08<00:30, 45.17it/s][A
 23%|██▎       | 398/1759 [00:08<00:30, 45.19it/s][A
 23%|██▎       | 403/1759 [00:08<00:30, 45.07it/s][A
 23%|██▎       | 408/1759 [00:09<00:30, 44.97it/s][A
 23%|██▎       | 413/1759 [00:09<00:30, 44.81it/s][A
 24%|██▍       | 418/1759 [00:09<00:29, 44.76it/s][A
 24%|██▍       | 423/1759 [00:09<00:29, 44.95it/s][A
 24%|██▍       | 428/1759 [00:09<00:29, 45.07it/s][A
 25%|██▍       | 433/1759 [00:09<00:30, 43.48it/s][A
 25%|██▍       | 438/1759 [00:09<00:29, 44.07it/s][A
 25%|██▌       | 443/1759 [00:09<00:29, 44.42it/s][A
 25%|██▌       | 448/1759 [00:09<00:29, 44.72it/s][A
 26%|██▌       | 453/1759 [00:10<00:29, 44.76it/s][A
 26%|██▌       | 458/1759 [00:10<00:29, 44.84it/s][A
 26%|██▋       | 463/1759 [00:10<00:28, 44.91it/s][A
 27%|██▋       | 468/1759 [00:10<00:28, 45.02it/s][A
 27%|██▋       | 473/1759 [00:10<00:28, 44.88it/s][A
 27%|██▋       | 478/1759 [00:10<00:28, 44.92it/s][A
 27%|██▋       | 483/1759 [00:10<00:28, 44.94it/s][A
 28%|██▊       | 488/1759 [00:10<00:28, 45.11it/s][A
 28%|██▊       | 493/1759 [00:10<00:28, 45.11it/s][A
 28%|██▊       | 498/1759 [00:11<00:28, 44.95it/s][A
 29%|██▊       | 503/1759 [00:11<00:27, 44.87it/s][A
 29%|██▉       | 508/1759 [00:11<00:27, 45.02it/s][A
 29%|██▉       | 513/1759 [00:11<00:27, 45.01it/s][A
 29%|██▉       | 518/1759 [00:11<00:27, 45.01it/s][A
 30%|██▉       | 523/1759 [00:11<00:27, 45.01it/s][A
 30%|███       | 528/1759 [00:11<00:27, 45.05it/s][A
 30%|███       | 533/1759 [00:11<00:27, 45.04it/s][A
 31%|███       | 538/1759 [00:11<00:27, 44.98it/s][A
 31%|███       | 543/1759 [00:12<00:27, 44.88it/s][A
 31%|███       | 548/1759 [00:12<00:26, 44.97it/s][A
 31%|███▏      | 553/1759 [00:12<00:26, 44.93it/s][A
 32%|███▏      | 558/1759 [00:12<00:26, 45.00it/s][A
 32%|███▏      | 563/1759 [00:12<00:26, 44.97it/s][A
 32%|███▏      | 568/1759 [00:12<00:26, 44.97it/s][A
 33%|███▎      | 573/1759 [00:12<00:26, 45.00it/s][A
 33%|███▎      | 578/1759 [00:12<00:26, 44.97it/s][A
 33%|███▎      | 583/1759 [00:12<00:26, 45.08it/s][A
 33%|███▎      | 588/1759 [00:13<00:26, 44.91it/s][A
 34%|███▎      | 593/1759 [00:13<00:25, 44.96it/s][A
 34%|███▍      | 598/1759 [00:13<00:25, 44.94it/s][A
 34%|███▍      | 603/1759 [00:13<00:25, 45.00it/s][A
 35%|███▍      | 608/1759 [00:13<00:25, 44.98it/s][A
 35%|███▍      | 613/1759 [00:13<00:25, 45.03it/s][A
 35%|███▌      | 618/1759 [00:13<00:25, 43.93it/s][A
 35%|███▌      | 623/1759 [00:13<00:25, 44.38it/s][A
 36%|███▌      | 628/1759 [00:13<00:25, 44.49it/s][A
 36%|███▌      | 633/1759 [00:14<00:25, 44.70it/s][A
 36%|███▋      | 638/1759 [00:14<00:25, 44.65it/s][A
 37%|███▋      | 643/1759 [00:14<00:24, 44.74it/s][A
 37%|███▋      | 648/1759 [00:14<00:24, 44.87it/s][A
 37%|███▋      | 653/1759 [00:14<00:24, 44.80it/s][A
 37%|███▋      | 658/1759 [00:14<00:24, 44.93it/s][A
 38%|███▊      | 663/1759 [00:14<00:24, 44.98it/s][A
 38%|███▊      | 668/1759 [00:14<00:24, 45.11it/s][A
 38%|███▊      | 673/1759 [00:14<00:24, 45.01it/s][A
 39%|███▊      | 678/1759 [00:15<00:24, 45.02it/s][A
 39%|███▉      | 683/1759 [00:15<00:23, 44.97it/s][A
 39%|███▉      | 688/1759 [00:15<00:23, 44.92it/s][A
 39%|███▉      | 693/1759 [00:15<00:23, 44.94it/s][A
 40%|███▉      | 698/1759 [00:15<00:23, 44.99it/s][A
 40%|███▉      | 703/1759 [00:15<00:23, 45.03it/s][A
 40%|████      | 708/1759 [00:15<00:23, 45.02it/s][A
 41%|████      | 713/1759 [00:15<00:23, 45.09it/s][A
 41%|████      | 718/1759 [00:15<00:23, 45.06it/s][A
 41%|████      | 723/1759 [00:16<00:23, 44.99it/s][A
 41%|████▏     | 728/1759 [00:16<00:22, 44.94it/s][A
 42%|████▏     | 733/1759 [00:16<00:22, 44.90it/s][A
 42%|████▏     | 738/1759 [00:16<00:22, 44.96it/s][A
 42%|████▏     | 743/1759 [00:16<00:22, 45.02it/s][A
 43%|████▎     | 748/1759 [00:16<00:22, 44.95it/s][A
 43%|████▎     | 753/1759 [00:16<00:22, 44.57it/s][A
 43%|████▎     | 758/1759 [00:16<00:22, 44.75it/s][A
 43%|████▎     | 763/1759 [00:16<00:22, 44.90it/s][A
 44%|████▎     | 768/1759 [00:17<00:22, 44.89it/s][A
 44%|████▍     | 773/1759 [00:17<00:22, 44.79it/s][A
 44%|████▍     | 778/1759 [00:17<00:21, 44.85it/s][A
 45%|████▍     | 783/1759 [00:17<00:21, 44.89it/s][A
 45%|████▍     | 788/1759 [00:17<00:21, 44.88it/s][A
 45%|████▌     | 793/1759 [00:17<00:21, 44.87it/s][A
 45%|████▌     | 798/1759 [00:17<00:21, 44.93it/s][A
 46%|████▌     | 803/1759 [00:17<00:21, 45.08it/s][A
 46%|████▌     | 808/1759 [00:17<00:21, 45.05it/s][A
 46%|████▌     | 813/1759 [00:18<00:21, 45.03it/s][A
 47%|████▋     | 818/1759 [00:18<00:20, 44.95it/s][A
 47%|████▋     | 823/1759 [00:18<00:20, 44.97it/s][A
 47%|████▋     | 828/1759 [00:18<00:20, 44.96it/s][A
 47%|████▋     | 833/1759 [00:18<00:20, 44.96it/s][A
 48%|████▊     | 838/1759 [00:18<00:20, 44.89it/s][A
 48%|████▊     | 843/1759 [00:18<00:20, 44.95it/s][A
 48%|████▊     | 848/1759 [00:18<00:20, 45.15it/s][A
 48%|████▊     | 853/1759 [00:18<00:20, 45.10it/s][A
 49%|████▉     | 858/1759 [00:19<00:19, 45.17it/s][A
 49%|████▉     | 863/1759 [00:19<00:19, 45.18it/s][A
 49%|████▉     | 868/1759 [00:19<00:19, 45.13it/s][A
 50%|████▉     | 873/1759 [00:19<00:19, 45.11it/s][A
 50%|████▉     | 878/1759 [00:19<00:19, 44.98it/s][A
 50%|█████     | 883/1759 [00:19<00:19, 44.92it/s][A
 50%|█████     | 888/1759 [00:19<00:19, 44.35it/s][A
 51%|█████     | 893/1759 [00:19<00:19, 44.56it/s][A
 51%|█████     | 898/1759 [00:19<00:19, 44.83it/s][A
 51%|█████▏    | 903/1759 [00:20<00:19, 44.88it/s][A
 52%|█████▏    | 908/1759 [00:20<00:18, 45.03it/s][A
 52%|█████▏    | 913/1759 [00:20<00:18, 45.05it/s][A
 52%|█████▏    | 918/1759 [00:20<00:18, 45.00it/s][A
 52%|█████▏    | 923/1759 [00:20<00:18, 44.97it/s][A
 53%|█████▎    | 928/1759 [00:20<00:18, 44.87it/s][A
 53%|█████▎    | 933/1759 [00:20<00:18, 44.95it/s][A
 53%|█████▎    | 938/1759 [00:20<00:18, 45.00it/s][A
 54%|█████▎    | 943/1759 [00:20<00:18, 45.03it/s][A
 54%|█████▍    | 948/1759 [00:21<00:17, 45.08it/s][A
 54%|█████▍    | 953/1759 [00:21<00:17, 45.17it/s][A
 54%|█████▍    | 958/1759 [00:21<00:17, 45.15it/s][A
 55%|█████▍    | 963/1759 [00:21<00:17, 45.06it/s][A
 55%|█████▌    | 968/1759 [00:21<00:17, 45.08it/s][A
 55%|█████▌    | 973/1759 [00:21<00:17, 45.02it/s][A
 56%|█████▌    | 978/1759 [00:21<00:17, 44.95it/s][A
 56%|█████▌    | 983/1759 [00:21<00:17, 44.91it/s][A
 56%|█████▌    | 988/1759 [00:21<00:17, 44.99it/s][A
 56%|█████▋    | 993/1759 [00:22<00:17, 45.02it/s][A
 57%|█████▋    | 998/1759 [00:22<00:16, 44.99it/s][A
 57%|█████▋    | 1003/1759 [00:22<00:16, 44.92it/s][A
 57%|█████▋    | 1008/1759 [00:22<00:16, 44.84it/s][A
 58%|█████▊    | 1013/1759 [00:22<00:16, 44.98it/s][A
 58%|█████▊    | 1018/1759 [00:22<00:16, 44.92it/s][A
 58%|█████▊    | 1023/1759 [00:22<00:18, 39.55it/s][A
 58%|█████▊    | 1028/1759 [00:22<00:17, 41.18it/s][A
 59%|█████▊    | 1033/1759 [00:23<00:17, 42.51it/s][A
 59%|█████▉    | 1038/1759 [00:23<00:16, 43.35it/s][A
 59%|█████▉    | 1043/1759 [00:23<00:16, 44.02it/s][A
 60%|█████▉    | 1048/1759 [00:23<00:16, 44.41it/s][A
 60%|█████▉    | 1053/1759 [00:23<00:15, 44.79it/s][A
 60%|██████    | 1058/1759 [00:23<00:15, 44.81it/s][A
 60%|██████    | 1063/1759 [00:23<00:15, 44.46it/s][A
 61%|██████    | 1068/1759 [00:23<00:15, 44.24it/s][A
 61%|██████    | 1073/1759 [00:23<00:15, 44.49it/s][A
 61%|██████▏   | 1078/1759 [00:24<00:15, 44.64it/s][A
 62%|██████▏   | 1083/1759 [00:24<00:15, 44.89it/s][A
 62%|██████▏   | 1088/1759 [00:24<00:14, 45.04it/s][A
 62%|██████▏   | 1093/1759 [00:24<00:14, 45.16it/s][A
 62%|██████▏   | 1098/1759 [00:24<00:14, 45.27it/s][A
 63%|██████▎   | 1103/1759 [00:24<00:14, 45.21it/s][A
 63%|██████▎   | 1108/1759 [00:24<00:14, 44.93it/s][A
 63%|██████▎   | 1113/1759 [00:24<00:14, 44.62it/s][A
 64%|██████▎   | 1118/1759 [00:24<00:14, 44.61it/s][A
 64%|██████▍   | 1123/1759 [00:25<00:14, 44.70it/s][A
 64%|██████▍   | 1128/1759 [00:25<00:14, 44.94it/s][A
 64%|██████▍   | 1133/1759 [00:25<00:13, 45.06it/s][A
 65%|██████▍   | 1138/1759 [00:25<00:13, 45.17it/s][A
 65%|██████▍   | 1143/1759 [00:25<00:13, 45.29it/s][A
 65%|██████▌   | 1148/1759 [00:25<00:13, 45.29it/s][A
 66%|██████▌   | 1153/1759 [00:25<00:13, 45.05it/s][A
 66%|██████▌   | 1158/1759 [00:25<00:14, 41.24it/s][A
 66%|██████▌   | 1163/1759 [00:25<00:14, 42.46it/s][A
 66%|██████▋   | 1168/1759 [00:26<00:13, 43.15it/s][A
 67%|██████▋   | 1173/1759 [00:26<00:13, 43.84it/s][A
 67%|██████▋   | 1178/1759 [00:26<00:13, 44.09it/s][A
 67%|██████▋   | 1183/1759 [00:26<00:12, 44.62it/s][A
 68%|██████▊   | 1188/1759 [00:26<00:12, 44.78it/s][A
 68%|██████▊   | 1193/1759 [00:26<00:12, 44.98it/s][A
 68%|██████▊   | 1198/1759 [00:26<00:12, 44.52it/s][A
 68%|██████▊   | 1203/1759 [00:26<00:12, 44.69it/s][A
 69%|██████▊   | 1208/1759 [00:26<00:12, 44.76it/s][A
 69%|██████▉   | 1213/1759 [00:27<00:12, 44.93it/s][A
 69%|██████▉   | 1218/1759 [00:27<00:12, 44.96it/s][A
 70%|██████▉   | 1223/1759 [00:27<00:11, 45.09it/s][A
 70%|██████▉   | 1228/1759 [00:27<00:11, 45.10it/s][A
 70%|███████   | 1233/1759 [00:27<00:11, 45.14it/s][A
 70%|███████   | 1238/1759 [00:27<00:11, 44.93it/s][A
 71%|███████   | 1243/1759 [00:27<00:11, 44.77it/s][A
 71%|███████   | 1248/1759 [00:27<00:11, 44.74it/s][A
 71%|███████   | 1253/1759 [00:27<00:11, 44.82it/s][A
 72%|███████▏  | 1258/1759 [00:28<00:11, 44.89it/s][A
 72%|███████▏  | 1263/1759 [00:28<00:11, 44.98it/s][A
 72%|███████▏  | 1268/1759 [00:28<00:10, 45.18it/s][A
 72%|███████▏  | 1273/1759 [00:28<00:10, 45.19it/s][A
 73%|███████▎  | 1278/1759 [00:28<00:10, 45.23it/s][A
 73%|███████▎  | 1283/1759 [00:28<00:10, 44.99it/s][A
 73%|███████▎  | 1288/1759 [00:28<00:10, 44.96it/s][A
 74%|███████▎  | 1293/1759 [00:28<00:11, 42.35it/s][A
 74%|███████▍  | 1298/1759 [00:28<00:10, 43.17it/s][A
 74%|███████▍  | 1303/1759 [00:29<00:10, 43.82it/s][A
 74%|███████▍  | 1308/1759 [00:29<00:10, 44.22it/s][A
 75%|███████▍  | 1313/1759 [00:29<00:10, 44.60it/s][A
 75%|███████▍  | 1318/1759 [00:29<00:09, 44.81it/s][A
 75%|███████▌  | 1323/1759 [00:29<00:09, 44.84it/s][A
 75%|███████▌  | 1328/1759 [00:29<00:09, 44.92it/s][A
 76%|███████▌  | 1333/1759 [00:29<00:09, 44.70it/s][A
 76%|███████▌  | 1338/1759 [00:29<00:09, 44.62it/s][A
 76%|███████▋  | 1343/1759 [00:29<00:09, 44.77it/s][A
 77%|███████▋  | 1348/1759 [00:30<00:09, 44.88it/s][A
 77%|███████▋  | 1353/1759 [00:30<00:09, 45.06it/s][A
 77%|███████▋  | 1358/1759 [00:30<00:08, 45.16it/s][A
 77%|███████▋  | 1363/1759 [00:30<00:08, 45.00it/s][A
 78%|███████▊  | 1368/1759 [00:30<00:08, 45.13it/s][A
 78%|███████▊  | 1373/1759 [00:30<00:08, 44.99it/s][A
 78%|███████▊  | 1378/1759 [00:30<00:08, 44.89it/s][A
 79%|███████▊  | 1383/1759 [00:30<00:08, 44.83it/s][A
 79%|███████▉  | 1388/1759 [00:30<00:08, 44.87it/s][A
 79%|███████▉  | 1393/1759 [00:31<00:08, 44.84it/s][A
 79%|███████▉  | 1398/1759 [00:31<00:08, 44.96it/s][A
 80%|███████▉  | 1403/1759 [00:31<00:07, 45.00it/s][A
 80%|████████  | 1408/1759 [00:31<00:07, 45.12it/s][A
 80%|████████  | 1413/1759 [00:31<00:07, 45.05it/s][A
 81%|████████  | 1418/1759 [00:31<00:07, 44.98it/s][A
 81%|████████  | 1423/1759 [00:31<00:07, 44.88it/s][A
 81%|████████  | 1428/1759 [00:31<00:07, 42.03it/s][A
 81%|████████▏ | 1433/1759 [00:31<00:07, 43.05it/s][A
 82%|████████▏ | 1438/1759 [00:32<00:07, 43.60it/s][A
 82%|████████▏ | 1443/1759 [00:32<00:07, 44.13it/s][A
 82%|████████▏ | 1448/1759 [00:32<00:07, 44.42it/s][A
 83%|████████▎ | 1453/1759 [00:32<00:06, 44.75it/s][A
 83%|████████▎ | 1458/1759 [00:32<00:06, 44.84it/s][A
 83%|████████▎ | 1463/1759 [00:32<00:06, 44.84it/s][A
 83%|████████▎ | 1468/1759 [00:32<00:06, 44.58it/s][A
 84%|████████▎ | 1473/1759 [00:32<00:06, 44.67it/s][A
 84%|████████▍ | 1478/1759 [00:32<00:06, 44.75it/s][A
 84%|████████▍ | 1483/1759 [00:33<00:06, 44.78it/s][A
 85%|████████▍ | 1488/1759 [00:33<00:06, 45.02it/s][A
 85%|████████▍ | 1493/1759 [00:33<00:05, 44.97it/s][A
 85%|████████▌ | 1498/1759 [00:33<00:05, 45.15it/s][A
 85%|████████▌ | 1503/1759 [00:33<00:05, 45.03it/s][A
 86%|████████▌ | 1508/1759 [00:33<00:05, 44.91it/s][A
 86%|████████▌ | 1513/1759 [00:33<00:05, 44.78it/s][A
 86%|████████▋ | 1518/1759 [00:33<00:05, 44.80it/s][A
 87%|████████▋ | 1523/1759 [00:33<00:05, 44.88it/s][A
 87%|████████▋ | 1528/1759 [00:34<00:05, 44.85it/s][A
 87%|████████▋ | 1533/1759 [00:34<00:05, 44.99it/s][A
 87%|████████▋ | 1538/1759 [00:34<00:04, 45.02it/s][A
 88%|████████▊ | 1543/1759 [00:34<00:04, 45.13it/s][A
 88%|████████▊ | 1548/1759 [00:34<00:04, 45.14it/s][A
 88%|████████▊ | 1553/1759 [00:34<00:04, 44.88it/s][A
 89%|████████▊ | 1558/1759 [00:34<00:04, 44.82it/s][A
 89%|████████▉ | 1563/1759 [00:34<00:04, 43.23it/s][A
 89%|████████▉ | 1568/1759 [00:34<00:04, 43.91it/s][A
 89%|████████▉ | 1573/1759 [00:35<00:04, 44.21it/s][A
 90%|████████▉ | 1578/1759 [00:35<00:04, 44.51it/s][A
 90%|████████▉ | 1583/1759 [00:35<00:03, 44.73it/s][A
 90%|█████████ | 1588/1759 [00:35<00:03, 44.98it/s][A
 91%|█████████ | 1593/1759 [00:35<00:03, 44.98it/s][A
 91%|█████████ | 1598/1759 [00:35<00:03, 44.97it/s][A
 91%|█████████ | 1603/1759 [00:35<00:03, 44.70it/s][A
 91%|█████████▏| 1608/1759 [00:35<00:03, 44.73it/s][A
 92%|█████████▏| 1613/1759 [00:35<00:03, 44.75it/s][A
 92%|█████████▏| 1618/1759 [00:36<00:03, 44.91it/s][A
 92%|█████████▏| 1623/1759 [00:36<00:03, 44.98it/s][A
 93%|█████████▎| 1628/1759 [00:36<00:02, 45.08it/s][A
 93%|█████████▎| 1633/1759 [00:36<00:02, 45.05it/s][A
 93%|█████████▎| 1638/1759 [00:36<00:02, 45.08it/s][A
 93%|█████████▎| 1643/1759 [00:36<00:02, 44.95it/s][A
 94%|█████████▎| 1648/1759 [00:36<00:02, 44.80it/s][A
 94%|█████████▍| 1653/1759 [00:36<00:02, 44.80it/s][A
 94%|█████████▍| 1658/1759 [00:36<00:02, 44.77it/s][A
 95%|█████████▍| 1663/1759 [00:37<00:02, 44.86it/s][A
 95%|█████████▍| 1668/1759 [00:37<00:02, 44.91it/s][A
 95%|█████████▌| 1673/1759 [00:37<00:01, 45.08it/s][A
 95%|█████████▌| 1678/1759 [00:37<00:01, 45.07it/s][A
 96%|█████████▌| 1683/1759 [00:37<00:01, 44.99it/s][A
 96%|█████████▌| 1688/1759 [00:37<00:01, 44.95it/s][A
 96%|█████████▌| 1693/1759 [00:37<00:01, 44.83it/s][A
 97%|█████████▋| 1698/1759 [00:37<00:01, 43.82it/s][A
 97%|█████████▋| 1703/1759 [00:37<00:01, 44.17it/s][A
 97%|█████████▋| 1708/1759 [00:38<00:01, 44.51it/s][A
 97%|█████████▋| 1713/1759 [00:38<00:01, 44.70it/s][A
 98%|█████████▊| 1718/1759 [00:38<00:00, 44.93it/s][A
 98%|█████████▊| 1723/1759 [00:38<00:00, 44.90it/s][A
 98%|█████████▊| 1728/1759 [00:38<00:00, 45.01it/s][A
 99%|█████████▊| 1733/1759 [00:38<00:00, 45.01it/s][A
 99%|█████████▉| 1738/1759 [00:38<00:00, 44.72it/s][A
 99%|█████████▉| 1743/1759 [00:38<00:00, 44.64it/s][A
 99%|█████████▉| 1748/1759 [00:39<00:00, 43.68it/s][A
100%|█████████▉| 1753/1759 [00:39<00:00, 44.35it/s][A
100%|█████████▉| 1758/1759 [00:39<00:00, 44.73it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 44.73it/s][A 80%|████████  | 128/160 [03:44<00:08,  3.78it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 09:30:07,437 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-128
[INFO|configuration_utils.py:351] 2023-08-29 09:30:07,544 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-128/config.json
[INFO|modeling_utils.py:886] 2023-08-29 09:30:10,324 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-128/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 09:30:10,422 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-128/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 09:30:10,478 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-128/special_tokens_map.json
 81%|████████  | 129/160 [03:54<07:50, 15.18s/it] 81%|████████▏ | 130/160 [03:55<05:21, 10.72s/it] 82%|████████▏ | 131/160 [03:55<03:40,  7.59s/it] 82%|████████▎ | 132/160 [03:55<02:31,  5.40s/it] 83%|████████▎ | 133/160 [03:56<01:44,  3.87s/it] 84%|████████▍ | 134/160 [03:56<01:12,  2.80s/it] 84%|████████▍ | 135/160 [03:56<00:51,  2.04s/it] 85%|████████▌ | 136/160 [03:56<00:36,  1.52s/it] 86%|████████▌ | 137/160 [03:57<00:26,  1.15s/it] 86%|████████▋ | 138/160 [03:57<00:19,  1.12it/s] 87%|████████▋ | 139/160 [03:57<00:14,  1.40it/s] 88%|████████▊ | 140/160 [03:58<00:11,  1.70it/s] 88%|████████▊ | 141/160 [03:58<00:09,  1.97it/s] 89%|████████▉ | 142/160 [03:58<00:07,  2.26it/s] 89%|████████▉ | 143/160 [03:59<00:06,  2.51it/s] 90%|█████████ | 144/160 [03:59<00:05,  2.73it/s] 91%|█████████ | 145/160 [03:59<00:05,  2.90it/s] 91%|█████████▏| 146/160 [03:59<00:04,  3.03it/s] 92%|█████████▏| 147/160 [04:00<00:04,  3.14it/s] 92%|█████████▎| 148/160 [04:00<00:03,  3.21it/s] 93%|█████████▎| 149/160 [04:00<00:03,  3.27it/s] 94%|█████████▍| 150/160 [04:01<00:03,  3.31it/s] 94%|█████████▍| 151/160 [04:01<00:02,  3.35it/s] 95%|█████████▌| 152/160 [04:01<00:02,  3.22it/s] 96%|█████████▌| 153/160 [04:02<00:02,  3.28it/s] 96%|█████████▋| 154/160 [04:02<00:01,  3.33it/s] 97%|█████████▋| 155/160 [04:02<00:01,  3.37it/s] 98%|█████████▊| 156/160 [04:02<00:01,  3.39it/s] 98%|█████████▊| 157/160 [04:03<00:00,  3.41it/s] 99%|█████████▉| 158/160 [04:03<00:00,  3.42it/s] 99%|█████████▉| 159/160 [04:03<00:00,  3.43it/s]100%|██████████| 160/160 [04:03<00:00,  3.84it/s][INFO|trainer.py:2140] 2023-08-29 09:30:27,157 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 09:30:27,157 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 09:30:27,157 >>   Batch size = 8
{'eval_loss': 0.9261903762817383, 'eval_runtime': 39.2643, 'eval_samples_per_second': 358.264, 'eval_steps_per_second': 44.799, 'epoch': 4.0}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:30, 56.83it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.49it/s][A
  1%|          | 18/1759 [00:00<00:36, 47.37it/s][A
  1%|▏         | 23/1759 [00:00<00:37, 46.39it/s][A
  2%|▏         | 28/1759 [00:00<00:38, 45.49it/s][A
  2%|▏         | 33/1759 [00:00<00:38, 45.36it/s][A
  2%|▏         | 38/1759 [00:00<00:38, 45.24it/s][A
  2%|▏         | 43/1759 [00:00<00:38, 45.02it/s][A
  3%|▎         | 48/1759 [00:01<00:37, 45.05it/s][A
  3%|▎         | 53/1759 [00:01<00:37, 45.13it/s][A
  3%|▎         | 58/1759 [00:01<00:37, 45.30it/s][A
  4%|▎         | 63/1759 [00:01<00:38, 44.05it/s][A
  4%|▍         | 68/1759 [00:01<00:37, 45.49it/s][A
  4%|▍         | 73/1759 [00:01<00:37, 45.23it/s][A
  4%|▍         | 78/1759 [00:01<00:37, 45.19it/s][A
  5%|▍         | 83/1759 [00:01<00:37, 45.05it/s][A
  5%|▌         | 88/1759 [00:01<00:37, 45.00it/s][A
  5%|▌         | 93/1759 [00:02<00:37, 44.99it/s][A
  6%|▌         | 98/1759 [00:02<00:36, 45.09it/s][A
  6%|▌         | 103/1759 [00:02<00:36, 45.22it/s][A
  6%|▌         | 108/1759 [00:02<00:36, 45.14it/s][A
  6%|▋         | 113/1759 [00:02<00:36, 45.20it/s][A
  7%|▋         | 118/1759 [00:02<00:36, 44.96it/s][A
  7%|▋         | 123/1759 [00:02<00:36, 44.93it/s][A
  7%|▋         | 128/1759 [00:02<00:36, 44.88it/s][A
  8%|▊         | 133/1759 [00:02<00:36, 44.82it/s][A
  8%|▊         | 138/1759 [00:03<00:36, 44.86it/s][A
  8%|▊         | 143/1759 [00:03<00:35, 44.93it/s][A
  8%|▊         | 148/1759 [00:03<00:35, 45.12it/s][A
  9%|▊         | 153/1759 [00:03<00:35, 45.09it/s][A
  9%|▉         | 158/1759 [00:03<00:35, 45.22it/s][A
  9%|▉         | 163/1759 [00:03<00:36, 43.83it/s][A
 10%|▉         | 168/1759 [00:03<00:35, 44.21it/s][A
 10%|▉         | 173/1759 [00:03<00:35, 44.41it/s][A
 10%|█         | 178/1759 [00:03<00:35, 44.45it/s][A
 10%|█         | 183/1759 [00:04<00:35, 44.59it/s][A
 11%|█         | 188/1759 [00:04<00:35, 44.76it/s][A
 11%|█         | 193/1759 [00:04<00:34, 44.96it/s][A
 11%|█▏        | 198/1759 [00:04<00:34, 44.98it/s][A
 12%|█▏        | 203/1759 [00:04<00:34, 44.95it/s][A
 12%|█▏        | 208/1759 [00:04<00:34, 44.97it/s][A
 12%|█▏        | 213/1759 [00:04<00:34, 45.00it/s][A
 12%|█▏        | 218/1759 [00:04<00:34, 44.94it/s][A
 13%|█▎        | 223/1759 [00:04<00:34, 44.98it/s][A
 13%|█▎        | 228/1759 [00:05<00:34, 44.95it/s][A
 13%|█▎        | 233/1759 [00:05<00:34, 44.83it/s][A
 14%|█▎        | 238/1759 [00:05<00:33, 45.12it/s][A
 14%|█▍        | 243/1759 [00:05<00:33, 45.07it/s][A
 14%|█▍        | 248/1759 [00:05<00:33, 45.03it/s][A
 14%|█▍        | 253/1759 [00:05<00:33, 45.06it/s][A
 15%|█▍        | 258/1759 [00:05<00:33, 44.99it/s][A
 15%|█▍        | 263/1759 [00:05<00:33, 45.01it/s][A
 15%|█▌        | 268/1759 [00:05<00:33, 44.96it/s][A
 16%|█▌        | 273/1759 [00:06<00:33, 44.92it/s][A
 16%|█▌        | 278/1759 [00:06<00:32, 44.90it/s][A
 16%|█▌        | 283/1759 [00:06<00:32, 45.03it/s][A
 16%|█▋        | 288/1759 [00:06<00:32, 45.11it/s][A
 17%|█▋        | 293/1759 [00:06<00:32, 45.09it/s][A
 17%|█▋        | 298/1759 [00:06<00:33, 44.21it/s][A
 17%|█▋        | 303/1759 [00:06<00:32, 44.55it/s][A
 18%|█▊        | 308/1759 [00:06<00:32, 44.66it/s][A
 18%|█▊        | 313/1759 [00:06<00:32, 44.70it/s][A
 18%|█▊        | 318/1759 [00:07<00:32, 44.80it/s][A
 18%|█▊        | 323/1759 [00:07<00:32, 44.84it/s][A
 19%|█▊        | 328/1759 [00:07<00:31, 44.89it/s][A
 19%|█▉        | 333/1759 [00:07<00:31, 44.97it/s][A
 19%|█▉        | 338/1759 [00:07<00:31, 44.96it/s][A
 19%|█▉        | 343/1759 [00:07<00:31, 45.04it/s][A
 20%|█▉        | 348/1759 [00:07<00:31, 45.05it/s][A
 20%|██        | 353/1759 [00:07<00:31, 44.95it/s][A
 20%|██        | 358/1759 [00:07<00:31, 44.91it/s][A
 21%|██        | 363/1759 [00:08<00:31, 44.88it/s][A
 21%|██        | 368/1759 [00:08<00:31, 44.86it/s][A
 21%|██        | 373/1759 [00:08<00:30, 44.94it/s][A
 21%|██▏       | 378/1759 [00:08<00:30, 44.93it/s][A
 22%|██▏       | 383/1759 [00:08<00:30, 45.06it/s][A
 22%|██▏       | 388/1759 [00:08<00:30, 45.02it/s][A
 22%|██▏       | 393/1759 [00:08<00:30, 45.09it/s][A
 23%|██▎       | 398/1759 [00:08<00:30, 45.07it/s][A
 23%|██▎       | 403/1759 [00:08<00:30, 44.99it/s][A
 23%|██▎       | 408/1759 [00:09<00:30, 44.93it/s][A
 23%|██▎       | 413/1759 [00:09<00:30, 44.77it/s][A
 24%|██▍       | 418/1759 [00:09<00:29, 44.94it/s][A
 24%|██▍       | 423/1759 [00:09<00:29, 45.06it/s][A
 24%|██▍       | 428/1759 [00:09<00:29, 45.08it/s][A
 25%|██▍       | 433/1759 [00:09<00:29, 44.39it/s][A
 25%|██▍       | 438/1759 [00:09<00:29, 44.58it/s][A
 25%|██▌       | 443/1759 [00:09<00:29, 44.75it/s][A
 25%|██▌       | 448/1759 [00:09<00:29, 44.79it/s][A
 26%|██▌       | 453/1759 [00:10<00:29, 44.72it/s][A
 26%|██▌       | 458/1759 [00:10<00:29, 44.73it/s][A
 26%|██▋       | 463/1759 [00:10<00:28, 44.82it/s][A
 27%|██▋       | 468/1759 [00:10<00:28, 44.98it/s][A
 27%|██▋       | 473/1759 [00:10<00:28, 44.96it/s][A
 27%|██▋       | 478/1759 [00:10<00:28, 45.07it/s][A
 27%|██▋       | 483/1759 [00:10<00:28, 45.04it/s][A
 28%|██▊       | 488/1759 [00:10<00:28, 45.18it/s][A
 28%|██▊       | 493/1759 [00:10<00:28, 44.97it/s][A
 28%|██▊       | 498/1759 [00:11<00:28, 44.78it/s][A
 29%|██▊       | 503/1759 [00:11<00:27, 44.89it/s][A
 29%|██▉       | 508/1759 [00:11<00:27, 44.87it/s][A
 29%|██▉       | 513/1759 [00:11<00:27, 45.03it/s][A
 29%|██▉       | 518/1759 [00:11<00:27, 45.00it/s][A
 30%|██▉       | 523/1759 [00:11<00:27, 45.08it/s][A
 30%|███       | 528/1759 [00:11<00:27, 45.13it/s][A
 30%|███       | 533/1759 [00:11<00:27, 45.04it/s][A
 31%|███       | 538/1759 [00:11<00:27, 45.00it/s][A
 31%|███       | 543/1759 [00:12<00:27, 44.74it/s][A
 31%|███       | 548/1759 [00:12<00:27, 44.80it/s][A
 31%|███▏      | 553/1759 [00:12<00:26, 44.93it/s][A
 32%|███▏      | 558/1759 [00:12<00:26, 44.99it/s][A
 32%|███▏      | 563/1759 [00:12<00:26, 45.09it/s][A
 32%|███▏      | 568/1759 [00:12<00:26, 44.63it/s][A
 33%|███▎      | 573/1759 [00:12<00:26, 44.71it/s][A
 33%|███▎      | 578/1759 [00:12<00:26, 44.93it/s][A
 33%|███▎      | 583/1759 [00:12<00:26, 44.84it/s][A
 33%|███▎      | 588/1759 [00:13<00:27, 42.54it/s][A
 34%|███▎      | 593/1759 [00:13<00:26, 43.61it/s][A
 34%|███▍      | 598/1759 [00:13<00:26, 44.12it/s][A
 34%|███▍      | 603/1759 [00:13<00:25, 44.51it/s][A
 35%|███▍      | 608/1759 [00:13<00:25, 44.73it/s][A
 35%|███▍      | 613/1759 [00:13<00:25, 44.78it/s][A
 35%|███▌      | 618/1759 [00:13<00:25, 44.94it/s][A
 35%|███▌      | 623/1759 [00:13<00:25, 45.00it/s][A
 36%|███▌      | 628/1759 [00:13<00:25, 44.76it/s][A
 36%|███▌      | 633/1759 [00:14<00:25, 44.86it/s][A
 36%|███▋      | 638/1759 [00:14<00:25, 44.80it/s][A
 37%|███▋      | 643/1759 [00:14<00:24, 44.96it/s][A
 37%|███▋      | 648/1759 [00:14<00:24, 45.17it/s][A
 37%|███▋      | 653/1759 [00:14<00:24, 45.09it/s][A
 37%|███▋      | 658/1759 [00:14<00:24, 45.11it/s][A
 38%|███▊      | 663/1759 [00:14<00:24, 45.09it/s][A
 38%|███▊      | 668/1759 [00:14<00:24, 45.03it/s][A
 38%|███▊      | 673/1759 [00:14<00:24, 44.87it/s][A
 39%|███▊      | 678/1759 [00:15<00:24, 44.83it/s][A
 39%|███▉      | 683/1759 [00:15<00:24, 44.76it/s][A
 39%|███▉      | 688/1759 [00:15<00:23, 44.87it/s][A
 39%|███▉      | 693/1759 [00:15<00:23, 44.99it/s][A
 40%|███▉      | 698/1759 [00:15<00:23, 45.10it/s][A
 40%|███▉      | 703/1759 [00:15<00:23, 45.18it/s][A
 40%|████      | 708/1759 [00:15<00:23, 45.06it/s][A
 41%|████      | 713/1759 [00:15<00:23, 45.01it/s][A
 41%|████      | 718/1759 [00:15<00:23, 44.87it/s][A
 41%|████      | 723/1759 [00:16<00:23, 44.49it/s][A
 41%|████▏     | 728/1759 [00:16<00:23, 44.59it/s][A
 42%|████▏     | 733/1759 [00:16<00:22, 44.72it/s][A
 42%|████▏     | 738/1759 [00:16<00:22, 44.91it/s][A
 42%|████▏     | 743/1759 [00:16<00:22, 45.05it/s][A
 43%|████▎     | 748/1759 [00:16<00:22, 45.02it/s][A
 43%|████▎     | 753/1759 [00:16<00:22, 45.09it/s][A
 43%|████▎     | 758/1759 [00:16<00:22, 44.91it/s][A
 43%|████▎     | 763/1759 [00:16<00:22, 44.79it/s][A
 44%|████▎     | 768/1759 [00:17<00:22, 44.87it/s][A
 44%|████▍     | 773/1759 [00:17<00:21, 44.83it/s][A
 44%|████▍     | 778/1759 [00:17<00:21, 44.97it/s][A
 45%|████▍     | 783/1759 [00:17<00:21, 45.00it/s][A
 45%|████▍     | 788/1759 [00:17<00:21, 45.17it/s][A
 45%|████▌     | 793/1759 [00:17<00:21, 45.09it/s][A
 45%|████▌     | 798/1759 [00:17<00:21, 45.05it/s][A
 46%|████▌     | 803/1759 [00:17<00:21, 44.93it/s][A
 46%|████▌     | 808/1759 [00:17<00:21, 44.82it/s][A
 46%|████▌     | 813/1759 [00:18<00:21, 44.74it/s][A
 47%|████▋     | 818/1759 [00:18<00:20, 44.87it/s][A
 47%|████▋     | 823/1759 [00:18<00:20, 44.94it/s][A
 47%|████▋     | 828/1759 [00:18<00:20, 45.08it/s][A
 47%|████▋     | 833/1759 [00:18<00:20, 45.10it/s][A
 48%|████▊     | 838/1759 [00:18<00:20, 45.10it/s][A
 48%|████▊     | 843/1759 [00:18<00:20, 45.02it/s][A
 48%|████▊     | 848/1759 [00:18<00:20, 44.93it/s][A
 48%|████▊     | 853/1759 [00:19<00:20, 44.88it/s][A
 49%|████▉     | 858/1759 [00:19<00:20, 43.17it/s][A
 49%|████▉     | 863/1759 [00:19<00:20, 43.88it/s][A
 49%|████▉     | 868/1759 [00:19<00:20, 44.28it/s][A
 50%|████▉     | 873/1759 [00:19<00:19, 44.62it/s][A
 50%|████▉     | 878/1759 [00:19<00:19, 44.74it/s][A
 50%|█████     | 883/1759 [00:19<00:19, 44.88it/s][A
 50%|█████     | 888/1759 [00:19<00:19, 44.85it/s][A
 51%|█████     | 893/1759 [00:19<00:19, 44.84it/s][A
 51%|█████     | 898/1759 [00:19<00:19, 44.60it/s][A
 51%|█████▏    | 903/1759 [00:20<00:19, 44.54it/s][A
 52%|█████▏    | 908/1759 [00:20<00:18, 44.79it/s][A
 52%|█████▏    | 913/1759 [00:20<00:18, 44.91it/s][A
 52%|█████▏    | 918/1759 [00:20<00:18, 45.15it/s][A
 52%|█████▏    | 923/1759 [00:20<00:18, 45.08it/s][A
 53%|█████▎    | 928/1759 [00:20<00:18, 45.16it/s][A
 53%|█████▎    | 933/1759 [00:20<00:18, 45.27it/s][A
 53%|█████▎    | 938/1759 [00:20<00:18, 45.10it/s][A
 54%|█████▎    | 943/1759 [00:20<00:18, 44.83it/s][A
 54%|█████▍    | 948/1759 [00:21<00:18, 44.83it/s][A
 54%|█████▍    | 953/1759 [00:21<00:17, 44.88it/s][A
 54%|█████▍    | 958/1759 [00:21<00:17, 44.99it/s][A
 55%|█████▍    | 963/1759 [00:21<00:17, 45.02it/s][A
 55%|█████▌    | 968/1759 [00:21<00:17, 45.07it/s][A
 55%|█████▌    | 973/1759 [00:21<00:17, 45.13it/s][A
 56%|█████▌    | 978/1759 [00:21<00:17, 44.98it/s][A
 56%|█████▌    | 983/1759 [00:21<00:17, 45.00it/s][A
 56%|█████▌    | 988/1759 [00:22<00:17, 44.78it/s][A
 56%|█████▋    | 993/1759 [00:22<00:17, 43.65it/s][A
 57%|█████▋    | 998/1759 [00:22<00:17, 44.23it/s][A
 57%|█████▋    | 1003/1759 [00:22<00:16, 44.47it/s][A
 57%|█████▋    | 1008/1759 [00:22<00:16, 44.68it/s][A
 58%|█████▊    | 1013/1759 [00:22<00:16, 44.85it/s][A
 58%|█████▊    | 1018/1759 [00:22<00:16, 44.96it/s][A
 58%|█████▊    | 1023/1759 [00:22<00:16, 45.02it/s][A
 58%|█████▊    | 1028/1759 [00:22<00:16, 44.93it/s][A
 59%|█████▊    | 1033/1759 [00:23<00:16, 44.75it/s][A
 59%|█████▉    | 1038/1759 [00:23<00:16, 44.77it/s][A
 59%|█████▉    | 1043/1759 [00:23<00:15, 44.89it/s][A
 60%|█████▉    | 1048/1759 [00:23<00:15, 45.03it/s][A
 60%|█████▉    | 1053/1759 [00:23<00:15, 44.92it/s][A
 60%|██████    | 1058/1759 [00:23<00:15, 45.06it/s][A
 60%|██████    | 1063/1759 [00:23<00:15, 45.00it/s][A
 61%|██████    | 1068/1759 [00:23<00:15, 45.07it/s][A
 61%|██████    | 1073/1759 [00:23<00:15, 44.92it/s][A
 61%|██████▏   | 1078/1759 [00:24<00:15, 44.75it/s][A
 62%|██████▏   | 1083/1759 [00:24<00:15, 44.78it/s][A
 62%|██████▏   | 1088/1759 [00:24<00:14, 44.87it/s][A
 62%|██████▏   | 1093/1759 [00:24<00:14, 45.01it/s][A
 62%|██████▏   | 1098/1759 [00:24<00:14, 44.91it/s][A
 63%|██████▎   | 1103/1759 [00:24<00:14, 45.08it/s][A
 63%|██████▎   | 1108/1759 [00:24<00:14, 45.03it/s][A
 63%|██████▎   | 1113/1759 [00:24<00:14, 45.10it/s][A
 64%|██████▎   | 1118/1759 [00:24<00:14, 44.85it/s][A
 64%|██████▍   | 1123/1759 [00:25<00:14, 44.75it/s][A
 64%|██████▍   | 1128/1759 [00:25<00:14, 42.73it/s][A
 64%|██████▍   | 1133/1759 [00:25<00:14, 43.48it/s][A
 65%|██████▍   | 1138/1759 [00:25<00:14, 43.99it/s][A
 65%|██████▍   | 1143/1759 [00:25<00:13, 44.30it/s][A
 65%|██████▌   | 1148/1759 [00:25<00:13, 44.54it/s][A
 66%|██████▌   | 1153/1759 [00:25<00:13, 44.77it/s][A
 66%|██████▌   | 1158/1759 [00:25<00:13, 44.78it/s][A
 66%|██████▌   | 1163/1759 [00:25<00:13, 44.67it/s][A
 66%|██████▋   | 1168/1759 [00:26<00:13, 44.45it/s][A
 67%|██████▋   | 1173/1759 [00:26<00:13, 44.59it/s][A
 67%|██████▋   | 1178/1759 [00:26<00:12, 44.74it/s][A
 67%|██████▋   | 1183/1759 [00:26<00:12, 44.90it/s][A
 68%|██████▊   | 1188/1759 [00:26<00:12, 45.00it/s][A
 68%|██████▊   | 1193/1759 [00:26<00:12, 45.16it/s][A
 68%|██████▊   | 1198/1759 [00:26<00:12, 45.13it/s][A
 68%|██████▊   | 1203/1759 [00:26<00:12, 45.06it/s][A
 69%|██████▊   | 1208/1759 [00:26<00:12, 44.91it/s][A
 69%|██████▉   | 1213/1759 [00:27<00:12, 44.55it/s][A
 69%|██████▉   | 1218/1759 [00:27<00:12, 44.52it/s][A
 70%|██████▉   | 1223/1759 [00:27<00:11, 44.72it/s][A
 70%|██████▉   | 1228/1759 [00:27<00:11, 44.91it/s][A
 70%|███████   | 1233/1759 [00:27<00:11, 45.02it/s][A
 70%|███████   | 1238/1759 [00:27<00:11, 45.13it/s][A
 71%|███████   | 1243/1759 [00:27<00:11, 45.11it/s][A
 71%|███████   | 1248/1759 [00:27<00:11, 45.26it/s][A
 71%|███████   | 1253/1759 [00:27<00:11, 45.02it/s][A
 72%|███████▏  | 1258/1759 [00:28<00:11, 44.87it/s][A
 72%|███████▏  | 1263/1759 [00:28<00:11, 43.00it/s][A
 72%|███████▏  | 1268/1759 [00:28<00:11, 43.73it/s][A
 72%|███████▏  | 1273/1759 [00:28<00:11, 44.16it/s][A
 73%|███████▎  | 1278/1759 [00:28<00:10, 44.53it/s][A
 73%|███████▎  | 1283/1759 [00:28<00:10, 44.64it/s][A
 73%|███████▎  | 1288/1759 [00:28<00:10, 44.82it/s][A
 74%|███████▎  | 1293/1759 [00:28<00:10, 44.84it/s][A
 74%|███████▍  | 1298/1759 [00:28<00:10, 44.79it/s][A
 74%|███████▍  | 1303/1759 [00:29<00:10, 44.49it/s][A
 74%|███████▍  | 1308/1759 [00:29<00:10, 44.52it/s][A
 75%|███████▍  | 1313/1759 [00:29<00:09, 44.78it/s][A
 75%|███████▍  | 1318/1759 [00:29<00:09, 44.94it/s][A
 75%|███████▌  | 1323/1759 [00:29<00:09, 45.12it/s][A
 75%|███████▌  | 1328/1759 [00:29<00:09, 45.12it/s][A
 76%|███████▌  | 1333/1759 [00:29<00:09, 45.04it/s][A
 76%|███████▌  | 1338/1759 [00:29<00:09, 45.04it/s][A
 76%|███████▋  | 1343/1759 [00:29<00:09, 44.89it/s][A
 77%|███████▋  | 1348/1759 [00:30<00:09, 44.55it/s][A
 77%|███████▋  | 1353/1759 [00:30<00:09, 44.61it/s][A
 77%|███████▋  | 1358/1759 [00:30<00:08, 44.73it/s][A
 77%|███████▋  | 1363/1759 [00:30<00:08, 45.02it/s][A
 78%|███████▊  | 1368/1759 [00:30<00:08, 45.14it/s][A
 78%|███████▊  | 1373/1759 [00:30<00:08, 45.24it/s][A
 78%|███████▊  | 1378/1759 [00:30<00:08, 45.18it/s][A
 79%|███████▊  | 1383/1759 [00:30<00:08, 45.08it/s][A
 79%|███████▉  | 1388/1759 [00:30<00:08, 44.84it/s][A
 79%|███████▉  | 1393/1759 [00:31<00:08, 44.63it/s][A
 79%|███████▉  | 1398/1759 [00:31<00:08, 41.15it/s][A
 80%|███████▉  | 1403/1759 [00:31<00:08, 42.31it/s][A
 80%|████████  | 1408/1759 [00:31<00:08, 43.16it/s][A
 80%|████████  | 1413/1759 [00:31<00:07, 43.73it/s][A
 81%|████████  | 1418/1759 [00:31<00:07, 44.08it/s][A
 81%|████████  | 1423/1759 [00:31<00:07, 44.36it/s][A
 81%|████████  | 1428/1759 [00:31<00:07, 44.63it/s][A
 81%|████████▏ | 1433/1759 [00:31<00:07, 44.82it/s][A
 82%|████████▏ | 1438/1759 [00:32<00:07, 44.54it/s][A
 82%|████████▏ | 1443/1759 [00:32<00:07, 44.55it/s][A
 82%|████████▏ | 1448/1759 [00:32<00:06, 44.77it/s][A
 83%|████████▎ | 1453/1759 [00:32<00:06, 44.81it/s][A
 83%|████████▎ | 1458/1759 [00:32<00:06, 44.97it/s][A
 83%|████████▎ | 1463/1759 [00:32<00:06, 45.02it/s][A
 83%|████████▎ | 1468/1759 [00:32<00:06, 45.03it/s][A
 84%|████████▎ | 1473/1759 [00:32<00:06, 45.14it/s][A
 84%|████████▍ | 1478/1759 [00:32<00:06, 44.93it/s][A
 84%|████████▍ | 1483/1759 [00:33<00:06, 44.85it/s][A
 85%|████████▍ | 1488/1759 [00:33<00:06, 44.70it/s][A
 85%|████████▍ | 1493/1759 [00:33<00:05, 44.74it/s][A
 85%|████████▌ | 1498/1759 [00:33<00:05, 44.90it/s][A
 85%|████████▌ | 1503/1759 [00:33<00:05, 44.91it/s][A
 86%|████████▌ | 1508/1759 [00:33<00:05, 45.06it/s][A
 86%|████████▌ | 1513/1759 [00:33<00:05, 45.04it/s][A
 86%|████████▋ | 1518/1759 [00:33<00:05, 45.08it/s][A
 87%|████████▋ | 1523/1759 [00:33<00:05, 44.97it/s][A
 87%|████████▋ | 1528/1759 [00:34<00:05, 44.78it/s][A
 87%|████████▋ | 1533/1759 [00:34<00:05, 44.59it/s][A
 87%|████████▋ | 1538/1759 [00:34<00:04, 44.65it/s][A
 88%|████████▊ | 1543/1759 [00:34<00:04, 44.76it/s][A
 88%|████████▊ | 1548/1759 [00:34<00:04, 44.99it/s][A
 88%|████████▊ | 1553/1759 [00:34<00:04, 45.06it/s][A
 89%|████████▊ | 1558/1759 [00:34<00:04, 45.11it/s][A
 89%|████████▉ | 1563/1759 [00:34<00:04, 45.01it/s][A
 89%|████████▉ | 1568/1759 [00:34<00:04, 44.92it/s][A
 89%|████████▉ | 1573/1759 [00:35<00:04, 44.87it/s][A
 90%|████████▉ | 1578/1759 [00:35<00:04, 44.78it/s][A
 90%|████████▉ | 1583/1759 [00:35<00:03, 44.75it/s][A
 90%|█████████ | 1588/1759 [00:35<00:03, 44.83it/s][A
 91%|█████████ | 1593/1759 [00:35<00:03, 44.90it/s][A
 91%|█████████ | 1598/1759 [00:35<00:03, 45.10it/s][A
 91%|█████████ | 1603/1759 [00:35<00:03, 45.09it/s][A
 91%|█████████▏| 1608/1759 [00:35<00:03, 45.04it/s][A
 92%|█████████▏| 1613/1759 [00:35<00:03, 45.00it/s][A
 92%|█████████▏| 1618/1759 [00:36<00:03, 44.88it/s][A
 92%|█████████▏| 1623/1759 [00:36<00:03, 44.80it/s][A
 93%|█████████▎| 1628/1759 [00:36<00:02, 44.80it/s][A
 93%|█████████▎| 1633/1759 [00:36<00:02, 44.75it/s][A
 93%|█████████▎| 1638/1759 [00:36<00:02, 44.89it/s][A
 93%|█████████▎| 1643/1759 [00:36<00:02, 44.97it/s][A
 94%|█████████▎| 1648/1759 [00:36<00:02, 45.08it/s][A
 94%|█████████▍| 1653/1759 [00:36<00:02, 45.14it/s][A
 94%|█████████▍| 1658/1759 [00:36<00:02, 45.05it/s][A
 95%|█████████▍| 1663/1759 [00:37<00:02, 44.96it/s][A
 95%|█████████▍| 1668/1759 [00:37<00:02, 44.77it/s][A
 95%|█████████▌| 1673/1759 [00:37<00:01, 44.86it/s][A
 95%|█████████▌| 1678/1759 [00:37<00:01, 44.72it/s][A
 96%|█████████▌| 1683/1759 [00:37<00:01, 44.83it/s][A
 96%|█████████▌| 1688/1759 [00:37<00:01, 44.87it/s][A
 96%|█████████▌| 1693/1759 [00:37<00:01, 44.98it/s][A
 97%|█████████▋| 1698/1759 [00:37<00:01, 44.96it/s][A
 97%|█████████▋| 1703/1759 [00:37<00:01, 44.94it/s][A
 97%|█████████▋| 1708/1759 [00:38<00:01, 44.87it/s][A
 97%|█████████▋| 1713/1759 [00:38<00:01, 44.84it/s][A
 98%|█████████▊| 1718/1759 [00:38<00:00, 44.93it/s][A
 98%|█████████▊| 1723/1759 [00:38<00:00, 44.84it/s][A
 98%|█████████▊| 1728/1759 [00:38<00:00, 44.96it/s][A
 99%|█████████▊| 1733/1759 [00:38<00:00, 44.96it/s][A
 99%|█████████▉| 1738/1759 [00:38<00:00, 44.96it/s][A
 99%|█████████▉| 1743/1759 [00:38<00:00, 45.00it/s][A
 99%|█████████▉| 1748/1759 [00:38<00:00, 44.95it/s][A
100%|█████████▉| 1753/1759 [00:39<00:00, 44.89it/s][A
100%|█████████▉| 1758/1759 [00:39<00:00, 44.84it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 44.84it/s][A100%|██████████| 160/160 [04:43<00:00,  3.84it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 09:31:06,536 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-160
[INFO|configuration_utils.py:351] 2023-08-29 09:31:06,662 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-160/config.json
[INFO|modeling_utils.py:886] 2023-08-29 09:31:09,293 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-160/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 09:31:09,406 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-160/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 09:31:09,460 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-160/special_tokens_map.json
[INFO|trainer.py:1343] 2023-08-29 09:31:15,068 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:1352] 2023-08-29 09:31:15,092 >> Loading best model from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-32 (score: 0.9000823497772217).
                                                 100%|██████████| 160/160 [05:01<00:00,  3.84it/s]100%|██████████| 160/160 [05:01<00:00,  1.88s/it]
[INFO|trainer.py:1894] 2023-08-29 09:31:24,434 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model
[INFO|configuration_utils.py:351] 2023-08-29 09:31:24,493 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/config.json
[INFO|modeling_utils.py:886] 2023-08-29 09:31:27,281 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 09:31:27,538 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 09:31:27,645 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/special_tokens_map.json
[INFO|trainer_pt_utils.py:908] 2023-08-29 09:31:28,081 >> ***** train metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:31:28,082 >>   epoch                    =        5.0
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:31:28,082 >>   train_loss               =     0.4685
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:31:28,082 >>   train_runtime            = 0:05:01.10
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:31:28,082 >>   train_samples            =       2019
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:31:28,082 >>   train_samples_per_second =     33.527
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:31:28,082 >>   train_steps_per_second   =      0.531
{'eval_loss': 0.9308466911315918, 'eval_runtime': 39.2393, 'eval_samples_per_second': 358.492, 'eval_steps_per_second': 44.827, 'epoch': 5.0}
{'train_runtime': 301.1031, 'train_samples_per_second': 33.527, 'train_steps_per_second': 0.531, 'train_loss': 0.46848340034484864, 'epoch': 5.0}
08/29/2023 09:31:28 - INFO - transformer_base.run_clm_rl -   *** Evaluate ***
[INFO|trainer.py:2140] 2023-08-29 09:31:28,212 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 09:31:28,212 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 09:31:28,213 >>   Batch size = 8
  0%|          | 0/1759 [00:00<?, ?it/s]  0%|          | 6/1759 [00:00<00:31, 55.78it/s]  1%|          | 12/1759 [00:00<00:35, 49.15it/s]  1%|          | 17/1759 [00:00<00:40, 43.47it/s]  1%|▏         | 22/1759 [00:00<00:38, 45.03it/s]  2%|▏         | 27/1759 [00:00<00:38, 45.23it/s]  2%|▏         | 32/1759 [00:00<00:38, 45.33it/s]  2%|▏         | 37/1759 [00:00<00:37, 45.38it/s]  2%|▏         | 42/1759 [00:00<00:37, 45.19it/s]  3%|▎         | 47/1759 [00:01<00:38, 44.89it/s]  3%|▎         | 52/1759 [00:01<00:38, 44.85it/s]  3%|▎         | 57/1759 [00:01<00:37, 44.91it/s]  4%|▎         | 62/1759 [00:01<00:37, 44.95it/s]  4%|▍         | 67/1759 [00:01<00:37, 45.03it/s]  4%|▍         | 72/1759 [00:01<00:37, 45.10it/s]  4%|▍         | 77/1759 [00:01<00:37, 45.16it/s]  5%|▍         | 82/1759 [00:01<00:37, 45.23it/s]  5%|▍         | 87/1759 [00:01<00:36, 45.24it/s]  5%|▌         | 92/1759 [00:02<00:37, 45.05it/s]  6%|▌         | 97/1759 [00:02<00:36, 45.06it/s]  6%|▌         | 102/1759 [00:02<00:36, 45.03it/s]  6%|▌         | 107/1759 [00:02<00:36, 45.11it/s]  6%|▋         | 112/1759 [00:02<00:37, 44.43it/s]  7%|▋         | 117/1759 [00:02<00:36, 44.82it/s]  7%|▋         | 122/1759 [00:02<00:36, 44.95it/s]  7%|▋         | 127/1759 [00:02<00:36, 45.09it/s]  8%|▊         | 132/1759 [00:02<00:36, 44.99it/s]  8%|▊         | 137/1759 [00:03<00:36, 45.02it/s]  8%|▊         | 142/1759 [00:03<00:35, 45.06it/s]  8%|▊         | 147/1759 [00:03<00:35, 44.99it/s]  9%|▊         | 152/1759 [00:03<00:35, 45.00it/s]  9%|▉         | 157/1759 [00:03<00:35, 44.95it/s]  9%|▉         | 162/1759 [00:03<00:35, 45.13it/s]  9%|▉         | 167/1759 [00:03<00:35, 45.23it/s] 10%|▉         | 172/1759 [00:03<00:35, 45.21it/s] 10%|█         | 177/1759 [00:03<00:35, 45.06it/s] 10%|█         | 182/1759 [00:04<00:35, 45.04it/s] 11%|█         | 187/1759 [00:04<00:34, 45.04it/s] 11%|█         | 192/1759 [00:04<00:34, 44.92it/s] 11%|█         | 197/1759 [00:04<00:34, 44.90it/s] 11%|█▏        | 202/1759 [00:04<00:34, 44.90it/s] 12%|█▏        | 207/1759 [00:04<00:34, 45.03it/s] 12%|█▏        | 212/1759 [00:04<00:34, 45.13it/s] 12%|█▏        | 217/1759 [00:04<00:34, 45.17it/s] 13%|█▎        | 222/1759 [00:04<00:34, 45.07it/s] 13%|█▎        | 227/1759 [00:05<00:34, 44.97it/s] 13%|█▎        | 232/1759 [00:05<00:33, 45.00it/s] 13%|█▎        | 237/1759 [00:05<00:33, 44.90it/s] 14%|█▍        | 242/1759 [00:05<00:33, 44.87it/s] 14%|█▍        | 247/1759 [00:05<00:34, 43.41it/s] 14%|█▍        | 252/1759 [00:05<00:34, 44.01it/s] 15%|█▍        | 257/1759 [00:05<00:33, 44.55it/s] 15%|█▍        | 262/1759 [00:05<00:33, 44.64it/s] 15%|█▌        | 267/1759 [00:05<00:33, 44.80it/s] 15%|█▌        | 272/1759 [00:06<00:33, 44.77it/s] 16%|█▌        | 277/1759 [00:06<00:33, 44.78it/s] 16%|█▌        | 282/1759 [00:06<00:32, 44.78it/s] 16%|█▋        | 287/1759 [00:06<00:32, 44.64it/s] 17%|█▋        | 292/1759 [00:06<00:32, 44.73it/s] 17%|█▋        | 297/1759 [00:06<00:32, 44.89it/s] 17%|█▋        | 302/1759 [00:06<00:32, 44.99it/s] 17%|█▋        | 307/1759 [00:06<00:32, 45.08it/s] 18%|█▊        | 312/1759 [00:06<00:32, 45.16it/s] 18%|█▊        | 317/1759 [00:07<00:31, 45.10it/s] 18%|█▊        | 322/1759 [00:07<00:32, 44.87it/s] 19%|█▊        | 327/1759 [00:07<00:31, 44.89it/s] 19%|█▉        | 332/1759 [00:07<00:31, 44.78it/s] 19%|█▉        | 337/1759 [00:07<00:31, 44.76it/s] 19%|█▉        | 342/1759 [00:07<00:31, 44.92it/s] 20%|█▉        | 347/1759 [00:07<00:31, 44.99it/s] 20%|██        | 352/1759 [00:07<00:31, 45.21it/s] 20%|██        | 357/1759 [00:07<00:31, 45.11it/s] 21%|██        | 362/1759 [00:08<00:30, 45.19it/s] 21%|██        | 367/1759 [00:08<00:30, 44.96it/s] 21%|██        | 372/1759 [00:08<00:30, 44.93it/s] 21%|██▏       | 377/1759 [00:08<00:30, 44.71it/s] 22%|██▏       | 382/1759 [00:08<00:31, 43.98it/s] 22%|██▏       | 387/1759 [00:08<00:30, 44.27it/s] 22%|██▏       | 392/1759 [00:08<00:30, 44.61it/s] 23%|██▎       | 397/1759 [00:08<00:30, 44.77it/s] 23%|██▎       | 402/1759 [00:08<00:30, 45.01it/s] 23%|██▎       | 407/1759 [00:09<00:30, 45.03it/s] 23%|██▎       | 412/1759 [00:09<00:29, 45.12it/s] 24%|██▎       | 417/1759 [00:09<00:29, 44.93it/s] 24%|██▍       | 422/1759 [00:09<00:29, 44.87it/s] 24%|██▍       | 427/1759 [00:09<00:29, 44.82it/s] 25%|██▍       | 432/1759 [00:09<00:29, 44.68it/s] 25%|██▍       | 437/1759 [00:09<00:29, 45.00it/s] 25%|██▌       | 442/1759 [00:09<00:29, 44.97it/s] 25%|██▌       | 447/1759 [00:09<00:29, 45.05it/s] 26%|██▌       | 452/1759 [00:10<00:28, 45.13it/s] 26%|██▌       | 457/1759 [00:10<00:28, 44.96it/s] 26%|██▋       | 462/1759 [00:10<00:28, 44.95it/s] 27%|██▋       | 467/1759 [00:10<00:28, 44.81it/s] 27%|██▋       | 472/1759 [00:10<00:28, 44.78it/s] 27%|██▋       | 477/1759 [00:10<00:28, 44.77it/s] 27%|██▋       | 482/1759 [00:10<00:28, 44.89it/s] 28%|██▊       | 487/1759 [00:10<00:28, 45.02it/s] 28%|██▊       | 492/1759 [00:10<00:28, 44.80it/s] 28%|██▊       | 497/1759 [00:11<00:27, 45.12it/s] 29%|██▊       | 502/1759 [00:11<00:27, 45.00it/s] 29%|██▉       | 507/1759 [00:11<00:27, 44.91it/s] 29%|██▉       | 512/1759 [00:11<00:27, 44.83it/s] 29%|██▉       | 517/1759 [00:11<00:29, 42.53it/s] 30%|██▉       | 522/1759 [00:11<00:28, 43.31it/s] 30%|██▉       | 527/1759 [00:11<00:28, 43.97it/s] 30%|███       | 532/1759 [00:11<00:27, 44.27it/s] 31%|███       | 537/1759 [00:11<00:27, 44.67it/s] 31%|███       | 542/1759 [00:12<00:27, 44.83it/s] 31%|███       | 547/1759 [00:12<00:27, 44.85it/s] 31%|███▏      | 552/1759 [00:12<00:26, 44.90it/s] 32%|███▏      | 557/1759 [00:12<00:26, 44.55it/s] 32%|███▏      | 562/1759 [00:12<00:26, 44.73it/s] 32%|███▏      | 567/1759 [00:12<00:26, 44.72it/s] 33%|███▎      | 572/1759 [00:12<00:26, 44.94it/s] 33%|███▎      | 577/1759 [00:12<00:26, 45.03it/s] 33%|███▎      | 582/1759 [00:12<00:26, 45.14it/s] 33%|███▎      | 587/1759 [00:13<00:25, 45.12it/s] 34%|███▎      | 592/1759 [00:13<00:25, 45.01it/s] 34%|███▍      | 597/1759 [00:13<00:25, 44.89it/s] 34%|███▍      | 602/1759 [00:13<00:25, 44.63it/s] 35%|███▍      | 607/1759 [00:13<00:25, 44.78it/s] 35%|███▍      | 612/1759 [00:13<00:25, 44.76it/s] 35%|███▌      | 617/1759 [00:13<00:25, 44.93it/s] 35%|███▌      | 622/1759 [00:13<00:25, 45.05it/s] 36%|███▌      | 627/1759 [00:13<00:25, 45.16it/s] 36%|███▌      | 632/1759 [00:14<00:24, 45.24it/s] 36%|███▌      | 637/1759 [00:14<00:24, 45.12it/s] 36%|███▋      | 642/1759 [00:14<00:24, 45.02it/s] 37%|███▋      | 647/1759 [00:14<00:24, 44.84it/s] 37%|███▋      | 652/1759 [00:14<00:24, 44.84it/s] 37%|███▋      | 657/1759 [00:14<00:24, 44.82it/s] 38%|███▊      | 662/1759 [00:14<00:24, 44.87it/s] 38%|███▊      | 667/1759 [00:14<00:24, 44.94it/s] 38%|███▊      | 672/1759 [00:14<00:24, 45.14it/s] 38%|███▊      | 677/1759 [00:15<00:24, 45.06it/s] 39%|███▉      | 682/1759 [00:15<00:23, 45.05it/s] 39%|███▉      | 687/1759 [00:15<00:23, 44.86it/s] 39%|███▉      | 692/1759 [00:15<00:23, 44.78it/s] 40%|███▉      | 697/1759 [00:15<00:23, 44.89it/s] 40%|███▉      | 702/1759 [00:15<00:23, 44.79it/s] 40%|████      | 707/1759 [00:15<00:23, 44.93it/s] 40%|████      | 712/1759 [00:15<00:23, 44.94it/s] 41%|████      | 717/1759 [00:15<00:23, 45.11it/s] 41%|████      | 722/1759 [00:16<00:23, 45.00it/s] 41%|████▏     | 727/1759 [00:16<00:22, 45.00it/s] 42%|████▏     | 732/1759 [00:16<00:22, 44.85it/s] 42%|████▏     | 737/1759 [00:16<00:22, 44.80it/s] 42%|████▏     | 742/1759 [00:16<00:22, 44.50it/s] 42%|████▏     | 747/1759 [00:16<00:22, 44.72it/s] 43%|████▎     | 752/1759 [00:16<00:22, 44.69it/s] 43%|████▎     | 757/1759 [00:16<00:22, 44.99it/s] 43%|████▎     | 762/1759 [00:16<00:22, 45.03it/s] 44%|████▎     | 767/1759 [00:17<00:21, 45.14it/s] 44%|████▍     | 772/1759 [00:17<00:21, 45.04it/s] 44%|████▍     | 777/1759 [00:17<00:21, 45.00it/s] 44%|████▍     | 782/1759 [00:17<00:21, 44.95it/s] 45%|████▍     | 787/1759 [00:17<00:21, 44.95it/s] 45%|████▌     | 792/1759 [00:17<00:21, 45.03it/s] 45%|████▌     | 797/1759 [00:17<00:21, 44.98it/s] 46%|████▌     | 802/1759 [00:17<00:21, 45.17it/s] 46%|████▌     | 807/1759 [00:17<00:21, 45.19it/s] 46%|████▌     | 812/1759 [00:18<00:20, 45.10it/s] 46%|████▋     | 817/1759 [00:18<00:20, 45.05it/s] 47%|████▋     | 822/1759 [00:18<00:20, 45.01it/s] 47%|████▋     | 827/1759 [00:18<00:20, 44.99it/s] 47%|████▋     | 832/1759 [00:18<00:20, 44.96it/s] 48%|████▊     | 837/1759 [00:18<00:20, 45.06it/s] 48%|████▊     | 842/1759 [00:18<00:20, 45.08it/s] 48%|████▊     | 847/1759 [00:18<00:20, 45.22it/s] 48%|████▊     | 852/1759 [00:18<00:20, 45.24it/s] 49%|████▊     | 857/1759 [00:19<00:19, 45.12it/s] 49%|████▉     | 862/1759 [00:19<00:19, 45.10it/s] 49%|████▉     | 867/1759 [00:19<00:19, 44.95it/s] 50%|████▉     | 872/1759 [00:19<00:19, 44.99it/s] 50%|████▉     | 877/1759 [00:19<00:20, 43.82it/s] 50%|█████     | 882/1759 [00:19<00:19, 44.28it/s] 50%|█████     | 887/1759 [00:19<00:19, 44.50it/s] 51%|█████     | 892/1759 [00:19<00:19, 44.81it/s] 51%|█████     | 897/1759 [00:19<00:19, 44.95it/s] 51%|█████▏    | 902/1759 [00:20<00:19, 44.91it/s] 52%|█████▏    | 907/1759 [00:20<00:18, 44.91it/s] 52%|█████▏    | 912/1759 [00:20<00:18, 44.89it/s] 52%|█████▏    | 917/1759 [00:20<00:18, 44.79it/s] 52%|█████▏    | 922/1759 [00:20<00:18, 44.84it/s] 53%|█████▎    | 927/1759 [00:20<00:18, 44.98it/s] 53%|█████▎    | 932/1759 [00:20<00:18, 45.10it/s] 53%|█████▎    | 937/1759 [00:20<00:18, 45.28it/s] 54%|█████▎    | 942/1759 [00:20<00:18, 45.23it/s] 54%|█████▍    | 947/1759 [00:21<00:17, 45.14it/s] 54%|█████▍    | 952/1759 [00:21<00:17, 45.02it/s] 54%|█████▍    | 957/1759 [00:21<00:17, 44.97it/s] 55%|█████▍    | 962/1759 [00:21<00:17, 44.88it/s] 55%|█████▍    | 967/1759 [00:21<00:17, 44.88it/s] 55%|█████▌    | 972/1759 [00:21<00:17, 44.94it/s] 56%|█████▌    | 977/1759 [00:21<00:17, 45.00it/s] 56%|█████▌    | 982/1759 [00:21<00:17, 45.22it/s] 56%|█████▌    | 987/1759 [00:21<00:17, 45.32it/s] 56%|█████▋    | 992/1759 [00:22<00:16, 45.21it/s] 57%|█████▋    | 997/1759 [00:22<00:16, 45.07it/s] 57%|█████▋    | 1002/1759 [00:22<00:16, 44.91it/s] 57%|█████▋    | 1007/1759 [00:22<00:16, 44.87it/s] 58%|█████▊    | 1012/1759 [00:22<00:17, 42.36it/s] 58%|█████▊    | 1017/1759 [00:22<00:17, 43.25it/s] 58%|█████▊    | 1022/1759 [00:22<00:16, 43.97it/s] 58%|█████▊    | 1027/1759 [00:22<00:16, 44.42it/s] 59%|█████▊    | 1032/1759 [00:22<00:16, 44.73it/s] 59%|█████▉    | 1037/1759 [00:23<00:16, 44.82it/s] 59%|█████▉    | 1042/1759 [00:23<00:15, 44.93it/s] 60%|█████▉    | 1047/1759 [00:23<00:15, 44.80it/s] 60%|█████▉    | 1052/1759 [00:23<00:15, 44.56it/s] 60%|██████    | 1057/1759 [00:23<00:15, 44.52it/s] 60%|██████    | 1062/1759 [00:23<00:15, 44.76it/s] 61%|██████    | 1067/1759 [00:23<00:15, 43.49it/s] 61%|██████    | 1072/1759 [00:23<00:15, 44.04it/s] 61%|██████    | 1077/1759 [00:24<00:15, 44.51it/s] 62%|██████▏   | 1082/1759 [00:24<00:15, 44.68it/s] 62%|██████▏   | 1087/1759 [00:24<00:14, 45.00it/s] 62%|██████▏   | 1092/1759 [00:24<00:14, 44.94it/s] 62%|██████▏   | 1097/1759 [00:24<00:14, 44.91it/s] 63%|██████▎   | 1102/1759 [00:24<00:14, 44.88it/s] 63%|██████▎   | 1107/1759 [00:24<00:14, 44.80it/s] 63%|██████▎   | 1112/1759 [00:24<00:14, 44.81it/s] 64%|██████▎   | 1117/1759 [00:24<00:14, 44.97it/s] 64%|██████▍   | 1122/1759 [00:25<00:14, 45.19it/s] 64%|██████▍   | 1127/1759 [00:25<00:13, 45.20it/s] 64%|██████▍   | 1132/1759 [00:25<00:13, 45.30it/s] 65%|██████▍   | 1137/1759 [00:25<00:13, 45.08it/s] 65%|██████▍   | 1142/1759 [00:25<00:13, 44.92it/s] 65%|██████▌   | 1147/1759 [00:25<00:13, 44.96it/s] 65%|██████▌   | 1152/1759 [00:25<00:13, 44.82it/s] 66%|██████▌   | 1157/1759 [00:25<00:13, 44.83it/s] 66%|██████▌   | 1162/1759 [00:25<00:13, 44.85it/s] 66%|██████▋   | 1167/1759 [00:26<00:13, 45.03it/s] 67%|██████▋   | 1172/1759 [00:26<00:12, 45.17it/s] 67%|██████▋   | 1177/1759 [00:26<00:12, 45.19it/s] 67%|██████▋   | 1182/1759 [00:26<00:12, 45.27it/s] 67%|██████▋   | 1187/1759 [00:26<00:12, 45.09it/s] 68%|██████▊   | 1192/1759 [00:26<00:12, 45.01it/s] 68%|██████▊   | 1197/1759 [00:26<00:12, 44.90it/s] 68%|██████▊   | 1202/1759 [00:26<00:12, 43.18it/s] 69%|██████▊   | 1207/1759 [00:26<00:12, 43.92it/s] 69%|██████▉   | 1212/1759 [00:27<00:12, 44.36it/s] 69%|██████▉   | 1217/1759 [00:27<00:12, 44.65it/s] 69%|██████▉   | 1222/1759 [00:27<00:11, 44.85it/s] 70%|██████▉   | 1227/1759 [00:27<00:11, 44.91it/s] 70%|███████   | 1232/1759 [00:27<00:11, 44.89it/s] 70%|███████   | 1237/1759 [00:27<00:11, 44.85it/s] 71%|███████   | 1242/1759 [00:27<00:11, 44.48it/s] 71%|███████   | 1247/1759 [00:27<00:11, 44.63it/s] 71%|███████   | 1252/1759 [00:27<00:11, 44.80it/s] 71%|███████▏  | 1257/1759 [00:28<00:11, 44.94it/s] 72%|███████▏  | 1262/1759 [00:28<00:10, 45.23it/s] 72%|███████▏  | 1267/1759 [00:28<00:10, 45.22it/s] 72%|███████▏  | 1272/1759 [00:28<00:10, 45.33it/s] 73%|███████▎  | 1277/1759 [00:28<00:10, 45.18it/s] 73%|███████▎  | 1282/1759 [00:28<00:10, 44.97it/s] 73%|███████▎  | 1287/1759 [00:28<00:10, 44.79it/s] 73%|███████▎  | 1292/1759 [00:28<00:10, 44.73it/s] 74%|███████▎  | 1297/1759 [00:28<00:10, 44.79it/s] 74%|███████▍  | 1302/1759 [00:29<00:10, 45.02it/s] 74%|███████▍  | 1307/1759 [00:29<00:10, 45.14it/s] 75%|███████▍  | 1312/1759 [00:29<00:09, 45.28it/s] 75%|███████▍  | 1317/1759 [00:29<00:09, 45.27it/s] 75%|███████▌  | 1322/1759 [00:29<00:09, 45.17it/s] 75%|███████▌  | 1327/1759 [00:29<00:09, 45.02it/s] 76%|███████▌  | 1332/1759 [00:29<00:09, 44.85it/s] 76%|███████▌  | 1337/1759 [00:29<00:09, 44.70it/s] 76%|███████▋  | 1342/1759 [00:29<00:09, 44.66it/s] 77%|███████▋  | 1347/1759 [00:30<00:09, 44.88it/s] 77%|███████▋  | 1352/1759 [00:30<00:09, 44.90it/s] 77%|███████▋  | 1357/1759 [00:30<00:08, 45.16it/s] 77%|███████▋  | 1362/1759 [00:30<00:08, 45.19it/s] 78%|███████▊  | 1367/1759 [00:30<00:08, 45.28it/s] 78%|███████▊  | 1372/1759 [00:30<00:08, 45.22it/s] 78%|███████▊  | 1377/1759 [00:30<00:08, 45.03it/s] 79%|███████▊  | 1382/1759 [00:30<00:08, 44.90it/s] 79%|███████▉  | 1387/1759 [00:30<00:08, 44.79it/s] 79%|███████▉  | 1392/1759 [00:31<00:08, 44.91it/s] 79%|███████▉  | 1397/1759 [00:31<00:08, 44.95it/s] 80%|███████▉  | 1402/1759 [00:31<00:07, 45.04it/s] 80%|███████▉  | 1407/1759 [00:31<00:07, 45.12it/s] 80%|████████  | 1412/1759 [00:31<00:07, 45.24it/s] 81%|████████  | 1417/1759 [00:31<00:07, 45.08it/s] 81%|████████  | 1422/1759 [00:31<00:07, 44.95it/s] 81%|████████  | 1427/1759 [00:31<00:07, 44.91it/s] 81%|████████▏ | 1432/1759 [00:31<00:07, 41.61it/s] 82%|████████▏ | 1437/1759 [00:32<00:07, 42.81it/s] 82%|████████▏ | 1442/1759 [00:32<00:07, 43.53it/s] 82%|████████▏ | 1447/1759 [00:32<00:07, 44.20it/s] 83%|████████▎ | 1452/1759 [00:32<00:06, 44.48it/s] 83%|████████▎ | 1457/1759 [00:32<00:06, 44.76it/s] 83%|████████▎ | 1462/1759 [00:32<00:06, 44.76it/s] 83%|████████▎ | 1467/1759 [00:32<00:06, 44.69it/s] 84%|████████▎ | 1472/1759 [00:32<00:06, 44.43it/s] 84%|████████▍ | 1477/1759 [00:32<00:06, 44.46it/s] 84%|████████▍ | 1482/1759 [00:33<00:06, 44.78it/s] 85%|████████▍ | 1487/1759 [00:33<00:06, 45.01it/s] 85%|████████▍ | 1492/1759 [00:33<00:05, 45.18it/s] 85%|████████▌ | 1497/1759 [00:33<00:05, 45.25it/s] 85%|████████▌ | 1502/1759 [00:33<00:05, 45.23it/s] 86%|████████▌ | 1507/1759 [00:33<00:05, 45.07it/s] 86%|████████▌ | 1512/1759 [00:33<00:05, 44.82it/s] 86%|████████▌ | 1517/1759 [00:33<00:05, 44.69it/s] 87%|████████▋ | 1522/1759 [00:33<00:05, 40.36it/s] 87%|████████▋ | 1527/1759 [00:34<00:05, 41.79it/s] 87%|████████▋ | 1532/1759 [00:34<00:05, 42.93it/s] 87%|████████▋ | 1537/1759 [00:34<00:05, 43.63it/s] 88%|████████▊ | 1542/1759 [00:34<00:04, 44.21it/s] 88%|████████▊ | 1547/1759 [00:34<00:04, 44.64it/s] 88%|████████▊ | 1552/1759 [00:34<00:04, 44.77it/s] 89%|████████▊ | 1557/1759 [00:34<00:04, 44.78it/s] 89%|████████▉ | 1562/1759 [00:34<00:04, 44.48it/s] 89%|████████▉ | 1567/1759 [00:34<00:04, 44.39it/s] 89%|████████▉ | 1572/1759 [00:35<00:04, 44.51it/s] 90%|████████▉ | 1577/1759 [00:35<00:04, 44.78it/s] 90%|████████▉ | 1582/1759 [00:35<00:03, 44.99it/s] 90%|█████████ | 1587/1759 [00:35<00:03, 45.12it/s] 91%|█████████ | 1592/1759 [00:35<00:03, 45.20it/s] 91%|█████████ | 1597/1759 [00:35<00:03, 45.18it/s] 91%|█████████ | 1602/1759 [00:35<00:03, 45.18it/s] 91%|█████████▏| 1607/1759 [00:35<00:03, 45.00it/s] 92%|█████████▏| 1612/1759 [00:35<00:03, 44.83it/s] 92%|█████████▏| 1617/1759 [00:36<00:03, 44.80it/s] 92%|█████████▏| 1622/1759 [00:36<00:03, 44.90it/s] 92%|█████████▏| 1627/1759 [00:36<00:02, 45.02it/s] 93%|█████████▎| 1632/1759 [00:36<00:02, 45.17it/s] 93%|█████████▎| 1637/1759 [00:36<00:02, 45.16it/s] 93%|█████████▎| 1642/1759 [00:36<00:02, 45.08it/s] 94%|█████████▎| 1647/1759 [00:36<00:02, 45.12it/s] 94%|█████████▍| 1652/1759 [00:36<00:02, 44.92it/s] 94%|█████████▍| 1657/1759 [00:36<00:02, 44.65it/s] 94%|█████████▍| 1662/1759 [00:37<00:02, 44.65it/s] 95%|█████████▍| 1667/1759 [00:37<00:02, 44.67it/s] 95%|█████████▌| 1672/1759 [00:37<00:01, 44.93it/s] 95%|█████████▌| 1677/1759 [00:37<00:01, 44.99it/s] 96%|█████████▌| 1682/1759 [00:37<00:01, 45.15it/s] 96%|█████████▌| 1687/1759 [00:37<00:01, 45.04it/s] 96%|█████████▌| 1692/1759 [00:37<00:01, 45.15it/s] 96%|█████████▋| 1697/1759 [00:37<00:01, 45.12it/s] 97%|█████████▋| 1702/1759 [00:37<00:01, 44.90it/s] 97%|█████████▋| 1707/1759 [00:38<00:01, 44.93it/s] 97%|█████████▋| 1712/1759 [00:38<00:01, 44.83it/s] 98%|█████████▊| 1717/1759 [00:38<00:00, 44.91it/s] 98%|█████████▊| 1722/1759 [00:38<00:00, 45.07it/s] 98%|█████████▊| 1727/1759 [00:38<00:00, 45.06it/s] 98%|█████████▊| 1732/1759 [00:38<00:00, 45.06it/s] 99%|█████████▊| 1737/1759 [00:38<00:00, 45.00it/s] 99%|█████████▉| 1742/1759 [00:38<00:00, 45.04it/s] 99%|█████████▉| 1747/1759 [00:38<00:00, 44.95it/s]100%|█████████▉| 1752/1759 [00:39<00:00, 44.74it/s]100%|█████████▉| 1757/1759 [00:39<00:00, 44.82it/s]100%|██████████| 1759/1759 [00:39<00:00, 44.83it/s]
[INFO|trainer_pt_utils.py:908] 2023-08-29 09:32:07,469 >> ***** eval metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:32:07,469 >>   epoch                   =        5.0
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:32:07,469 >>   eval_loss               =     0.9001
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:32:07,469 >>   eval_runtime            = 0:00:39.25
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:32:07,469 >>   eval_samples            =      14067
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:32:07,469 >>   eval_samples_per_second =    358.339
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:32:07,469 >>   eval_steps_per_second   =     44.808
[INFO|trainer_pt_utils.py:913] 2023-08-29 09:32:07,469 >>   perplexity              =     2.4598
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:20,553 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:20,593 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:20,593 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:20,593 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:20,593 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 09:32:21,289 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 09:32:21,290 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:32:21,734 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 09:32:22,873 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:32:22,873 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:25,288 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:25,308 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:25,308 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:25,309 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:32:25,309 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 09:32:26,089 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 09:32:26,090 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:32:26,719 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 09:32:26,962 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:32:26,962 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-128
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-64
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-32
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-160
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/checkpoint-96
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl', 'labels': ['country', 'part of', 'platform', 'publisher', 'sport'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_in_all_single_is_eval_True.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_out_filter_all_single_is_eval_True.jsonl'}}
predict vocab size: 22024
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 22124, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.48it/s]Extractor Predicting: 2it [00:01,  1.55it/s]Extractor Predicting: 3it [00:01,  1.55it/s]Extractor Predicting: 4it [00:02,  1.62it/s]Extractor Predicting: 5it [00:03,  1.64it/s]Extractor Predicting: 6it [00:03,  1.67it/s]Extractor Predicting: 7it [00:04,  1.67it/s]Extractor Predicting: 8it [00:04,  1.65it/s]Extractor Predicting: 9it [00:05,  1.63it/s]Extractor Predicting: 10it [00:06,  1.58it/s]Extractor Predicting: 11it [00:06,  1.56it/s]Extractor Predicting: 12it [00:07,  1.54it/s]Extractor Predicting: 13it [00:08,  1.51it/s]Extractor Predicting: 14it [00:08,  1.49it/s]Extractor Predicting: 15it [00:09,  1.46it/s]Extractor Predicting: 16it [00:10,  1.46it/s]Extractor Predicting: 17it [00:11,  1.46it/s]Extractor Predicting: 18it [00:11,  1.46it/s]Extractor Predicting: 19it [00:12,  1.48it/s]Extractor Predicting: 20it [00:13,  1.47it/s]Extractor Predicting: 21it [00:13,  1.46it/s]Extractor Predicting: 22it [00:14,  1.47it/s]Extractor Predicting: 23it [00:15,  1.45it/s]Extractor Predicting: 24it [00:15,  1.47it/s]Extractor Predicting: 25it [00:16,  1.52it/s]Extractor Predicting: 26it [00:17,  1.51it/s]Extractor Predicting: 27it [00:17,  1.51it/s]Extractor Predicting: 28it [00:18,  1.57it/s]Extractor Predicting: 29it [00:18,  1.61it/s]Extractor Predicting: 30it [00:19,  1.60it/s]Extractor Predicting: 31it [00:20,  1.62it/s]Extractor Predicting: 32it [00:20,  1.57it/s]Extractor Predicting: 33it [00:21,  1.61it/s]Extractor Predicting: 34it [00:22,  1.62it/s]Extractor Predicting: 35it [00:22,  1.63it/s]Extractor Predicting: 36it [00:23,  1.61it/s]Extractor Predicting: 37it [00:23,  1.62it/s]Extractor Predicting: 38it [00:24,  1.64it/s]Extractor Predicting: 39it [00:25,  1.61it/s]Extractor Predicting: 40it [00:25,  1.60it/s]Extractor Predicting: 41it [00:26,  1.56it/s]Extractor Predicting: 42it [00:27,  1.59it/s]Extractor Predicting: 43it [00:27,  1.57it/s]Extractor Predicting: 44it [00:28,  1.59it/s]Extractor Predicting: 45it [00:28,  1.62it/s]Extractor Predicting: 46it [00:29,  1.63it/s]Extractor Predicting: 47it [00:30,  1.64it/s]Extractor Predicting: 48it [00:30,  1.60it/s]Extractor Predicting: 49it [00:31,  1.66it/s]Extractor Predicting: 50it [00:31,  1.65it/s]Extractor Predicting: 51it [00:32,  1.66it/s]Extractor Predicting: 52it [00:33,  1.67it/s]Extractor Predicting: 53it [00:33,  1.67it/s]Extractor Predicting: 54it [00:34,  1.69it/s]Extractor Predicting: 55it [00:34,  1.68it/s]Extractor Predicting: 56it [00:35,  1.68it/s]Extractor Predicting: 57it [00:36,  1.64it/s]Extractor Predicting: 58it [00:36,  1.64it/s]Extractor Predicting: 59it [00:37,  1.62it/s]Extractor Predicting: 60it [00:37,  1.64it/s]Extractor Predicting: 61it [00:38,  1.65it/s]Extractor Predicting: 62it [00:39,  1.62it/s]Extractor Predicting: 63it [00:39,  1.63it/s]Extractor Predicting: 64it [00:40,  1.62it/s]Extractor Predicting: 65it [00:41,  1.59it/s]Extractor Predicting: 66it [00:41,  1.59it/s]Extractor Predicting: 67it [00:42,  1.59it/s]Extractor Predicting: 68it [00:43,  1.54it/s]Extractor Predicting: 69it [00:43,  1.59it/s]Extractor Predicting: 70it [00:44,  1.63it/s]Extractor Predicting: 71it [00:44,  1.64it/s]Extractor Predicting: 72it [00:45,  1.60it/s]Extractor Predicting: 73it [00:46,  1.56it/s]Extractor Predicting: 74it [00:46,  1.57it/s]Extractor Predicting: 75it [00:47,  1.55it/s]Extractor Predicting: 76it [00:48,  1.54it/s]Extractor Predicting: 77it [00:48,  1.54it/s]Extractor Predicting: 78it [00:49,  1.62it/s]Extractor Predicting: 79it [00:49,  1.59it/s]Extractor Predicting: 80it [00:50,  1.60it/s]Extractor Predicting: 81it [00:51,  1.59it/s]Extractor Predicting: 82it [00:51,  1.61it/s]Extractor Predicting: 83it [00:52,  1.63it/s]Extractor Predicting: 84it [00:52,  1.67it/s]Extractor Predicting: 85it [00:53,  1.65it/s]Extractor Predicting: 86it [00:54,  1.62it/s]Extractor Predicting: 87it [00:54,  1.61it/s]Extractor Predicting: 88it [00:55,  1.52it/s]Extractor Predicting: 89it [00:56,  1.58it/s]Extractor Predicting: 90it [00:56,  1.59it/s]Extractor Predicting: 91it [00:57,  1.62it/s]Extractor Predicting: 92it [00:58,  1.57it/s]Extractor Predicting: 93it [00:58,  1.53it/s]Extractor Predicting: 94it [00:59,  1.56it/s]Extractor Predicting: 95it [00:59,  1.61it/s]Extractor Predicting: 96it [01:00,  1.63it/s]Extractor Predicting: 97it [01:01,  1.69it/s]Extractor Predicting: 98it [01:01,  1.71it/s]Extractor Predicting: 99it [01:02,  1.68it/s]Extractor Predicting: 100it [01:02,  1.77it/s]Extractor Predicting: 101it [01:03,  1.72it/s]Extractor Predicting: 102it [01:03,  1.70it/s]Extractor Predicting: 103it [01:04,  1.71it/s]Extractor Predicting: 104it [01:05,  1.49it/s]Extractor Predicting: 105it [01:05,  1.57it/s]Extractor Predicting: 106it [01:06,  1.58it/s]Extractor Predicting: 107it [01:07,  1.59it/s]Extractor Predicting: 108it [01:07,  1.61it/s]Extractor Predicting: 109it [01:08,  1.63it/s]Extractor Predicting: 110it [01:09,  1.64it/s]Extractor Predicting: 111it [01:09,  1.67it/s]Extractor Predicting: 112it [01:10,  1.69it/s]Extractor Predicting: 113it [01:10,  1.70it/s]Extractor Predicting: 114it [01:11,  1.74it/s]Extractor Predicting: 115it [01:11,  1.71it/s]Extractor Predicting: 116it [01:12,  1.75it/s]Extractor Predicting: 117it [01:13,  1.73it/s]Extractor Predicting: 118it [01:13,  1.74it/s]Extractor Predicting: 119it [01:14,  1.75it/s]Extractor Predicting: 120it [01:14,  1.77it/s]Extractor Predicting: 121it [01:15,  1.75it/s]Extractor Predicting: 122it [01:15,  1.70it/s]Extractor Predicting: 123it [01:16,  1.70it/s]Extractor Predicting: 124it [01:17,  1.67it/s]Extractor Predicting: 125it [01:17,  1.69it/s]Extractor Predicting: 126it [01:18,  1.70it/s]Extractor Predicting: 127it [01:18,  1.76it/s]Extractor Predicting: 128it [01:19,  1.76it/s]Extractor Predicting: 129it [01:19,  1.77it/s]Extractor Predicting: 130it [01:20,  1.75it/s]Extractor Predicting: 131it [01:21,  1.73it/s]Extractor Predicting: 132it [01:21,  1.76it/s]Extractor Predicting: 133it [01:22,  1.70it/s]Extractor Predicting: 134it [01:22,  1.73it/s]Extractor Predicting: 135it [01:23,  1.73it/s]Extractor Predicting: 136it [01:24,  1.72it/s]Extractor Predicting: 137it [01:24,  1.72it/s]Extractor Predicting: 138it [01:25,  1.70it/s]Extractor Predicting: 139it [01:25,  1.70it/s]Extractor Predicting: 140it [01:26,  1.69it/s]Extractor Predicting: 141it [01:26,  1.68it/s]Extractor Predicting: 142it [01:27,  1.72it/s]Extractor Predicting: 143it [01:28,  1.75it/s]Extractor Predicting: 144it [01:28,  1.75it/s]Extractor Predicting: 145it [01:29,  1.69it/s]Extractor Predicting: 146it [01:29,  1.68it/s]Extractor Predicting: 147it [01:30,  1.68it/s]Extractor Predicting: 148it [01:31,  1.66it/s]Extractor Predicting: 149it [01:31,  1.65it/s]Extractor Predicting: 150it [01:32,  1.64it/s]Extractor Predicting: 151it [01:33,  1.58it/s]Extractor Predicting: 152it [01:33,  1.54it/s]Extractor Predicting: 153it [01:34,  1.50it/s]Extractor Predicting: 154it [01:35,  1.51it/s]Extractor Predicting: 155it [01:35,  1.52it/s]Extractor Predicting: 156it [01:36,  1.51it/s]Extractor Predicting: 157it [01:36,  1.55it/s]Extractor Predicting: 158it [01:37,  1.53it/s]Extractor Predicting: 159it [01:38,  1.56it/s]Extractor Predicting: 160it [01:38,  1.60it/s]Extractor Predicting: 161it [01:39,  1.62it/s]Extractor Predicting: 162it [01:40,  1.62it/s]Extractor Predicting: 163it [01:40,  1.60it/s]Extractor Predicting: 164it [01:41,  1.63it/s]Extractor Predicting: 165it [01:41,  1.61it/s]Extractor Predicting: 166it [01:42,  1.57it/s]Extractor Predicting: 167it [01:43,  1.61it/s]Extractor Predicting: 168it [01:43,  1.59it/s]Extractor Predicting: 169it [01:44,  1.61it/s]Extractor Predicting: 170it [01:45,  1.64it/s]Extractor Predicting: 171it [01:45,  1.67it/s]Extractor Predicting: 172it [01:46,  1.65it/s]Extractor Predicting: 173it [01:46,  1.68it/s]Extractor Predicting: 174it [01:47,  1.65it/s]Extractor Predicting: 175it [01:48,  1.62it/s]Extractor Predicting: 176it [01:48,  1.62it/s]Extractor Predicting: 177it [01:49,  1.59it/s]Extractor Predicting: 178it [01:49,  1.66it/s]Extractor Predicting: 179it [01:50,  1.78it/s]Extractor Predicting: 180it [01:50,  1.88it/s]Extractor Predicting: 181it [01:51,  1.86it/s]Extractor Predicting: 182it [01:51,  1.85it/s]Extractor Predicting: 183it [01:52,  1.72it/s]Extractor Predicting: 184it [01:53,  1.64it/s]Extractor Predicting: 185it [01:53,  1.65it/s]Extractor Predicting: 186it [01:54,  1.64it/s]Extractor Predicting: 187it [01:55,  1.63it/s]Extractor Predicting: 188it [01:55,  1.60it/s]Extractor Predicting: 189it [01:56,  1.60it/s]Extractor Predicting: 190it [01:57,  1.58it/s]Extractor Predicting: 191it [01:57,  1.54it/s]Extractor Predicting: 192it [01:58,  1.57it/s]Extractor Predicting: 193it [01:58,  1.65it/s]Extractor Predicting: 194it [01:59,  1.66it/s]Extractor Predicting: 195it [02:00,  1.68it/s]Extractor Predicting: 196it [02:00,  1.65it/s]Extractor Predicting: 197it [02:01,  1.64it/s]Extractor Predicting: 198it [02:01,  1.59it/s]Extractor Predicting: 199it [02:02,  1.59it/s]Extractor Predicting: 200it [02:03,  1.60it/s]Extractor Predicting: 201it [02:03,  1.61it/s]Extractor Predicting: 202it [02:04,  1.60it/s]Extractor Predicting: 203it [02:05,  1.61it/s]Extractor Predicting: 204it [02:05,  1.63it/s]Extractor Predicting: 205it [02:06,  1.64it/s]Extractor Predicting: 206it [02:06,  1.64it/s]Extractor Predicting: 207it [02:07,  1.63it/s]Extractor Predicting: 208it [02:08,  1.63it/s]Extractor Predicting: 209it [02:08,  1.63it/s]Extractor Predicting: 210it [02:09,  1.66it/s]Extractor Predicting: 211it [02:09,  1.63it/s]Extractor Predicting: 212it [02:10,  1.59it/s]Extractor Predicting: 213it [02:11,  1.58it/s]Extractor Predicting: 214it [02:11,  1.58it/s]Extractor Predicting: 215it [02:12,  1.61it/s]Extractor Predicting: 216it [02:13,  1.58it/s]Extractor Predicting: 217it [02:13,  1.64it/s]Extractor Predicting: 218it [02:14,  1.67it/s]Extractor Predicting: 219it [02:14,  1.65it/s]Extractor Predicting: 220it [02:15,  1.66it/s]Extractor Predicting: 221it [02:16,  1.65it/s]Extractor Predicting: 222it [02:16,  1.66it/s]Extractor Predicting: 223it [02:17,  1.63it/s]Extractor Predicting: 224it [02:18,  1.59it/s]Extractor Predicting: 225it [02:18,  1.58it/s]Extractor Predicting: 226it [02:19,  1.60it/s]Extractor Predicting: 227it [02:19,  1.61it/s]Extractor Predicting: 228it [02:20,  1.58it/s]Extractor Predicting: 229it [02:21,  1.58it/s]Extractor Predicting: 230it [02:22,  1.39it/s]Extractor Predicting: 231it [02:22,  1.43it/s]Extractor Predicting: 232it [02:23,  1.50it/s]Extractor Predicting: 233it [02:23,  1.49it/s]Extractor Predicting: 234it [02:24,  1.51it/s]Extractor Predicting: 235it [02:25,  1.54it/s]Extractor Predicting: 236it [02:25,  1.56it/s]Extractor Predicting: 237it [02:26,  1.57it/s]Extractor Predicting: 238it [02:27,  1.55it/s]Extractor Predicting: 239it [02:27,  1.58it/s]Extractor Predicting: 240it [02:28,  1.57it/s]Extractor Predicting: 241it [02:29,  1.59it/s]Extractor Predicting: 242it [02:29,  1.58it/s]Extractor Predicting: 243it [02:30,  1.60it/s]Extractor Predicting: 244it [02:30,  1.60it/s]Extractor Predicting: 245it [02:31,  1.56it/s]Extractor Predicting: 246it [02:32,  1.59it/s]Extractor Predicting: 247it [02:32,  1.62it/s]Extractor Predicting: 248it [02:33,  1.58it/s]Extractor Predicting: 249it [02:34,  1.55it/s]Extractor Predicting: 250it [02:34,  1.61it/s]Extractor Predicting: 251it [02:35,  1.64it/s]Extractor Predicting: 252it [02:35,  1.67it/s]Extractor Predicting: 253it [02:36,  1.66it/s]Extractor Predicting: 254it [02:37,  1.66it/s]Extractor Predicting: 255it [02:37,  1.64it/s]Extractor Predicting: 256it [02:38,  1.63it/s]Extractor Predicting: 257it [02:38,  1.62it/s]Extractor Predicting: 258it [02:39,  1.64it/s]Extractor Predicting: 259it [02:40,  1.64it/s]Extractor Predicting: 260it [02:40,  1.65it/s]Extractor Predicting: 261it [02:41,  1.66it/s]Extractor Predicting: 262it [02:41,  1.70it/s]Extractor Predicting: 263it [02:42,  1.69it/s]Extractor Predicting: 264it [02:43,  1.71it/s]Extractor Predicting: 265it [02:43,  1.70it/s]Extractor Predicting: 266it [02:44,  1.67it/s]Extractor Predicting: 267it [02:44,  1.67it/s]Extractor Predicting: 268it [02:45,  1.63it/s]Extractor Predicting: 269it [02:46,  1.66it/s]Extractor Predicting: 270it [02:46,  1.65it/s]Extractor Predicting: 271it [02:47,  1.66it/s]Extractor Predicting: 272it [02:47,  1.68it/s]Extractor Predicting: 273it [02:48,  1.67it/s]Extractor Predicting: 274it [02:49,  1.66it/s]Extractor Predicting: 275it [02:49,  1.65it/s]Extractor Predicting: 276it [02:50,  1.67it/s]Extractor Predicting: 277it [02:50,  1.67it/s]Extractor Predicting: 278it [02:51,  1.67it/s]Extractor Predicting: 279it [02:52,  1.64it/s]Extractor Predicting: 280it [02:52,  1.62it/s]Extractor Predicting: 281it [02:53,  1.61it/s]Extractor Predicting: 282it [02:54,  1.58it/s]Extractor Predicting: 283it [02:54,  1.58it/s]Extractor Predicting: 284it [02:55,  1.63it/s]Extractor Predicting: 285it [02:55,  1.62it/s]Extractor Predicting: 286it [02:56,  1.59it/s]Extractor Predicting: 287it [02:57,  1.57it/s]Extractor Predicting: 288it [02:57,  1.59it/s]Extractor Predicting: 289it [02:58,  1.55it/s]Extractor Predicting: 290it [02:59,  1.55it/s]Extractor Predicting: 291it [02:59,  1.57it/s]Extractor Predicting: 292it [03:00,  1.56it/s]Extractor Predicting: 293it [03:01,  1.57it/s]Extractor Predicting: 294it [03:01,  1.58it/s]Extractor Predicting: 295it [03:02,  1.60it/s]Extractor Predicting: 296it [03:02,  1.60it/s]Extractor Predicting: 297it [03:03,  1.59it/s]Extractor Predicting: 298it [03:04,  1.63it/s]Extractor Predicting: 299it [03:04,  1.59it/s]Extractor Predicting: 300it [03:05,  1.57it/s]Extractor Predicting: 301it [03:06,  1.57it/s]Extractor Predicting: 302it [03:06,  1.59it/s]Extractor Predicting: 303it [03:07,  1.60it/s]Extractor Predicting: 304it [03:07,  1.61it/s]Extractor Predicting: 305it [03:08,  1.64it/s]Extractor Predicting: 306it [03:09,  1.61it/s]Extractor Predicting: 307it [03:09,  1.63it/s]Extractor Predicting: 308it [03:10,  1.64it/s]Extractor Predicting: 309it [03:10,  1.61it/s]Extractor Predicting: 310it [03:11,  1.56it/s]Extractor Predicting: 311it [03:12,  1.51it/s]Extractor Predicting: 312it [03:13,  1.49it/s]Extractor Predicting: 313it [03:13,  1.47it/s]Extractor Predicting: 314it [03:14,  1.44it/s]Extractor Predicting: 315it [03:15,  1.42it/s]Extractor Predicting: 316it [03:15,  1.42it/s]Extractor Predicting: 317it [03:16,  1.43it/s]Extractor Predicting: 318it [03:17,  1.43it/s]Extractor Predicting: 319it [03:18,  1.42it/s]Extractor Predicting: 320it [03:18,  1.43it/s]Extractor Predicting: 321it [03:19,  1.42it/s]Extractor Predicting: 322it [03:20,  1.42it/s]Extractor Predicting: 323it [03:20,  1.42it/s]Extractor Predicting: 324it [03:21,  1.43it/s]Extractor Predicting: 325it [03:22,  1.42it/s]Extractor Predicting: 326it [03:22,  1.43it/s]Extractor Predicting: 327it [03:23,  1.49it/s]Extractor Predicting: 328it [03:24,  1.50it/s]Extractor Predicting: 329it [03:24,  1.53it/s]Extractor Predicting: 330it [03:25,  1.58it/s]Extractor Predicting: 331it [03:26,  1.61it/s]Extractor Predicting: 332it [03:26,  1.42it/s]Extractor Predicting: 333it [03:27,  1.47it/s]Extractor Predicting: 334it [03:28,  1.49it/s]Extractor Predicting: 335it [03:28,  1.52it/s]Extractor Predicting: 336it [03:29,  1.50it/s]Extractor Predicting: 337it [03:30,  1.54it/s]Extractor Predicting: 338it [03:30,  1.57it/s]Extractor Predicting: 339it [03:31,  1.57it/s]Extractor Predicting: 340it [03:32,  1.50it/s]Extractor Predicting: 341it [03:32,  1.49it/s]Extractor Predicting: 342it [03:33,  1.50it/s]Extractor Predicting: 343it [03:34,  1.51it/s]Extractor Predicting: 344it [03:34,  1.49it/s]Extractor Predicting: 345it [03:35,  1.45it/s]Extractor Predicting: 346it [03:36,  1.45it/s]Extractor Predicting: 347it [03:36,  1.46it/s]Extractor Predicting: 348it [03:37,  1.48it/s]Extractor Predicting: 349it [03:38,  1.50it/s]Extractor Predicting: 350it [03:38,  1.48it/s]Extractor Predicting: 351it [03:39,  1.50it/s]Extractor Predicting: 352it [03:40,  1.49it/s]Extractor Predicting: 353it [03:40,  1.48it/s]Extractor Predicting: 354it [03:41,  1.49it/s]Extractor Predicting: 355it [03:42,  1.51it/s]Extractor Predicting: 356it [03:42,  1.53it/s]Extractor Predicting: 357it [03:43,  1.54it/s]Extractor Predicting: 358it [03:44,  1.53it/s]Extractor Predicting: 359it [03:44,  1.51it/s]Extractor Predicting: 360it [03:45,  1.53it/s]Extractor Predicting: 361it [03:46,  1.58it/s]Extractor Predicting: 362it [03:46,  1.57it/s]Extractor Predicting: 363it [03:47,  1.57it/s]Extractor Predicting: 364it [03:47,  1.56it/s]Extractor Predicting: 365it [03:48,  1.61it/s]Extractor Predicting: 366it [03:49,  1.58it/s]Extractor Predicting: 367it [03:49,  1.57it/s]Extractor Predicting: 368it [03:50,  1.55it/s]Extractor Predicting: 369it [03:51,  1.55it/s]Extractor Predicting: 370it [03:51,  1.58it/s]Extractor Predicting: 371it [03:52,  1.56it/s]Extractor Predicting: 372it [03:53,  1.55it/s]Extractor Predicting: 373it [03:53,  1.53it/s]Extractor Predicting: 374it [03:54,  1.56it/s]Extractor Predicting: 375it [03:54,  1.58it/s]Extractor Predicting: 376it [03:55,  1.59it/s]Extractor Predicting: 377it [03:56,  1.59it/s]Extractor Predicting: 378it [03:56,  1.59it/s]Extractor Predicting: 379it [03:57,  1.55it/s]Extractor Predicting: 380it [03:58,  1.55it/s]Extractor Predicting: 381it [03:58,  1.56it/s]Extractor Predicting: 382it [03:59,  1.56it/s]Extractor Predicting: 383it [04:00,  1.57it/s]Extractor Predicting: 384it [04:00,  1.57it/s]Extractor Predicting: 385it [04:01,  1.59it/s]Extractor Predicting: 386it [04:01,  1.60it/s]Extractor Predicting: 387it [04:02,  1.58it/s]Extractor Predicting: 388it [04:03,  1.57it/s]Extractor Predicting: 389it [04:03,  1.61it/s]Extractor Predicting: 390it [04:04,  1.61it/s]Extractor Predicting: 391it [04:05,  1.62it/s]Extractor Predicting: 392it [04:05,  1.64it/s]Extractor Predicting: 393it [04:06,  1.61it/s]Extractor Predicting: 394it [04:06,  1.62it/s]Extractor Predicting: 395it [04:07,  1.63it/s]Extractor Predicting: 396it [04:08,  1.60it/s]Extractor Predicting: 397it [04:08,  1.61it/s]Extractor Predicting: 398it [04:09,  1.64it/s]Extractor Predicting: 399it [04:09,  1.64it/s]Extractor Predicting: 400it [04:10,  1.60it/s]Extractor Predicting: 401it [04:11,  1.54it/s]Extractor Predicting: 402it [04:11,  1.52it/s]Extractor Predicting: 403it [04:12,  1.54it/s]Extractor Predicting: 404it [04:13,  1.57it/s]Extractor Predicting: 405it [04:13,  1.58it/s]Extractor Predicting: 406it [04:14,  1.59it/s]Extractor Predicting: 407it [04:15,  1.62it/s]Extractor Predicting: 408it [04:15,  1.67it/s]Extractor Predicting: 409it [04:16,  1.68it/s]Extractor Predicting: 410it [04:16,  1.70it/s]Extractor Predicting: 411it [04:17,  1.70it/s]Extractor Predicting: 412it [04:17,  1.72it/s]Extractor Predicting: 413it [04:18,  1.76it/s]Extractor Predicting: 414it [04:19,  1.78it/s]Extractor Predicting: 415it [04:19,  1.69it/s]Extractor Predicting: 416it [04:20,  1.61it/s]Extractor Predicting: 417it [04:21,  1.53it/s]Extractor Predicting: 418it [04:21,  1.48it/s]Extractor Predicting: 419it [04:22,  1.46it/s]Extractor Predicting: 420it [04:23,  1.46it/s]Extractor Predicting: 421it [04:23,  1.45it/s]Extractor Predicting: 422it [04:24,  1.67it/s]Extractor Predicting: 422it [04:24,  1.60it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:06,571 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:06,632 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:06,632 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:06,632 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:06,632 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 09:37:07,549 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 09:37:07,551 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:37:08,207 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 09:37:09,380 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:37:09,381 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:12,351 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:12,369 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:12,369 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:12,369 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:37:12,369 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 09:37:13,083 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 09:37:13,084 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:37:13,679 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 09:37:13,885 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:37:13,885 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_out_filter_all_single_is_eval_True.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_in_all_single_is_eval_True.jsonl",
  "precision": 0.24875,
  "recall": 0.11317267363332623,
  "score": 0.15556749890066937,
  "mode": "all_single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/results_all_single_is_eval_True.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_in_single_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_out_filter_single_is_eval_False.jsonl'}}
predict vocab size: 13679
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 13779, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.62it/s]Extractor Predicting: 2it [00:01,  1.57it/s]Extractor Predicting: 3it [00:01,  1.58it/s]Extractor Predicting: 4it [00:02,  1.58it/s]Extractor Predicting: 5it [00:03,  1.58it/s]Extractor Predicting: 6it [00:03,  1.62it/s]Extractor Predicting: 7it [00:04,  1.63it/s]Extractor Predicting: 8it [00:04,  1.61it/s]Extractor Predicting: 9it [00:05,  1.60it/s]Extractor Predicting: 10it [00:06,  1.61it/s]Extractor Predicting: 11it [00:06,  1.61it/s]Extractor Predicting: 12it [00:07,  1.60it/s]Extractor Predicting: 13it [00:08,  1.61it/s]Extractor Predicting: 14it [00:08,  1.60it/s]Extractor Predicting: 15it [00:09,  1.61it/s]Extractor Predicting: 16it [00:09,  1.65it/s]Extractor Predicting: 17it [00:10,  1.64it/s]Extractor Predicting: 18it [00:11,  1.63it/s]Extractor Predicting: 19it [00:11,  1.61it/s]Extractor Predicting: 20it [00:12,  1.60it/s]Extractor Predicting: 21it [00:13,  1.60it/s]Extractor Predicting: 22it [00:13,  1.60it/s]Extractor Predicting: 23it [00:14,  1.57it/s]Extractor Predicting: 24it [00:14,  1.59it/s]Extractor Predicting: 25it [00:15,  1.62it/s]Extractor Predicting: 26it [00:16,  1.60it/s]Extractor Predicting: 27it [00:16,  1.63it/s]Extractor Predicting: 28it [00:17,  1.59it/s]Extractor Predicting: 29it [00:18,  1.50it/s]Extractor Predicting: 30it [00:18,  1.53it/s]Extractor Predicting: 31it [00:19,  1.52it/s]Extractor Predicting: 32it [00:20,  1.54it/s]Extractor Predicting: 33it [00:20,  1.56it/s]Extractor Predicting: 34it [00:21,  1.56it/s]Extractor Predicting: 35it [00:22,  1.56it/s]Extractor Predicting: 36it [00:22,  1.55it/s]Extractor Predicting: 37it [00:23,  1.56it/s]Extractor Predicting: 38it [00:23,  1.58it/s]Extractor Predicting: 39it [00:24,  1.55it/s]Extractor Predicting: 40it [00:25,  1.56it/s]Extractor Predicting: 41it [00:25,  1.56it/s]Extractor Predicting: 42it [00:26,  1.58it/s]Extractor Predicting: 43it [00:27,  1.63it/s]Extractor Predicting: 44it [00:27,  1.59it/s]Extractor Predicting: 45it [00:28,  1.57it/s]Extractor Predicting: 46it [00:29,  1.52it/s]Extractor Predicting: 47it [00:29,  1.53it/s]Extractor Predicting: 48it [00:30,  1.54it/s]Extractor Predicting: 49it [00:31,  1.54it/s]Extractor Predicting: 50it [00:31,  1.55it/s]Extractor Predicting: 51it [00:32,  1.54it/s]Extractor Predicting: 52it [00:32,  1.52it/s]Extractor Predicting: 53it [00:33,  1.54it/s]Extractor Predicting: 54it [00:34,  1.53it/s]Extractor Predicting: 55it [00:34,  1.52it/s]Extractor Predicting: 56it [00:35,  1.53it/s]Extractor Predicting: 57it [00:36,  1.53it/s]Extractor Predicting: 58it [00:36,  1.52it/s]Extractor Predicting: 59it [00:37,  1.52it/s]Extractor Predicting: 60it [00:38,  1.54it/s]Extractor Predicting: 61it [00:38,  1.54it/s]Extractor Predicting: 62it [00:39,  1.55it/s]Extractor Predicting: 63it [00:40,  1.55it/s]Extractor Predicting: 64it [00:40,  1.58it/s]Extractor Predicting: 65it [00:41,  1.62it/s]Extractor Predicting: 66it [00:41,  1.61it/s]Extractor Predicting: 67it [00:42,  1.60it/s]Extractor Predicting: 68it [00:43,  1.59it/s]Extractor Predicting: 69it [00:43,  1.60it/s]Extractor Predicting: 70it [00:44,  1.59it/s]Extractor Predicting: 71it [00:45,  1.57it/s]Extractor Predicting: 72it [00:45,  1.59it/s]Extractor Predicting: 73it [00:46,  1.59it/s]Extractor Predicting: 74it [00:46,  1.59it/s]Extractor Predicting: 75it [00:47,  1.60it/s]Extractor Predicting: 76it [00:48,  1.57it/s]Extractor Predicting: 77it [00:48,  1.62it/s]Extractor Predicting: 78it [00:49,  1.63it/s]Extractor Predicting: 79it [00:50,  1.62it/s]Extractor Predicting: 80it [00:50,  1.62it/s]Extractor Predicting: 81it [00:51,  1.64it/s]Extractor Predicting: 82it [00:51,  1.62it/s]Extractor Predicting: 83it [00:52,  1.58it/s]Extractor Predicting: 84it [00:53,  1.55it/s]Extractor Predicting: 85it [00:53,  1.55it/s]Extractor Predicting: 86it [00:54,  1.57it/s]Extractor Predicting: 87it [00:55,  1.60it/s]Extractor Predicting: 88it [00:55,  1.57it/s]Extractor Predicting: 89it [00:56,  1.55it/s]Extractor Predicting: 90it [00:57,  1.56it/s]Extractor Predicting: 91it [00:57,  1.59it/s]Extractor Predicting: 92it [00:58,  1.61it/s]Extractor Predicting: 93it [00:58,  1.62it/s]Extractor Predicting: 94it [00:59,  1.63it/s]Extractor Predicting: 95it [01:00,  1.63it/s]Extractor Predicting: 96it [01:00,  1.62it/s]Extractor Predicting: 97it [01:01,  1.65it/s]Extractor Predicting: 98it [01:01,  1.65it/s]Extractor Predicting: 99it [01:02,  1.65it/s]Extractor Predicting: 100it [01:03,  1.63it/s]Extractor Predicting: 101it [01:03,  1.57it/s]Extractor Predicting: 102it [01:04,  1.57it/s]Extractor Predicting: 103it [01:05,  1.59it/s]Extractor Predicting: 104it [01:05,  1.61it/s]Extractor Predicting: 105it [01:06,  1.45it/s]Extractor Predicting: 106it [01:07,  1.48it/s]Extractor Predicting: 107it [01:07,  1.53it/s]Extractor Predicting: 108it [01:08,  1.58it/s]Extractor Predicting: 109it [01:09,  1.57it/s]Extractor Predicting: 110it [01:09,  1.61it/s]Extractor Predicting: 111it [01:10,  1.62it/s]Extractor Predicting: 112it [01:10,  1.60it/s]Extractor Predicting: 113it [01:11,  1.59it/s]Extractor Predicting: 114it [01:12,  1.62it/s]Extractor Predicting: 115it [01:12,  1.62it/s]Extractor Predicting: 116it [01:13,  1.62it/s]Extractor Predicting: 117it [01:13,  1.64it/s]Extractor Predicting: 118it [01:14,  1.62it/s]Extractor Predicting: 119it [01:15,  1.64it/s]Extractor Predicting: 120it [01:15,  1.68it/s]Extractor Predicting: 121it [01:16,  1.68it/s]Extractor Predicting: 122it [01:16,  1.65it/s]Extractor Predicting: 123it [01:17,  1.64it/s]Extractor Predicting: 124it [01:18,  1.62it/s]Extractor Predicting: 125it [01:18,  1.57it/s]Extractor Predicting: 126it [01:19,  1.59it/s]Extractor Predicting: 127it [01:20,  1.62it/s]Extractor Predicting: 128it [01:20,  1.64it/s]Extractor Predicting: 129it [01:21,  1.64it/s]Extractor Predicting: 130it [01:21,  1.62it/s]Extractor Predicting: 131it [01:22,  1.59it/s]Extractor Predicting: 132it [01:23,  1.60it/s]Extractor Predicting: 133it [01:23,  1.61it/s]Extractor Predicting: 134it [01:24,  1.59it/s]Extractor Predicting: 135it [01:25,  1.61it/s]Extractor Predicting: 136it [01:25,  1.66it/s]Extractor Predicting: 137it [01:26,  1.66it/s]Extractor Predicting: 138it [01:26,  1.64it/s]Extractor Predicting: 139it [01:27,  1.62it/s]Extractor Predicting: 140it [01:28,  1.65it/s]Extractor Predicting: 141it [01:28,  1.67it/s]Extractor Predicting: 142it [01:29,  1.68it/s]Extractor Predicting: 143it [01:29,  1.72it/s]Extractor Predicting: 144it [01:30,  1.68it/s]Extractor Predicting: 145it [01:30,  1.69it/s]Extractor Predicting: 146it [01:31,  1.68it/s]Extractor Predicting: 147it [01:32,  1.68it/s]Extractor Predicting: 148it [01:32,  1.67it/s]Extractor Predicting: 149it [01:33,  1.68it/s]Extractor Predicting: 150it [01:33,  1.68it/s]Extractor Predicting: 151it [01:34,  1.66it/s]Extractor Predicting: 152it [01:35,  1.69it/s]Extractor Predicting: 153it [01:35,  1.67it/s]Extractor Predicting: 154it [01:36,  1.66it/s]Extractor Predicting: 155it [01:36,  1.66it/s]Extractor Predicting: 156it [01:37,  1.66it/s]Extractor Predicting: 157it [01:38,  1.65it/s]Extractor Predicting: 158it [01:38,  1.66it/s]Extractor Predicting: 159it [01:39,  1.68it/s]Extractor Predicting: 160it [01:39,  1.71it/s]Extractor Predicting: 161it [01:40,  1.65it/s]Extractor Predicting: 162it [01:41,  1.62it/s]Extractor Predicting: 163it [01:41,  1.62it/s]Extractor Predicting: 164it [01:42,  1.67it/s]Extractor Predicting: 165it [01:43,  1.66it/s]Extractor Predicting: 166it [01:43,  1.59it/s]Extractor Predicting: 167it [01:44,  1.55it/s]Extractor Predicting: 168it [01:45,  1.56it/s]Extractor Predicting: 169it [01:45,  1.57it/s]Extractor Predicting: 170it [01:46,  1.54it/s]Extractor Predicting: 170it [01:46,  1.60it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:11,768 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:11,819 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:11,819 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:11,819 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:11,819 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 09:39:12,720 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 09:39:12,721 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:39:13,343 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 09:39:14,437 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:39:14,437 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:17,402 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:17,404 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:17,404 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:17,404 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:39:17,404 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 09:39:18,177 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 09:39:18,178 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:39:18,785 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 09:39:18,973 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:39:18,974 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_out_filter_single_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_in_single_is_eval_False.jsonl",
  "precision": 0.3289017341040462,
  "recall": 0.1396319018404908,
  "score": 0.19603789836347973,
  "mode": "single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/results_single_is_eval_False.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_in_multi_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_out_filter_multi_is_eval_False.jsonl'}}
predict vocab size: 3869
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 3969, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.55it/s]Extractor Predicting: 2it [00:01,  1.51it/s]Extractor Predicting: 3it [00:01,  1.54it/s]Extractor Predicting: 4it [00:02,  1.51it/s]Extractor Predicting: 5it [00:03,  1.53it/s]Extractor Predicting: 6it [00:03,  1.50it/s]Extractor Predicting: 7it [00:04,  1.48it/s]Extractor Predicting: 8it [00:05,  1.50it/s]Extractor Predicting: 9it [00:05,  1.52it/s]Extractor Predicting: 10it [00:06,  1.52it/s]Extractor Predicting: 11it [00:07,  1.48it/s]Extractor Predicting: 12it [00:07,  1.52it/s]Extractor Predicting: 13it [00:08,  1.54it/s]Extractor Predicting: 14it [00:09,  1.56it/s]Extractor Predicting: 15it [00:09,  1.56it/s]Extractor Predicting: 16it [00:10,  1.57it/s]Extractor Predicting: 17it [00:11,  1.55it/s]Extractor Predicting: 18it [00:11,  1.55it/s]Extractor Predicting: 19it [00:12,  1.55it/s]Extractor Predicting: 20it [00:13,  1.51it/s]Extractor Predicting: 21it [00:13,  1.54it/s]Extractor Predicting: 22it [00:14,  1.57it/s]Extractor Predicting: 23it [00:14,  1.56it/s]Extractor Predicting: 24it [00:15,  1.56it/s]Extractor Predicting: 25it [00:16,  1.58it/s]Extractor Predicting: 26it [00:16,  1.59it/s]Extractor Predicting: 27it [00:17,  1.57it/s]Extractor Predicting: 28it [00:18,  1.58it/s]Extractor Predicting: 29it [00:18,  1.57it/s]Extractor Predicting: 30it [00:19,  1.57it/s]Extractor Predicting: 31it [00:20,  1.56it/s]Extractor Predicting: 32it [00:20,  1.57it/s]Extractor Predicting: 33it [00:21,  1.49it/s]Extractor Predicting: 33it [00:21,  1.54it/s]
[INFO|configuration_utils.py:515] 2023-08-29 09:39:42,216 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 09:39:42,217 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 09:39:42,253 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 09:39:42,254 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|modeling_utils.py:1150] 2023-08-29 09:39:42,274 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 09:39:50,653 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.

[INFO|modeling_utils.py:1345] 2023-08-29 09:39:50,673 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.
[INFO|configuration_utils.py:515] 2023-08-29 09:39:50,747 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 09:39:50,748 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki/unseen_5_seed_3/generator/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 09:39:50,810 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:39:50,844 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:39:50,844 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:39:50,844 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:39:50,844 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:39:50,844 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 09:39:50,844 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model/tokenizer_config.json
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_out_filter_multi_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/pred_in_multi_is_eval_False.jsonl",
  "precision": 0.5833333333333334,
  "recall": 0.08559276980329612,
  "score": 0.1492814093648586,
  "mode": "multi",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/results_multi_is_eval_False.json"
}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
Generating:   0%|          | 0/10 [00:00<?, ?it/s][WARNING|generation_utils.py:914] 2023-08-29 09:39:51,151 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:51,672 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:52,260 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:52,838 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:53,398 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:53,949 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:54,526 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:55,064 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:55,606 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:56,251 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:56,793 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:57,326 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:57,913 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:58,472 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:59,133 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:39:59,743 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:00,308 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:00,895 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:01,379 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:02,004 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:02,516 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:03,161 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:03,745 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  10%|█         | 1/10 [00:13<01:57, 13.11s/it][WARNING|generation_utils.py:914] 2023-08-29 09:40:04,300 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:04,897 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:05,440 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:06,000 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:06,559 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:07,108 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:07,740 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:08,326 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:08,887 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:09,492 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:10,164 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:10,805 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:11,392 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:11,940 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:12,490 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:13,119 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:13,714 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:14,286 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:14,985 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:15,524 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:16,150 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  20%|██        | 2/10 [00:25<01:41, 12.75s/it][WARNING|generation_utils.py:914] 2023-08-29 09:40:16,750 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:17,285 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:17,799 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:18,247 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:18,721 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:19,178 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:19,683 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:20,142 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:20,599 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:21,073 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:21,549 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:22,017 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:22,491 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:22,969 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:23,453 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:23,910 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:24,407 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:24,938 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:25,465 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:25,932 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:26,359 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  30%|███       | 3/10 [00:35<01:20, 11.54s/it][WARNING|generation_utils.py:914] 2023-08-29 09:40:26,854 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:27,474 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:27,969 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:28,525 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:29,287 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:29,865 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:30,631 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:31,173 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:31,824 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:32,362 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:33,421 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:33,981 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:34,502 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:35,078 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:35,645 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:36,259 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:37,011 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:37,655 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:38,247 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:38,845 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:39,425 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  40%|████      | 4/10 [00:48<01:13, 12.20s/it][WARNING|generation_utils.py:914] 2023-08-29 09:40:40,094 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:40,706 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:41,283 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:41,802 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:42,358 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:42,897 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:43,611 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:44,199 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:44,815 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:45,448 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:45,981 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:46,693 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:47,283 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:47,883 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:48,426 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:48,997 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:49,523 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:50,134 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:50,681 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:51,188 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:51,743 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:52,282 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:52,863 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  50%|█████     | 5/10 [01:02<01:03, 12.62s/it][WARNING|generation_utils.py:914] 2023-08-29 09:40:53,439 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:53,936 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:54,540 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:55,118 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:55,628 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:56,233 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:56,701 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:57,274 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:57,877 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:58,417 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:58,962 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:40:59,527 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:00,127 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:00,804 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:01,373 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:01,926 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:02,471 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:03,041 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:03,547 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:04,140 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:04,729 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:05,235 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  60%|██████    | 6/10 [01:14<00:50, 12.56s/it][WARNING|generation_utils.py:914] 2023-08-29 09:41:05,933 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:06,558 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:07,148 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:07,721 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:08,311 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:08,925 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:09,459 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:10,154 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:10,726 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:11,437 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:12,041 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:12,634 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:13,177 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:13,716 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:14,467 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:15,145 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:15,688 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:16,262 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:16,869 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:17,483 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  70%|███████   | 7/10 [01:26<00:37, 12.44s/it][WARNING|generation_utils.py:914] 2023-08-29 09:41:18,059 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:18,622 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:19,208 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:19,797 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:20,337 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:20,891 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:21,547 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:22,142 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:22,741 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:23,447 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:24,004 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:24,614 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:25,183 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:25,755 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:26,312 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:26,889 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:27,560 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:28,076 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:28,748 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:29,280 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  80%|████████  | 8/10 [01:38<00:24, 12.24s/it][WARNING|generation_utils.py:914] 2023-08-29 09:41:29,871 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:30,437 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:31,045 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:31,627 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:32,265 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:32,828 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:33,394 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:34,014 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:34,608 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:35,165 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:35,803 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:36,397 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:36,966 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:37,522 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:38,069 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:38,717 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:39,293 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:39,884 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:40,461 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:41,073 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  90%|█████████ | 9/10 [01:50<00:12, 12.10s/it][WARNING|generation_utils.py:914] 2023-08-29 09:41:41,707 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:42,261 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:42,814 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:43,353 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:44,051 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:44,678 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:45,305 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:45,897 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:46,497 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:47,079 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:47,698 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:48,267 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:48,812 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:49,331 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:49,912 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:50,478 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:51,008 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:51,720 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:52,280 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:52,830 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 09:41:53,414 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating: 100%|██████████| 10/10 [02:02<00:00, 12.17s/it]Generating: 100%|██████████| 10/10 [02:02<00:00, 12.28s/it]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:00,091 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:00,118 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:00,118 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:00,118 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:00,118 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 09:42:00,643 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 09:42:00,644 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:42:01,364 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 09:42:02,486 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:42:02,486 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:03,842 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:03,857 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:03,857 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:03,857 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:42:03,857 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 09:42:04,249 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 09:42:04,250 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:42:04,542 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 09:42:04,726 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:42:04,727 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 55, 'raw': 64}
{'target': 600, 'success': 78, 'raw': 96}
{'target': 600, 'success': 101, 'raw': 128}
{'target': 600, 'success': 124, 'raw': 160}
{'target': 600, 'success': 151, 'raw': 192}
{'target': 600, 'success': 178, 'raw': 224}
{'target': 600, 'success': 204, 'raw': 256}
{'target': 600, 'success': 231, 'raw': 288}
{'target': 600, 'success': 258, 'raw': 320}
{'target': 600, 'success': 290, 'raw': 352}
{'target': 600, 'success': 318, 'raw': 384}
{'target': 600, 'success': 345, 'raw': 416}
{'target': 600, 'success': 369, 'raw': 448}
{'target': 600, 'success': 391, 'raw': 480}
{'target': 600, 'success': 417, 'raw': 512}
{'target': 600, 'success': 444, 'raw': 544}
{'target': 600, 'success': 472, 'raw': 576}
{'target': 600, 'success': 499, 'raw': 608}
{'target': 600, 'success': 525, 'raw': 640}
{'target': 600, 'success': 551, 'raw': 672}
{'target': 600, 'success': 579, 'raw': 704}
{'target': 600, 'success': 607, 'raw': 736}
{'prompt': 'Relation : country .', 'success_rate': 0.8247282608695652, 'errors': {'', 'not enough values to unpack (expected 2, got 1)', "('The Sopranos', 'country', '', 'In addition , she is known for her work as a producer of the hit sitcom The Sopranos .')"}}
{'target': 600, 'success': 30, 'raw': 32}
{'target': 600, 'success': 56, 'raw': 64}
{'target': 600, 'success': 84, 'raw': 96}
{'target': 600, 'success': 113, 'raw': 128}
{'target': 600, 'success': 143, 'raw': 160}
{'target': 600, 'success': 172, 'raw': 192}
{'target': 600, 'success': 201, 'raw': 224}
{'target': 600, 'success': 231, 'raw': 256}
{'target': 600, 'success': 258, 'raw': 288}
{'target': 600, 'success': 286, 'raw': 320}
{'target': 600, 'success': 316, 'raw': 352}
{'target': 600, 'success': 346, 'raw': 384}
{'target': 600, 'success': 376, 'raw': 416}
{'target': 600, 'success': 408, 'raw': 448}
{'target': 600, 'success': 437, 'raw': 480}
{'target': 600, 'success': 468, 'raw': 512}
{'target': 600, 'success': 498, 'raw': 544}
{'target': 600, 'success': 523, 'raw': 576}
{'target': 600, 'success': 552, 'raw': 608}
{'target': 600, 'success': 581, 'raw': 640}
{'target': 600, 'success': 610, 'raw': 672}
{'prompt': 'Relation : part of .', 'success_rate': 0.9077380952380952, 'errors': {''}}
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 58, 'raw': 64}
{'target': 600, 'success': 88, 'raw': 96}
{'target': 600, 'success': 117, 'raw': 128}
{'target': 600, 'success': 149, 'raw': 160}
{'target': 600, 'success': 179, 'raw': 192}
{'target': 600, 'success': 208, 'raw': 224}
{'target': 600, 'success': 238, 'raw': 256}
{'target': 600, 'success': 269, 'raw': 288}
{'target': 600, 'success': 297, 'raw': 320}
{'target': 600, 'success': 325, 'raw': 352}
{'target': 600, 'success': 355, 'raw': 384}
{'target': 600, 'success': 387, 'raw': 416}
{'target': 600, 'success': 418, 'raw': 448}
{'target': 600, 'success': 445, 'raw': 480}
{'target': 600, 'success': 475, 'raw': 512}
{'target': 600, 'success': 504, 'raw': 544}
{'target': 600, 'success': 535, 'raw': 576}
{'target': 600, 'success': 562, 'raw': 608}
{'target': 600, 'success': 591, 'raw': 640}
{'target': 600, 'success': 621, 'raw': 672}
{'prompt': 'Relation : platform .', 'success_rate': 0.9241071428571429, 'errors': {''}}
{'target': 600, 'success': 28, 'raw': 32}
{'target': 600, 'success': 58, 'raw': 64}
{'target': 600, 'success': 88, 'raw': 96}
{'target': 600, 'success': 119, 'raw': 128}
{'target': 600, 'success': 149, 'raw': 160}
{'target': 600, 'success': 176, 'raw': 192}
{'target': 600, 'success': 204, 'raw': 224}
{'target': 600, 'success': 232, 'raw': 256}
{'target': 600, 'success': 261, 'raw': 288}
{'target': 600, 'success': 290, 'raw': 320}
{'target': 600, 'success': 320, 'raw': 352}
{'target': 600, 'success': 348, 'raw': 384}
{'target': 600, 'success': 380, 'raw': 416}
{'target': 600, 'success': 411, 'raw': 448}
{'target': 600, 'success': 442, 'raw': 480}
{'target': 600, 'success': 471, 'raw': 512}
{'target': 600, 'success': 498, 'raw': 544}
{'target': 600, 'success': 527, 'raw': 576}
{'target': 600, 'success': 559, 'raw': 608}
{'target': 600, 'success': 588, 'raw': 640}
{'target': 600, 'success': 617, 'raw': 672}
{'prompt': 'Relation : publisher .', 'success_rate': 0.9181547619047619, 'errors': {''}}
{'target': 600, 'success': 31, 'raw': 32}
{'target': 600, 'success': 56, 'raw': 64}
{'target': 600, 'success': 82, 'raw': 96}
{'target': 600, 'success': 110, 'raw': 128}
{'target': 600, 'success': 137, 'raw': 160}
{'target': 600, 'success': 167, 'raw': 192}
{'target': 600, 'success': 192, 'raw': 224}
{'target': 600, 'success': 216, 'raw': 256}
{'target': 600, 'success': 241, 'raw': 288}
{'target': 600, 'success': 267, 'raw': 320}
{'target': 600, 'success': 295, 'raw': 352}
{'target': 600, 'success': 322, 'raw': 384}
{'target': 600, 'success': 346, 'raw': 416}
{'target': 600, 'success': 371, 'raw': 448}
{'target': 600, 'success': 402, 'raw': 480}
{'target': 600, 'success': 422, 'raw': 512}
{'target': 600, 'success': 450, 'raw': 544}
{'target': 600, 'success': 480, 'raw': 576}
{'target': 600, 'success': 501, 'raw': 608}
{'target': 600, 'success': 527, 'raw': 640}
{'target': 600, 'success': 551, 'raw': 672}
{'target': 600, 'success': 577, 'raw': 704}
{'target': 600, 'success': 601, 'raw': 736}
{'prompt': 'Relation : sport .', 'success_rate': 0.8165760869565217, 'errors': {'', "('Team USA', 'sport', '', 'He also competed in the 2000 Summer Olympics as part of the team of Team USA against Canada .')", 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 30, 'raw': 32}
{'target': 600, 'success': 57, 'raw': 64}
{'target': 600, 'success': 83, 'raw': 96}
{'target': 600, 'success': 111, 'raw': 128}
{'target': 600, 'success': 140, 'raw': 160}
{'target': 600, 'success': 170, 'raw': 192}
{'target': 600, 'success': 199, 'raw': 224}
{'target': 600, 'success': 228, 'raw': 256}
{'target': 600, 'success': 252, 'raw': 288}
{'target': 600, 'success': 281, 'raw': 320}
{'target': 600, 'success': 311, 'raw': 352}
{'target': 600, 'success': 338, 'raw': 384}
{'target': 600, 'success': 368, 'raw': 416}
{'target': 600, 'success': 398, 'raw': 448}
{'target': 600, 'success': 423, 'raw': 480}
{'target': 600, 'success': 448, 'raw': 512}
{'target': 600, 'success': 474, 'raw': 544}
{'target': 600, 'success': 501, 'raw': 576}
{'target': 600, 'success': 527, 'raw': 608}
{'target': 600, 'success': 553, 'raw': 640}
{'target': 600, 'success': 583, 'raw': 672}
{'target': 600, 'success': 612, 'raw': 704}
{'prompt': 'Relation : continent .', 'success_rate': 0.8693181818181818, 'errors': {''}}
{'target': 600, 'success': 30, 'raw': 32}
{'target': 600, 'success': 59, 'raw': 64}
{'target': 600, 'success': 89, 'raw': 96}
{'target': 600, 'success': 118, 'raw': 128}
{'target': 600, 'success': 148, 'raw': 160}
{'target': 600, 'success': 179, 'raw': 192}
{'target': 600, 'success': 210, 'raw': 224}
{'target': 600, 'success': 242, 'raw': 256}
{'target': 600, 'success': 272, 'raw': 288}
{'target': 600, 'success': 300, 'raw': 320}
{'target': 600, 'success': 328, 'raw': 352}
{'target': 600, 'success': 359, 'raw': 384}
{'target': 600, 'success': 388, 'raw': 416}
{'target': 600, 'success': 419, 'raw': 448}
{'target': 600, 'success': 449, 'raw': 480}
{'target': 600, 'success': 480, 'raw': 512}
{'target': 600, 'success': 512, 'raw': 544}
{'target': 600, 'success': 542, 'raw': 576}
{'target': 600, 'success': 573, 'raw': 608}
{'target': 600, 'success': 605, 'raw': 640}
{'prompt': 'Relation : owned by .', 'success_rate': 0.9453125, 'errors': {''}}
{'target': 600, 'success': 28, 'raw': 32}
{'target': 600, 'success': 60, 'raw': 64}
{'target': 600, 'success': 90, 'raw': 96}
{'target': 600, 'success': 121, 'raw': 128}
{'target': 600, 'success': 152, 'raw': 160}
{'target': 600, 'success': 183, 'raw': 192}
{'target': 600, 'success': 212, 'raw': 224}
{'target': 600, 'success': 243, 'raw': 256}
{'target': 600, 'success': 275, 'raw': 288}
{'target': 600, 'success': 307, 'raw': 320}
{'target': 600, 'success': 338, 'raw': 352}
{'target': 600, 'success': 366, 'raw': 384}
{'target': 600, 'success': 397, 'raw': 416}
{'target': 600, 'success': 427, 'raw': 448}
{'target': 600, 'success': 457, 'raw': 480}
{'target': 600, 'success': 487, 'raw': 512}
{'target': 600, 'success': 518, 'raw': 544}
{'target': 600, 'success': 549, 'raw': 576}
{'target': 600, 'success': 581, 'raw': 608}
{'target': 600, 'success': 613, 'raw': 640}
{'prompt': 'Relation : performer .', 'success_rate': 0.9578125, 'errors': {'', "('The People v. O.J. Simpson', 'performer', '', 'In 2007 , she performed on the soundtrack for NBC s musical The People v. O.J. Simpson , which was featured in the episode The People v. O.J. Simpson .')"}}
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 60, 'raw': 64}
{'target': 600, 'success': 89, 'raw': 96}
{'target': 600, 'success': 121, 'raw': 128}
{'target': 600, 'success': 150, 'raw': 160}
{'target': 600, 'success': 180, 'raw': 192}
{'target': 600, 'success': 211, 'raw': 224}
{'target': 600, 'success': 241, 'raw': 256}
{'target': 600, 'success': 273, 'raw': 288}
{'target': 600, 'success': 304, 'raw': 320}
{'target': 600, 'success': 334, 'raw': 352}
{'target': 600, 'success': 365, 'raw': 384}
{'target': 600, 'success': 395, 'raw': 416}
{'target': 600, 'success': 424, 'raw': 448}
{'target': 600, 'success': 453, 'raw': 480}
{'target': 600, 'success': 483, 'raw': 512}
{'target': 600, 'success': 513, 'raw': 544}
{'target': 600, 'success': 543, 'raw': 576}
{'target': 600, 'success': 575, 'raw': 608}
{'target': 600, 'success': 605, 'raw': 640}
{'prompt': 'Relation : producer .', 'success_rate': 0.9453125, 'errors': {''}}
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 58, 'raw': 64}
{'target': 600, 'success': 89, 'raw': 96}
{'target': 600, 'success': 119, 'raw': 128}
{'target': 600, 'success': 150, 'raw': 160}
{'target': 600, 'success': 177, 'raw': 192}
{'target': 600, 'success': 208, 'raw': 224}
{'target': 600, 'success': 238, 'raw': 256}
{'target': 600, 'success': 267, 'raw': 288}
{'target': 600, 'success': 294, 'raw': 320}
{'target': 600, 'success': 324, 'raw': 352}
{'target': 600, 'success': 349, 'raw': 384}
{'target': 600, 'success': 381, 'raw': 416}
{'target': 600, 'success': 409, 'raw': 448}
{'target': 600, 'success': 436, 'raw': 480}
{'target': 600, 'success': 466, 'raw': 512}
{'target': 600, 'success': 495, 'raw': 544}
{'target': 600, 'success': 525, 'raw': 576}
{'target': 600, 'success': 557, 'raw': 608}
{'target': 600, 'success': 586, 'raw': 640}
{'target': 600, 'success': 617, 'raw': 672}
{'prompt': 'Relation : replaces .', 'success_rate': 0.9181547619047619, 'errors': {'', "('womens singles', 'replaces', '', 'After its success in the 2008 Summer Olympics , the team competed in the womens singles event with their rivals , the Dutch team , together with their Swedish teammates .')"}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/2.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/2_ext.jsonl'}}
estimate vocab size: 7219
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 7319, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/data/estimate.txt
Extractor Estimating: 0it [00:00, ?it/s]Extractor Estimating: 1it [00:00,  1.76it/s]Extractor Estimating: 2it [00:01,  1.65it/s]Extractor Estimating: 3it [00:01,  1.71it/s]Extractor Estimating: 4it [00:02,  1.72it/s]Extractor Estimating: 5it [00:02,  1.65it/s]Extractor Estimating: 6it [00:03,  1.70it/s]Extractor Estimating: 7it [00:04,  1.77it/s]Extractor Estimating: 8it [00:04,  1.75it/s]Extractor Estimating: 9it [00:05,  1.78it/s]Extractor Estimating: 10it [00:05,  1.64it/s]Extractor Estimating: 11it [00:06,  1.65it/s]Extractor Estimating: 12it [00:07,  1.61it/s]Extractor Estimating: 13it [00:07,  1.63it/s]Extractor Estimating: 14it [00:08,  1.68it/s]Extractor Estimating: 15it [00:08,  1.73it/s]Extractor Estimating: 16it [00:09,  1.69it/s]Extractor Estimating: 17it [00:09,  1.75it/s]Extractor Estimating: 18it [00:10,  1.71it/s]Extractor Estimating: 19it [00:11,  1.71it/s]Extractor Estimating: 20it [00:11,  1.74it/s]Extractor Estimating: 21it [00:12,  1.70it/s]Extractor Estimating: 22it [00:12,  1.69it/s]Extractor Estimating: 23it [00:13,  1.67it/s]Extractor Estimating: 24it [00:14,  1.67it/s]Extractor Estimating: 25it [00:14,  1.70it/s]Extractor Estimating: 26it [00:15,  1.65it/s]Extractor Estimating: 27it [00:16,  1.63it/s]Extractor Estimating: 28it [00:16,  1.67it/s]Extractor Estimating: 29it [00:17,  1.70it/s]Extractor Estimating: 30it [00:17,  1.71it/s]Extractor Estimating: 31it [00:18,  1.72it/s]Extractor Estimating: 32it [00:18,  1.71it/s]Extractor Estimating: 33it [00:19,  1.75it/s]Extractor Estimating: 34it [00:19,  1.78it/s]Extractor Estimating: 35it [00:20,  1.77it/s]Extractor Estimating: 36it [00:21,  1.76it/s]Extractor Estimating: 37it [00:21,  1.71it/s]Extractor Estimating: 38it [00:22,  1.71it/s]Extractor Estimating: 39it [00:22,  1.70it/s]Extractor Estimating: 40it [00:23,  1.69it/s]Extractor Estimating: 41it [00:24,  1.71it/s]Extractor Estimating: 42it [00:24,  1.73it/s]Extractor Estimating: 43it [00:25,  1.71it/s]Extractor Estimating: 44it [00:25,  1.67it/s]Extractor Estimating: 45it [00:26,  1.61it/s]Extractor Estimating: 46it [00:27,  1.59it/s]Extractor Estimating: 47it [00:27,  1.59it/s]Extractor Estimating: 48it [00:28,  1.65it/s]Extractor Estimating: 49it [00:29,  1.64it/s]Extractor Estimating: 50it [00:29,  1.64it/s]Extractor Estimating: 51it [00:30,  1.75it/s]Extractor Estimating: 52it [00:30,  1.78it/s]Extractor Estimating: 53it [00:31,  1.79it/s]Extractor Estimating: 54it [00:31,  1.81it/s]Extractor Estimating: 55it [00:32,  1.86it/s]Extractor Estimating: 56it [00:32,  1.91it/s]Extractor Estimating: 57it [00:33,  1.94it/s]Extractor Estimating: 58it [00:33,  1.94it/s]Extractor Estimating: 59it [00:34,  1.95it/s]Extractor Estimating: 60it [00:34,  2.00it/s]Extractor Estimating: 61it [00:35,  1.98it/s]Extractor Estimating: 62it [00:35,  2.01it/s]Extractor Estimating: 63it [00:36,  2.01it/s]Extractor Estimating: 64it [00:36,  1.96it/s]Extractor Estimating: 65it [00:37,  2.00it/s]Extractor Estimating: 66it [00:37,  2.01it/s]Extractor Estimating: 67it [00:38,  2.01it/s]Extractor Estimating: 68it [00:38,  2.02it/s]Extractor Estimating: 69it [00:39,  1.95it/s]Extractor Estimating: 70it [00:39,  1.97it/s]Extractor Estimating: 71it [00:40,  1.93it/s]Extractor Estimating: 72it [00:40,  1.93it/s]Extractor Estimating: 73it [00:41,  1.94it/s]Extractor Estimating: 74it [00:41,  1.99it/s]Extractor Estimating: 75it [00:42,  1.98it/s]Extractor Estimating: 76it [00:42,  1.81it/s]Extractor Estimating: 77it [00:43,  1.76it/s]Extractor Estimating: 78it [00:44,  1.72it/s]Extractor Estimating: 79it [00:44,  1.67it/s]Extractor Estimating: 80it [00:45,  1.65it/s]Extractor Estimating: 81it [00:46,  1.61it/s]Extractor Estimating: 82it [00:46,  1.54it/s]Extractor Estimating: 83it [00:47,  1.55it/s]Extractor Estimating: 84it [00:48,  1.60it/s]Extractor Estimating: 85it [00:48,  1.63it/s]Extractor Estimating: 86it [00:49,  1.64it/s]Extractor Estimating: 87it [00:51,  1.25s/it]Extractor Estimating: 88it [00:52,  1.07s/it]Extractor Estimating: 89it [00:53,  1.08it/s]Extractor Estimating: 90it [00:53,  1.21it/s]Extractor Estimating: 91it [00:54,  1.31it/s]Extractor Estimating: 92it [00:54,  1.41it/s]Extractor Estimating: 93it [00:55,  1.34it/s]Extractor Estimating: 94it [00:56,  1.46it/s]Extractor Estimating: 95it [00:57,  1.42it/s]Extractor Estimating: 96it [00:57,  1.45it/s]Extractor Estimating: 97it [00:58,  1.54it/s]Extractor Estimating: 98it [00:58,  1.61it/s]Extractor Estimating: 99it [00:59,  1.60it/s]Extractor Estimating: 100it [01:00,  1.61it/s]Extractor Estimating: 101it [01:00,  1.63it/s]Extractor Estimating: 102it [01:01,  1.69it/s]Extractor Estimating: 103it [01:01,  1.71it/s]Extractor Estimating: 104it [01:02,  1.68it/s]Extractor Estimating: 105it [01:03,  1.68it/s]Extractor Estimating: 106it [01:03,  1.71it/s]Extractor Estimating: 107it [01:04,  1.75it/s]Extractor Estimating: 108it [01:04,  1.69it/s]Extractor Estimating: 109it [01:05,  1.72it/s]Extractor Estimating: 110it [01:05,  1.71it/s]Extractor Estimating: 111it [01:06,  1.73it/s]Extractor Estimating: 112it [01:07,  1.72it/s]Extractor Estimating: 113it [01:07,  1.72it/s]Extractor Estimating: 114it [01:08,  1.70it/s]Extractor Estimating: 115it [01:08,  1.72it/s]Extractor Estimating: 116it [01:09,  1.73it/s]Extractor Estimating: 117it [01:09,  1.75it/s]Extractor Estimating: 118it [01:10,  1.79it/s]Extractor Estimating: 119it [01:11,  1.77it/s]Extractor Estimating: 120it [01:11,  1.77it/s]Extractor Estimating: 121it [01:12,  1.79it/s]Extractor Estimating: 122it [01:12,  1.74it/s]Extractor Estimating: 123it [01:13,  1.77it/s]Extractor Estimating: 124it [01:13,  1.76it/s]Extractor Estimating: 125it [01:14,  1.73it/s]Extractor Estimating: 126it [01:15,  1.75it/s]Extractor Estimating: 127it [01:15,  1.74it/s]Extractor Estimating: 128it [01:16,  1.77it/s]Extractor Estimating: 129it [01:16,  1.81it/s]Extractor Estimating: 130it [01:17,  1.75it/s]Extractor Estimating: 131it [01:17,  1.77it/s]Extractor Estimating: 132it [01:18,  1.83it/s]Extractor Estimating: 133it [01:18,  1.80it/s]Extractor Estimating: 134it [01:19,  1.79it/s]Extractor Estimating: 135it [01:20,  1.81it/s]Extractor Estimating: 136it [01:20,  1.80it/s]Extractor Estimating: 137it [01:21,  1.77it/s]Extractor Estimating: 138it [01:21,  1.77it/s]Extractor Estimating: 139it [01:22,  1.74it/s]Extractor Estimating: 140it [01:22,  1.75it/s]Extractor Estimating: 141it [01:23,  1.76it/s]Extractor Estimating: 142it [01:24,  1.76it/s]Extractor Estimating: 143it [01:24,  1.78it/s]Extractor Estimating: 144it [01:25,  1.81it/s]Extractor Estimating: 145it [01:25,  1.80it/s]Extractor Estimating: 146it [01:26,  1.80it/s]Extractor Estimating: 147it [01:26,  1.89it/s]Extractor Estimating: 148it [01:27,  1.90it/s]Extractor Estimating: 149it [01:27,  1.81it/s]Extractor Estimating: 150it [01:28,  1.81it/s]Extractor Estimating: 151it [01:28,  1.79it/s]Extractor Estimating: 152it [01:29,  1.73it/s]Extractor Estimating: 153it [01:30,  1.71it/s]Extractor Estimating: 154it [01:30,  1.72it/s]Extractor Estimating: 155it [01:31,  1.70it/s]Extractor Estimating: 156it [01:32,  1.68it/s]Extractor Estimating: 157it [01:32,  1.68it/s]Extractor Estimating: 158it [01:33,  1.62it/s]Extractor Estimating: 159it [01:33,  1.65it/s]Extractor Estimating: 160it [01:34,  1.65it/s]Extractor Estimating: 161it [01:35,  1.64it/s]Extractor Estimating: 162it [01:35,  1.63it/s]Extractor Estimating: 163it [01:36,  1.67it/s]Extractor Estimating: 164it [01:36,  1.68it/s]Extractor Estimating: 165it [01:37,  1.72it/s]Extractor Estimating: 166it [01:38,  1.67it/s]Extractor Estimating: 167it [01:38,  1.70it/s]Extractor Estimating: 168it [01:39,  1.69it/s]Extractor Estimating: 169it [01:39,  1.63it/s]Extractor Estimating: 170it [01:40,  1.65it/s]Extractor Estimating: 171it [01:41,  1.65it/s]Extractor Estimating: 172it [01:41,  1.68it/s]Extractor Estimating: 173it [01:42,  1.65it/s]Extractor Estimating: 174it [01:42,  1.67it/s]Extractor Estimating: 175it [01:43,  1.64it/s]Extractor Estimating: 176it [01:44,  1.66it/s]Extractor Estimating: 177it [01:44,  1.52it/s]Extractor Estimating: 178it [01:45,  1.54it/s]Extractor Estimating: 179it [01:46,  1.58it/s]Extractor Estimating: 180it [01:46,  1.63it/s]Extractor Estimating: 181it [01:47,  1.63it/s]Extractor Estimating: 182it [01:47,  1.62it/s]Extractor Estimating: 183it [01:48,  1.62it/s]Extractor Estimating: 184it [01:49,  1.61it/s]Extractor Estimating: 185it [01:49,  1.58it/s]Extractor Estimating: 186it [01:50,  1.58it/s]Extractor Estimating: 187it [01:51,  1.60it/s]Extractor Estimating: 188it [01:51,  1.62it/s]Extractor Estimating: 189it [01:52,  1.63it/s]Extractor Estimating: 190it [01:52,  1.63it/s]Extractor Estimating: 191it [01:53,  1.62it/s]Extractor Estimating: 192it [01:54,  1.66it/s]Extractor Estimating: 193it [01:54,  1.65it/s]Extractor Estimating: 194it [01:55,  1.65it/s]Extractor Estimating: 195it [01:55,  1.64it/s]Extractor Estimating: 196it [01:56,  1.71it/s]Extractor Estimating: 197it [01:56,  1.69it/s]Extractor Estimating: 198it [01:57,  1.64it/s]Extractor Estimating: 199it [01:58,  1.65it/s]Extractor Estimating: 200it [01:58,  1.65it/s]Extractor Estimating: 201it [01:59,  1.64it/s]Extractor Estimating: 202it [02:00,  1.61it/s]Extractor Estimating: 203it [02:00,  1.60it/s]Extractor Estimating: 204it [02:01,  1.58it/s]Extractor Estimating: 205it [02:02,  1.59it/s]Extractor Estimating: 206it [02:02,  1.56it/s]Extractor Estimating: 207it [02:03,  1.60it/s]Extractor Estimating: 208it [02:03,  1.54it/s]Extractor Estimating: 209it [02:04,  1.58it/s]Extractor Estimating: 210it [02:05,  1.61it/s]Extractor Estimating: 211it [02:05,  1.65it/s]Extractor Estimating: 212it [02:06,  1.65it/s]Extractor Estimating: 213it [02:06,  1.64it/s]Extractor Estimating: 214it [02:07,  1.69it/s]Extractor Estimating: 215it [02:08,  1.70it/s]Extractor Estimating: 216it [02:08,  1.65it/s]Extractor Estimating: 217it [02:09,  1.66it/s]Extractor Estimating: 218it [02:10,  1.60it/s]Extractor Estimating: 219it [02:10,  1.62it/s]Extractor Estimating: 220it [02:11,  1.67it/s]Extractor Estimating: 221it [02:11,  1.65it/s]Extractor Estimating: 222it [02:12,  1.66it/s]Extractor Estimating: 223it [02:13,  1.65it/s]Extractor Estimating: 224it [02:13,  1.64it/s]Extractor Estimating: 225it [02:14,  1.63it/s]Extractor Estimating: 226it [02:14,  1.67it/s]Extractor Estimating: 227it [02:15,  1.67it/s]Extractor Estimating: 228it [02:16,  1.66it/s]Extractor Estimating: 229it [02:16,  1.66it/s]Extractor Estimating: 230it [02:17,  1.65it/s]Extractor Estimating: 231it [02:17,  1.66it/s]Extractor Estimating: 232it [02:18,  1.68it/s]Extractor Estimating: 233it [02:19,  1.64it/s]Extractor Estimating: 234it [02:19,  1.64it/s]Extractor Estimating: 235it [02:20,  1.68it/s]Extractor Estimating: 236it [02:20,  1.67it/s]Extractor Estimating: 237it [02:21,  1.67it/s]Extractor Estimating: 238it [02:22,  1.65it/s]Extractor Estimating: 239it [02:22,  1.66it/s]Extractor Estimating: 240it [02:23,  1.68it/s]Extractor Estimating: 241it [02:23,  1.72it/s]Extractor Estimating: 242it [02:24,  1.70it/s]Extractor Estimating: 243it [02:24,  1.69it/s]Extractor Estimating: 244it [02:25,  1.69it/s]Extractor Estimating: 245it [02:26,  1.70it/s]Extractor Estimating: 246it [02:26,  1.69it/s]Extractor Estimating: 247it [02:27,  1.72it/s]Extractor Estimating: 248it [02:28,  1.52it/s]Extractor Estimating: 249it [02:28,  1.56it/s]Extractor Estimating: 250it [02:29,  1.67it/s]Extractor Estimating: 250it [02:29,  1.67it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:52,829 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:52,839 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:52,839 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:52,839 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:52,839 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 09:44:53,566 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 09:44:53,567 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:44:54,244 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 09:44:55,367 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:44:55,367 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:58,433 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:58,450 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:58,450 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:58,451 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 09:44:58,451 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 09:44:59,238 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 09:44:59,239 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 09:44:59,877 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 09:45:00,079 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 09:45:00,080 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1113: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[INFO|training_args.py:725] 2023-08-29 10:56:37,799 >> PyTorch: setting up devices
[INFO|training_args.py:625] 2023-08-29 10:56:38,083 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/2_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_5_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/2.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.6, 'with_train': False, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
{'num_pseudo': 3000, 'num_train': 2000}
num of filtered data: 2996 mean pseudo reward: 0.9483147619897135
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/2.jsonl', 'path_dev': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl'}
train vocab size: 23416
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 23516, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/data/train.txt
{"train_model: args: ModelArguments(model_class='JointModel', model_read_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter2/model', model_write_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/model', pretrained_wv='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/data/train.txt', label_config=None, batch_size=24, evaluate_interval=500, max_steps=10000, max_epoches=20, decay_rate=0.05, token_emb_dim=100, char_encoder='lstm', char_emb_dim=30, cased=False, hidden_dim=200, num_layers=3, crf=None, loss_reduction='sum', maxlen=None, dropout=0.5, optimizer='adam', lr=0.001, vocab_size=23516, vocab_file=None, ner_tag_vocab_size=64, re_tag_vocab_size=250, lm_emb_dim=1024, lm_emb_path='albert-large-v2', head_emb_dim=384, tag_form='iob2', warm_steps=1000, grad_period=1, device='cuda', seed=42)"}
warm up: learning rate was adjusted to 1e-06
warm up: learning rate was adjusted to 1.1e-05
warm up: learning rate was adjusted to 2.1000000000000002e-05
warm up: learning rate was adjusted to 3.1e-05
warm up: learning rate was adjusted to 4.1e-05
warm up: learning rate was adjusted to 5.1000000000000006e-05
warm up: learning rate was adjusted to 6.1e-05
warm up: learning rate was adjusted to 7.1e-05
warm up: learning rate was adjusted to 8.1e-05
warm up: learning rate was adjusted to 9.1e-05
g_step 100, step 100, avg_time 1.022, loss:503.8406
warm up: learning rate was adjusted to 0.000101
warm up: learning rate was adjusted to 0.000111
warm up: learning rate was adjusted to 0.000121
warm up: learning rate was adjusted to 0.000131
warm up: learning rate was adjusted to 0.000141
warm up: learning rate was adjusted to 0.00015099999999999998
warm up: learning rate was adjusted to 0.000161
warm up: learning rate was adjusted to 0.000171
warm up: learning rate was adjusted to 0.00018099999999999998
warm up: learning rate was adjusted to 0.000191
g_step 200, step 75, avg_time 0.984, loss:461.3889
warm up: learning rate was adjusted to 0.000201
warm up: learning rate was adjusted to 0.000211
warm up: learning rate was adjusted to 0.000221
warm up: learning rate was adjusted to 0.000231
warm up: learning rate was adjusted to 0.000241
warm up: learning rate was adjusted to 0.000251
warm up: learning rate was adjusted to 0.000261
warm up: learning rate was adjusted to 0.00027100000000000003
warm up: learning rate was adjusted to 0.00028100000000000005
warm up: learning rate was adjusted to 0.00029099999999999997
g_step 300, step 50, avg_time 0.975, loss:458.1820
warm up: learning rate was adjusted to 0.000301
warm up: learning rate was adjusted to 0.000311
warm up: learning rate was adjusted to 0.000321
warm up: learning rate was adjusted to 0.000331
warm up: learning rate was adjusted to 0.00034100000000000005
warm up: learning rate was adjusted to 0.000351
warm up: learning rate was adjusted to 0.000361
warm up: learning rate was adjusted to 0.000371
warm up: learning rate was adjusted to 0.000381
warm up: learning rate was adjusted to 0.000391
g_step 400, step 25, avg_time 0.988, loss:421.6217
warm up: learning rate was adjusted to 0.00040100000000000004
warm up: learning rate was adjusted to 0.000411
warm up: learning rate was adjusted to 0.000421
warm up: learning rate was adjusted to 0.000431
warm up: learning rate was adjusted to 0.000441
warm up: learning rate was adjusted to 0.000451
warm up: learning rate was adjusted to 0.00046100000000000004
warm up: learning rate was adjusted to 0.000471
warm up: learning rate was adjusted to 0.000481
warm up: learning rate was adjusted to 0.000491
g_step 500, step 125, avg_time 0.991, loss:413.2587
>> valid entity prec:0.4506, rec:0.4468, f1:0.4487
>> valid relation prec:0.2168, rec:0.1263, f1:0.1596
>> valid relation with NER prec:0.2168, rec:0.1263, f1:0.1596
new max entity f1 on valid!
new max relation f1 on valid!
new max relation f1 with NER on valid!
new max averaged entity f1 and relation f1 on valid!
new max averaged entity f1 and relation f1 with NER on valid!
warm up: learning rate was adjusted to 0.000501
warm up: learning rate was adjusted to 0.0005110000000000001
warm up: learning rate was adjusted to 0.000521
warm up: learning rate was adjusted to 0.000531
warm up: learning rate was adjusted to 0.000541
warm up: learning rate was adjusted to 0.0005510000000000001
warm up: learning rate was adjusted to 0.0005610000000000001
warm up: learning rate was adjusted to 0.0005710000000000001
warm up: learning rate was adjusted to 0.0005809999999999999
warm up: learning rate was adjusted to 0.0005909999999999999
g_step 600, step 100, avg_time 0.984, loss:391.2851
warm up: learning rate was adjusted to 0.000601
warm up: learning rate was adjusted to 0.000611
warm up: learning rate was adjusted to 0.000621
warm up: learning rate was adjusted to 0.000631
warm up: learning rate was adjusted to 0.000641
warm up: learning rate was adjusted to 0.000651
warm up: learning rate was adjusted to 0.000661
warm up: learning rate was adjusted to 0.000671
warm up: learning rate was adjusted to 0.0006810000000000001
warm up: learning rate was adjusted to 0.0006910000000000001
g_step 700, step 75, avg_time 0.992, loss:384.2917
warm up: learning rate was adjusted to 0.000701
warm up: learning rate was adjusted to 0.0007109999999999999
warm up: learning rate was adjusted to 0.000721
warm up: learning rate was adjusted to 0.000731
warm up: learning rate was adjusted to 0.000741
warm up: learning rate was adjusted to 0.000751
warm up: learning rate was adjusted to 0.000761
warm up: learning rate was adjusted to 0.000771
warm up: learning rate was adjusted to 0.000781
warm up: learning rate was adjusted to 0.000791
g_step 800, step 50, avg_time 0.974, loss:366.3004
warm up: learning rate was adjusted to 0.0008010000000000001
warm up: learning rate was adjusted to 0.0008110000000000001
warm up: learning rate was adjusted to 0.0008210000000000001
warm up: learning rate was adjusted to 0.000831
warm up: learning rate was adjusted to 0.000841
warm up: learning rate was adjusted to 0.000851
warm up: learning rate was adjusted to 0.000861
warm up: learning rate was adjusted to 0.000871
warm up: learning rate was adjusted to 0.0008810000000000001
warm up: learning rate was adjusted to 0.000891
g_step 900, step 25, avg_time 0.993, loss:373.2613
warm up: learning rate was adjusted to 0.000901
warm up: learning rate was adjusted to 0.000911
warm up: learning rate was adjusted to 0.000921
warm up: learning rate was adjusted to 0.0009310000000000001
warm up: learning rate was adjusted to 0.0009410000000000001
warm up: learning rate was adjusted to 0.000951
warm up: learning rate was adjusted to 0.0009609999999999999
warm up: learning rate was adjusted to 0.000971
warm up: learning rate was adjusted to 0.0009809999999999999
warm up: learning rate was adjusted to 0.000991
g_step 1000, step 125, avg_time 0.993, loss:357.3585
learning rate was adjusted to 0.0009523809523809524
>> valid entity prec:0.4442, rec:0.4661, f1:0.4549
>> valid relation prec:0.2063, rec:0.1075, f1:0.1414
>> valid relation with NER prec:0.2063, rec:0.1075, f1:0.1414
new max entity f1 on valid!
g_step 1100, step 100, avg_time 0.985, loss:354.1048
g_step 1200, step 75, avg_time 0.978, loss:325.0096
g_step 1300, step 50, avg_time 0.989, loss:320.9357
g_step 1400, step 25, avg_time 0.977, loss:313.5101
g_step 1500, step 125, avg_time 0.983, loss:302.0718
>> valid entity prec:0.4540, rec:0.3795, f1:0.4134
>> valid relation prec:0.1918, rec:0.1047, f1:0.1354
>> valid relation with NER prec:0.1918, rec:0.1047, f1:0.1354
g_step 1600, step 100, avg_time 0.980, loss:274.9153
g_step 1700, step 75, avg_time 0.988, loss:276.1129
g_step 1800, step 50, avg_time 0.980, loss:262.6766
g_step 1900, step 25, avg_time 0.974, loss:257.7816
g_step 2000, step 125, avg_time 1.002, loss:258.4631
learning rate was adjusted to 0.0009090909090909091
>> valid entity prec:0.4333, rec:0.4357, f1:0.4345
>> valid relation prec:0.1778, rec:0.1002, f1:0.1282
>> valid relation with NER prec:0.1778, rec:0.1002, f1:0.1282
g_step 2100, step 100, avg_time 0.976, loss:229.2238
g_step 2200, step 75, avg_time 0.979, loss:230.9210
g_step 2300, step 50, avg_time 0.991, loss:213.6313
g_step 2400, step 25, avg_time 0.979, loss:222.4326
g_step 2500, step 125, avg_time 0.976, loss:214.4093
>> valid entity prec:0.4459, rec:0.4205, f1:0.4328
>> valid relation prec:0.1836, rec:0.1136, f1:0.1403
>> valid relation with NER prec:0.1836, rec:0.1136, f1:0.1403
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
08/29/2023 10:56:38 - WARNING - transformer_base.run_clm_rl -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True
08/29/2023 10:56:38 - INFO - transformer_base.run_clm_rl -   Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=2,
greater_is_better=False,
group_by_length=False,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_on_each_node=True,
logging_dir=runs/Aug29_10-56-37_ctolab07.scc.idea,
logging_first_step=False,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
output_dir=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
08/29/2023 10:56:39 - WARNING - datasets.builder -   Using custom data configuration default-9e22479a8c51671d
Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/xuting/.cache/huggingface/datasets/json/default-9e22479a8c51671d/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...
0 tables [00:00, ? tables/s]1 tables [00:00,  2.14 tables/s]                                0 tables [00:00, ? tables/s]                            [INFO|configuration_utils.py:515] 2023-08-29 10:56:42,431 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 10:56:42,432 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 10:56:42,433 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 10:56:42,434 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 10:56:42,530 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 10:56:42,598 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 10:56:42,598 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 10:56:42,598 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 10:56:42,598 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 10:56:42,598 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 10:56:42,598 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/tokenizer_config.json
[INFO|modeling_utils.py:1150] 2023-08-29 10:56:43,292 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 10:56:46,479 >> All model checkpoint weights were used when initializing Model.

[INFO|modeling_utils.py:1345] 2023-08-29 10:56:46,508 >> All the weights of Model were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Model for predictions without further training.
Dataset json downloaded and prepared to /home/xuting/.cache/huggingface/datasets/json/default-9e22479a8c51671d/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.
PreTrainedTokenizerFast(name_or_path='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'})
  0%|          | 0/3 [00:00<?, ?ba/s] 33%|███▎      | 1/3 [00:00<00:00,  2.32ba/s] 67%|██████▋   | 2/3 [00:00<00:00,  3.40ba/s]100%|██████████| 3/3 [00:00<00:00,  4.00ba/s]100%|██████████| 3/3 [00:00<00:00,  3.63ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:04,  3.14ba/s] 13%|█▎        | 2/15 [00:00<00:03,  3.96ba/s] 20%|██        | 3/15 [00:00<00:02,  4.30ba/s] 27%|██▋       | 4/15 [00:00<00:02,  4.47ba/s] 33%|███▎      | 5/15 [00:01<00:02,  3.66ba/s] 40%|████      | 6/15 [00:01<00:02,  3.98ba/s] 47%|████▋     | 7/15 [00:01<00:01,  4.21ba/s] 53%|█████▎    | 8/15 [00:01<00:01,  4.37ba/s] 60%|██████    | 9/15 [00:02<00:01,  4.51ba/s] 67%|██████▋   | 10/15 [00:02<00:01,  4.59ba/s] 73%|███████▎  | 11/15 [00:02<00:00,  4.43ba/s] 80%|████████  | 12/15 [00:02<00:00,  4.54ba/s] 87%|████████▋ | 13/15 [00:03<00:00,  4.60ba/s] 93%|█████████▎| 14/15 [00:03<00:00,  4.66ba/s]100%|██████████| 15/15 [00:03<00:00,  4.63ba/s]
  0%|          | 0/3 [00:00<?, ?ba/s] 33%|███▎      | 1/3 [00:00<00:00,  3.23ba/s]100%|██████████| 3/3 [00:00<00:00,  6.53ba/s]100%|██████████| 3/3 [00:00<00:00,  5.92ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:04,  2.84ba/s] 20%|██        | 3/15 [00:00<00:01,  6.15ba/s] 33%|███▎      | 5/15 [00:00<00:01,  7.66ba/s] 47%|████▋     | 7/15 [00:00<00:00,  8.57ba/s] 60%|██████    | 9/15 [00:01<00:00,  9.16ba/s] 73%|███████▎  | 11/15 [00:01<00:00,  9.44ba/s] 87%|████████▋ | 13/15 [00:01<00:00,  9.67ba/s]100%|██████████| 15/15 [00:01<00:00, 11.45ba/s]100%|██████████| 15/15 [00:01<00:00,  9.15ba/s]
[INFO|trainer.py:414] 2023-08-29 10:56:55,101 >> Using amp fp16 backend
[INFO|trainer.py:1147] 2023-08-29 10:56:55,378 >> ***** Running training *****
[INFO|trainer.py:1148] 2023-08-29 10:56:55,378 >>   Num examples = 3000
[INFO|trainer.py:1149] 2023-08-29 10:56:55,378 >>   Num Epochs = 5
[INFO|trainer.py:1150] 2023-08-29 10:56:55,378 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1151] 2023-08-29 10:56:55,378 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1152] 2023-08-29 10:56:55,378 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1153] 2023-08-29 10:56:55,378 >>   Total optimization steps = 235
  0%|          | 0/235 [00:00<?, ?it/s]  0%|          | 1/235 [00:02<09:40,  2.48s/it]  1%|          | 2/235 [00:02<04:57,  1.28s/it]  1%|▏         | 3/235 [00:03<03:24,  1.14it/s]  2%|▏         | 4/235 [00:03<02:29,  1.54it/s]  2%|▏         | 5/235 [00:03<01:59,  1.92it/s]  3%|▎         | 6/235 [00:04<01:41,  2.26it/s]  3%|▎         | 7/235 [00:04<01:36,  2.36it/s]  3%|▎         | 8/235 [00:04<01:32,  2.45it/s]  4%|▍         | 9/235 [00:05<01:24,  2.69it/s]  4%|▍         | 10/235 [00:05<01:18,  2.87it/s]  5%|▍         | 11/235 [00:05<01:14,  3.02it/s]  5%|▌         | 12/235 [00:06<01:11,  3.13it/s]  6%|▌         | 13/235 [00:06<01:09,  3.21it/s]  6%|▌         | 14/235 [00:06<01:07,  3.26it/s]  6%|▋         | 15/235 [00:07<01:14,  2.95it/s]  7%|▋         | 16/235 [00:07<01:11,  3.08it/s]  7%|▋         | 17/235 [00:07<01:08,  3.17it/s]  8%|▊         | 18/235 [00:08<01:07,  3.24it/s]  8%|▊         | 19/235 [00:08<01:05,  3.28it/s]  9%|▊         | 20/235 [00:08<01:04,  3.32it/s]  9%|▉         | 21/235 [00:08<01:04,  3.34it/s]  9%|▉         | 22/235 [00:09<01:03,  3.36it/s] 10%|▉         | 23/235 [00:09<01:02,  3.37it/s] 10%|█         | 24/235 [00:09<01:02,  3.38it/s] 11%|█         | 25/235 [00:10<01:03,  3.28it/s] 11%|█         | 26/235 [00:10<01:03,  3.32it/s] 11%|█▏        | 27/235 [00:10<01:02,  3.34it/s] 12%|█▏        | 28/235 [00:10<01:01,  3.36it/s] 12%|█▏        | 29/235 [00:11<01:01,  3.37it/s] 13%|█▎        | 30/235 [00:11<01:00,  3.38it/s] 13%|█▎        | 31/235 [00:11<01:00,  3.39it/s] 14%|█▎        | 32/235 [00:12<01:01,  3.32it/s] 14%|█▍        | 33/235 [00:12<01:00,  3.35it/s] 14%|█▍        | 34/235 [00:12<00:59,  3.37it/s] 15%|█▍        | 35/235 [00:13<00:59,  3.38it/s] 15%|█▌        | 36/235 [00:13<00:58,  3.38it/s] 16%|█▌        | 37/235 [00:13<00:58,  3.39it/s] 16%|█▌        | 38/235 [00:13<00:58,  3.39it/s] 17%|█▋        | 39/235 [00:14<00:57,  3.39it/s] 17%|█▋        | 40/235 [00:14<00:57,  3.40it/s] 17%|█▋        | 41/235 [00:14<00:57,  3.40it/s] 18%|█▊        | 42/235 [00:15<00:59,  3.26it/s] 18%|█▊        | 43/235 [00:15<00:58,  3.30it/s] 19%|█▊        | 44/235 [00:15<00:57,  3.33it/s] 19%|█▉        | 45/235 [00:16<00:56,  3.35it/s] 20%|█▉        | 46/235 [00:16<00:56,  3.36it/s] 20%|██        | 47/235 [00:16<00:53,  3.49it/s][INFO|trainer.py:2140] 2023-08-29 10:57:11,987 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 10:57:11,987 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 10:57:11,987 >>   Batch size = 8

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.24it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.15it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.56it/s][A
  1%|▏         | 22/1759 [00:00<00:38, 45.63it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 45.60it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 45.46it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 45.21it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 44.92it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 44.97it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.04it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.17it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.15it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.15it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.19it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 45.15it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 44.99it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.87it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.88it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 44.96it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.07it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.10it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.12it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.18it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 45.03it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 45.03it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 44.89it/s][A
  8%|▊         | 137/1759 [00:03<00:36, 44.93it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 44.93it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.07it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.17it/s][A
  9%|▉         | 157/1759 [00:03<00:39, 40.43it/s][A
  9%|▉         | 162/1759 [00:03<00:38, 41.78it/s][A
  9%|▉         | 167/1759 [00:03<00:37, 42.92it/s][A
 10%|▉         | 172/1759 [00:03<00:36, 43.73it/s][A
 10%|█         | 177/1759 [00:03<00:35, 44.21it/s][A
 10%|█         | 182/1759 [00:04<00:35, 44.45it/s][A
 11%|█         | 187/1759 [00:04<00:35, 44.65it/s][A
 11%|█         | 192/1759 [00:04<00:34, 44.84it/s][A
 11%|█         | 197/1759 [00:04<00:35, 44.46it/s][A
 11%|█▏        | 202/1759 [00:04<00:35, 44.42it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 44.51it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 44.82it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 45.00it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 45.18it/s][A
 13%|█▎        | 227/1759 [00:05<00:33, 45.27it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 45.15it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.13it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 44.85it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 44.64it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 44.63it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 44.76it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 45.01it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 45.15it/s][A
 15%|█▌        | 272/1759 [00:06<00:32, 45.34it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.32it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.11it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 44.88it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 44.65it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 44.64it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 44.70it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 44.96it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 45.19it/s][A
 18%|█▊        | 317/1759 [00:07<00:31, 45.32it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 45.24it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.12it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 44.77it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 44.65it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 44.68it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 44.74it/s][A
 20%|██        | 352/1759 [00:07<00:31, 44.89it/s][A
 20%|██        | 357/1759 [00:07<00:31, 45.07it/s][A
 21%|██        | 362/1759 [00:08<00:30, 45.25it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.28it/s][A
 21%|██        | 372/1759 [00:08<00:30, 45.07it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 44.87it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 44.74it/s][A
 22%|██▏       | 387/1759 [00:08<00:33, 40.97it/s][A
 22%|██▏       | 392/1759 [00:08<00:32, 42.20it/s][A
 23%|██▎       | 397/1759 [00:08<00:31, 43.07it/s][A
 23%|██▎       | 402/1759 [00:08<00:30, 43.78it/s][A
 23%|██▎       | 407/1759 [00:09<00:30, 44.22it/s][A
 23%|██▎       | 412/1759 [00:09<00:30, 44.51it/s][A
 24%|██▎       | 417/1759 [00:09<00:30, 44.73it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 44.92it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 44.56it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 44.56it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 44.78it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 44.89it/s][A
 25%|██▌       | 447/1759 [00:09<00:29, 45.07it/s][A
 26%|██▌       | 452/1759 [00:10<00:28, 45.15it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 45.25it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.24it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.18it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 44.83it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 44.87it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 45.07it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 45.21it/s][A
 28%|██▊       | 492/1759 [00:10<00:27, 45.29it/s][A
 28%|██▊       | 497/1759 [00:11<00:27, 45.27it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.35it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 45.29it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 45.17it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 44.91it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 44.88it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 44.96it/s][A
 30%|███       | 532/1759 [00:11<00:27, 45.13it/s][A
 31%|███       | 537/1759 [00:11<00:27, 45.18it/s][A
 31%|███       | 542/1759 [00:12<00:26, 45.25it/s][A
 31%|███       | 547/1759 [00:12<00:26, 45.26it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.11it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 45.13it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 44.91it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 44.98it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 45.07it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 45.08it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 45.26it/s][A
 33%|███▎      | 587/1759 [00:13<00:25, 45.31it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.30it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.26it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 45.05it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 44.89it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 45.00it/s][A
 35%|███▌      | 617/1759 [00:13<00:27, 41.93it/s][A
 35%|███▌      | 622/1759 [00:13<00:26, 42.97it/s][A
 36%|███▌      | 627/1759 [00:13<00:25, 43.66it/s][A
 36%|███▌      | 632/1759 [00:14<00:25, 44.30it/s][A
 36%|███▌      | 637/1759 [00:14<00:25, 44.63it/s][A
 36%|███▋      | 642/1759 [00:14<00:24, 44.84it/s][A
 37%|███▋      | 647/1759 [00:14<00:24, 44.87it/s][A
 37%|███▋      | 652/1759 [00:14<00:24, 44.69it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 44.59it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 44.55it/s][A
 38%|███▊      | 667/1759 [00:14<00:24, 44.79it/s][A
 38%|███▊      | 672/1759 [00:14<00:24, 45.00it/s][A
 38%|███▊      | 677/1759 [00:15<00:23, 45.15it/s][A
 39%|███▉      | 682/1759 [00:15<00:23, 45.25it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 45.39it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 45.33it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 45.05it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 44.83it/s][A
 40%|████      | 707/1759 [00:15<00:23, 44.76it/s][A
 40%|████      | 712/1759 [00:15<00:23, 44.92it/s][A
 41%|████      | 717/1759 [00:15<00:23, 45.08it/s][A
 41%|████      | 722/1759 [00:16<00:22, 45.24it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 45.38it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 45.38it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 45.28it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 44.96it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 44.87it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 44.81it/s][A
 43%|████▎     | 757/1759 [00:16<00:22, 44.85it/s][A
 43%|████▎     | 762/1759 [00:16<00:22, 45.05it/s][A
 44%|████▎     | 767/1759 [00:17<00:21, 45.29it/s][A
 44%|████▍     | 772/1759 [00:17<00:21, 45.41it/s][A
 44%|████▍     | 777/1759 [00:17<00:21, 45.40it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 45.22it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 44.94it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 44.87it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 44.80it/s][A
 46%|████▌     | 802/1759 [00:17<00:21, 44.84it/s][A
 46%|████▌     | 807/1759 [00:17<00:21, 45.08it/s][A
 46%|████▌     | 812/1759 [00:18<00:20, 45.18it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 45.39it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 45.30it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 45.30it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 44.90it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 45.04it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 44.87it/s][A
 48%|████▊     | 847/1759 [00:18<00:21, 42.66it/s][A
 48%|████▊     | 852/1759 [00:19<00:20, 43.59it/s][A
 49%|████▊     | 857/1759 [00:19<00:20, 44.22it/s][A
 49%|████▉     | 862/1759 [00:19<00:20, 44.58it/s][A
 49%|████▉     | 867/1759 [00:19<00:21, 42.41it/s][A
 50%|████▉     | 873/1759 [00:19<00:19, 44.63it/s][A
 50%|████▉     | 878/1759 [00:19<00:19, 44.67it/s][A
 50%|█████     | 883/1759 [00:19<00:19, 44.62it/s][A
 50%|█████     | 888/1759 [00:19<00:19, 44.54it/s][A
 51%|█████     | 893/1759 [00:19<00:19, 44.67it/s][A
 51%|█████     | 898/1759 [00:20<00:19, 44.83it/s][A
 51%|█████▏    | 903/1759 [00:20<00:19, 44.90it/s][A
 52%|█████▏    | 908/1759 [00:20<00:18, 45.20it/s][A
 52%|█████▏    | 913/1759 [00:20<00:18, 45.19it/s][A
 52%|█████▏    | 918/1759 [00:20<00:18, 45.39it/s][A
 52%|█████▏    | 923/1759 [00:20<00:18, 45.34it/s][A
 53%|█████▎    | 928/1759 [00:20<00:18, 45.06it/s][A
 53%|█████▎    | 933/1759 [00:20<00:18, 45.02it/s][A
 53%|█████▎    | 938/1759 [00:20<00:20, 40.57it/s][A
 54%|█████▎    | 943/1759 [00:21<00:19, 41.93it/s][A
 54%|█████▍    | 948/1759 [00:21<00:18, 43.03it/s][A
 54%|█████▍    | 953/1759 [00:21<00:18, 43.79it/s][A
 54%|█████▍    | 958/1759 [00:21<00:18, 44.27it/s][A
 55%|█████▍    | 963/1759 [00:21<00:17, 44.69it/s][A
 55%|█████▌    | 968/1759 [00:21<00:17, 44.97it/s][A
 55%|█████▌    | 973/1759 [00:21<00:17, 44.88it/s][A
 56%|█████▌    | 978/1759 [00:21<00:17, 44.62it/s][A
 56%|█████▌    | 983/1759 [00:21<00:17, 44.48it/s][A
 56%|█████▌    | 988/1759 [00:22<00:17, 44.54it/s][A
 56%|█████▋    | 993/1759 [00:22<00:17, 44.74it/s][A
 57%|█████▋    | 998/1759 [00:22<00:16, 44.99it/s][A
 57%|█████▋    | 1003/1759 [00:22<00:16, 45.11it/s][A
 57%|█████▋    | 1008/1759 [00:22<00:16, 45.24it/s][A
 58%|█████▊    | 1013/1759 [00:22<00:16, 45.31it/s][A
 58%|█████▊    | 1018/1759 [00:22<00:16, 45.25it/s][A
 58%|█████▊    | 1023/1759 [00:22<00:16, 45.14it/s][A
 58%|█████▊    | 1028/1759 [00:22<00:16, 44.91it/s][A
 59%|█████▊    | 1033/1759 [00:23<00:16, 44.81it/s][A
 59%|█████▉    | 1038/1759 [00:23<00:16, 44.83it/s][A
 59%|█████▉    | 1043/1759 [00:23<00:17, 41.06it/s][A
 60%|█████▉    | 1048/1759 [00:23<00:16, 42.56it/s][A
 60%|█████▉    | 1053/1759 [00:23<00:16, 43.37it/s][A
 60%|██████    | 1058/1759 [00:23<00:15, 44.11it/s][A
 60%|██████    | 1063/1759 [00:23<00:15, 44.54it/s][A
 61%|██████    | 1068/1759 [00:23<00:15, 44.70it/s][A
 61%|██████    | 1073/1759 [00:24<00:16, 41.45it/s][A
 61%|██████▏   | 1078/1759 [00:24<00:15, 42.68it/s][A
 62%|██████▏   | 1083/1759 [00:24<00:15, 43.08it/s][A
 62%|██████▏   | 1088/1759 [00:24<00:15, 43.61it/s][A
 62%|██████▏   | 1093/1759 [00:24<00:15, 44.08it/s][A
 62%|██████▏   | 1098/1759 [00:24<00:14, 44.34it/s][A
 63%|██████▎   | 1103/1759 [00:24<00:14, 44.73it/s][A
 63%|██████▎   | 1108/1759 [00:24<00:14, 44.98it/s][A
 63%|██████▎   | 1113/1759 [00:24<00:14, 44.76it/s][A
 64%|██████▎   | 1118/1759 [00:25<00:14, 44.76it/s][A
 64%|██████▍   | 1123/1759 [00:25<00:14, 44.89it/s][A
 64%|██████▍   | 1128/1759 [00:25<00:14, 44.93it/s][A
 64%|██████▍   | 1133/1759 [00:25<00:13, 44.90it/s][A
 65%|██████▍   | 1138/1759 [00:25<00:13, 44.97it/s][A
 65%|██████▍   | 1143/1759 [00:25<00:13, 45.02it/s][A
 65%|██████▌   | 1148/1759 [00:25<00:13, 45.21it/s][A
 66%|██████▌   | 1153/1759 [00:25<00:13, 45.03it/s][A
 66%|██████▌   | 1158/1759 [00:26<00:23, 25.06it/s][A
 66%|██████▌   | 1163/1759 [00:26<00:20, 29.03it/s][A
 66%|██████▋   | 1168/1759 [00:26<00:18, 32.55it/s][A
 67%|██████▋   | 1173/1759 [00:26<00:16, 35.61it/s][A
 67%|██████▋   | 1178/1759 [00:26<00:15, 38.13it/s][A
 67%|██████▋   | 1183/1759 [00:26<00:14, 40.11it/s][A
 68%|██████▊   | 1188/1759 [00:26<00:13, 41.65it/s][A
 68%|██████▊   | 1193/1759 [00:26<00:13, 42.80it/s][A
 68%|██████▊   | 1198/1759 [00:27<00:13, 43.10it/s][A
 68%|██████▊   | 1203/1759 [00:27<00:12, 43.25it/s][A
 69%|██████▊   | 1208/1759 [00:27<00:12, 43.45it/s][A
 69%|██████▉   | 1213/1759 [00:27<00:12, 44.10it/s][A
 69%|██████▉   | 1218/1759 [00:27<00:12, 44.27it/s][A
 70%|██████▉   | 1223/1759 [00:27<00:11, 44.78it/s][A
 70%|██████▉   | 1228/1759 [00:27<00:11, 44.98it/s][A
 70%|███████   | 1233/1759 [00:27<00:11, 45.24it/s][A
 70%|███████   | 1238/1759 [00:27<00:11, 45.34it/s][A
 71%|███████   | 1243/1759 [00:28<00:11, 45.20it/s][A
 71%|███████   | 1248/1759 [00:28<00:11, 44.85it/s][A
 71%|███████   | 1253/1759 [00:28<00:11, 44.66it/s][A
 72%|███████▏  | 1258/1759 [00:28<00:11, 44.63it/s][A
 72%|███████▏  | 1263/1759 [00:28<00:11, 44.75it/s][A
 72%|███████▏  | 1268/1759 [00:28<00:10, 45.00it/s][A
 72%|███████▏  | 1273/1759 [00:28<00:10, 45.18it/s][A
 73%|███████▎  | 1278/1759 [00:28<00:10, 45.37it/s][A
 73%|███████▎  | 1283/1759 [00:28<00:10, 45.39it/s][A
 73%|███████▎  | 1288/1759 [00:29<00:10, 43.63it/s][A
 74%|███████▎  | 1293/1759 [00:29<00:10, 43.97it/s][A
 74%|███████▍  | 1298/1759 [00:29<00:10, 44.16it/s][A
 74%|███████▍  | 1303/1759 [00:29<00:10, 44.31it/s][A
 74%|███████▍  | 1308/1759 [00:29<00:10, 44.44it/s][A
 75%|███████▍  | 1313/1759 [00:29<00:09, 44.71it/s][A
 75%|███████▍  | 1318/1759 [00:29<00:09, 44.77it/s][A
 75%|███████▌  | 1323/1759 [00:29<00:09, 45.04it/s][A
 75%|███████▌  | 1328/1759 [00:29<00:09, 45.10it/s][A
 76%|███████▌  | 1333/1759 [00:30<00:09, 45.12it/s][A
 76%|███████▌  | 1338/1759 [00:30<00:09, 45.03it/s][A
 76%|███████▋  | 1343/1759 [00:30<00:09, 44.91it/s][A
 77%|███████▋  | 1348/1759 [00:30<00:09, 44.74it/s][A
 77%|███████▋  | 1353/1759 [00:30<00:09, 44.80it/s][A
 77%|███████▋  | 1358/1759 [00:30<00:08, 45.00it/s][A
 77%|███████▋  | 1363/1759 [00:30<00:08, 45.14it/s][A
 78%|███████▊  | 1368/1759 [00:30<00:08, 45.15it/s][A
 78%|███████▊  | 1373/1759 [00:30<00:08, 45.18it/s][A
 78%|███████▊  | 1378/1759 [00:31<00:08, 45.10it/s][A
 79%|███████▊  | 1383/1759 [00:31<00:09, 41.50it/s][A
 79%|███████▉  | 1388/1759 [00:31<00:08, 42.66it/s][A
 79%|███████▉  | 1393/1759 [00:31<00:08, 43.29it/s][A
 79%|███████▉  | 1398/1759 [00:31<00:08, 43.84it/s][A
 80%|███████▉  | 1403/1759 [00:31<00:08, 44.25it/s][A
 80%|████████  | 1408/1759 [00:31<00:07, 44.57it/s][A
 80%|████████  | 1413/1759 [00:31<00:07, 44.78it/s][A
 81%|████████  | 1418/1759 [00:32<00:07, 44.88it/s][A
 81%|████████  | 1423/1759 [00:32<00:07, 44.71it/s][A
 81%|████████  | 1428/1759 [00:32<00:07, 44.75it/s][A
 81%|████████▏ | 1433/1759 [00:32<00:07, 44.71it/s][A
 82%|████████▏ | 1438/1759 [00:32<00:07, 44.84it/s][A
 82%|████████▏ | 1443/1759 [00:32<00:07, 44.96it/s][A
 82%|████████▏ | 1448/1759 [00:32<00:06, 45.19it/s][A
 83%|████████▎ | 1453/1759 [00:32<00:06, 45.24it/s][A
 83%|████████▎ | 1458/1759 [00:32<00:06, 45.31it/s][A
 83%|████████▎ | 1463/1759 [00:33<00:06, 45.15it/s][A
 83%|████████▎ | 1468/1759 [00:33<00:06, 45.05it/s][A
 84%|████████▎ | 1473/1759 [00:33<00:06, 44.89it/s][A
 84%|████████▍ | 1478/1759 [00:33<00:06, 44.94it/s][A
 84%|████████▍ | 1483/1759 [00:33<00:06, 45.03it/s][A
 85%|████████▍ | 1488/1759 [00:33<00:06, 44.98it/s][A
 85%|████████▍ | 1493/1759 [00:33<00:05, 45.14it/s][A
 85%|████████▌ | 1498/1759 [00:33<00:05, 45.21it/s][A
 85%|████████▌ | 1503/1759 [00:33<00:05, 45.29it/s][A
 86%|████████▌ | 1508/1759 [00:34<00:05, 45.11it/s][A
 86%|████████▌ | 1513/1759 [00:34<00:05, 44.91it/s][A
 86%|████████▋ | 1518/1759 [00:34<00:06, 40.05it/s][A
 87%|████████▋ | 1523/1759 [00:34<00:05, 41.56it/s][A
 87%|████████▋ | 1528/1759 [00:34<00:05, 42.67it/s][A
 87%|████████▋ | 1533/1759 [00:34<00:05, 43.47it/s][A
 87%|████████▋ | 1538/1759 [00:34<00:05, 44.05it/s][A
 88%|████████▊ | 1543/1759 [00:34<00:04, 44.45it/s][A
 88%|████████▊ | 1548/1759 [00:34<00:04, 44.70it/s][A
 88%|████████▊ | 1553/1759 [00:35<00:04, 44.81it/s][A
 89%|████████▊ | 1558/1759 [00:35<00:04, 44.59it/s][A
 89%|████████▉ | 1563/1759 [00:35<00:04, 44.58it/s][A
 89%|████████▉ | 1568/1759 [00:35<00:04, 44.78it/s][A
 89%|████████▉ | 1573/1759 [00:35<00:04, 44.96it/s][A
 90%|████████▉ | 1578/1759 [00:35<00:04, 44.95it/s][A
 90%|████████▉ | 1583/1759 [00:35<00:03, 45.18it/s][A
 90%|█████████ | 1588/1759 [00:35<00:03, 45.10it/s][A
 91%|█████████ | 1593/1759 [00:35<00:03, 45.23it/s][A
 91%|█████████ | 1598/1759 [00:36<00:03, 45.06it/s][A
 91%|█████████ | 1603/1759 [00:36<00:03, 44.87it/s][A
 91%|█████████▏| 1608/1759 [00:36<00:03, 44.75it/s][A
 92%|█████████▏| 1613/1759 [00:36<00:03, 44.77it/s][A
 92%|█████████▏| 1618/1759 [00:36<00:03, 45.02it/s][A
 92%|█████████▏| 1623/1759 [00:36<00:03, 45.16it/s][A
 93%|█████████▎| 1628/1759 [00:36<00:02, 45.24it/s][A
 93%|█████████▎| 1633/1759 [00:36<00:02, 45.19it/s][A
 93%|█████████▎| 1638/1759 [00:36<00:02, 45.20it/s][A
 93%|█████████▎| 1643/1759 [00:37<00:02, 44.97it/s][A
 94%|█████████▎| 1648/1759 [00:37<00:02, 44.84it/s][A
 94%|█████████▍| 1653/1759 [00:37<00:02, 44.73it/s][A
 94%|█████████▍| 1658/1759 [00:37<00:02, 44.74it/s][A
 95%|█████████▍| 1663/1759 [00:37<00:02, 45.04it/s][A
 95%|█████████▍| 1668/1759 [00:37<00:02, 45.17it/s][A
 95%|█████████▌| 1673/1759 [00:37<00:01, 45.28it/s][A
 95%|█████████▌| 1678/1759 [00:37<00:01, 45.22it/s][A
 96%|█████████▌| 1683/1759 [00:37<00:01, 45.10it/s][A
 96%|█████████▌| 1688/1759 [00:38<00:01, 45.02it/s][A
 96%|█████████▌| 1693/1759 [00:38<00:01, 44.80it/s][A
 97%|█████████▋| 1698/1759 [00:38<00:01, 44.73it/s][A
 97%|█████████▋| 1703/1759 [00:38<00:01, 44.70it/s][A
 97%|█████████▋| 1708/1759 [00:38<00:01, 44.89it/s][A
 97%|█████████▋| 1713/1759 [00:38<00:01, 45.11it/s][A
 98%|█████████▊| 1718/1759 [00:38<00:00, 45.19it/s][A
 98%|█████████▊| 1723/1759 [00:38<00:00, 45.22it/s][A
 98%|█████████▊| 1728/1759 [00:38<00:00, 45.13it/s][A
 99%|█████████▊| 1733/1759 [00:39<00:00, 45.01it/s][A
 99%|█████████▉| 1738/1759 [00:39<00:00, 44.87it/s][A
 99%|█████████▉| 1743/1759 [00:39<00:00, 44.80it/s][A
 99%|█████████▉| 1748/1759 [00:39<00:00, 43.45it/s][A
100%|█████████▉| 1753/1759 [00:39<00:00, 43.99it/s][A
100%|█████████▉| 1758/1759 [00:39<00:00, 44.38it/s][A
                                                   [A                                                
100%|██████████| 1759/1759 [00:39<00:00, 44.38it/s][A 20%|██        | 47/235 [00:56<00:53,  3.49it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 10:57:52,110 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-47
[INFO|configuration_utils.py:351] 2023-08-29 10:57:52,339 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-47/config.json
[INFO|modeling_utils.py:886] 2023-08-29 10:57:57,800 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-47/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 10:57:58,184 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-47/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 10:57:58,373 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-47/special_tokens_map.json
 20%|██        | 48/235 [01:16<56:50, 18.24s/it] 21%|██        | 49/235 [01:17<39:55, 12.88s/it] 21%|██▏       | 50/235 [01:17<28:04,  9.10s/it] 22%|██▏       | 51/235 [01:17<19:48,  6.46s/it] 22%|██▏       | 52/235 [01:17<14:03,  4.61s/it] 23%|██▎       | 53/235 [01:18<10:03,  3.32s/it] 23%|██▎       | 54/235 [01:18<07:15,  2.41s/it] 23%|██▎       | 55/235 [01:18<05:19,  1.77s/it] 24%|██▍       | 56/235 [01:19<03:58,  1.33s/it] 24%|██▍       | 57/235 [01:19<03:01,  1.02s/it] 25%|██▍       | 58/235 [01:19<02:21,  1.25it/s] 25%|██▌       | 59/235 [01:20<01:56,  1.51it/s] 26%|██▌       | 60/235 [01:20<01:36,  1.82it/s] 26%|██▌       | 61/235 [01:20<01:22,  2.11it/s] 26%|██▋       | 62/235 [01:20<01:12,  2.38it/s] 27%|██▋       | 63/235 [01:21<01:05,  2.62it/s] 27%|██▋       | 64/235 [01:21<01:00,  2.82it/s] 28%|██▊       | 65/235 [01:21<00:57,  2.97it/s] 28%|██▊       | 66/235 [01:22<00:54,  3.09it/s] 29%|██▊       | 67/235 [01:22<00:52,  3.18it/s] 29%|██▉       | 68/235 [01:22<00:51,  3.24it/s] 29%|██▉       | 69/235 [01:23<00:50,  3.29it/s] 30%|██▉       | 70/235 [01:23<00:51,  3.22it/s] 30%|███       | 71/235 [01:23<00:50,  3.28it/s] 31%|███       | 72/235 [01:23<00:49,  3.31it/s] 31%|███       | 73/235 [01:24<00:48,  3.34it/s] 31%|███▏      | 74/235 [01:24<00:47,  3.36it/s] 32%|███▏      | 75/235 [01:24<00:47,  3.38it/s] 32%|███▏      | 76/235 [01:25<00:47,  3.38it/s] 33%|███▎      | 77/235 [01:25<00:46,  3.39it/s] 33%|███▎      | 78/235 [01:25<00:46,  3.39it/s] 34%|███▎      | 79/235 [01:25<00:45,  3.40it/s] 34%|███▍      | 80/235 [01:26<00:45,  3.40it/s] 34%|███▍      | 81/235 [01:26<00:45,  3.40it/s] 35%|███▍      | 82/235 [01:26<00:46,  3.27it/s] 35%|███▌      | 83/235 [01:27<00:45,  3.32it/s] 36%|███▌      | 84/235 [01:27<00:44,  3.36it/s] 36%|███▌      | 85/235 [01:27<00:44,  3.39it/s] 37%|███▋      | 86/235 [01:28<00:43,  3.41it/s] 37%|███▋      | 87/235 [01:28<00:43,  3.42it/s] 37%|███▋      | 88/235 [01:28<00:42,  3.43it/s] 38%|███▊      | 89/235 [01:28<00:42,  3.44it/s] 38%|███▊      | 90/235 [01:29<00:42,  3.45it/s] 39%|███▊      | 91/235 [01:29<00:41,  3.45it/s] 39%|███▉      | 92/235 [01:29<00:41,  3.45it/s] 40%|███▉      | 93/235 [01:30<00:42,  3.32it/s] 40%|████      | 94/235 [01:30<00:40,  3.48it/s][INFO|trainer.py:2140] 2023-08-29 10:58:25,766 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 10:58:25,766 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 10:58:25,766 >>   Batch size = 8
{'eval_loss': 0.9230651259422302, 'eval_runtime': 39.647, 'eval_samples_per_second': 354.806, 'eval_steps_per_second': 44.366, 'epoch': 1.0}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:30, 56.63it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.35it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.47it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.44it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 45.89it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 45.53it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 45.19it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 44.97it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 44.99it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.02it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.22it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.25it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.25it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 44.96it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 44.93it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 44.81it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.79it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.95it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 44.97it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.05it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.12it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.23it/s][A
  7%|▋         | 117/1759 [00:02<00:39, 41.16it/s][A
  7%|▋         | 122/1759 [00:02<00:38, 42.38it/s][A
  7%|▋         | 127/1759 [00:02<00:37, 43.28it/s][A
  8%|▊         | 132/1759 [00:02<00:37, 43.82it/s][A
  8%|▊         | 137/1759 [00:03<00:36, 44.29it/s][A
  8%|▊         | 142/1759 [00:03<00:36, 44.63it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 44.87it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.04it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 44.77it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 44.73it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 44.80it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 44.99it/s][A
 10%|█         | 177/1759 [00:03<00:35, 45.13it/s][A
 10%|█         | 182/1759 [00:04<00:34, 45.26it/s][A
 11%|█         | 187/1759 [00:04<00:34, 45.29it/s][A
 11%|█         | 192/1759 [00:04<00:34, 45.34it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.18it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 45.05it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 44.92it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 44.86it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 45.00it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 45.10it/s][A
 13%|█▎        | 227/1759 [00:05<00:33, 45.29it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 45.33it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.34it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.26it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.04it/s][A
 14%|█▍        | 252/1759 [00:05<00:40, 37.06it/s][A
 15%|█▍        | 257/1759 [00:05<00:38, 39.28it/s][A
 15%|█▍        | 262/1759 [00:05<00:36, 40.99it/s][A
 15%|█▌        | 267/1759 [00:06<00:35, 42.22it/s][A
 15%|█▌        | 272/1759 [00:06<00:34, 43.13it/s][A
 16%|█▌        | 277/1759 [00:06<00:33, 43.86it/s][A
 16%|█▌        | 282/1759 [00:06<00:33, 44.29it/s][A
 16%|█▋        | 287/1759 [00:06<00:33, 44.53it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 44.47it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 44.51it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 44.86it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 45.03it/s][A
 18%|█▊        | 312/1759 [00:07<00:32, 45.20it/s][A
 18%|█▊        | 317/1759 [00:07<00:31, 45.13it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 45.20it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.24it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 45.15it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 44.94it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 44.81it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 44.91it/s][A
 20%|██        | 352/1759 [00:07<00:31, 45.06it/s][A
 20%|██        | 357/1759 [00:07<00:30, 45.28it/s][A
 21%|██        | 362/1759 [00:08<00:30, 45.25it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.36it/s][A
 21%|██        | 372/1759 [00:08<00:30, 45.31it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.24it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 45.11it/s][A
 22%|██▏       | 387/1759 [00:08<00:31, 43.07it/s][A
 22%|██▏       | 392/1759 [00:08<00:31, 43.80it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 44.29it/s][A
 23%|██▎       | 402/1759 [00:09<00:30, 44.67it/s][A
 23%|██▎       | 407/1759 [00:09<00:30, 44.81it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 44.93it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.04it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.00it/s][A
 24%|██▍       | 427/1759 [00:09<00:31, 42.85it/s][A
 25%|██▍       | 432/1759 [00:09<00:30, 43.64it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 44.15it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 44.53it/s][A
 25%|██▌       | 447/1759 [00:10<00:29, 44.81it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 44.93it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 45.14it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.05it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 44.74it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 44.76it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 44.82it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 45.07it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 45.17it/s][A
 28%|██▊       | 492/1759 [00:11<00:28, 45.25it/s][A
 28%|██▊       | 497/1759 [00:11<00:27, 45.21it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.31it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 45.13it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 44.96it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 44.85it/s][A
 30%|██▉       | 522/1759 [00:11<00:29, 42.03it/s][A
 30%|██▉       | 527/1759 [00:11<00:28, 43.01it/s][A
 30%|███       | 532/1759 [00:11<00:28, 43.71it/s][A
 31%|███       | 537/1759 [00:12<00:27, 44.31it/s][A
 31%|███       | 542/1759 [00:12<00:53, 22.93it/s][A
 31%|███       | 547/1759 [00:12<00:44, 26.97it/s][A
 31%|███▏      | 552/1759 [00:12<00:39, 30.78it/s][A
 32%|███▏      | 557/1759 [00:12<00:35, 34.10it/s][A
 32%|███▏      | 562/1759 [00:12<00:32, 36.92it/s][A
 32%|███▏      | 567/1759 [00:13<00:30, 39.13it/s][A
 33%|███▎      | 572/1759 [00:13<00:29, 40.90it/s][A
 33%|███▎      | 577/1759 [00:13<00:28, 42.19it/s][A
 33%|███▎      | 582/1759 [00:13<00:27, 42.70it/s][A
 33%|███▎      | 587/1759 [00:13<00:27, 43.11it/s][A
 34%|███▎      | 592/1759 [00:13<00:26, 43.44it/s][A
 34%|███▍      | 597/1759 [00:13<00:26, 43.75it/s][A
 34%|███▍      | 602/1759 [00:13<00:26, 44.34it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 44.85it/s][A
 35%|███▍      | 612/1759 [00:14<00:25, 45.06it/s][A
 35%|███▌      | 617/1759 [00:14<00:25, 45.32it/s][A
 35%|███▌      | 622/1759 [00:14<00:25, 45.20it/s][A
 36%|███▌      | 627/1759 [00:14<00:25, 45.10it/s][A
 36%|███▌      | 632/1759 [00:14<00:25, 44.75it/s][A
 36%|███▌      | 637/1759 [00:14<00:25, 44.70it/s][A
 36%|███▋      | 642/1759 [00:14<00:27, 41.28it/s][A
 37%|███▋      | 647/1759 [00:14<00:26, 42.50it/s][A
 37%|███▋      | 652/1759 [00:14<00:25, 43.36it/s][A
 37%|███▋      | 657/1759 [00:15<00:25, 43.91it/s][A
 38%|███▊      | 662/1759 [00:15<00:24, 44.32it/s][A
 38%|███▊      | 667/1759 [00:15<00:24, 44.65it/s][A
 38%|███▊      | 672/1759 [00:15<00:24, 44.93it/s][A
 38%|███▊      | 677/1759 [00:15<00:24, 45.01it/s][A
 39%|███▉      | 682/1759 [00:15<00:24, 44.80it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 44.72it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 44.88it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 45.03it/s][A
 40%|███▉      | 702/1759 [00:16<00:23, 45.10it/s][A
 40%|████      | 707/1759 [00:16<00:23, 45.15it/s][A
 40%|████      | 712/1759 [00:16<00:23, 45.20it/s][A
 41%|████      | 717/1759 [00:16<00:23, 45.20it/s][A
 41%|████      | 722/1759 [00:16<00:22, 45.09it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 45.01it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 44.83it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 45.05it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 45.07it/s][A
 42%|████▏     | 747/1759 [00:17<00:22, 45.14it/s][A
 43%|████▎     | 752/1759 [00:17<00:22, 45.12it/s][A
 43%|████▎     | 757/1759 [00:17<00:22, 45.18it/s][A
 43%|████▎     | 762/1759 [00:17<00:22, 45.20it/s][A
 44%|████▎     | 767/1759 [00:17<00:22, 45.07it/s][A
 44%|████▍     | 772/1759 [00:17<00:22, 44.81it/s][A
 44%|████▍     | 777/1759 [00:17<00:23, 41.07it/s][A
 44%|████▍     | 782/1759 [00:17<00:23, 42.36it/s][A
 45%|████▍     | 787/1759 [00:17<00:22, 43.32it/s][A
 45%|████▌     | 792/1759 [00:18<00:21, 43.97it/s][A
 45%|████▌     | 797/1759 [00:18<00:21, 44.53it/s][A
 46%|████▌     | 802/1759 [00:18<00:21, 44.73it/s][A
 46%|████▌     | 807/1759 [00:18<00:21, 44.93it/s][A
 46%|████▌     | 812/1759 [00:18<00:21, 44.77it/s][A
 46%|████▋     | 817/1759 [00:18<00:21, 44.49it/s][A
 47%|████▋     | 822/1759 [00:18<00:21, 44.50it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 44.63it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 44.83it/s][A
 48%|████▊     | 837/1759 [00:19<00:20, 45.03it/s][A
 48%|████▊     | 842/1759 [00:19<00:20, 45.17it/s][A
 48%|████▊     | 847/1759 [00:19<00:20, 45.16it/s][A
 48%|████▊     | 852/1759 [00:19<00:19, 45.35it/s][A
 49%|████▊     | 857/1759 [00:19<00:19, 45.23it/s][A
 49%|████▉     | 862/1759 [00:19<00:19, 45.00it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 44.95it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 44.92it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 45.07it/s][A
 50%|█████     | 882/1759 [00:20<00:19, 45.19it/s][A
 50%|█████     | 887/1759 [00:20<00:19, 45.22it/s][A
 51%|█████     | 892/1759 [00:20<00:19, 45.17it/s][A
 51%|█████     | 897/1759 [00:20<00:19, 45.20it/s][A
 51%|█████▏    | 902/1759 [00:20<00:18, 45.17it/s][A
 52%|█████▏    | 907/1759 [00:20<00:18, 44.95it/s][A
 52%|█████▏    | 912/1759 [00:20<00:19, 42.38it/s][A
 52%|█████▏    | 917/1759 [00:20<00:19, 43.29it/s][A
 52%|█████▏    | 922/1759 [00:21<00:19, 43.88it/s][A
 53%|█████▎    | 927/1759 [00:21<00:18, 44.41it/s][A
 53%|█████▎    | 932/1759 [00:21<00:18, 44.59it/s][A
 53%|█████▎    | 937/1759 [00:21<00:18, 44.81it/s][A
 54%|█████▎    | 942/1759 [00:21<00:18, 44.94it/s][A
 54%|█████▍    | 947/1759 [00:21<00:18, 44.89it/s][A
 54%|█████▍    | 952/1759 [00:21<00:18, 44.58it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 44.62it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 44.80it/s][A
 55%|█████▍    | 967/1759 [00:22<00:17, 45.02it/s][A
 55%|█████▌    | 972/1759 [00:22<00:17, 45.05it/s][A
 56%|█████▌    | 977/1759 [00:22<00:17, 45.22it/s][A
 56%|█████▌    | 982/1759 [00:22<00:17, 45.24it/s][A
 56%|█████▌    | 987/1759 [00:22<00:17, 45.22it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 45.03it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 44.84it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 44.83it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 44.91it/s][A
 58%|█████▊    | 1012/1759 [00:23<00:16, 44.89it/s][A
 58%|█████▊    | 1017/1759 [00:23<00:16, 45.03it/s][A
 58%|█████▊    | 1022/1759 [00:23<00:16, 45.23it/s][A
 58%|█████▊    | 1027/1759 [00:23<00:16, 45.27it/s][A
 59%|█████▊    | 1032/1759 [00:23<00:16, 45.28it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:15, 45.14it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:15, 45.01it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:16, 42.32it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:16, 43.15it/s][A
 60%|██████    | 1057/1759 [00:24<00:16, 43.82it/s][A
 60%|██████    | 1062/1759 [00:24<00:15, 44.32it/s][A
 61%|██████    | 1067/1759 [00:24<00:15, 44.66it/s][A
 61%|██████    | 1072/1759 [00:24<00:15, 44.85it/s][A
 61%|██████    | 1077/1759 [00:24<00:15, 44.95it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:15, 45.04it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:14, 44.83it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 44.72it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 44.93it/s][A
 63%|██████▎   | 1102/1759 [00:25<00:14, 44.97it/s][A
 63%|██████▎   | 1107/1759 [00:25<00:14, 45.12it/s][A
 63%|██████▎   | 1112/1759 [00:25<00:14, 45.19it/s][A
 64%|██████▎   | 1117/1759 [00:25<00:14, 45.24it/s][A
 64%|██████▍   | 1122/1759 [00:25<00:14, 45.24it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 45.05it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:13, 44.84it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 44.69it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 44.83it/s][A
 65%|██████▌   | 1147/1759 [00:26<00:13, 44.96it/s][A
 65%|██████▌   | 1152/1759 [00:26<00:13, 45.14it/s][A
 66%|██████▌   | 1157/1759 [00:26<00:13, 45.26it/s][A
 66%|██████▌   | 1162/1759 [00:26<00:13, 45.28it/s][A
 66%|██████▋   | 1167/1759 [00:26<00:13, 45.16it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 44.95it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:12, 44.86it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:12, 44.85it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 44.93it/s][A
 68%|██████▊   | 1192/1759 [00:27<00:13, 43.14it/s][A
 68%|██████▊   | 1197/1759 [00:27<00:12, 43.81it/s][A
 68%|██████▊   | 1202/1759 [00:27<00:12, 44.39it/s][A
 69%|██████▊   | 1207/1759 [00:27<00:12, 44.76it/s][A
 69%|██████▉   | 1212/1759 [00:27<00:12, 44.93it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 44.79it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:11, 44.75it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 44.69it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 44.51it/s][A
 70%|███████   | 1237/1759 [00:28<00:11, 44.62it/s][A
 71%|███████   | 1242/1759 [00:28<00:11, 44.81it/s][A
 71%|███████   | 1247/1759 [00:28<00:11, 45.03it/s][A
 71%|███████   | 1252/1759 [00:28<00:11, 45.15it/s][A
 71%|███████▏  | 1257/1759 [00:28<00:11, 45.03it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:10, 45.26it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:10, 45.16it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 44.98it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 44.88it/s][A
 73%|███████▎  | 1282/1759 [00:29<00:10, 44.89it/s][A
 73%|███████▎  | 1287/1759 [00:29<00:10, 44.97it/s][A
 73%|███████▎  | 1292/1759 [00:29<00:10, 44.92it/s][A
 74%|███████▎  | 1297/1759 [00:29<00:10, 45.16it/s][A
 74%|███████▍  | 1302/1759 [00:29<00:10, 45.17it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:09, 45.25it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:09, 45.10it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:09, 44.84it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 44.89it/s][A
 75%|███████▌  | 1327/1759 [00:30<00:10, 40.07it/s][A
 76%|███████▌  | 1332/1759 [00:30<00:10, 41.60it/s][A
 76%|███████▌  | 1337/1759 [00:30<00:09, 42.67it/s][A
 76%|███████▋  | 1342/1759 [00:30<00:09, 43.45it/s][A
 77%|███████▋  | 1347/1759 [00:30<00:09, 44.08it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 44.52it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:08, 44.83it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 44.84it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 44.59it/s][A
 78%|███████▊  | 1372/1759 [00:31<00:08, 44.46it/s][A
 78%|███████▊  | 1377/1759 [00:31<00:08, 44.47it/s][A
 79%|███████▊  | 1382/1759 [00:31<00:08, 44.70it/s][A
 79%|███████▉  | 1387/1759 [00:31<00:08, 44.99it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 45.12it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:07, 45.33it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:07, 45.31it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 45.21it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 44.85it/s][A
 81%|████████  | 1417/1759 [00:32<00:07, 44.59it/s][A
 81%|████████  | 1422/1759 [00:32<00:07, 44.74it/s][A
 81%|████████  | 1427/1759 [00:32<00:07, 44.84it/s][A
 81%|████████▏ | 1432/1759 [00:32<00:07, 44.96it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 45.15it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 45.23it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 45.34it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 45.28it/s][A
 83%|████████▎ | 1457/1759 [00:33<00:06, 44.98it/s][A
 83%|████████▎ | 1462/1759 [00:33<00:07, 39.20it/s][A
 83%|████████▎ | 1467/1759 [00:33<00:07, 40.93it/s][A
 84%|████████▎ | 1472/1759 [00:33<00:06, 42.19it/s][A
 84%|████████▍ | 1477/1759 [00:33<00:06, 43.05it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 43.75it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 44.18it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 44.57it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 44.78it/s][A
 85%|████████▌ | 1502/1759 [00:34<00:05, 44.42it/s][A
 86%|████████▌ | 1507/1759 [00:34<00:05, 44.52it/s][A
 86%|████████▌ | 1512/1759 [00:34<00:05, 44.66it/s][A
 86%|████████▌ | 1517/1759 [00:34<00:05, 44.91it/s][A
 87%|████████▋ | 1522/1759 [00:34<00:05, 44.93it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 45.16it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 45.22it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 45.31it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 45.19it/s][A
 88%|████████▊ | 1547/1759 [00:35<00:04, 44.96it/s][A
 88%|████████▊ | 1552/1759 [00:35<00:04, 44.87it/s][A
 89%|████████▊ | 1557/1759 [00:35<00:04, 44.82it/s][A
 89%|████████▉ | 1562/1759 [00:35<00:04, 44.94it/s][A
 89%|████████▉ | 1567/1759 [00:35<00:04, 45.00it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 45.08it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 45.20it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 45.22it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 45.13it/s][A
 91%|█████████ | 1592/1759 [00:36<00:03, 44.97it/s][A
 91%|█████████ | 1597/1759 [00:36<00:04, 39.50it/s][A
 91%|█████████ | 1602/1759 [00:36<00:03, 41.20it/s][A
 91%|█████████▏| 1607/1759 [00:36<00:03, 42.46it/s][A
 92%|█████████▏| 1612/1759 [00:36<00:03, 43.30it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 44.06it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 44.46it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 44.78it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 44.76it/s][A
 93%|█████████▎| 1637/1759 [00:37<00:02, 44.57it/s][A
 93%|█████████▎| 1642/1759 [00:37<00:02, 44.43it/s][A
 94%|█████████▎| 1647/1759 [00:37<00:02, 44.46it/s][A
 94%|█████████▍| 1652/1759 [00:37<00:02, 44.63it/s][A
 94%|█████████▍| 1657/1759 [00:37<00:02, 44.74it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 44.99it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 45.15it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 45.15it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 45.22it/s][A
 96%|█████████▌| 1682/1759 [00:38<00:01, 44.96it/s][A
 96%|█████████▌| 1687/1759 [00:38<00:01, 44.77it/s][A
 96%|█████████▌| 1692/1759 [00:38<00:01, 44.75it/s][A
 96%|█████████▋| 1697/1759 [00:38<00:01, 44.77it/s][A
 97%|█████████▋| 1702/1759 [00:38<00:01, 44.92it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 44.90it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 45.08it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 45.12it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 45.23it/s][A
 98%|█████████▊| 1727/1759 [00:39<00:00, 45.22it/s][A
 98%|█████████▊| 1732/1759 [00:39<00:00, 39.47it/s][A
 99%|█████████▊| 1737/1759 [00:39<00:00, 41.12it/s][A
 99%|█████████▉| 1742/1759 [00:39<00:00, 42.34it/s][A
 99%|█████████▉| 1747/1759 [00:39<00:00, 43.28it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 43.96it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 44.38it/s][A
                                                   [A                                                
100%|██████████| 1759/1759 [00:39<00:00, 44.38it/s][A 40%|████      | 94/235 [02:10<00:40,  3.48it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 10:59:06,106 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-94
[INFO|configuration_utils.py:351] 2023-08-29 10:59:06,359 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-94/config.json
[INFO|modeling_utils.py:886] 2023-08-29 10:59:09,814 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-94/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 10:59:09,973 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-94/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 10:59:10,081 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-94/special_tokens_map.json
 40%|████      | 95/235 [02:24<38:21, 16.44s/it] 41%|████      | 96/235 [02:24<26:52, 11.60s/it] 41%|████▏     | 97/235 [02:25<18:53,  8.21s/it] 42%|████▏     | 98/235 [02:25<13:19,  5.84s/it] 42%|████▏     | 99/235 [02:25<09:27,  4.17s/it] 43%|████▎     | 100/235 [02:26<06:46,  3.01s/it] 43%|████▎     | 101/235 [02:26<04:54,  2.19s/it] 43%|████▎     | 102/235 [02:26<03:36,  1.62s/it] 44%|████▍     | 103/235 [02:26<02:41,  1.23s/it] 44%|████▍     | 104/235 [02:27<02:03,  1.06it/s] 45%|████▍     | 105/235 [02:27<01:37,  1.33it/s] 45%|████▌     | 106/235 [02:27<01:19,  1.63it/s] 46%|████▌     | 107/235 [02:28<01:06,  1.93it/s] 46%|████▌     | 108/235 [02:28<00:59,  2.15it/s] 46%|████▋     | 109/235 [02:28<00:52,  2.42it/s] 47%|████▋     | 110/235 [02:28<00:47,  2.65it/s] 47%|████▋     | 111/235 [02:29<00:43,  2.84it/s] 48%|████▊     | 112/235 [02:29<00:41,  2.98it/s] 48%|████▊     | 113/235 [02:29<00:39,  3.10it/s] 49%|████▊     | 114/235 [02:30<00:37,  3.18it/s] 49%|████▉     | 115/235 [02:30<00:36,  3.25it/s] 49%|████▉     | 116/235 [02:30<00:36,  3.29it/s] 50%|████▉     | 117/235 [02:31<00:35,  3.33it/s] 50%|█████     | 118/235 [02:31<00:34,  3.35it/s] 51%|█████     | 119/235 [02:31<00:36,  3.21it/s] 51%|█████     | 120/235 [02:31<00:35,  3.27it/s] 51%|█████▏    | 121/235 [02:32<00:34,  3.31it/s] 52%|█████▏    | 122/235 [02:32<00:33,  3.33it/s] 52%|█████▏    | 123/235 [02:32<00:33,  3.35it/s] 53%|█████▎    | 124/235 [02:33<00:32,  3.37it/s] 53%|█████▎    | 125/235 [02:33<00:32,  3.38it/s] 54%|█████▎    | 126/235 [02:33<00:32,  3.39it/s] 54%|█████▍    | 127/235 [02:34<00:31,  3.39it/s] 54%|█████▍    | 128/235 [02:34<00:31,  3.39it/s] 55%|█████▍    | 129/235 [02:34<00:31,  3.40it/s] 55%|█████▌    | 130/235 [02:34<00:32,  3.23it/s] 56%|█████▌    | 131/235 [02:35<00:31,  3.28it/s] 56%|█████▌    | 132/235 [02:35<00:31,  3.31it/s] 57%|█████▋    | 133/235 [02:35<00:30,  3.34it/s] 57%|█████▋    | 134/235 [02:36<00:30,  3.36it/s] 57%|█████▋    | 135/235 [02:36<00:29,  3.37it/s] 58%|█████▊    | 136/235 [02:36<00:29,  3.37it/s] 58%|█████▊    | 137/235 [02:37<00:29,  3.38it/s] 59%|█████▊    | 138/235 [02:37<00:28,  3.38it/s] 59%|█████▉    | 139/235 [02:37<00:28,  3.38it/s] 60%|█████▉    | 140/235 [02:37<00:28,  3.39it/s] 60%|██████    | 141/235 [02:38<00:27,  3.40it/s][INFO|trainer.py:2140] 2023-08-29 10:59:33,592 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 10:59:33,592 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 10:59:33,592 >>   Batch size = 8
{'eval_loss': 0.9334884285926819, 'eval_runtime': 39.8333, 'eval_samples_per_second': 353.147, 'eval_steps_per_second': 44.159, 'epoch': 2.0}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 55.77it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.06it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.75it/s][A
  1%|▏         | 22/1759 [00:00<00:36, 46.98it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 46.53it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 45.73it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 45.26it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 45.06it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 45.02it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.21it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.37it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.48it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.40it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.41it/s][A
  4%|▍         | 77/1759 [00:01<00:40, 41.91it/s][A
  5%|▍         | 82/1759 [00:01<00:38, 43.53it/s][A
  5%|▍         | 87/1759 [00:01<00:38, 43.98it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.33it/s][A
  6%|▌         | 97/1759 [00:02<00:37, 44.55it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 44.82it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.07it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.24it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.31it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 44.88it/s][A
  7%|▋         | 127/1759 [00:02<00:39, 41.80it/s][A
  8%|▊         | 132/1759 [00:02<00:37, 42.88it/s][A
  8%|▊         | 137/1759 [00:03<00:37, 43.65it/s][A
  8%|▊         | 142/1759 [00:03<00:36, 44.15it/s][A
  8%|▊         | 147/1759 [00:03<00:36, 44.54it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 44.77it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.06it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 45.10it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 44.69it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 44.74it/s][A
 10%|█         | 177/1759 [00:03<00:35, 44.72it/s][A
 10%|█         | 182/1759 [00:04<00:34, 45.07it/s][A
 11%|█         | 187/1759 [00:04<00:34, 45.14it/s][A
 11%|█         | 192/1759 [00:04<00:58, 26.71it/s][A
 11%|█         | 196/1759 [00:04<00:58, 26.88it/s][A
 11%|█▏        | 201/1759 [00:04<00:50, 30.85it/s][A
 12%|█▏        | 206/1759 [00:04<00:45, 34.32it/s][A
 12%|█▏        | 211/1759 [00:05<00:41, 37.16it/s][A
 12%|█▏        | 216/1759 [00:05<00:39, 39.43it/s][A
 13%|█▎        | 221/1759 [00:05<00:37, 41.06it/s][A
 13%|█▎        | 226/1759 [00:05<00:36, 42.36it/s][A
 13%|█▎        | 231/1759 [00:05<00:35, 43.31it/s][A
 13%|█▎        | 236/1759 [00:05<00:34, 43.62it/s][A
 14%|█▎        | 241/1759 [00:05<00:34, 43.60it/s][A
 14%|█▍        | 246/1759 [00:05<00:34, 43.80it/s][A
 14%|█▍        | 251/1759 [00:05<00:36, 41.40it/s][A
 15%|█▍        | 256/1759 [00:06<00:35, 42.63it/s][A
 15%|█▍        | 261/1759 [00:06<00:34, 43.52it/s][A
 15%|█▌        | 266/1759 [00:06<00:33, 44.19it/s][A
 15%|█▌        | 271/1759 [00:06<00:33, 44.65it/s][A
 16%|█▌        | 276/1759 [00:06<00:33, 44.88it/s][A
 16%|█▌        | 281/1759 [00:06<00:32, 44.95it/s][A
 16%|█▋        | 286/1759 [00:06<00:32, 44.79it/s][A
 17%|█▋        | 291/1759 [00:06<00:32, 44.54it/s][A
 17%|█▋        | 296/1759 [00:06<00:32, 44.48it/s][A
 17%|█▋        | 301/1759 [00:07<00:32, 44.65it/s][A
 17%|█▋        | 306/1759 [00:07<00:32, 44.87it/s][A
 18%|█▊        | 311/1759 [00:07<00:32, 45.09it/s][A
 18%|█▊        | 316/1759 [00:07<00:31, 45.19it/s][A
 18%|█▊        | 321/1759 [00:07<00:31, 45.27it/s][A
 19%|█▊        | 326/1759 [00:07<00:31, 45.24it/s][A
 19%|█▉        | 331/1759 [00:07<00:31, 45.18it/s][A
 19%|█▉        | 336/1759 [00:07<00:31, 45.09it/s][A
 19%|█▉        | 341/1759 [00:07<00:31, 44.95it/s][A
 20%|█▉        | 346/1759 [00:08<00:31, 44.96it/s][A
 20%|█▉        | 351/1759 [00:08<00:31, 45.00it/s][A
 20%|██        | 356/1759 [00:08<00:31, 45.00it/s][A
 21%|██        | 361/1759 [00:08<00:30, 45.18it/s][A
 21%|██        | 366/1759 [00:08<00:30, 45.19it/s][A
 21%|██        | 371/1759 [00:08<00:30, 45.15it/s][A
 21%|██▏       | 376/1759 [00:08<00:30, 45.22it/s][A
 22%|██▏       | 381/1759 [00:08<00:30, 45.08it/s][A
 22%|██▏       | 386/1759 [00:08<00:31, 42.93it/s][A
 22%|██▏       | 391/1759 [00:09<00:31, 43.69it/s][A
 23%|██▎       | 396/1759 [00:09<00:30, 44.18it/s][A
 23%|██▎       | 401/1759 [00:09<00:30, 44.60it/s][A
 23%|██▎       | 406/1759 [00:09<00:30, 44.81it/s][A
 23%|██▎       | 411/1759 [00:09<00:29, 45.02it/s][A
 24%|██▎       | 416/1759 [00:09<00:29, 44.97it/s][A
 24%|██▍       | 421/1759 [00:09<00:29, 45.10it/s][A
 24%|██▍       | 426/1759 [00:09<00:29, 44.83it/s][A
 25%|██▍       | 431/1759 [00:09<00:29, 44.74it/s][A
 25%|██▍       | 436/1759 [00:10<00:29, 44.94it/s][A
 25%|██▌       | 441/1759 [00:10<00:29, 45.01it/s][A
 25%|██▌       | 446/1759 [00:10<00:29, 45.07it/s][A
 26%|██▌       | 451/1759 [00:10<00:29, 45.09it/s][A
 26%|██▌       | 456/1759 [00:10<00:28, 45.04it/s][A
 26%|██▌       | 461/1759 [00:10<00:28, 45.11it/s][A
 26%|██▋       | 466/1759 [00:10<00:28, 45.04it/s][A
 27%|██▋       | 471/1759 [00:10<00:28, 44.85it/s][A
 27%|██▋       | 476/1759 [00:10<00:28, 44.86it/s][A
 27%|██▋       | 481/1759 [00:11<00:28, 45.02it/s][A
 28%|██▊       | 486/1759 [00:11<00:28, 45.07it/s][A
 28%|██▊       | 491/1759 [00:11<00:28, 45.20it/s][A
 28%|██▊       | 496/1759 [00:11<00:27, 45.21it/s][A
 28%|██▊       | 501/1759 [00:11<00:27, 45.21it/s][A
 29%|██▉       | 506/1759 [00:11<00:27, 45.22it/s][A
 29%|██▉       | 511/1759 [00:11<00:27, 45.03it/s][A
 29%|██▉       | 516/1759 [00:11<00:27, 44.96it/s][A
 30%|██▉       | 521/1759 [00:11<00:29, 42.31it/s][A
 30%|██▉       | 526/1759 [00:12<00:28, 43.25it/s][A
 30%|███       | 531/1759 [00:12<00:27, 43.92it/s][A
 30%|███       | 536/1759 [00:12<00:27, 44.28it/s][A
 31%|███       | 541/1759 [00:12<00:27, 44.65it/s][A
 31%|███       | 546/1759 [00:12<00:27, 44.80it/s][A
 31%|███▏      | 551/1759 [00:12<00:26, 44.96it/s][A
 32%|███▏      | 556/1759 [00:12<00:26, 45.00it/s][A
 32%|███▏      | 561/1759 [00:12<00:26, 44.73it/s][A
 32%|███▏      | 566/1759 [00:12<00:26, 44.73it/s][A
 32%|███▏      | 571/1759 [00:13<00:26, 44.91it/s][A
 33%|███▎      | 576/1759 [00:13<00:26, 44.95it/s][A
 33%|███▎      | 581/1759 [00:13<00:26, 45.06it/s][A
 33%|███▎      | 586/1759 [00:13<00:26, 45.09it/s][A
 34%|███▎      | 591/1759 [00:13<00:25, 45.20it/s][A
 34%|███▍      | 596/1759 [00:13<00:25, 45.23it/s][A
 34%|███▍      | 601/1759 [00:13<00:25, 45.13it/s][A
 34%|███▍      | 606/1759 [00:13<00:25, 44.88it/s][A
 35%|███▍      | 611/1759 [00:13<00:25, 44.72it/s][A
 35%|███▌      | 616/1759 [00:14<00:25, 44.86it/s][A
 35%|███▌      | 621/1759 [00:14<00:25, 44.97it/s][A
 36%|███▌      | 626/1759 [00:14<00:25, 45.11it/s][A
 36%|███▌      | 631/1759 [00:14<00:24, 45.17it/s][A
 36%|███▌      | 636/1759 [00:14<00:24, 45.21it/s][A
 36%|███▋      | 641/1759 [00:14<00:24, 45.20it/s][A
 37%|███▋      | 646/1759 [00:14<00:24, 45.16it/s][A
 37%|███▋      | 651/1759 [00:14<00:24, 45.02it/s][A
 37%|███▋      | 656/1759 [00:14<00:24, 44.91it/s][A
 38%|███▊      | 661/1759 [00:15<00:24, 45.00it/s][A
 38%|███▊      | 666/1759 [00:15<00:24, 44.97it/s][A
 38%|███▊      | 671/1759 [00:15<00:24, 45.12it/s][A
 38%|███▊      | 676/1759 [00:15<00:24, 45.07it/s][A
 39%|███▊      | 681/1759 [00:15<00:25, 42.47it/s][A
 39%|███▉      | 686/1759 [00:15<00:24, 43.39it/s][A
 39%|███▉      | 691/1759 [00:15<00:24, 43.93it/s][A
 40%|███▉      | 696/1759 [00:15<00:24, 44.24it/s][A
 40%|███▉      | 701/1759 [00:15<00:23, 44.37it/s][A
 40%|████      | 706/1759 [00:16<00:23, 44.62it/s][A
 40%|████      | 711/1759 [00:16<00:23, 44.77it/s][A
 41%|████      | 716/1759 [00:16<00:23, 44.95it/s][A
 41%|████      | 721/1759 [00:16<00:23, 44.73it/s][A
 41%|████▏     | 726/1759 [00:16<00:23, 44.81it/s][A
 42%|████▏     | 731/1759 [00:16<00:22, 44.97it/s][A
 42%|████▏     | 736/1759 [00:16<00:22, 45.11it/s][A
 42%|████▏     | 741/1759 [00:16<00:22, 45.05it/s][A
 42%|████▏     | 746/1759 [00:16<00:22, 45.03it/s][A
 43%|████▎     | 751/1759 [00:17<00:22, 44.90it/s][A
 43%|████▎     | 756/1759 [00:17<00:22, 44.92it/s][A
 43%|████▎     | 761/1759 [00:17<00:22, 45.00it/s][A
 44%|████▎     | 766/1759 [00:17<00:22, 44.99it/s][A
 44%|████▍     | 771/1759 [00:17<00:21, 45.03it/s][A
 44%|████▍     | 776/1759 [00:17<00:21, 45.10it/s][A
 44%|████▍     | 781/1759 [00:17<00:21, 45.06it/s][A
 45%|████▍     | 786/1759 [00:17<00:21, 45.09it/s][A
 45%|████▍     | 791/1759 [00:17<00:21, 45.10it/s][A
 45%|████▌     | 796/1759 [00:18<00:21, 44.94it/s][A
 46%|████▌     | 801/1759 [00:18<00:21, 44.98it/s][A
 46%|████▌     | 806/1759 [00:18<00:21, 44.99it/s][A
 46%|████▌     | 811/1759 [00:18<00:21, 44.86it/s][A
 46%|████▋     | 816/1759 [00:18<00:20, 45.07it/s][A
 47%|████▋     | 821/1759 [00:18<00:20, 45.11it/s][A
 47%|████▋     | 826/1759 [00:18<00:20, 45.15it/s][A
 47%|████▋     | 831/1759 [00:18<00:20, 45.11it/s][A
 48%|████▊     | 836/1759 [00:18<00:20, 45.08it/s][A
 48%|████▊     | 841/1759 [00:19<00:20, 44.92it/s][A
 48%|████▊     | 846/1759 [00:19<00:20, 44.92it/s][A
 48%|████▊     | 851/1759 [00:19<00:20, 44.89it/s][A
 49%|████▊     | 856/1759 [00:19<00:20, 44.94it/s][A
 49%|████▉     | 861/1759 [00:19<00:19, 45.11it/s][A
 49%|████▉     | 866/1759 [00:19<00:19, 45.11it/s][A
 50%|████▉     | 871/1759 [00:19<00:19, 45.11it/s][A
 50%|████▉     | 876/1759 [00:19<00:19, 45.09it/s][A
 50%|█████     | 881/1759 [00:19<00:19, 45.03it/s][A
 50%|█████     | 886/1759 [00:20<00:19, 45.00it/s][A
 51%|█████     | 891/1759 [00:20<00:19, 44.92it/s][A
 51%|█████     | 896/1759 [00:20<00:19, 45.00it/s][A
 51%|█████     | 901/1759 [00:20<00:19, 44.80it/s][A
 52%|█████▏    | 906/1759 [00:20<00:18, 44.96it/s][A
 52%|█████▏    | 911/1759 [00:20<00:19, 43.07it/s][A
 52%|█████▏    | 916/1759 [00:20<00:19, 43.88it/s][A
 52%|█████▏    | 921/1759 [00:20<00:18, 44.35it/s][A
 53%|█████▎    | 926/1759 [00:20<00:18, 44.55it/s][A
 53%|█████▎    | 931/1759 [00:21<00:18, 44.58it/s][A
 53%|█████▎    | 936/1759 [00:21<00:18, 44.76it/s][A
 53%|█████▎    | 941/1759 [00:21<00:18, 44.81it/s][A
 54%|█████▍    | 946/1759 [00:21<00:18, 44.88it/s][A
 54%|█████▍    | 951/1759 [00:21<00:18, 44.60it/s][A
 54%|█████▍    | 956/1759 [00:21<00:17, 44.70it/s][A
 55%|█████▍    | 961/1759 [00:21<00:17, 44.84it/s][A
 55%|█████▍    | 966/1759 [00:21<00:17, 45.08it/s][A
 55%|█████▌    | 971/1759 [00:21<00:17, 45.15it/s][A
 55%|█████▌    | 976/1759 [00:22<00:17, 45.11it/s][A
 56%|█████▌    | 981/1759 [00:22<00:17, 45.10it/s][A
 56%|█████▌    | 986/1759 [00:22<00:17, 45.04it/s][A
 56%|█████▋    | 991/1759 [00:22<00:17, 44.83it/s][A
 57%|█████▋    | 996/1759 [00:22<00:17, 44.81it/s][A
 57%|█████▋    | 1001/1759 [00:22<00:16, 44.84it/s][A
 57%|█████▋    | 1006/1759 [00:22<00:17, 43.54it/s][A
 57%|█████▋    | 1011/1759 [00:22<00:16, 44.22it/s][A
 58%|█████▊    | 1016/1759 [00:22<00:16, 44.59it/s][A
 58%|█████▊    | 1021/1759 [00:23<00:16, 44.73it/s][A
 58%|█████▊    | 1026/1759 [00:23<00:16, 44.80it/s][A
 59%|█████▊    | 1031/1759 [00:23<00:16, 44.68it/s][A
 59%|█████▉    | 1036/1759 [00:23<00:16, 44.76it/s][A
 59%|█████▉    | 1041/1759 [00:23<00:16, 44.75it/s][A
 59%|█████▉    | 1046/1759 [00:23<00:15, 44.71it/s][A
 60%|█████▉    | 1051/1759 [00:23<00:15, 44.73it/s][A
 60%|██████    | 1056/1759 [00:23<00:15, 44.97it/s][A
 60%|██████    | 1061/1759 [00:23<00:15, 45.10it/s][A
 61%|██████    | 1066/1759 [00:24<00:15, 45.19it/s][A
 61%|██████    | 1071/1759 [00:24<00:15, 45.14it/s][A
 61%|██████    | 1076/1759 [00:24<00:15, 45.14it/s][A
 61%|██████▏   | 1081/1759 [00:24<00:15, 45.05it/s][A
 62%|██████▏   | 1086/1759 [00:24<00:14, 44.96it/s][A
 62%|██████▏   | 1091/1759 [00:24<00:14, 44.92it/s][A
 62%|██████▏   | 1096/1759 [00:24<00:14, 44.96it/s][A
 63%|██████▎   | 1101/1759 [00:24<00:14, 45.00it/s][A
 63%|██████▎   | 1106/1759 [00:24<00:14, 45.11it/s][A
 63%|██████▎   | 1111/1759 [00:25<00:14, 45.07it/s][A
 63%|██████▎   | 1116/1759 [00:25<00:14, 45.09it/s][A
 64%|██████▎   | 1121/1759 [00:25<00:14, 45.03it/s][A
 64%|██████▍   | 1126/1759 [00:25<00:14, 44.92it/s][A
 64%|██████▍   | 1131/1759 [00:25<00:13, 44.94it/s][A
 65%|██████▍   | 1136/1759 [00:25<00:13, 44.86it/s][A
 65%|██████▍   | 1141/1759 [00:25<00:15, 38.63it/s][A
 65%|██████▌   | 1146/1759 [00:25<00:15, 40.48it/s][A
 65%|██████▌   | 1151/1759 [00:26<00:14, 41.80it/s][A
 66%|██████▌   | 1156/1759 [00:26<00:14, 42.87it/s][A
 66%|██████▌   | 1161/1759 [00:26<00:13, 43.58it/s][A
 66%|██████▋   | 1166/1759 [00:26<00:13, 44.15it/s][A
 67%|██████▋   | 1171/1759 [00:26<00:13, 44.53it/s][A
 67%|██████▋   | 1176/1759 [00:26<00:13, 44.62it/s][A
 67%|██████▋   | 1181/1759 [00:26<00:12, 44.49it/s][A
 67%|██████▋   | 1186/1759 [00:26<00:12, 44.47it/s][A
 68%|██████▊   | 1191/1759 [00:26<00:12, 44.69it/s][A
 68%|██████▊   | 1196/1759 [00:27<00:12, 44.86it/s][A
 68%|██████▊   | 1201/1759 [00:27<00:12, 44.96it/s][A
 69%|██████▊   | 1206/1759 [00:27<00:12, 44.93it/s][A
 69%|██████▉   | 1211/1759 [00:27<00:12, 45.13it/s][A
 69%|██████▉   | 1216/1759 [00:27<00:12, 45.22it/s][A
 69%|██████▉   | 1221/1759 [00:27<00:11, 45.05it/s][A
 70%|██████▉   | 1226/1759 [00:27<00:11, 44.88it/s][A
 70%|██████▉   | 1231/1759 [00:27<00:14, 36.54it/s][A
 70%|███████   | 1236/1759 [00:28<00:13, 38.87it/s][A
 71%|███████   | 1241/1759 [00:28<00:12, 40.69it/s][A
 71%|███████   | 1246/1759 [00:28<00:12, 42.02it/s][A
 71%|███████   | 1251/1759 [00:28<00:11, 43.01it/s][A
 71%|███████▏  | 1256/1759 [00:28<00:11, 43.73it/s][A
 72%|███████▏  | 1261/1759 [00:28<00:11, 44.16it/s][A
 72%|███████▏  | 1266/1759 [00:28<00:11, 44.51it/s][A
 72%|███████▏  | 1271/1759 [00:28<00:11, 44.26it/s][A
 73%|███████▎  | 1276/1759 [00:28<00:10, 44.18it/s][A
 73%|███████▎  | 1281/1759 [00:29<00:10, 44.31it/s][A
 73%|███████▎  | 1286/1759 [00:29<00:10, 44.63it/s][A
 73%|███████▎  | 1291/1759 [00:29<00:10, 44.80it/s][A
 74%|███████▎  | 1296/1759 [00:29<00:10, 44.99it/s][A
 74%|███████▍  | 1301/1759 [00:29<00:10, 45.13it/s][A
 74%|███████▍  | 1306/1759 [00:29<00:10, 45.22it/s][A
 75%|███████▍  | 1311/1759 [00:29<00:09, 45.22it/s][A
 75%|███████▍  | 1316/1759 [00:29<00:09, 44.94it/s][A
 75%|███████▌  | 1321/1759 [00:29<00:09, 44.62it/s][A
 75%|███████▌  | 1326/1759 [00:30<00:09, 44.67it/s][A
 76%|███████▌  | 1331/1759 [00:30<00:09, 44.63it/s][A
 76%|███████▌  | 1336/1759 [00:30<00:09, 44.98it/s][A
 76%|███████▌  | 1341/1759 [00:30<00:09, 45.05it/s][A
 77%|███████▋  | 1346/1759 [00:30<00:09, 45.25it/s][A
 77%|███████▋  | 1351/1759 [00:30<00:09, 45.21it/s][A
 77%|███████▋  | 1356/1759 [00:30<00:08, 45.22it/s][A
 77%|███████▋  | 1361/1759 [00:30<00:08, 44.99it/s][A
 78%|███████▊  | 1366/1759 [00:30<00:10, 36.23it/s][A
 78%|███████▊  | 1371/1759 [00:31<00:10, 38.63it/s][A
 78%|███████▊  | 1376/1759 [00:31<00:09, 40.43it/s][A
 79%|███████▊  | 1381/1759 [00:31<00:09, 41.87it/s][A
 79%|███████▉  | 1386/1759 [00:31<00:08, 42.96it/s][A
 79%|███████▉  | 1391/1759 [00:31<00:08, 43.69it/s][A
 79%|███████▉  | 1396/1759 [00:31<00:08, 44.22it/s][A
 80%|███████▉  | 1401/1759 [00:31<00:08, 44.47it/s][A
 80%|███████▉  | 1406/1759 [00:31<00:07, 44.33it/s][A
 80%|████████  | 1411/1759 [00:31<00:07, 44.13it/s][A
 81%|████████  | 1416/1759 [00:32<00:07, 44.26it/s][A
 81%|████████  | 1421/1759 [00:32<00:07, 44.57it/s][A
 81%|████████  | 1426/1759 [00:32<00:07, 44.73it/s][A
 81%|████████▏ | 1431/1759 [00:32<00:07, 44.94it/s][A
 82%|████████▏ | 1436/1759 [00:32<00:07, 45.08it/s][A
 82%|████████▏ | 1441/1759 [00:32<00:07, 45.28it/s][A
 82%|████████▏ | 1446/1759 [00:32<00:06, 45.23it/s][A
 82%|████████▏ | 1451/1759 [00:32<00:06, 44.92it/s][A
 83%|████████▎ | 1456/1759 [00:32<00:07, 42.80it/s][A
 83%|████████▎ | 1461/1759 [00:33<00:06, 43.38it/s][A
 83%|████████▎ | 1466/1759 [00:33<00:06, 43.83it/s][A
 84%|████████▎ | 1471/1759 [00:33<00:06, 44.26it/s][A
 84%|████████▍ | 1476/1759 [00:33<00:06, 44.61it/s][A
 84%|████████▍ | 1481/1759 [00:33<00:06, 44.83it/s][A
 84%|████████▍ | 1486/1759 [00:33<00:06, 45.12it/s][A
 85%|████████▍ | 1491/1759 [00:33<00:05, 44.93it/s][A
 85%|████████▌ | 1496/1759 [00:33<00:05, 44.69it/s][A
 85%|████████▌ | 1501/1759 [00:33<00:05, 44.68it/s][A
 86%|████████▌ | 1506/1759 [00:34<00:05, 44.77it/s][A
 86%|████████▌ | 1511/1759 [00:34<00:05, 44.85it/s][A
 86%|████████▌ | 1516/1759 [00:34<00:05, 44.94it/s][A
 86%|████████▋ | 1521/1759 [00:34<00:05, 44.98it/s][A
 87%|████████▋ | 1526/1759 [00:34<00:05, 45.13it/s][A
 87%|████████▋ | 1531/1759 [00:34<00:05, 45.23it/s][A
 87%|████████▋ | 1536/1759 [00:34<00:04, 45.05it/s][A
 88%|████████▊ | 1541/1759 [00:34<00:04, 44.88it/s][A
 88%|████████▊ | 1546/1759 [00:34<00:04, 44.83it/s][A
 88%|████████▊ | 1551/1759 [00:35<00:04, 44.74it/s][A
 88%|████████▊ | 1556/1759 [00:35<00:04, 44.85it/s][A
 89%|████████▊ | 1561/1759 [00:35<00:04, 44.99it/s][A
 89%|████████▉ | 1566/1759 [00:35<00:04, 45.06it/s][A
 89%|████████▉ | 1571/1759 [00:35<00:04, 45.11it/s][A
 90%|████████▉ | 1576/1759 [00:35<00:04, 45.03it/s][A
 90%|████████▉ | 1581/1759 [00:35<00:03, 44.99it/s][A
 90%|█████████ | 1586/1759 [00:35<00:03, 44.97it/s][A
 90%|█████████ | 1591/1759 [00:36<00:04, 41.14it/s][A
 91%|█████████ | 1596/1759 [00:36<00:03, 42.40it/s][A
 91%|█████████ | 1601/1759 [00:36<00:03, 43.18it/s][A
 91%|█████████▏| 1606/1759 [00:36<00:03, 43.91it/s][A
 92%|█████████▏| 1611/1759 [00:36<00:03, 44.33it/s][A
 92%|█████████▏| 1616/1759 [00:36<00:03, 44.65it/s][A
 92%|█████████▏| 1621/1759 [00:36<00:03, 44.83it/s][A
 92%|█████████▏| 1626/1759 [00:36<00:02, 44.99it/s][A
 93%|█████████▎| 1631/1759 [00:36<00:02, 44.63it/s][A
 93%|█████████▎| 1636/1759 [00:37<00:02, 44.61it/s][A
 93%|█████████▎| 1641/1759 [00:37<00:02, 44.73it/s][A
 94%|█████████▎| 1646/1759 [00:37<00:02, 44.81it/s][A
 94%|█████████▍| 1651/1759 [00:37<00:02, 44.97it/s][A
 94%|█████████▍| 1656/1759 [00:37<00:02, 45.19it/s][A
 94%|█████████▍| 1661/1759 [00:37<00:02, 45.08it/s][A
 95%|█████████▍| 1666/1759 [00:37<00:02, 45.11it/s][A
 95%|█████████▍| 1671/1759 [00:37<00:01, 44.99it/s][A
 95%|█████████▌| 1676/1759 [00:37<00:01, 44.81it/s][A
 96%|█████████▌| 1681/1759 [00:38<00:02, 38.67it/s][A
 96%|█████████▌| 1686/1759 [00:38<00:01, 40.48it/s][A
 96%|█████████▌| 1691/1759 [00:38<00:01, 41.83it/s][A
 96%|█████████▋| 1696/1759 [00:38<00:01, 42.98it/s][A
 97%|█████████▋| 1701/1759 [00:38<00:01, 43.65it/s][A
 97%|█████████▋| 1706/1759 [00:38<00:01, 44.08it/s][A
 97%|█████████▋| 1711/1759 [00:38<00:01, 44.47it/s][A
 98%|█████████▊| 1716/1759 [00:38<00:00, 44.68it/s][A
 98%|█████████▊| 1721/1759 [00:38<00:00, 44.40it/s][A
 98%|█████████▊| 1726/1759 [00:39<00:00, 44.31it/s][A
 98%|█████████▊| 1731/1759 [00:39<00:00, 44.42it/s][A
 99%|█████████▊| 1736/1759 [00:39<00:00, 44.59it/s][A
 99%|█████████▉| 1741/1759 [00:39<00:00, 44.87it/s][A
 99%|█████████▉| 1746/1759 [00:39<00:00, 44.97it/s][A
100%|█████████▉| 1751/1759 [00:39<00:00, 45.25it/s][A
100%|█████████▉| 1756/1759 [00:39<00:00, 45.38it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 45.38it/s][A 60%|██████    | 141/235 [03:18<00:27,  3.40it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 11:00:13,598 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-141
[INFO|configuration_utils.py:351] 2023-08-29 11:00:13,776 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-141/config.json
[INFO|modeling_utils.py:886] 2023-08-29 11:00:17,450 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-141/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 11:00:17,608 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-141/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 11:00:17,705 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-141/special_tokens_map.json
 60%|██████    | 142/235 [03:32<25:24, 16.40s/it] 61%|██████    | 143/235 [03:32<17:45, 11.58s/it] 61%|██████▏   | 144/235 [03:32<12:25,  8.20s/it] 62%|██████▏   | 145/235 [03:33<08:44,  5.82s/it] 62%|██████▏   | 146/235 [03:33<06:10,  4.17s/it] 63%|██████▎   | 147/235 [03:33<04:24,  3.00s/it] 63%|██████▎   | 148/235 [03:33<03:10,  2.19s/it] 63%|██████▎   | 149/235 [03:34<02:19,  1.62s/it] 64%|██████▍   | 150/235 [03:34<01:43,  1.22s/it] 64%|██████▍   | 151/235 [03:34<01:19,  1.06it/s] 65%|██████▍   | 152/235 [03:35<01:02,  1.33it/s] 65%|██████▌   | 153/235 [03:35<00:50,  1.63it/s] 66%|██████▌   | 154/235 [03:35<00:42,  1.90it/s] 66%|██████▌   | 155/235 [03:36<00:38,  2.09it/s] 66%|██████▋   | 156/235 [03:36<00:33,  2.36it/s] 67%|██████▋   | 157/235 [03:36<00:30,  2.60it/s] 67%|██████▋   | 158/235 [03:37<00:27,  2.80it/s] 68%|██████▊   | 159/235 [03:37<00:25,  2.96it/s] 68%|██████▊   | 160/235 [03:37<00:24,  3.08it/s] 69%|██████▊   | 161/235 [03:37<00:23,  3.17it/s] 69%|██████▉   | 162/235 [03:38<00:22,  3.24it/s] 69%|██████▉   | 163/235 [03:38<00:21,  3.29it/s] 70%|██████▉   | 164/235 [03:38<00:22,  3.18it/s] 70%|███████   | 165/235 [03:39<00:21,  3.24it/s] 71%|███████   | 166/235 [03:39<00:20,  3.29it/s] 71%|███████   | 167/235 [03:39<00:20,  3.32it/s] 71%|███████▏  | 168/235 [03:40<00:21,  3.19it/s] 72%|███████▏  | 169/235 [03:40<00:20,  3.25it/s] 72%|███████▏  | 170/235 [03:40<00:19,  3.29it/s] 73%|███████▎  | 171/235 [03:40<00:19,  3.33it/s] 73%|███████▎  | 172/235 [03:41<00:18,  3.35it/s] 74%|███████▎  | 173/235 [03:41<00:18,  3.37it/s] 74%|███████▍  | 174/235 [03:41<00:18,  3.24it/s] 74%|███████▍  | 175/235 [03:42<00:18,  3.29it/s] 75%|███████▍  | 176/235 [03:42<00:17,  3.32it/s] 75%|███████▌  | 177/235 [03:43<00:25,  2.31it/s] 76%|███████▌  | 178/235 [03:43<00:22,  2.56it/s] 76%|███████▌  | 179/235 [03:43<00:20,  2.76it/s] 77%|███████▋  | 180/235 [03:44<00:18,  2.93it/s] 77%|███████▋  | 181/235 [03:44<00:17,  3.05it/s] 77%|███████▋  | 182/235 [03:44<00:16,  3.15it/s] 78%|███████▊  | 183/235 [03:44<00:16,  3.13it/s] 78%|███████▊  | 184/235 [03:45<00:15,  3.21it/s] 79%|███████▊  | 185/235 [03:45<00:15,  3.27it/s] 79%|███████▉  | 186/235 [03:45<00:14,  3.31it/s] 80%|███████▉  | 187/235 [03:46<00:14,  3.33it/s] 80%|████████  | 188/235 [03:46<00:13,  3.47it/s][INFO|trainer.py:2140] 2023-08-29 11:00:41,811 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 11:00:41,811 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 11:00:41,811 >>   Batch size = 8
{'eval_loss': 0.9494664669036865, 'eval_runtime': 39.8315, 'eval_samples_per_second': 353.163, 'eval_steps_per_second': 44.161, 'epoch': 3.0}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.40it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.37it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.69it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.46it/s][A
  2%|▏         | 27/1759 [00:00<00:44, 39.27it/s][A
  2%|▏         | 32/1759 [00:00<00:41, 41.26it/s][A
  2%|▏         | 37/1759 [00:00<00:40, 42.54it/s][A
  2%|▏         | 42/1759 [00:00<00:39, 43.51it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 44.17it/s][A
  3%|▎         | 52/1759 [00:01<00:38, 44.63it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 44.95it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.07it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 44.74it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 44.48it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 44.56it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 44.67it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.80it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 45.04it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 45.00it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.35it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.38it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.35it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.10it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 45.08it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 45.01it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 45.16it/s][A
  8%|▊         | 137/1759 [00:03<00:35, 45.17it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.23it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.31it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.36it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.24it/s][A
  9%|▉         | 162/1759 [00:03<00:41, 38.23it/s][A
  9%|▉         | 167/1759 [00:03<00:39, 40.26it/s][A
 10%|▉         | 172/1759 [00:03<00:38, 41.72it/s][A
 10%|█         | 177/1759 [00:04<00:36, 42.85it/s][A
 10%|█         | 182/1759 [00:04<00:36, 43.68it/s][A
 11%|█         | 187/1759 [00:04<00:35, 44.31it/s][A
 11%|█         | 192/1759 [00:04<00:35, 44.75it/s][A
 11%|█         | 197/1759 [00:04<00:34, 44.95it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 44.61it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 44.46it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 44.48it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 44.77it/s][A
 13%|█▎        | 222/1759 [00:05<00:34, 44.95it/s][A
 13%|█▎        | 227/1759 [00:05<00:34, 45.01it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 45.29it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.34it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.38it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.26it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 45.02it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 44.89it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 44.96it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 45.14it/s][A
 15%|█▌        | 272/1759 [00:06<00:32, 45.20it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.27it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.29it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.29it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.09it/s][A
 17%|█▋        | 297/1759 [00:06<00:34, 42.30it/s][A
 17%|█▋        | 302/1759 [00:06<00:33, 43.17it/s][A
 17%|█▋        | 307/1759 [00:06<00:33, 43.84it/s][A
 18%|█▊        | 312/1759 [00:07<00:32, 44.34it/s][A
 18%|█▊        | 317/1759 [00:07<00:32, 44.69it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 44.94it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.11it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 45.14it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 44.84it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 44.74it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 44.90it/s][A
 20%|██        | 352/1759 [00:07<00:31, 44.99it/s][A
 20%|██        | 357/1759 [00:08<00:31, 45.09it/s][A
 21%|██        | 362/1759 [00:08<00:30, 45.13it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.31it/s][A
 21%|██        | 372/1759 [00:08<00:30, 45.30it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.22it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 44.84it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 44.81it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 44.94it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 45.02it/s][A
 23%|██▎       | 402/1759 [00:09<00:30, 45.16it/s][A
 23%|██▎       | 407/1759 [00:09<00:29, 45.25it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.37it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.25it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.10it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 44.95it/s][A
 25%|██▍       | 432/1759 [00:09<00:31, 42.23it/s][A
 25%|██▍       | 437/1759 [00:09<00:30, 43.12it/s][A
 25%|██▌       | 442/1759 [00:09<00:30, 43.83it/s][A
 25%|██▌       | 447/1759 [00:10<00:29, 44.28it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 44.67it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 44.91it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.08it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.02it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 44.81it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 44.77it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 44.90it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 44.92it/s][A
 28%|██▊       | 492/1759 [00:11<00:28, 45.20it/s][A
 28%|██▊       | 497/1759 [00:11<00:27, 45.31it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.20it/s][A
 29%|██▉       | 507/1759 [00:14<04:24,  4.74it/s][A
 29%|██▉       | 511/1759 [00:14<03:24,  6.10it/s][A
 29%|██▉       | 516/1759 [00:14<02:28,  8.37it/s][A
 30%|██▉       | 521/1759 [00:14<01:50, 11.20it/s][A
 30%|██▉       | 526/1759 [00:14<01:24, 14.58it/s][A
 30%|███       | 531/1759 [00:15<01:06, 18.40it/s][A
 30%|███       | 536/1759 [00:15<00:54, 22.45it/s][A
 31%|███       | 541/1759 [00:15<00:45, 26.55it/s][A
 31%|███       | 546/1759 [00:15<00:40, 30.24it/s][A
 31%|███▏      | 551/1759 [00:15<00:36, 33.38it/s][A
 32%|███▏      | 556/1759 [00:15<00:33, 36.05it/s][A
 32%|███▏      | 561/1759 [00:15<00:31, 38.32it/s][A
 32%|███▏      | 566/1759 [00:15<00:29, 40.29it/s][A
 32%|███▏      | 571/1759 [00:15<00:28, 41.75it/s][A
 33%|███▎      | 576/1759 [00:16<00:27, 42.93it/s][A
 33%|███▎      | 581/1759 [00:16<00:26, 43.70it/s][A
 33%|███▎      | 586/1759 [00:16<00:26, 44.36it/s][A
 34%|███▎      | 591/1759 [00:16<00:26, 44.51it/s][A
 34%|███▍      | 596/1759 [00:16<00:26, 44.44it/s][A
 34%|███▍      | 601/1759 [00:16<00:26, 44.46it/s][A
 34%|███▍      | 606/1759 [00:16<00:25, 44.50it/s][A
 35%|███▍      | 611/1759 [00:16<00:25, 44.85it/s][A
 35%|███▌      | 616/1759 [00:16<00:25, 45.05it/s][A
 35%|███▌      | 621/1759 [00:17<00:25, 45.15it/s][A
 36%|███▌      | 626/1759 [00:17<00:24, 45.32it/s][A
 36%|███▌      | 631/1759 [00:17<00:24, 45.44it/s][A
 36%|███▌      | 636/1759 [00:17<00:24, 45.47it/s][A
 36%|███▋      | 641/1759 [00:17<00:24, 45.30it/s][A
 37%|███▋      | 646/1759 [00:17<00:24, 45.09it/s][A
 37%|███▋      | 651/1759 [00:17<00:31, 34.91it/s][A
 37%|███▋      | 656/1759 [00:17<00:29, 37.52it/s][A
 38%|███▊      | 661/1759 [00:18<00:27, 39.62it/s][A
 38%|███▊      | 666/1759 [00:18<00:26, 41.19it/s][A
 38%|███▊      | 671/1759 [00:18<00:25, 42.38it/s][A
 38%|███▊      | 676/1759 [00:18<00:25, 43.29it/s][A
 39%|███▊      | 681/1759 [00:18<00:24, 43.95it/s][A
 39%|███▉      | 686/1759 [00:18<00:24, 44.32it/s][A
 39%|███▉      | 691/1759 [00:18<00:24, 44.18it/s][A
 40%|███▉      | 696/1759 [00:18<00:23, 44.44it/s][A
 40%|███▉      | 701/1759 [00:18<00:23, 44.60it/s][A
 40%|████      | 706/1759 [00:19<00:23, 44.89it/s][A
 40%|████      | 711/1759 [00:19<00:23, 44.90it/s][A
 41%|████      | 716/1759 [00:19<00:23, 45.15it/s][A
 41%|████      | 721/1759 [00:19<00:22, 45.30it/s][A
 41%|████▏     | 726/1759 [00:19<00:22, 45.33it/s][A
 42%|████▏     | 731/1759 [00:19<00:22, 45.16it/s][A
 42%|████▏     | 736/1759 [00:19<00:22, 44.96it/s][A
 42%|████▏     | 741/1759 [00:19<00:22, 44.94it/s][A
 42%|████▏     | 746/1759 [00:19<00:22, 44.99it/s][A
 43%|████▎     | 751/1759 [00:20<00:22, 45.08it/s][A
 43%|████▎     | 756/1759 [00:20<00:22, 45.25it/s][A
 43%|████▎     | 761/1759 [00:20<00:22, 45.36it/s][A
 44%|████▎     | 766/1759 [00:20<00:21, 45.42it/s][A
 44%|████▍     | 771/1759 [00:20<00:21, 45.40it/s][A
 44%|████▍     | 776/1759 [00:20<00:21, 45.17it/s][A
 44%|████▍     | 781/1759 [00:20<00:21, 45.03it/s][A
 45%|████▍     | 786/1759 [00:20<00:28, 33.74it/s][A
 45%|████▍     | 791/1759 [00:21<00:26, 36.63it/s][A
 45%|████▌     | 796/1759 [00:21<00:24, 38.97it/s][A
 46%|████▌     | 801/1759 [00:21<00:23, 40.76it/s][A
 46%|████▌     | 806/1759 [00:21<00:22, 42.18it/s][A
 46%|████▌     | 811/1759 [00:21<00:21, 43.21it/s][A
 46%|████▋     | 816/1759 [00:21<00:21, 43.94it/s][A
 47%|████▋     | 821/1759 [00:21<00:21, 44.33it/s][A
 47%|████▋     | 826/1759 [00:21<00:21, 44.23it/s][A
 47%|████▋     | 831/1759 [00:21<00:21, 44.10it/s][A
 48%|████▊     | 836/1759 [00:22<00:20, 44.34it/s][A
 48%|████▊     | 841/1759 [00:22<00:20, 44.63it/s][A
 48%|████▊     | 846/1759 [00:22<00:20, 44.87it/s][A
 48%|████▊     | 851/1759 [00:22<00:20, 45.07it/s][A
 49%|████▊     | 856/1759 [00:22<00:19, 45.29it/s][A
 49%|████▉     | 861/1759 [00:22<00:19, 45.43it/s][A
 49%|████▉     | 866/1759 [00:22<00:19, 45.38it/s][A
 50%|████▉     | 871/1759 [00:22<00:19, 45.00it/s][A
 50%|████▉     | 876/1759 [00:22<00:19, 44.81it/s][A
 50%|█████     | 881/1759 [00:23<00:19, 44.76it/s][A
 50%|█████     | 886/1759 [00:23<00:19, 44.86it/s][A
 51%|█████     | 891/1759 [00:23<00:19, 45.02it/s][A
 51%|█████     | 896/1759 [00:23<00:19, 45.05it/s][A
 51%|█████     | 901/1759 [00:23<00:18, 45.21it/s][A
 52%|█████▏    | 906/1759 [00:23<00:18, 45.33it/s][A
 52%|█████▏    | 911/1759 [00:23<00:18, 45.31it/s][A
 52%|█████▏    | 916/1759 [00:23<00:23, 36.57it/s][A
 52%|█████▏    | 921/1759 [00:23<00:21, 38.81it/s][A
 53%|█████▎    | 926/1759 [00:24<00:20, 40.62it/s][A
 53%|█████▎    | 931/1759 [00:24<00:19, 41.94it/s][A
 53%|█████▎    | 936/1759 [00:24<00:19, 42.98it/s][A
 53%|█████▎    | 941/1759 [00:24<00:18, 43.62it/s][A
 54%|█████▍    | 946/1759 [00:24<00:18, 44.17it/s][A
 54%|█████▍    | 951/1759 [00:24<00:18, 44.51it/s][A
 54%|█████▍    | 956/1759 [00:24<00:18, 44.37it/s][A
 55%|█████▍    | 961/1759 [00:24<00:17, 44.53it/s][A
 55%|█████▍    | 966/1759 [00:24<00:17, 44.62it/s][A
 55%|█████▌    | 971/1759 [00:25<00:17, 44.91it/s][A
 55%|█████▌    | 976/1759 [00:25<00:17, 45.06it/s][A
 56%|█████▌    | 981/1759 [00:25<00:17, 45.14it/s][A
 56%|█████▌    | 986/1759 [00:25<00:17, 45.13it/s][A
 56%|█████▋    | 991/1759 [00:25<00:16, 45.25it/s][A
 57%|█████▋    | 996/1759 [00:25<00:16, 45.10it/s][A
 57%|█████▋    | 1001/1759 [00:25<00:16, 45.00it/s][A
 57%|█████▋    | 1006/1759 [00:25<00:16, 44.90it/s][A
 57%|█████▋    | 1011/1759 [00:25<00:16, 44.97it/s][A
 58%|█████▊    | 1016/1759 [00:26<00:16, 45.12it/s][A
 58%|█████▊    | 1021/1759 [00:26<00:16, 45.27it/s][A
 58%|█████▊    | 1026/1759 [00:26<00:16, 45.27it/s][A
 59%|█████▊    | 1031/1759 [00:26<00:16, 45.25it/s][A
 59%|█████▉    | 1036/1759 [00:26<00:15, 45.21it/s][A
 59%|█████▉    | 1041/1759 [00:26<00:15, 45.12it/s][A
 59%|█████▉    | 1046/1759 [00:26<00:15, 45.01it/s][A
 60%|█████▉    | 1051/1759 [00:26<00:18, 38.68it/s][A
 60%|██████    | 1056/1759 [00:27<00:17, 40.43it/s][A
 60%|██████    | 1061/1759 [00:27<00:16, 41.80it/s][A
 61%|██████    | 1066/1759 [00:27<00:16, 42.86it/s][A
 61%|██████    | 1071/1759 [00:27<00:15, 43.49it/s][A
 61%|██████    | 1076/1759 [00:27<00:15, 44.12it/s][A
 61%|██████▏   | 1081/1759 [00:27<00:15, 44.47it/s][A
 62%|██████▏   | 1086/1759 [00:27<00:15, 44.74it/s][A
 62%|██████▏   | 1091/1759 [00:27<00:14, 44.56it/s][A
 62%|██████▏   | 1096/1759 [00:27<00:14, 44.70it/s][A
 63%|██████▎   | 1101/1759 [00:28<00:14, 44.79it/s][A
 63%|██████▎   | 1106/1759 [00:28<00:14, 45.02it/s][A
 63%|██████▎   | 1111/1759 [00:28<00:14, 45.19it/s][A
 63%|██████▎   | 1116/1759 [00:28<00:14, 45.27it/s][A
 64%|██████▎   | 1121/1759 [00:28<00:14, 45.29it/s][A
 64%|██████▍   | 1126/1759 [00:28<00:13, 45.24it/s][A
 64%|██████▍   | 1131/1759 [00:28<00:13, 45.08it/s][A
 65%|██████▍   | 1136/1759 [00:28<00:13, 44.93it/s][A
 65%|██████▍   | 1141/1759 [00:28<00:13, 44.84it/s][A
 65%|██████▌   | 1146/1759 [00:29<00:13, 44.93it/s][A
 65%|██████▌   | 1151/1759 [00:29<00:13, 45.03it/s][A
 66%|██████▌   | 1156/1759 [00:29<00:13, 45.13it/s][A
 66%|██████▌   | 1161/1759 [00:29<00:13, 45.26it/s][A
 66%|██████▋   | 1166/1759 [00:29<00:13, 45.28it/s][A
 67%|██████▋   | 1171/1759 [00:29<00:13, 45.21it/s][A
 67%|██████▋   | 1176/1759 [00:29<00:12, 45.07it/s][A
 67%|██████▋   | 1181/1759 [00:29<00:12, 44.95it/s][A
 67%|██████▋   | 1186/1759 [00:30<00:15, 36.45it/s][A
 68%|██████▊   | 1191/1759 [00:30<00:14, 38.80it/s][A
 68%|██████▊   | 1196/1759 [00:30<00:13, 40.60it/s][A
 68%|██████▊   | 1201/1759 [00:30<00:13, 41.97it/s][A
 69%|██████▊   | 1206/1759 [00:30<00:12, 42.96it/s][A
 69%|██████▉   | 1211/1759 [00:30<00:12, 43.66it/s][A
 69%|██████▉   | 1216/1759 [00:30<00:12, 44.19it/s][A
 69%|██████▉   | 1221/1759 [00:30<00:12, 44.54it/s][A
 70%|██████▉   | 1226/1759 [00:30<00:12, 44.31it/s][A
 70%|██████▉   | 1231/1759 [00:31<00:11, 44.35it/s][A
 70%|███████   | 1236/1759 [00:31<00:11, 44.65it/s][A
 71%|███████   | 1241/1759 [00:31<00:11, 44.94it/s][A
 71%|███████   | 1246/1759 [00:31<00:11, 45.06it/s][A
 71%|███████   | 1251/1759 [00:31<00:11, 45.07it/s][A
 71%|███████▏  | 1256/1759 [00:31<00:11, 45.17it/s][A
 72%|███████▏  | 1261/1759 [00:31<00:11, 45.17it/s][A
 72%|███████▏  | 1266/1759 [00:31<00:10, 44.99it/s][A
 72%|███████▏  | 1271/1759 [00:31<00:10, 44.84it/s][A
 73%|███████▎  | 1276/1759 [00:32<00:10, 44.74it/s][A
 73%|███████▎  | 1281/1759 [00:32<00:10, 44.90it/s][A
 73%|███████▎  | 1286/1759 [00:32<00:10, 45.02it/s][A
 73%|███████▎  | 1291/1759 [00:32<00:10, 45.15it/s][A
 74%|███████▎  | 1296/1759 [00:32<00:10, 45.21it/s][A
 74%|███████▍  | 1301/1759 [00:32<00:10, 45.25it/s][A
 74%|███████▍  | 1306/1759 [00:32<00:10, 45.14it/s][A
 75%|███████▍  | 1311/1759 [00:32<00:09, 45.03it/s][A
 75%|███████▍  | 1316/1759 [00:32<00:09, 44.91it/s][A
 75%|███████▌  | 1321/1759 [00:33<00:09, 44.79it/s][A
 75%|███████▌  | 1326/1759 [00:33<00:09, 44.90it/s][A
 76%|███████▌  | 1331/1759 [00:33<00:09, 44.94it/s][A
 76%|███████▌  | 1336/1759 [00:33<00:09, 45.15it/s][A
 76%|███████▌  | 1341/1759 [00:33<00:09, 45.26it/s][A
 77%|███████▋  | 1346/1759 [00:33<00:09, 45.32it/s][A
 77%|███████▋  | 1351/1759 [00:33<00:09, 45.18it/s][A
 77%|███████▋  | 1356/1759 [00:33<00:08, 45.00it/s][A
 77%|███████▋  | 1361/1759 [00:33<00:08, 44.92it/s][A
 78%|███████▊  | 1366/1759 [00:34<00:08, 44.90it/s][A
 78%|███████▊  | 1371/1759 [00:34<00:08, 45.00it/s][A
 78%|███████▊  | 1376/1759 [00:34<00:08, 45.07it/s][A
 79%|███████▊  | 1381/1759 [00:34<00:08, 42.79it/s][A
 79%|███████▉  | 1386/1759 [00:34<00:08, 43.57it/s][A
 79%|███████▉  | 1391/1759 [00:34<00:08, 44.13it/s][A
 79%|███████▉  | 1396/1759 [00:34<00:08, 44.55it/s][A
 80%|███████▉  | 1401/1759 [00:34<00:08, 44.62it/s][A
 80%|███████▉  | 1406/1759 [00:34<00:07, 44.64it/s][A
 80%|████████  | 1411/1759 [00:35<00:07, 44.67it/s][A
 81%|████████  | 1416/1759 [00:35<00:07, 44.83it/s][A
 81%|████████  | 1421/1759 [00:35<00:07, 44.67it/s][A
 81%|████████  | 1426/1759 [00:35<00:07, 44.78it/s][A
 81%|████████▏ | 1431/1759 [00:35<00:07, 44.77it/s][A
 82%|████████▏ | 1436/1759 [00:35<00:07, 45.04it/s][A
 82%|████████▏ | 1441/1759 [00:35<00:07, 45.25it/s][A
 82%|████████▏ | 1446/1759 [00:35<00:06, 45.18it/s][A
 82%|████████▏ | 1451/1759 [00:35<00:06, 45.07it/s][A
 83%|████████▎ | 1456/1759 [00:36<00:06, 45.02it/s][A
 83%|████████▎ | 1461/1759 [00:36<00:06, 44.95it/s][A
 83%|████████▎ | 1466/1759 [00:36<00:06, 44.76it/s][A
 84%|████████▎ | 1471/1759 [00:36<00:06, 44.84it/s][A
 84%|████████▍ | 1476/1759 [00:36<00:06, 44.93it/s][A
 84%|████████▍ | 1481/1759 [00:36<00:06, 45.12it/s][A
 84%|████████▍ | 1486/1759 [00:36<00:06, 45.24it/s][A
 85%|████████▍ | 1491/1759 [00:36<00:05, 45.21it/s][A
 85%|████████▌ | 1496/1759 [00:36<00:05, 45.09it/s][A
 85%|████████▌ | 1501/1759 [00:37<00:05, 45.05it/s][A
 86%|████████▌ | 1506/1759 [00:37<00:05, 44.83it/s][A
 86%|████████▌ | 1511/1759 [00:37<00:05, 44.90it/s][A
 86%|████████▌ | 1516/1759 [00:37<00:05, 42.89it/s][A
 86%|████████▋ | 1521/1759 [00:37<00:05, 43.60it/s][A
 87%|████████▋ | 1526/1759 [00:37<00:05, 44.15it/s][A
 87%|████████▋ | 1531/1759 [00:37<00:05, 44.44it/s][A
 87%|████████▋ | 1536/1759 [00:37<00:04, 44.73it/s][A
 88%|████████▊ | 1541/1759 [00:37<00:04, 44.95it/s][A
 88%|████████▊ | 1546/1759 [00:38<00:04, 44.96it/s][A
 88%|████████▊ | 1551/1759 [00:38<00:04, 45.05it/s][A
 88%|████████▊ | 1556/1759 [00:38<00:04, 44.82it/s][A
 89%|████████▊ | 1561/1759 [00:38<00:04, 44.77it/s][A
 89%|████████▉ | 1566/1759 [00:38<00:04, 44.82it/s][A
 89%|████████▉ | 1571/1759 [00:38<00:04, 45.01it/s][A
 90%|████████▉ | 1576/1759 [00:38<00:04, 45.04it/s][A
 90%|████████▉ | 1581/1759 [00:38<00:03, 45.17it/s][A
 90%|█████████ | 1586/1759 [00:38<00:03, 45.20it/s][A
 90%|█████████ | 1591/1759 [00:39<00:03, 45.11it/s][A
 91%|█████████ | 1596/1759 [00:39<00:03, 45.07it/s][A
 91%|█████████ | 1601/1759 [00:39<00:03, 44.90it/s][A
 91%|█████████▏| 1606/1759 [00:39<00:03, 44.81it/s][A
 92%|█████████▏| 1611/1759 [00:39<00:03, 44.86it/s][A
 92%|█████████▏| 1616/1759 [00:39<00:03, 45.00it/s][A
 92%|█████████▏| 1621/1759 [00:39<00:03, 45.10it/s][A
 92%|█████████▏| 1626/1759 [00:39<00:02, 45.15it/s][A
 93%|█████████▎| 1631/1759 [00:39<00:02, 45.12it/s][A
 93%|█████████▎| 1636/1759 [00:40<00:02, 45.14it/s][A
 93%|█████████▎| 1641/1759 [00:40<00:02, 45.04it/s][A
 94%|█████████▎| 1646/1759 [00:40<00:02, 44.90it/s][A
 94%|█████████▍| 1651/1759 [00:40<00:02, 42.32it/s][A
 94%|█████████▍| 1656/1759 [00:40<00:02, 43.17it/s][A
 94%|█████████▍| 1661/1759 [00:40<00:02, 44.01it/s][A
 95%|█████████▍| 1666/1759 [00:40<00:02, 44.41it/s][A
 95%|█████████▍| 1671/1759 [00:40<00:01, 44.61it/s][A
 95%|█████████▌| 1676/1759 [00:40<00:01, 44.87it/s][A
 96%|█████████▌| 1681/1759 [00:41<00:01, 44.93it/s][A
 96%|█████████▌| 1686/1759 [00:41<00:01, 44.87it/s][A
 96%|█████████▌| 1691/1759 [00:41<00:01, 44.62it/s][A
 96%|█████████▋| 1696/1759 [00:41<00:01, 44.50it/s][A
 97%|█████████▋| 1701/1759 [00:41<00:01, 44.71it/s][A
 97%|█████████▋| 1706/1759 [00:41<00:01, 44.88it/s][A
 97%|█████████▋| 1711/1759 [00:41<00:01, 44.97it/s][A
 98%|█████████▊| 1716/1759 [00:41<00:00, 45.12it/s][A
 98%|█████████▊| 1721/1759 [00:41<00:00, 45.24it/s][A
 98%|█████████▊| 1726/1759 [00:42<00:00, 45.31it/s][A
 98%|█████████▊| 1731/1759 [00:42<00:00, 45.25it/s][A
 99%|█████████▊| 1736/1759 [00:42<00:00, 45.02it/s][A
 99%|█████████▉| 1741/1759 [00:42<00:00, 44.72it/s][A
 99%|█████████▉| 1746/1759 [00:42<00:00, 44.85it/s][A
100%|█████████▉| 1751/1759 [00:42<00:00, 44.97it/s][A
100%|█████████▉| 1756/1759 [00:42<00:00, 45.10it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:42<00:00, 45.10it/s][A 80%|████████  | 188/235 [04:29<00:13,  3.47it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 11:01:25,028 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-188
[INFO|configuration_utils.py:351] 2023-08-29 11:01:25,319 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-188/config.json
[INFO|modeling_utils.py:886] 2023-08-29 11:01:29,559 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-188/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 11:01:29,846 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-188/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 11:01:29,958 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-188/special_tokens_map.json
 80%|████████  | 189/235 [04:45<13:40, 17.84s/it] 81%|████████  | 190/235 [04:45<09:26, 12.59s/it] 81%|████████▏ | 191/235 [04:45<06:31,  8.90s/it] 82%|████████▏ | 192/235 [04:46<04:31,  6.32s/it] 82%|████████▏ | 193/235 [04:46<03:09,  4.51s/it] 83%|████████▎ | 194/235 [04:46<02:13,  3.25s/it] 83%|████████▎ | 195/235 [04:47<01:34,  2.36s/it] 83%|████████▎ | 196/235 [04:47<01:07,  1.74s/it] 84%|████████▍ | 197/235 [04:47<00:49,  1.31s/it] 84%|████████▍ | 198/235 [04:47<00:37,  1.00s/it] 85%|████████▍ | 199/235 [04:48<00:28,  1.27it/s] 85%|████████▌ | 200/235 [04:48<00:22,  1.56it/s] 86%|████████▌ | 201/235 [04:48<00:18,  1.86it/s] 86%|████████▌ | 202/235 [04:49<00:15,  2.16it/s] 86%|████████▋ | 203/235 [04:49<00:13,  2.43it/s] 87%|████████▋ | 204/235 [04:49<00:11,  2.66it/s] 87%|████████▋ | 205/235 [04:49<00:10,  2.85it/s] 88%|████████▊ | 206/235 [04:50<00:09,  3.00it/s] 88%|████████▊ | 207/235 [04:50<00:09,  3.11it/s] 89%|████████▊ | 208/235 [04:50<00:08,  3.20it/s] 89%|████████▉ | 209/235 [04:51<00:07,  3.25it/s] 89%|████████▉ | 210/235 [04:51<00:07,  3.30it/s] 90%|████████▉ | 211/235 [04:51<00:07,  3.22it/s] 90%|█████████ | 212/235 [04:52<00:07,  3.27it/s] 91%|█████████ | 213/235 [04:52<00:06,  3.31it/s] 91%|█████████ | 214/235 [04:52<00:06,  3.34it/s] 91%|█████████▏| 215/235 [04:52<00:05,  3.36it/s] 92%|█████████▏| 216/235 [04:53<00:05,  3.38it/s] 92%|█████████▏| 217/235 [04:53<00:05,  3.39it/s] 93%|█████████▎| 218/235 [04:53<00:05,  3.39it/s] 93%|█████████▎| 219/235 [04:54<00:04,  3.40it/s] 94%|█████████▎| 220/235 [04:54<00:04,  3.40it/s] 94%|█████████▍| 221/235 [04:54<00:04,  3.40it/s] 94%|█████████▍| 222/235 [04:55<00:03,  3.26it/s] 95%|█████████▍| 223/235 [04:55<00:03,  3.30it/s] 95%|█████████▌| 224/235 [04:55<00:03,  3.33it/s] 96%|█████████▌| 225/235 [04:55<00:02,  3.35it/s] 96%|█████████▌| 226/235 [04:56<00:02,  3.37it/s] 97%|█████████▋| 227/235 [04:56<00:02,  3.38it/s] 97%|█████████▋| 228/235 [04:56<00:02,  3.39it/s] 97%|█████████▋| 229/235 [04:57<00:01,  3.39it/s] 98%|█████████▊| 230/235 [04:57<00:01,  3.40it/s] 98%|█████████▊| 231/235 [04:57<00:01,  3.40it/s] 99%|█████████▊| 232/235 [04:57<00:00,  3.40it/s] 99%|█████████▉| 233/235 [04:58<00:00,  3.18it/s]100%|█████████▉| 234/235 [04:58<00:00,  3.25it/s]100%|██████████| 235/235 [04:58<00:00,  3.41it/s][INFO|trainer.py:2140] 2023-08-29 11:01:54,893 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 11:01:54,894 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 11:01:54,894 >>   Batch size = 8
{'eval_loss': 0.958597719669342, 'eval_runtime': 42.8317, 'eval_samples_per_second': 328.425, 'eval_steps_per_second': 41.068, 'epoch': 4.0}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 7/1759 [00:00<00:30, 58.20it/s][A
  1%|          | 13/1759 [00:00<00:34, 50.87it/s][A
  1%|          | 19/1759 [00:00<00:35, 48.48it/s][A
  1%|▏         | 24/1759 [00:00<00:36, 47.41it/s][A
  2%|▏         | 29/1759 [00:00<00:36, 46.80it/s][A
  2%|▏         | 34/1759 [00:00<00:37, 46.51it/s][A
  2%|▏         | 39/1759 [00:00<00:37, 46.17it/s][A
  3%|▎         | 44/1759 [00:00<00:37, 45.47it/s][A
  3%|▎         | 49/1759 [00:01<00:38, 44.99it/s][A
  3%|▎         | 54/1759 [00:01<00:37, 44.89it/s][A
  3%|▎         | 59/1759 [00:01<00:37, 45.06it/s][A
  4%|▎         | 64/1759 [00:01<00:37, 45.25it/s][A
  4%|▍         | 69/1759 [00:01<00:38, 43.47it/s][A
  4%|▍         | 74/1759 [00:01<00:38, 44.17it/s][A
  4%|▍         | 79/1759 [00:01<00:37, 44.67it/s][A
  5%|▍         | 84/1759 [00:01<00:37, 44.91it/s][A
  5%|▌         | 89/1759 [00:01<00:37, 44.83it/s][A
  5%|▌         | 94/1759 [00:02<00:37, 44.76it/s][A
  6%|▌         | 99/1759 [00:02<00:37, 44.74it/s][A
  6%|▌         | 104/1759 [00:02<00:36, 44.96it/s][A
  6%|▌         | 109/1759 [00:02<00:36, 44.85it/s][A
  6%|▋         | 114/1759 [00:02<00:36, 45.00it/s][A
  7%|▋         | 119/1759 [00:02<00:36, 45.19it/s][A
  7%|▋         | 124/1759 [00:02<00:36, 45.34it/s][A
  7%|▋         | 129/1759 [00:02<00:35, 45.38it/s][A
  8%|▊         | 134/1759 [00:02<00:35, 45.44it/s][A
  8%|▊         | 139/1759 [00:03<00:35, 45.24it/s][A
  8%|▊         | 144/1759 [00:03<00:35, 45.03it/s][A
  8%|▊         | 149/1759 [00:03<00:35, 45.18it/s][A
  9%|▉         | 154/1759 [00:03<00:35, 45.09it/s][A
  9%|▉         | 159/1759 [00:03<00:35, 45.13it/s][A
  9%|▉         | 164/1759 [00:03<00:35, 45.18it/s][A
 10%|▉         | 169/1759 [00:03<00:35, 45.29it/s][A
 10%|▉         | 174/1759 [00:03<00:34, 45.33it/s][A
 10%|█         | 179/1759 [00:03<00:34, 45.33it/s][A
 10%|█         | 184/1759 [00:04<00:34, 45.09it/s][A
 11%|█         | 189/1759 [00:04<00:34, 45.24it/s][A
 11%|█         | 194/1759 [00:04<00:34, 45.12it/s][A
 11%|█▏        | 199/1759 [00:04<00:34, 45.09it/s][A
 12%|█▏        | 204/1759 [00:04<00:40, 38.28it/s][A
 12%|█▏        | 209/1759 [00:04<00:38, 40.28it/s][A
 12%|█▏        | 214/1759 [00:04<00:37, 41.74it/s][A
 12%|█▏        | 219/1759 [00:04<00:35, 42.91it/s][A
 13%|█▎        | 224/1759 [00:04<00:35, 43.68it/s][A
 13%|█▎        | 229/1759 [00:05<00:34, 44.32it/s][A
 13%|█▎        | 234/1759 [00:05<00:34, 44.66it/s][A
 14%|█▎        | 239/1759 [00:05<00:33, 44.85it/s][A
 14%|█▍        | 244/1759 [00:05<00:33, 44.62it/s][A
 14%|█▍        | 249/1759 [00:05<00:34, 44.40it/s][A
 14%|█▍        | 254/1759 [00:05<00:33, 44.50it/s][A
 15%|█▍        | 259/1759 [00:05<00:33, 44.70it/s][A
 15%|█▌        | 264/1759 [00:05<00:33, 44.91it/s][A
 15%|█▌        | 269/1759 [00:05<00:33, 45.14it/s][A
 16%|█▌        | 274/1759 [00:06<00:32, 45.22it/s][A
 16%|█▌        | 279/1759 [00:06<00:32, 45.30it/s][A
 16%|█▌        | 284/1759 [00:06<00:32, 45.32it/s][A
 16%|█▋        | 289/1759 [00:06<00:32, 45.30it/s][A
 17%|█▋        | 294/1759 [00:06<00:32, 45.07it/s][A
 17%|█▋        | 299/1759 [00:06<00:32, 45.06it/s][A
 17%|█▋        | 304/1759 [00:06<00:32, 45.01it/s][A
 18%|█▊        | 309/1759 [00:06<00:32, 45.06it/s][A
 18%|█▊        | 314/1759 [00:06<00:31, 45.16it/s][A
 18%|█▊        | 319/1759 [00:07<00:31, 45.29it/s][A
 18%|█▊        | 324/1759 [00:07<00:31, 45.33it/s][A
 19%|█▊        | 329/1759 [00:07<00:31, 45.27it/s][A
 19%|█▉        | 334/1759 [00:07<00:31, 45.26it/s][A
 19%|█▉        | 339/1759 [00:07<00:35, 40.35it/s][A
 20%|█▉        | 344/1759 [00:07<00:33, 41.82it/s][A
 20%|█▉        | 349/1759 [00:07<00:32, 42.88it/s][A
 20%|██        | 354/1759 [00:07<00:32, 43.72it/s][A
 20%|██        | 359/1759 [00:08<00:31, 44.34it/s][A
 21%|██        | 364/1759 [00:08<00:31, 44.63it/s][A
 21%|██        | 369/1759 [00:08<00:30, 44.88it/s][A
 21%|██▏       | 374/1759 [00:08<00:30, 44.93it/s][A
 22%|██▏       | 379/1759 [00:08<00:30, 44.59it/s][A
 22%|██▏       | 384/1759 [00:08<00:30, 44.49it/s][A
 22%|██▏       | 389/1759 [00:08<00:30, 44.57it/s][A
 22%|██▏       | 394/1759 [00:08<00:30, 44.90it/s][A
 23%|██▎       | 399/1759 [00:08<00:30, 45.13it/s][A
 23%|██▎       | 404/1759 [00:09<00:29, 45.35it/s][A
 23%|██▎       | 409/1759 [00:09<00:29, 45.29it/s][A
 24%|██▎       | 414/1759 [00:09<00:29, 45.44it/s][A
 24%|██▍       | 419/1759 [00:09<00:29, 45.27it/s][A
 24%|██▍       | 424/1759 [00:09<00:29, 44.82it/s][A
 24%|██▍       | 429/1759 [00:09<00:29, 44.69it/s][A
 25%|██▍       | 434/1759 [00:09<00:29, 44.80it/s][A
 25%|██▍       | 439/1759 [00:09<00:29, 45.01it/s][A
 25%|██▌       | 444/1759 [00:09<00:29, 45.20it/s][A
 26%|██▌       | 449/1759 [00:10<00:28, 45.38it/s][A
 26%|██▌       | 454/1759 [00:10<00:28, 45.38it/s][A
 26%|██▌       | 459/1759 [00:10<00:28, 45.38it/s][A
 26%|██▋       | 464/1759 [00:10<00:28, 45.26it/s][A
 27%|██▋       | 469/1759 [00:10<00:28, 45.01it/s][A
 27%|██▋       | 474/1759 [00:10<00:30, 42.06it/s][A
 27%|██▋       | 479/1759 [00:10<00:29, 43.06it/s][A
 28%|██▊       | 484/1759 [00:10<00:29, 43.73it/s][A
 28%|██▊       | 489/1759 [00:10<00:28, 44.25it/s][A
 28%|██▊       | 494/1759 [00:11<00:28, 44.60it/s][A
 28%|██▊       | 499/1759 [00:11<00:28, 44.81it/s][A
 29%|██▊       | 504/1759 [00:11<00:27, 45.05it/s][A
 29%|██▉       | 509/1759 [00:11<00:27, 45.08it/s][A
 29%|██▉       | 514/1759 [00:11<00:27, 44.81it/s][A
 30%|██▉       | 519/1759 [00:11<00:27, 44.69it/s][A
 30%|██▉       | 524/1759 [00:11<00:27, 44.81it/s][A
 30%|███       | 529/1759 [00:11<00:27, 45.02it/s][A
 30%|███       | 534/1759 [00:11<00:27, 45.18it/s][A
 31%|███       | 539/1759 [00:12<00:26, 45.28it/s][A
 31%|███       | 544/1759 [00:12<00:26, 45.32it/s][A
 31%|███       | 549/1759 [00:12<00:26, 45.33it/s][A
 31%|███▏      | 554/1759 [00:12<00:26, 45.06it/s][A
 32%|███▏      | 559/1759 [00:12<00:26, 44.89it/s][A
 32%|███▏      | 564/1759 [00:12<00:26, 44.74it/s][A
 32%|███▏      | 569/1759 [00:12<00:26, 44.78it/s][A
 33%|███▎      | 574/1759 [00:12<00:26, 45.00it/s][A
 33%|███▎      | 579/1759 [00:12<00:26, 45.16it/s][A
 33%|███▎      | 584/1759 [00:13<00:25, 45.27it/s][A
 33%|███▎      | 589/1759 [00:13<00:25, 45.37it/s][A
 34%|███▍      | 594/1759 [00:13<00:25, 45.37it/s][A
 34%|███▍      | 599/1759 [00:13<00:25, 45.13it/s][A
 34%|███▍      | 604/1759 [00:13<00:25, 44.89it/s][A
 35%|███▍      | 609/1759 [00:13<00:26, 43.33it/s][A
 35%|███▍      | 614/1759 [00:13<00:26, 43.94it/s][A
 35%|███▌      | 619/1759 [00:13<00:25, 44.43it/s][A
 35%|███▌      | 624/1759 [00:13<00:25, 44.68it/s][A
 36%|███▌      | 629/1759 [00:14<00:25, 44.89it/s][A
 36%|███▌      | 634/1759 [00:14<00:24, 45.04it/s][A
 36%|███▋      | 639/1759 [00:14<00:24, 45.13it/s][A
 37%|███▋      | 644/1759 [00:14<00:24, 45.14it/s][A
 37%|███▋      | 649/1759 [00:14<00:24, 44.84it/s][A
 37%|███▋      | 654/1759 [00:14<00:24, 44.81it/s][A
 37%|███▋      | 659/1759 [00:14<00:24, 44.86it/s][A
 38%|███▊      | 664/1759 [00:14<00:24, 44.98it/s][A
 38%|███▊      | 669/1759 [00:14<00:24, 45.11it/s][A
 38%|███▊      | 674/1759 [00:15<00:24, 45.19it/s][A
 39%|███▊      | 679/1759 [00:15<00:23, 45.21it/s][A
 39%|███▉      | 684/1759 [00:15<00:23, 45.27it/s][A
 39%|███▉      | 689/1759 [00:15<00:23, 45.15it/s][A
 39%|███▉      | 694/1759 [00:15<00:23, 44.87it/s][A
 40%|███▉      | 699/1759 [00:15<00:23, 44.82it/s][A
 40%|████      | 704/1759 [00:15<00:23, 44.88it/s][A
 40%|████      | 709/1759 [00:15<00:23, 45.00it/s][A
 41%|████      | 714/1759 [00:15<00:23, 45.09it/s][A
 41%|████      | 719/1759 [00:16<00:23, 45.20it/s][A
 41%|████      | 724/1759 [00:16<00:22, 45.18it/s][A
 41%|████▏     | 729/1759 [00:16<00:22, 45.30it/s][A
 42%|████▏     | 734/1759 [00:16<00:22, 45.32it/s][A
 42%|████▏     | 739/1759 [00:16<00:22, 45.17it/s][A
 42%|████▏     | 744/1759 [00:16<00:25, 40.40it/s][A
 43%|████▎     | 749/1759 [00:16<00:24, 41.87it/s][A
 43%|████▎     | 754/1759 [00:16<00:23, 42.99it/s][A
 43%|████▎     | 759/1759 [00:16<00:22, 43.78it/s][A
 43%|████▎     | 764/1759 [00:17<00:22, 44.32it/s][A
 44%|████▎     | 769/1759 [00:17<00:22, 44.62it/s][A
 44%|████▍     | 774/1759 [00:17<00:21, 44.80it/s][A
 44%|████▍     | 779/1759 [00:17<00:21, 44.83it/s][A
 45%|████▍     | 784/1759 [00:17<00:21, 44.60it/s][A
 45%|████▍     | 789/1759 [00:17<00:21, 44.34it/s][A
 45%|████▌     | 794/1759 [00:17<00:21, 44.59it/s][A
 45%|████▌     | 799/1759 [00:17<00:21, 44.85it/s][A
 46%|████▌     | 804/1759 [00:17<00:21, 45.07it/s][A
 46%|████▌     | 809/1759 [00:18<00:20, 45.26it/s][A
 46%|████▋     | 814/1759 [00:18<00:20, 45.35it/s][A
 47%|████▋     | 819/1759 [00:18<00:20, 45.38it/s][A
 47%|████▋     | 824/1759 [00:18<00:20, 45.11it/s][A
 47%|████▋     | 829/1759 [00:18<00:20, 44.93it/s][A
 47%|████▋     | 834/1759 [00:18<00:20, 44.72it/s][A
 48%|████▊     | 839/1759 [00:18<00:20, 44.74it/s][A
 48%|████▊     | 844/1759 [00:18<00:20, 44.98it/s][A
 48%|████▊     | 849/1759 [00:18<00:20, 45.08it/s][A
 49%|████▊     | 854/1759 [00:19<00:19, 45.34it/s][A
 49%|████▉     | 859/1759 [00:19<00:19, 45.40it/s][A
 49%|████▉     | 864/1759 [00:19<00:19, 45.38it/s][A
 49%|████▉     | 869/1759 [00:19<00:19, 45.10it/s][A
 50%|████▉     | 874/1759 [00:19<00:21, 40.57it/s][A
 50%|████▉     | 879/1759 [00:19<00:21, 41.89it/s][A
 50%|█████     | 884/1759 [00:19<00:20, 42.91it/s][A
 51%|█████     | 889/1759 [00:19<00:19, 43.63it/s][A
 51%|█████     | 894/1759 [00:19<00:19, 44.17it/s][A
 51%|█████     | 899/1759 [00:20<00:19, 44.54it/s][A
 51%|█████▏    | 904/1759 [00:20<00:19, 44.80it/s][A
 52%|█████▏    | 909/1759 [00:20<00:18, 44.96it/s][A
 52%|█████▏    | 914/1759 [00:20<00:18, 44.59it/s][A
 52%|█████▏    | 919/1759 [00:20<00:18, 44.68it/s][A
 53%|█████▎    | 924/1759 [00:20<00:18, 44.76it/s][A
 53%|█████▎    | 929/1759 [00:20<00:18, 44.90it/s][A
 53%|█████▎    | 934/1759 [00:20<00:18, 45.12it/s][A
 53%|█████▎    | 939/1759 [00:20<00:18, 45.24it/s][A
 54%|█████▎    | 944/1759 [00:21<00:18, 45.24it/s][A
 54%|█████▍    | 949/1759 [00:21<00:17, 45.30it/s][A
 54%|█████▍    | 954/1759 [00:21<00:17, 45.06it/s][A
 55%|█████▍    | 959/1759 [00:21<00:17, 44.88it/s][A
 55%|█████▍    | 964/1759 [00:21<00:17, 44.77it/s][A
 55%|█████▌    | 969/1759 [00:21<00:17, 44.81it/s][A
 55%|█████▌    | 974/1759 [00:21<00:17, 45.06it/s][A
 56%|█████▌    | 979/1759 [00:21<00:17, 45.11it/s][A
 56%|█████▌    | 984/1759 [00:21<00:17, 45.21it/s][A
 56%|█████▌    | 989/1759 [00:22<00:16, 45.30it/s][A
 57%|█████▋    | 994/1759 [00:22<00:16, 45.31it/s][A
 57%|█████▋    | 999/1759 [00:22<00:16, 45.11it/s][A
 57%|█████▋    | 1004/1759 [00:22<00:16, 44.84it/s][A
 57%|█████▋    | 1009/1759 [00:22<00:17, 42.81it/s][A
 58%|█████▊    | 1014/1759 [00:22<00:17, 43.58it/s][A
 58%|█████▊    | 1019/1759 [00:22<00:16, 44.10it/s][A
 58%|█████▊    | 1024/1759 [00:22<00:16, 44.40it/s][A
 58%|█████▊    | 1029/1759 [00:23<00:16, 44.79it/s][A
 59%|█████▉    | 1034/1759 [00:23<00:16, 44.99it/s][A
 59%|█████▉    | 1039/1759 [00:23<00:15, 45.12it/s][A
 59%|█████▉    | 1044/1759 [00:23<00:15, 45.03it/s][A
 60%|█████▉    | 1049/1759 [00:23<00:15, 44.73it/s][A
 60%|█████▉    | 1054/1759 [00:23<00:15, 44.79it/s][A
 60%|██████    | 1059/1759 [00:23<00:15, 44.89it/s][A
 60%|██████    | 1064/1759 [00:23<00:15, 45.02it/s][A
 61%|██████    | 1069/1759 [00:23<00:15, 45.14it/s][A
 61%|██████    | 1074/1759 [00:24<00:15, 45.05it/s][A
 61%|██████▏   | 1079/1759 [00:24<00:15, 45.13it/s][A
 62%|██████▏   | 1084/1759 [00:24<00:14, 45.11it/s][A
 62%|██████▏   | 1089/1759 [00:24<00:14, 44.96it/s][A
 62%|██████▏   | 1094/1759 [00:24<00:14, 44.82it/s][A
 62%|██████▏   | 1099/1759 [00:24<00:14, 44.75it/s][A
 63%|██████▎   | 1104/1759 [00:24<00:14, 44.95it/s][A
 63%|██████▎   | 1109/1759 [00:24<00:14, 45.07it/s][A
 63%|██████▎   | 1114/1759 [00:24<00:14, 45.12it/s][A
 64%|██████▎   | 1119/1759 [00:25<00:14, 45.19it/s][A
 64%|██████▍   | 1124/1759 [00:25<00:14, 45.30it/s][A
 64%|██████▍   | 1129/1759 [00:25<00:13, 45.31it/s][A
 64%|██████▍   | 1134/1759 [00:25<00:13, 45.09it/s][A
 65%|██████▍   | 1139/1759 [00:25<00:13, 44.98it/s][A
 65%|██████▌   | 1144/1759 [00:25<00:14, 43.33it/s][A
 65%|██████▌   | 1149/1759 [00:25<00:13, 43.90it/s][A
 66%|██████▌   | 1154/1759 [00:25<00:13, 44.33it/s][A
 66%|██████▌   | 1159/1759 [00:25<00:13, 44.59it/s][A
 66%|██████▌   | 1164/1759 [00:26<00:13, 44.90it/s][A
 66%|██████▋   | 1169/1759 [00:26<00:13, 45.05it/s][A
 67%|██████▋   | 1174/1759 [00:26<00:12, 45.12it/s][A
 67%|██████▋   | 1179/1759 [00:26<00:12, 45.01it/s][A
 67%|██████▋   | 1184/1759 [00:26<00:12, 44.73it/s][A
 68%|██████▊   | 1189/1759 [00:26<00:12, 44.72it/s][A
 68%|██████▊   | 1194/1759 [00:26<00:12, 44.89it/s][A
 68%|██████▊   | 1199/1759 [00:26<00:12, 44.94it/s][A
 68%|██████▊   | 1204/1759 [00:26<00:12, 44.98it/s][A
 69%|██████▊   | 1209/1759 [00:27<00:12, 45.12it/s][A
 69%|██████▉   | 1214/1759 [00:27<00:12, 45.24it/s][A
 69%|██████▉   | 1219/1759 [00:27<00:11, 45.22it/s][A
 70%|██████▉   | 1224/1759 [00:27<00:11, 45.02it/s][A
 70%|██████▉   | 1229/1759 [00:27<00:11, 44.91it/s][A
 70%|███████   | 1234/1759 [00:27<00:11, 44.91it/s][A
 70%|███████   | 1239/1759 [00:27<00:11, 44.93it/s][A
 71%|███████   | 1244/1759 [00:27<00:11, 44.96it/s][A
 71%|███████   | 1249/1759 [00:27<00:11, 44.98it/s][A
 71%|███████▏  | 1254/1759 [00:28<00:11, 45.18it/s][A
 72%|███████▏  | 1259/1759 [00:28<00:11, 45.29it/s][A
 72%|███████▏  | 1264/1759 [00:28<00:10, 45.13it/s][A
 72%|███████▏  | 1269/1759 [00:28<00:10, 44.98it/s][A
 72%|███████▏  | 1274/1759 [00:28<00:10, 44.95it/s][A
 73%|███████▎  | 1279/1759 [00:28<00:11, 43.23it/s][A
 73%|███████▎  | 1284/1759 [00:28<00:10, 43.88it/s][A
 73%|███████▎  | 1289/1759 [00:28<00:10, 44.33it/s][A
 74%|███████▎  | 1294/1759 [00:28<00:10, 44.57it/s][A
 74%|███████▍  | 1299/1759 [00:29<00:10, 44.88it/s][A
 74%|███████▍  | 1304/1759 [00:29<00:10, 45.01it/s][A
 74%|███████▍  | 1309/1759 [00:29<00:09, 45.04it/s][A
 75%|███████▍  | 1314/1759 [00:29<00:09, 44.94it/s][A
 75%|███████▍  | 1319/1759 [00:29<00:09, 44.79it/s][A
 75%|███████▌  | 1324/1759 [00:29<00:09, 44.74it/s][A
 76%|███████▌  | 1329/1759 [00:29<00:09, 44.82it/s][A
 76%|███████▌  | 1334/1759 [00:29<00:09, 45.06it/s][A
 76%|███████▌  | 1339/1759 [00:29<00:09, 45.16it/s][A
 76%|███████▋  | 1344/1759 [00:30<00:09, 45.22it/s][A
 77%|███████▋  | 1349/1759 [00:30<00:09, 45.24it/s][A
 77%|███████▋  | 1354/1759 [00:30<00:08, 45.23it/s][A
 77%|███████▋  | 1359/1759 [00:30<00:08, 45.04it/s][A
 78%|███████▊  | 1364/1759 [00:30<00:08, 44.91it/s][A
 78%|███████▊  | 1369/1759 [00:30<00:08, 44.80it/s][A
 78%|███████▊  | 1374/1759 [00:30<00:08, 44.85it/s][A
 78%|███████▊  | 1379/1759 [00:30<00:08, 44.96it/s][A
 79%|███████▊  | 1384/1759 [00:30<00:08, 45.04it/s][A
 79%|███████▉  | 1389/1759 [00:31<00:08, 45.16it/s][A
 79%|███████▉  | 1394/1759 [00:31<00:08, 45.23it/s][A
 80%|███████▉  | 1399/1759 [00:31<00:07, 45.28it/s][A
 80%|███████▉  | 1404/1759 [00:31<00:07, 45.11it/s][A
 80%|████████  | 1409/1759 [00:31<00:07, 44.86it/s][A
 80%|████████  | 1414/1759 [00:31<00:08, 42.24it/s][A
 81%|████████  | 1419/1759 [00:31<00:07, 43.22it/s][A
 81%|████████  | 1424/1759 [00:31<00:07, 43.82it/s][A
 81%|████████  | 1429/1759 [00:31<00:07, 44.26it/s][A
 82%|████████▏ | 1434/1759 [00:32<00:07, 44.55it/s][A
 82%|████████▏ | 1439/1759 [00:32<00:07, 44.89it/s][A
 82%|████████▏ | 1444/1759 [00:32<00:06, 45.04it/s][A
 82%|████████▏ | 1449/1759 [00:32<00:06, 45.03it/s][A
 83%|████████▎ | 1454/1759 [00:32<00:06, 44.65it/s][A
 83%|████████▎ | 1459/1759 [00:32<00:06, 44.37it/s][A
 83%|████████▎ | 1464/1759 [00:32<00:06, 44.83it/s][A
 84%|████████▎ | 1469/1759 [00:32<00:06, 44.93it/s][A
 84%|████████▍ | 1474/1759 [00:32<00:06, 45.07it/s][A
 84%|████████▍ | 1479/1759 [00:33<00:06, 45.05it/s][A
 84%|████████▍ | 1484/1759 [00:33<00:06, 45.12it/s][A
 85%|████████▍ | 1489/1759 [00:33<00:05, 45.17it/s][A
 85%|████████▍ | 1494/1759 [00:33<00:05, 45.02it/s][A
 85%|████████▌ | 1499/1759 [00:33<00:05, 44.83it/s][A
 86%|████████▌ | 1504/1759 [00:33<00:05, 44.74it/s][A
 86%|████████▌ | 1509/1759 [00:33<00:05, 44.78it/s][A
 86%|████████▌ | 1514/1759 [00:33<00:05, 44.95it/s][A
 86%|████████▋ | 1519/1759 [00:33<00:05, 45.06it/s][A
 87%|████████▋ | 1524/1759 [00:34<00:05, 45.21it/s][A
 87%|████████▋ | 1529/1759 [00:34<00:05, 45.22it/s][A
 87%|████████▋ | 1534/1759 [00:34<00:04, 45.14it/s][A
 87%|████████▋ | 1539/1759 [00:34<00:04, 45.03it/s][A
 88%|████████▊ | 1544/1759 [00:34<00:04, 44.88it/s][A
 88%|████████▊ | 1549/1759 [00:34<00:04, 43.17it/s][A
 88%|████████▊ | 1554/1759 [00:34<00:04, 43.78it/s][A
 89%|████████▊ | 1559/1759 [00:34<00:04, 44.17it/s][A
 89%|████████▉ | 1564/1759 [00:34<00:04, 44.53it/s][A
 89%|████████▉ | 1569/1759 [00:35<00:04, 44.81it/s][A
 89%|████████▉ | 1574/1759 [00:35<00:04, 45.03it/s][A
 90%|████████▉ | 1579/1759 [00:35<00:03, 45.05it/s][A
 90%|█████████ | 1584/1759 [00:35<00:03, 44.95it/s][A
 90%|█████████ | 1589/1759 [00:35<00:03, 44.65it/s][A
 91%|█████████ | 1594/1759 [00:35<00:03, 44.65it/s][A
 91%|█████████ | 1599/1759 [00:35<00:03, 44.75it/s][A
 91%|█████████ | 1604/1759 [00:35<00:03, 44.92it/s][A
 91%|█████████▏| 1609/1759 [00:35<00:03, 45.03it/s][A
 92%|█████████▏| 1614/1759 [00:36<00:03, 45.17it/s][A
 92%|█████████▏| 1619/1759 [00:36<00:03, 45.26it/s][A
 92%|█████████▏| 1624/1759 [00:36<00:02, 45.16it/s][A
 93%|█████████▎| 1629/1759 [00:36<00:02, 45.04it/s][A
 93%|█████████▎| 1634/1759 [00:36<00:02, 44.75it/s][A
 93%|█████████▎| 1639/1759 [00:36<00:02, 44.32it/s][A
 93%|█████████▎| 1644/1759 [00:36<00:02, 44.65it/s][A
 94%|█████████▎| 1649/1759 [00:36<00:02, 44.77it/s][A
 94%|█████████▍| 1654/1759 [00:36<00:02, 44.98it/s][A
 94%|█████████▍| 1659/1759 [00:37<00:02, 45.10it/s][A
 95%|█████████▍| 1664/1759 [00:37<00:02, 45.23it/s][A
 95%|█████████▍| 1669/1759 [00:37<00:01, 45.19it/s][A
 95%|█████████▌| 1674/1759 [00:37<00:01, 45.13it/s][A
 95%|█████████▌| 1679/1759 [00:37<00:01, 45.01it/s][A
 96%|█████████▌| 1684/1759 [00:37<00:01, 43.93it/s][A
 96%|█████████▌| 1689/1759 [00:37<00:01, 44.22it/s][A
 96%|█████████▋| 1694/1759 [00:37<00:01, 44.48it/s][A
 97%|█████████▋| 1699/1759 [00:37<00:01, 44.73it/s][A
 97%|█████████▋| 1704/1759 [00:38<00:01, 44.91it/s][A
 97%|█████████▋| 1709/1759 [00:38<00:01, 44.98it/s][A
 97%|█████████▋| 1714/1759 [00:38<00:01, 44.98it/s][A
 98%|█████████▊| 1719/1759 [00:38<00:00, 44.94it/s][A
 98%|█████████▊| 1724/1759 [00:38<00:00, 44.76it/s][A
 98%|█████████▊| 1729/1759 [00:38<00:00, 44.85it/s][A
 99%|█████████▊| 1734/1759 [00:38<00:00, 44.86it/s][A
 99%|█████████▉| 1739/1759 [00:38<00:00, 44.94it/s][A
 99%|█████████▉| 1744/1759 [00:38<00:00, 45.01it/s][A
 99%|█████████▉| 1749/1759 [00:39<00:00, 45.17it/s][A
100%|█████████▉| 1754/1759 [00:39<00:00, 45.11it/s][A
100%|██████████| 1759/1759 [00:39<00:00, 45.14it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 45.14it/s][A100%|██████████| 235/235 [05:38<00:00,  3.41it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 11:02:34,554 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-235
[INFO|configuration_utils.py:351] 2023-08-29 11:02:34,743 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-235/config.json
[INFO|modeling_utils.py:886] 2023-08-29 11:02:38,482 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-235/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 11:02:38,619 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-235/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 11:02:38,705 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-235/special_tokens_map.json
[INFO|trainer.py:1343] 2023-08-29 11:02:47,456 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:1352] 2023-08-29 11:02:47,457 >> Loading best model from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-47 (score: 0.9230651259422302).
                                                 100%|██████████| 235/235 [06:02<00:00,  3.41it/s]100%|██████████| 235/235 [06:02<00:00,  1.54s/it]
[INFO|trainer.py:1894] 2023-08-29 11:02:58,046 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model
[INFO|configuration_utils.py:351] 2023-08-29 11:02:58,156 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/config.json
[INFO|modeling_utils.py:886] 2023-08-29 11:03:03,061 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 11:03:03,531 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 11:03:03,740 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/special_tokens_map.json
[INFO|trainer_pt_utils.py:908] 2023-08-29 11:03:04,714 >> ***** train metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:04,714 >>   epoch                    =        5.0
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:04,714 >>   train_loss               =     0.4094
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:04,714 >>   train_runtime            = 0:06:02.62
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:04,715 >>   train_samples            =       3000
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:04,715 >>   train_samples_per_second =     41.365
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:04,715 >>   train_steps_per_second   =      0.648
{'eval_loss': 0.9644681811332703, 'eval_runtime': 39.3922, 'eval_samples_per_second': 357.102, 'eval_steps_per_second': 44.654, 'epoch': 5.0}
{'train_runtime': 362.6238, 'train_samples_per_second': 41.365, 'train_steps_per_second': 0.648, 'train_loss': 0.40936142941738696, 'epoch': 5.0}
08/29/2023 11:03:05 - INFO - transformer_base.run_clm_rl -   *** Evaluate ***
[INFO|trainer.py:2140] 2023-08-29 11:03:05,324 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 11:03:05,324 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 11:03:05,324 >>   Batch size = 8
  0%|          | 0/1759 [00:00<?, ?it/s]  0%|          | 6/1759 [00:00<00:31, 55.63it/s]  1%|          | 12/1759 [00:00<00:35, 49.53it/s]  1%|          | 17/1759 [00:00<00:36, 47.92it/s]  1%|▏         | 22/1759 [00:00<00:36, 47.05it/s]  2%|▏         | 27/1759 [00:00<00:37, 46.51it/s]  2%|▏         | 32/1759 [00:00<00:37, 46.25it/s]  2%|▏         | 37/1759 [00:00<00:37, 46.05it/s]  2%|▏         | 42/1759 [00:00<00:46, 37.30it/s]  3%|▎         | 47/1759 [00:01<00:43, 39.52it/s]  3%|▎         | 52/1759 [00:01<00:41, 41.23it/s]  3%|▎         | 57/1759 [00:01<00:40, 42.46it/s]  4%|▎         | 62/1759 [00:01<00:39, 43.43it/s]  4%|▍         | 67/1759 [00:01<00:38, 44.03it/s]  4%|▍         | 72/1759 [00:01<00:37, 44.57it/s]  4%|▍         | 77/1759 [00:01<00:37, 44.80it/s]  5%|▍         | 82/1759 [00:01<00:37, 44.68it/s]  5%|▍         | 87/1759 [00:01<00:37, 44.61it/s]  5%|▌         | 92/1759 [00:02<00:37, 44.77it/s]  6%|▌         | 97/1759 [00:02<00:36, 45.04it/s]  6%|▌         | 102/1759 [00:02<00:36, 45.22it/s]  6%|▌         | 107/1759 [00:02<00:36, 45.29it/s]  6%|▋         | 112/1759 [00:02<00:36, 45.33it/s]  7%|▋         | 117/1759 [00:02<00:36, 45.45it/s]  7%|▋         | 122/1759 [00:02<00:36, 45.33it/s]  7%|▋         | 127/1759 [00:02<00:36, 45.06it/s]  8%|▊         | 132/1759 [00:02<00:36, 44.91it/s]  8%|▊         | 137/1759 [00:03<00:36, 45.00it/s]  8%|▊         | 142/1759 [00:03<00:35, 45.12it/s]  8%|▊         | 147/1759 [00:03<00:35, 45.15it/s]  9%|▊         | 152/1759 [00:03<00:35, 45.32it/s]  9%|▉         | 157/1759 [00:03<00:35, 45.40it/s]  9%|▉         | 162/1759 [00:03<00:35, 45.44it/s]  9%|▉         | 167/1759 [00:03<00:35, 45.22it/s] 10%|▉         | 172/1759 [00:03<00:35, 44.96it/s] 10%|█         | 177/1759 [00:04<00:39, 39.92it/s] 10%|█         | 182/1759 [00:04<00:37, 41.54it/s] 11%|█         | 187/1759 [00:04<00:36, 42.60it/s] 11%|█         | 192/1759 [00:04<00:35, 43.57it/s] 11%|█         | 197/1759 [00:04<00:35, 44.13it/s] 11%|█▏        | 202/1759 [00:04<00:34, 44.61it/s] 12%|█▏        | 207/1759 [00:04<00:34, 44.88it/s] 12%|█▏        | 212/1759 [00:04<00:34, 45.07it/s] 12%|█▏        | 217/1759 [00:04<00:34, 44.77it/s] 13%|█▎        | 222/1759 [00:04<00:34, 44.69it/s] 13%|█▎        | 227/1759 [00:05<00:34, 44.79it/s] 13%|█▎        | 232/1759 [00:05<00:33, 45.04it/s] 13%|█▎        | 237/1759 [00:05<00:33, 45.19it/s] 14%|█▍        | 242/1759 [00:05<00:33, 45.39it/s] 14%|█▍        | 247/1759 [00:05<00:33, 45.37it/s] 14%|█▍        | 252/1759 [00:05<00:33, 45.48it/s] 15%|█▍        | 257/1759 [00:05<00:33, 45.33it/s] 15%|█▍        | 262/1759 [00:05<00:33, 45.11it/s] 15%|█▌        | 267/1759 [00:05<00:33, 45.00it/s] 15%|█▌        | 272/1759 [00:06<00:33, 45.00it/s] 16%|█▌        | 277/1759 [00:06<00:32, 45.03it/s] 16%|█▌        | 282/1759 [00:06<00:32, 45.18it/s] 16%|█▋        | 287/1759 [00:06<00:32, 45.30it/s] 17%|█▋        | 292/1759 [00:06<00:32, 45.31it/s] 17%|█▋        | 297/1759 [00:06<00:32, 45.42it/s] 17%|█▋        | 302/1759 [00:06<00:32, 45.23it/s] 17%|█▋        | 307/1759 [00:06<00:32, 45.01it/s] 18%|█▊        | 312/1759 [00:07<00:33, 43.15it/s] 18%|█▊        | 317/1759 [00:07<00:32, 43.78it/s] 18%|█▊        | 322/1759 [00:07<00:32, 44.23it/s] 19%|█▊        | 327/1759 [00:07<00:32, 44.65it/s] 19%|█▉        | 332/1759 [00:07<00:31, 44.82it/s] 19%|█▉        | 337/1759 [00:07<00:31, 45.10it/s] 19%|█▉        | 342/1759 [00:07<00:31, 45.15it/s] 20%|█▉        | 347/1759 [00:07<00:31, 45.23it/s] 20%|██        | 352/1759 [00:07<00:31, 44.94it/s] 20%|██        | 357/1759 [00:07<00:31, 44.88it/s] 21%|██        | 362/1759 [00:08<00:31, 44.99it/s] 21%|██        | 367/1759 [00:08<00:30, 45.05it/s] 21%|██        | 372/1759 [00:08<00:30, 45.20it/s] 21%|██▏       | 377/1759 [00:08<00:30, 45.21it/s] 22%|██▏       | 382/1759 [00:08<00:30, 45.39it/s] 22%|██▏       | 387/1759 [00:08<00:30, 45.32it/s] 22%|██▏       | 392/1759 [00:08<00:30, 45.22it/s] 23%|██▎       | 397/1759 [00:08<00:30, 44.97it/s] 23%|██▎       | 402/1759 [00:08<00:30, 44.98it/s] 23%|██▎       | 407/1759 [00:09<00:30, 44.96it/s] 23%|██▎       | 412/1759 [00:09<00:29, 44.96it/s] 24%|██▎       | 417/1759 [00:09<00:29, 45.14it/s] 24%|██▍       | 422/1759 [00:09<00:29, 45.19it/s] 24%|██▍       | 427/1759 [00:09<00:29, 45.34it/s] 25%|██▍       | 432/1759 [00:09<00:29, 45.35it/s] 25%|██▍       | 437/1759 [00:09<00:29, 45.23it/s] 25%|██▌       | 442/1759 [00:09<00:29, 45.02it/s] 25%|██▌       | 447/1759 [00:10<00:30, 43.13it/s] 26%|██▌       | 452/1759 [00:10<00:29, 43.72it/s] 26%|██▌       | 457/1759 [00:10<00:29, 44.20it/s] 26%|██▋       | 462/1759 [00:10<00:29, 44.47it/s] 27%|██▋       | 467/1759 [00:10<00:28, 44.81it/s] 27%|██▋       | 472/1759 [00:10<00:28, 44.94it/s] 27%|██▋       | 477/1759 [00:10<00:28, 44.95it/s] 27%|██▋       | 482/1759 [00:10<00:28, 44.96it/s] 28%|██▊       | 487/1759 [00:10<00:28, 44.73it/s] 28%|██▊       | 492/1759 [00:11<00:28, 44.81it/s] 28%|██▊       | 497/1759 [00:11<00:28, 44.96it/s] 29%|██▊       | 502/1759 [00:11<00:27, 45.03it/s] 29%|██▉       | 507/1759 [00:11<00:27, 45.14it/s] 29%|██▉       | 512/1759 [00:11<00:27, 45.17it/s] 29%|██▉       | 517/1759 [00:11<00:27, 45.20it/s] 30%|██▉       | 522/1759 [00:11<00:27, 45.23it/s] 30%|██▉       | 527/1759 [00:11<00:27, 45.02it/s] 30%|███       | 532/1759 [00:11<00:27, 44.88it/s] 31%|███       | 537/1759 [00:12<00:27, 44.92it/s] 31%|███       | 542/1759 [00:12<00:27, 45.07it/s] 31%|███       | 547/1759 [00:12<00:26, 45.12it/s] 31%|███▏      | 552/1759 [00:12<00:26, 45.17it/s] 32%|███▏      | 557/1759 [00:12<00:26, 45.15it/s] 32%|███▏      | 562/1759 [00:12<00:26, 45.21it/s] 32%|███▏      | 567/1759 [00:12<00:26, 45.14it/s] 33%|███▎      | 572/1759 [00:12<00:26, 45.03it/s] 33%|███▎      | 577/1759 [00:12<00:26, 44.82it/s] 33%|███▎      | 582/1759 [00:13<00:26, 44.88it/s] 33%|███▎      | 587/1759 [00:13<00:26, 45.04it/s] 34%|███▎      | 592/1759 [00:13<00:25, 45.03it/s] 34%|███▍      | 597/1759 [00:13<00:25, 45.14it/s] 34%|███▍      | 602/1759 [00:13<00:25, 45.13it/s] 35%|███▍      | 607/1759 [00:13<00:25, 45.26it/s] 35%|███▍      | 612/1759 [00:13<00:26, 42.53it/s] 35%|███▌      | 617/1759 [00:13<00:26, 43.27it/s] 35%|███▌      | 622/1759 [00:13<00:25, 43.77it/s] 36%|███▌      | 627/1759 [00:14<00:25, 44.15it/s] 36%|███▌      | 632/1759 [00:14<00:25, 44.47it/s] 36%|███▌      | 637/1759 [00:14<00:25, 44.72it/s] 36%|███▋      | 642/1759 [00:14<00:24, 44.81it/s] 37%|███▋      | 647/1759 [00:14<00:24, 44.98it/s] 37%|███▋      | 652/1759 [00:14<00:24, 44.77it/s] 37%|███▋      | 657/1759 [00:14<00:24, 44.89it/s] 38%|███▊      | 662/1759 [00:14<00:24, 44.92it/s] 38%|███▊      | 667/1759 [00:14<00:24, 44.99it/s] 38%|███▊      | 672/1759 [00:15<00:24, 45.04it/s] 38%|███▊      | 677/1759 [00:15<00:23, 45.12it/s] 39%|███▉      | 682/1759 [00:15<00:23, 45.15it/s] 39%|███▉      | 687/1759 [00:15<00:23, 45.19it/s] 39%|███▉      | 692/1759 [00:15<00:23, 45.09it/s] 40%|███▉      | 697/1759 [00:15<00:23, 44.92it/s] 40%|███▉      | 702/1759 [00:15<00:23, 44.93it/s] 40%|████      | 707/1759 [00:15<00:23, 44.89it/s] 40%|████      | 712/1759 [00:15<00:23, 44.94it/s] 41%|████      | 717/1759 [00:16<00:23, 44.99it/s] 41%|████      | 722/1759 [00:16<00:23, 45.08it/s] 41%|████▏     | 727/1759 [00:16<00:22, 45.14it/s] 42%|████▏     | 732/1759 [00:16<00:22, 45.07it/s] 42%|████▏     | 737/1759 [00:16<00:22, 45.06it/s] 42%|████▏     | 742/1759 [00:16<00:22, 44.95it/s] 42%|████▏     | 747/1759 [00:16<00:23, 42.58it/s] 43%|████▎     | 752/1759 [00:16<00:23, 43.36it/s] 43%|████▎     | 757/1759 [00:16<00:22, 43.95it/s] 43%|████▎     | 762/1759 [00:17<00:22, 44.27it/s] 44%|████▎     | 767/1759 [00:17<00:22, 44.61it/s] 44%|████▍     | 772/1759 [00:17<00:22, 44.70it/s] 44%|████▍     | 777/1759 [00:17<00:21, 44.84it/s] 44%|████▍     | 782/1759 [00:17<00:21, 44.80it/s] 45%|████▍     | 787/1759 [00:17<00:21, 44.64it/s] 45%|████▌     | 792/1759 [00:17<00:21, 44.69it/s] 45%|████▌     | 797/1759 [00:17<00:21, 44.83it/s] 46%|████▌     | 802/1759 [00:17<00:21, 45.02it/s] 46%|████▌     | 807/1759 [00:18<00:21, 45.08it/s] 46%|████▌     | 812/1759 [00:18<00:20, 45.17it/s] 46%|████▋     | 817/1759 [00:18<00:20, 45.15it/s] 47%|████▋     | 822/1759 [00:18<00:20, 45.10it/s] 47%|████▋     | 827/1759 [00:18<00:20, 44.95it/s] 47%|████▋     | 832/1759 [00:18<00:20, 44.72it/s] 48%|████▊     | 837/1759 [00:18<00:20, 44.83it/s] 48%|████▊     | 842/1759 [00:18<00:20, 44.80it/s] 48%|████▊     | 847/1759 [00:18<00:20, 44.97it/s] 48%|████▊     | 852/1759 [00:19<00:20, 45.13it/s] 49%|████▊     | 857/1759 [00:19<00:19, 45.20it/s] 49%|████▉     | 862/1759 [00:19<00:19, 45.12it/s] 49%|████▉     | 867/1759 [00:19<00:19, 45.09it/s] 50%|████▉     | 872/1759 [00:19<00:19, 44.97it/s] 50%|████▉     | 877/1759 [00:19<00:19, 44.82it/s] 50%|█████     | 882/1759 [00:19<00:21, 40.42it/s] 50%|█████     | 887/1759 [00:19<00:20, 41.83it/s] 51%|█████     | 892/1759 [00:19<00:20, 42.83it/s] 51%|█████     | 897/1759 [00:20<00:19, 43.58it/s] 51%|█████▏    | 902/1759 [00:20<00:19, 44.10it/s] 52%|█████▏    | 907/1759 [00:20<00:19, 44.41it/s] 52%|█████▏    | 912/1759 [00:20<00:18, 44.72it/s] 52%|█████▏    | 917/1759 [00:20<00:18, 44.94it/s] 52%|█████▏    | 922/1759 [00:20<00:18, 44.54it/s] 53%|█████▎    | 927/1759 [00:20<00:18, 44.67it/s] 53%|█████▎    | 932/1759 [00:20<00:18, 44.63it/s] 53%|█████▎    | 937/1759 [00:20<00:18, 44.97it/s] 54%|█████▎    | 942/1759 [00:21<00:18, 45.07it/s] 54%|█████▍    | 947/1759 [00:21<00:18, 45.09it/s] 54%|█████▍    | 952/1759 [00:21<00:17, 45.10it/s] 54%|█████▍    | 957/1759 [00:21<00:17, 45.10it/s] 55%|█████▍    | 962/1759 [00:21<00:17, 45.02it/s] 55%|█████▍    | 967/1759 [00:21<00:17, 44.79it/s] 55%|█████▌    | 972/1759 [00:21<00:17, 44.78it/s] 56%|█████▌    | 977/1759 [00:21<00:17, 44.76it/s] 56%|█████▌    | 982/1759 [00:21<00:17, 45.01it/s] 56%|█████▌    | 987/1759 [00:22<00:17, 45.07it/s] 56%|█████▋    | 992/1759 [00:22<00:16, 45.18it/s] 57%|█████▋    | 997/1759 [00:22<00:16, 45.11it/s] 57%|█████▋    | 1002/1759 [00:22<00:16, 45.18it/s] 57%|█████▋    | 1007/1759 [00:22<00:16, 45.07it/s] 58%|█████▊    | 1012/1759 [00:22<00:16, 44.82it/s] 58%|█████▊    | 1017/1759 [00:22<00:18, 40.57it/s] 58%|█████▊    | 1022/1759 [00:22<00:17, 41.92it/s] 58%|█████▊    | 1027/1759 [00:23<00:17, 42.92it/s] 59%|█████▊    | 1032/1759 [00:23<00:16, 43.62it/s] 59%|█████▉    | 1037/1759 [00:23<00:16, 44.11it/s] 59%|█████▉    | 1042/1759 [00:23<00:16, 44.48it/s] 60%|█████▉    | 1047/1759 [00:23<00:15, 44.78it/s] 60%|█████▉    | 1052/1759 [00:23<00:15, 44.90it/s] 60%|██████    | 1057/1759 [00:23<00:15, 44.59it/s] 60%|██████    | 1062/1759 [00:23<00:15, 44.51it/s] 61%|██████    | 1067/1759 [00:23<00:15, 44.65it/s] 61%|██████    | 1072/1759 [00:24<00:15, 44.86it/s] 61%|██████    | 1077/1759 [00:24<00:15, 44.90it/s] 62%|██████▏   | 1082/1759 [00:24<00:15, 45.12it/s] 62%|██████▏   | 1087/1759 [00:24<00:14, 45.17it/s] 62%|██████▏   | 1092/1759 [00:24<00:14, 45.34it/s] 62%|██████▏   | 1097/1759 [00:24<00:14, 45.22it/s] 63%|██████▎   | 1102/1759 [00:24<00:14, 44.97it/s] 63%|██████▎   | 1107/1759 [00:24<00:14, 44.90it/s] 63%|██████▎   | 1112/1759 [00:24<00:14, 44.92it/s] 64%|██████▎   | 1117/1759 [00:25<00:14, 44.95it/s] 64%|██████▍   | 1122/1759 [00:25<00:14, 45.14it/s] 64%|██████▍   | 1127/1759 [00:25<00:13, 45.19it/s] 64%|██████▍   | 1132/1759 [00:25<00:13, 45.31it/s] 65%|██████▍   | 1137/1759 [00:25<00:13, 45.34it/s] 65%|██████▍   | 1142/1759 [00:25<00:13, 45.36it/s] 65%|██████▌   | 1147/1759 [00:25<00:13, 45.22it/s] 65%|██████▌   | 1152/1759 [00:25<00:13, 43.61it/s] 66%|██████▌   | 1157/1759 [00:25<00:13, 44.03it/s] 66%|██████▌   | 1162/1759 [00:26<00:13, 44.46it/s] 66%|██████▋   | 1167/1759 [00:26<00:13, 44.74it/s] 67%|██████▋   | 1172/1759 [00:26<00:13, 42.07it/s] 67%|██████▋   | 1178/1759 [00:26<00:13, 44.41it/s] 67%|██████▋   | 1183/1759 [00:26<00:12, 44.76it/s] 68%|██████▊   | 1188/1759 [00:26<00:12, 44.93it/s] 68%|██████▊   | 1193/1759 [00:26<00:12, 44.89it/s] 68%|██████▊   | 1198/1759 [00:26<00:12, 44.96it/s] 68%|██████▊   | 1203/1759 [00:26<00:12, 45.02it/s] 69%|██████▊   | 1208/1759 [00:27<00:12, 45.11it/s] 69%|██████▉   | 1213/1759 [00:27<00:12, 45.11it/s] 69%|██████▉   | 1218/1759 [00:27<00:12, 45.05it/s] 70%|██████▉   | 1223/1759 [00:27<00:11, 45.08it/s] 70%|██████▉   | 1228/1759 [00:27<00:11, 45.14it/s] 70%|███████   | 1233/1759 [00:27<00:11, 45.13it/s] 70%|███████   | 1238/1759 [00:27<00:11, 45.00it/s] 71%|███████   | 1243/1759 [00:27<00:11, 45.03it/s] 71%|███████   | 1248/1759 [00:27<00:11, 45.05it/s] 71%|███████   | 1253/1759 [00:28<00:11, 45.22it/s] 72%|███████▏  | 1258/1759 [00:28<00:11, 45.16it/s] 72%|███████▏  | 1263/1759 [00:28<00:11, 45.08it/s] 72%|███████▏  | 1268/1759 [00:28<00:10, 45.10it/s] 72%|███████▏  | 1273/1759 [00:28<00:10, 45.20it/s] 73%|███████▎  | 1278/1759 [00:28<00:10, 45.19it/s] 73%|███████▎  | 1283/1759 [00:28<00:10, 45.11it/s] 73%|███████▎  | 1288/1759 [00:28<00:11, 40.52it/s] 74%|███████▎  | 1293/1759 [00:28<00:11, 42.00it/s] 74%|███████▍  | 1298/1759 [00:29<00:10, 43.03it/s] 74%|███████▍  | 1303/1759 [00:29<00:10, 43.80it/s] 74%|███████▍  | 1308/1759 [00:29<00:10, 44.39it/s] 75%|███████▍  | 1313/1759 [00:29<00:09, 44.72it/s] 75%|███████▍  | 1318/1759 [00:29<00:09, 44.93it/s] 75%|███████▌  | 1323/1759 [00:29<00:09, 44.95it/s] 75%|███████▌  | 1328/1759 [00:29<00:09, 44.70it/s] 76%|███████▌  | 1333/1759 [00:29<00:09, 44.50it/s] 76%|███████▌  | 1338/1759 [00:29<00:09, 44.66it/s] 76%|███████▋  | 1343/1759 [00:30<00:09, 44.89it/s] 77%|███████▋  | 1348/1759 [00:30<00:09, 45.15it/s] 77%|███████▋  | 1353/1759 [00:30<00:08, 45.34it/s] 77%|███████▋  | 1358/1759 [00:30<00:08, 45.45it/s] 77%|███████▋  | 1363/1759 [00:30<00:08, 45.38it/s] 78%|███████▊  | 1368/1759 [00:30<00:08, 45.16it/s] 78%|███████▊  | 1373/1759 [00:30<00:08, 45.02it/s] 78%|███████▊  | 1378/1759 [00:30<00:08, 44.78it/s] 79%|███████▊  | 1383/1759 [00:30<00:08, 44.81it/s] 79%|███████▉  | 1388/1759 [00:31<00:08, 44.85it/s] 79%|███████▉  | 1393/1759 [00:31<00:08, 45.02it/s] 79%|███████▉  | 1398/1759 [00:31<00:07, 45.18it/s] 80%|███████▉  | 1403/1759 [00:31<00:07, 45.28it/s] 80%|████████  | 1408/1759 [00:31<00:07, 45.41it/s] 80%|████████  | 1413/1759 [00:31<00:07, 45.32it/s] 81%|████████  | 1418/1759 [00:31<00:07, 45.13it/s] 81%|████████  | 1423/1759 [00:31<00:07, 43.45it/s] 81%|████████  | 1428/1759 [00:31<00:07, 43.93it/s] 81%|████████▏ | 1433/1759 [00:32<00:07, 44.22it/s] 82%|████████▏ | 1438/1759 [00:32<00:07, 44.57it/s] 82%|████████▏ | 1443/1759 [00:32<00:07, 44.74it/s] 82%|████████▏ | 1448/1759 [00:32<00:06, 44.95it/s] 83%|████████▎ | 1453/1759 [00:32<00:06, 45.16it/s] 83%|████████▎ | 1458/1759 [00:32<00:06, 45.31it/s] 83%|████████▎ | 1463/1759 [00:32<00:06, 45.03it/s] 83%|████████▎ | 1468/1759 [00:32<00:06, 44.92it/s] 84%|████████▎ | 1473/1759 [00:32<00:06, 44.99it/s] 84%|████████▍ | 1478/1759 [00:33<00:06, 44.89it/s] 84%|████████▍ | 1483/1759 [00:33<00:06, 45.04it/s] 85%|████████▍ | 1488/1759 [00:33<00:06, 45.07it/s] 85%|████████▍ | 1493/1759 [00:33<00:05, 45.18it/s] 85%|████████▌ | 1498/1759 [00:33<00:05, 45.25it/s] 85%|████████▌ | 1503/1759 [00:33<00:05, 45.23it/s] 86%|████████▌ | 1508/1759 [00:33<00:05, 45.00it/s] 86%|████████▌ | 1513/1759 [00:33<00:05, 44.90it/s] 86%|████████▋ | 1518/1759 [00:33<00:05, 42.39it/s] 87%|████████▋ | 1523/1759 [00:34<00:05, 43.32it/s] 87%|████████▋ | 1528/1759 [00:34<00:05, 43.96it/s] 87%|████████▋ | 1533/1759 [00:34<00:05, 44.36it/s] 87%|████████▋ | 1538/1759 [00:34<00:04, 44.74it/s] 88%|████████▊ | 1543/1759 [00:34<00:04, 44.87it/s] 88%|████████▊ | 1548/1759 [00:34<00:04, 45.06it/s] 88%|████████▊ | 1553/1759 [00:34<00:04, 45.09it/s] 89%|████████▊ | 1558/1759 [00:34<00:04, 42.38it/s] 89%|████████▉ | 1563/1759 [00:34<00:04, 43.26it/s] 89%|████████▉ | 1568/1759 [00:35<00:04, 43.84it/s] 89%|████████▉ | 1573/1759 [00:35<00:04, 44.28it/s] 90%|████████▉ | 1578/1759 [00:35<00:04, 44.64it/s] 90%|████████▉ | 1583/1759 [00:35<00:03, 44.85it/s] 90%|█████████ | 1588/1759 [00:35<00:03, 44.93it/s] 91%|█████████ | 1593/1759 [00:35<00:03, 44.97it/s] 91%|█████████ | 1598/1759 [00:35<00:03, 44.69it/s] 91%|█████████ | 1603/1759 [00:35<00:03, 44.67it/s] 91%|█████████▏| 1608/1759 [00:35<00:03, 44.88it/s] 92%|█████████▏| 1613/1759 [00:36<00:03, 45.03it/s] 92%|█████████▏| 1618/1759 [00:36<00:03, 45.16it/s] 92%|█████████▏| 1623/1759 [00:36<00:03, 45.22it/s] 93%|█████████▎| 1628/1759 [00:36<00:02, 45.27it/s] 93%|█████████▎| 1633/1759 [00:36<00:02, 45.25it/s] 93%|█████████▎| 1638/1759 [00:36<00:02, 45.21it/s] 93%|█████████▎| 1643/1759 [00:36<00:02, 45.05it/s] 94%|█████████▎| 1648/1759 [00:36<00:02, 44.91it/s] 94%|█████████▍| 1653/1759 [00:36<00:02, 44.98it/s] 94%|█████████▍| 1658/1759 [00:37<00:02, 45.15it/s] 95%|█████████▍| 1663/1759 [00:37<00:02, 45.20it/s] 95%|█████████▍| 1668/1759 [00:37<00:02, 45.25it/s] 95%|█████████▌| 1673/1759 [00:37<00:01, 45.24it/s] 95%|█████████▌| 1678/1759 [00:37<00:01, 45.33it/s] 96%|█████████▌| 1683/1759 [00:37<00:01, 45.23it/s] 96%|█████████▌| 1688/1759 [00:37<00:01, 45.10it/s] 96%|█████████▌| 1693/1759 [00:37<00:01, 43.38it/s] 97%|█████████▋| 1698/1759 [00:38<00:01, 43.96it/s] 97%|█████████▋| 1703/1759 [00:38<00:01, 44.41it/s] 97%|█████████▋| 1708/1759 [00:38<00:01, 44.68it/s] 97%|█████████▋| 1713/1759 [00:38<00:01, 44.92it/s] 98%|█████████▊| 1718/1759 [00:38<00:00, 45.10it/s] 98%|█████████▊| 1723/1759 [00:38<00:00, 45.16it/s] 98%|█████████▊| 1728/1759 [00:38<00:00, 45.12it/s] 99%|█████████▊| 1733/1759 [00:38<00:00, 44.90it/s] 99%|█████████▉| 1738/1759 [00:38<00:00, 44.81it/s] 99%|█████████▉| 1743/1759 [00:38<00:00, 44.95it/s] 99%|█████████▉| 1748/1759 [00:39<00:00, 45.15it/s]100%|█████████▉| 1753/1759 [00:39<00:00, 45.10it/s]100%|█████████▉| 1758/1759 [00:39<00:00, 45.19it/s]100%|██████████| 1759/1759 [00:39<00:00, 44.70it/s]
[INFO|trainer_pt_utils.py:908] 2023-08-29 11:03:44,694 >> ***** eval metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:44,694 >>   epoch                   =        5.0
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:44,695 >>   eval_loss               =     0.9231
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:44,695 >>   eval_runtime            = 0:00:39.37
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:44,695 >>   eval_samples            =      14067
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:44,695 >>   eval_samples_per_second =    357.301
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:44,695 >>   eval_steps_per_second   =     44.678
[INFO|trainer_pt_utils.py:913] 2023-08-29 11:03:44,695 >>   perplexity              =      2.517
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:04:58,527 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:04:58,548 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:04:58,548 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:04:58,548 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:04:58,548 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 11:04:59,457 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 11:04:59,458 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:05:00,097 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 11:05:13,875 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:05:13,903 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:05:15,827 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:05:15,829 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:05:15,829 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:05:15,829 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:05:15,829 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 11:05:16,509 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 11:05:16,511 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:05:16,833 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 11:05:18,485 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:05:18,518 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-235
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-188
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-141
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-47
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/checkpoint-94
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl', 'labels': ['country', 'part of', 'platform', 'publisher', 'sport'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_in_all_single_is_eval_True.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_out_filter_all_single_is_eval_True.jsonl'}}
predict vocab size: 22024
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 22124, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:01,  1.11s/it]Extractor Predicting: 2it [00:01,  1.21it/s]Extractor Predicting: 3it [00:02,  1.35it/s]Extractor Predicting: 4it [00:02,  1.48it/s]Extractor Predicting: 5it [00:03,  1.55it/s]Extractor Predicting: 6it [00:04,  1.60it/s]Extractor Predicting: 7it [00:04,  1.63it/s]Extractor Predicting: 8it [00:05,  1.63it/s]Extractor Predicting: 9it [00:05,  1.62it/s]Extractor Predicting: 10it [00:06,  1.58it/s]Extractor Predicting: 11it [00:07,  1.57it/s]Extractor Predicting: 12it [00:07,  1.55it/s]Extractor Predicting: 13it [00:08,  1.52it/s]Extractor Predicting: 14it [00:09,  1.49it/s]Extractor Predicting: 15it [00:10,  1.47it/s]Extractor Predicting: 16it [00:10,  1.47it/s]Extractor Predicting: 17it [00:11,  1.48it/s]Extractor Predicting: 18it [00:12,  1.48it/s]Extractor Predicting: 19it [00:12,  1.50it/s]Extractor Predicting: 20it [00:13,  1.49it/s]Extractor Predicting: 21it [00:14,  1.47it/s]Extractor Predicting: 22it [00:14,  1.48it/s]Extractor Predicting: 23it [00:15,  1.46it/s]Extractor Predicting: 24it [00:16,  1.49it/s]Extractor Predicting: 25it [00:16,  1.54it/s]Extractor Predicting: 26it [00:17,  1.52it/s]Extractor Predicting: 27it [00:18,  1.53it/s]Extractor Predicting: 28it [00:18,  1.58it/s]Extractor Predicting: 29it [00:19,  1.61it/s]Extractor Predicting: 30it [00:19,  1.62it/s]Extractor Predicting: 31it [00:20,  1.64it/s]Extractor Predicting: 32it [00:21,  1.60it/s]Extractor Predicting: 33it [00:21,  1.63it/s]Extractor Predicting: 34it [00:22,  1.64it/s]Extractor Predicting: 35it [00:22,  1.65it/s]Extractor Predicting: 36it [00:23,  1.63it/s]Extractor Predicting: 37it [00:24,  1.50it/s]Extractor Predicting: 38it [00:24,  1.54it/s]Extractor Predicting: 39it [00:25,  1.55it/s]Extractor Predicting: 40it [00:26,  1.59it/s]Extractor Predicting: 41it [00:26,  1.54it/s]Extractor Predicting: 42it [00:27,  1.58it/s]Extractor Predicting: 43it [00:27,  1.61it/s]Extractor Predicting: 44it [00:28,  1.63it/s]Extractor Predicting: 45it [00:29,  1.64it/s]Extractor Predicting: 46it [00:29,  1.63it/s]Extractor Predicting: 47it [00:30,  1.64it/s]Extractor Predicting: 48it [00:31,  1.61it/s]Extractor Predicting: 49it [00:31,  1.67it/s]Extractor Predicting: 50it [00:32,  1.66it/s]Extractor Predicting: 51it [00:32,  1.67it/s]Extractor Predicting: 52it [00:33,  1.67it/s]Extractor Predicting: 53it [00:33,  1.68it/s]Extractor Predicting: 54it [00:34,  1.68it/s]Extractor Predicting: 55it [00:35,  1.68it/s]Extractor Predicting: 56it [00:35,  1.67it/s]Extractor Predicting: 57it [00:36,  1.65it/s]Extractor Predicting: 58it [00:37,  1.65it/s]Extractor Predicting: 59it [00:37,  1.63it/s]Extractor Predicting: 60it [00:38,  1.66it/s]Extractor Predicting: 61it [00:38,  1.66it/s]Extractor Predicting: 62it [00:39,  1.62it/s]Extractor Predicting: 63it [00:40,  1.59it/s]Extractor Predicting: 64it [00:40,  1.59it/s]Extractor Predicting: 65it [00:41,  1.58it/s]Extractor Predicting: 66it [00:42,  1.58it/s]Extractor Predicting: 67it [00:42,  1.58it/s]Extractor Predicting: 68it [00:43,  1.54it/s]Extractor Predicting: 69it [00:43,  1.59it/s]Extractor Predicting: 70it [00:44,  1.64it/s]Extractor Predicting: 71it [00:45,  1.60it/s]Extractor Predicting: 72it [00:45,  1.58it/s]Extractor Predicting: 73it [00:46,  1.57it/s]Extractor Predicting: 74it [00:47,  1.58it/s]Extractor Predicting: 75it [00:47,  1.57it/s]Extractor Predicting: 76it [00:48,  1.56it/s]Extractor Predicting: 77it [00:49,  1.55it/s]Extractor Predicting: 78it [00:49,  1.63it/s]Extractor Predicting: 79it [00:50,  1.59it/s]Extractor Predicting: 80it [00:50,  1.61it/s]Extractor Predicting: 81it [00:51,  1.60it/s]Extractor Predicting: 82it [00:52,  1.63it/s]Extractor Predicting: 83it [00:52,  1.63it/s]Extractor Predicting: 84it [00:53,  1.68it/s]Extractor Predicting: 85it [00:53,  1.67it/s]Extractor Predicting: 86it [00:54,  1.63it/s]Extractor Predicting: 87it [00:55,  1.59it/s]Extractor Predicting: 88it [00:55,  1.51it/s]Extractor Predicting: 89it [00:56,  1.57it/s]Extractor Predicting: 90it [00:57,  1.60it/s]Extractor Predicting: 91it [00:57,  1.62it/s]Extractor Predicting: 92it [00:58,  1.57it/s]Extractor Predicting: 93it [00:59,  1.54it/s]Extractor Predicting: 94it [00:59,  1.57it/s]Extractor Predicting: 95it [01:00,  1.56it/s]Extractor Predicting: 96it [01:00,  1.60it/s]Extractor Predicting: 97it [01:01,  1.67it/s]Extractor Predicting: 98it [01:01,  1.72it/s]Extractor Predicting: 99it [01:02,  1.69it/s]Extractor Predicting: 100it [01:03,  1.77it/s]Extractor Predicting: 101it [01:03,  1.73it/s]Extractor Predicting: 102it [01:04,  1.72it/s]Extractor Predicting: 103it [01:04,  1.73it/s]Extractor Predicting: 104it [01:05,  1.70it/s]Extractor Predicting: 105it [01:05,  1.74it/s]Extractor Predicting: 106it [01:06,  1.72it/s]Extractor Predicting: 107it [01:07,  1.70it/s]Extractor Predicting: 108it [01:07,  1.69it/s]Extractor Predicting: 109it [01:08,  1.69it/s]Extractor Predicting: 110it [01:08,  1.70it/s]Extractor Predicting: 111it [01:09,  1.72it/s]Extractor Predicting: 112it [01:10,  1.73it/s]Extractor Predicting: 113it [01:10,  1.71it/s]Extractor Predicting: 114it [01:11,  1.75it/s]Extractor Predicting: 115it [01:11,  1.74it/s]Extractor Predicting: 116it [01:12,  1.78it/s]Extractor Predicting: 117it [01:12,  1.75it/s]Extractor Predicting: 118it [01:13,  1.76it/s]Extractor Predicting: 119it [01:14,  1.77it/s]Extractor Predicting: 120it [01:14,  1.80it/s]Extractor Predicting: 121it [01:15,  1.76it/s]Extractor Predicting: 122it [01:15,  1.71it/s]Extractor Predicting: 123it [01:16,  1.71it/s]Extractor Predicting: 124it [01:16,  1.70it/s]Extractor Predicting: 125it [01:17,  1.72it/s]Extractor Predicting: 126it [01:18,  1.72it/s]Extractor Predicting: 127it [01:18,  1.78it/s]Extractor Predicting: 128it [01:19,  1.78it/s]Extractor Predicting: 129it [01:19,  1.78it/s]Extractor Predicting: 130it [01:20,  1.77it/s]Extractor Predicting: 131it [01:20,  1.72it/s]Extractor Predicting: 132it [01:21,  1.75it/s]Extractor Predicting: 133it [01:22,  1.70it/s]Extractor Predicting: 134it [01:22,  1.75it/s]Extractor Predicting: 135it [01:23,  1.75it/s]Extractor Predicting: 136it [01:23,  1.73it/s]Extractor Predicting: 137it [01:24,  1.73it/s]Extractor Predicting: 138it [01:25,  1.72it/s]Extractor Predicting: 139it [01:25,  1.70it/s]Extractor Predicting: 140it [01:26,  1.69it/s]Extractor Predicting: 141it [01:26,  1.72it/s]Extractor Predicting: 142it [01:27,  1.75it/s]Extractor Predicting: 143it [01:27,  1.78it/s]Extractor Predicting: 144it [01:28,  1.77it/s]Extractor Predicting: 145it [01:29,  1.72it/s]Extractor Predicting: 146it [01:29,  1.70it/s]Extractor Predicting: 147it [01:30,  1.71it/s]Extractor Predicting: 148it [01:30,  1.67it/s]Extractor Predicting: 149it [01:31,  1.67it/s]Extractor Predicting: 150it [01:32,  1.68it/s]Extractor Predicting: 151it [01:32,  1.62it/s]Extractor Predicting: 152it [01:33,  1.57it/s]Extractor Predicting: 153it [01:34,  1.53it/s]Extractor Predicting: 154it [01:34,  1.54it/s]Extractor Predicting: 155it [01:35,  1.55it/s]Extractor Predicting: 156it [01:36,  1.52it/s]Extractor Predicting: 157it [01:36,  1.56it/s]Extractor Predicting: 158it [01:37,  1.56it/s]Extractor Predicting: 159it [01:37,  1.59it/s]Extractor Predicting: 160it [01:38,  1.63it/s]Extractor Predicting: 161it [01:39,  1.65it/s]Extractor Predicting: 162it [01:39,  1.66it/s]Extractor Predicting: 163it [01:40,  1.44it/s]Extractor Predicting: 164it [01:41,  1.46it/s]Extractor Predicting: 165it [01:41,  1.49it/s]Extractor Predicting: 166it [01:42,  1.50it/s]Extractor Predicting: 167it [01:43,  1.54it/s]Extractor Predicting: 168it [01:43,  1.55it/s]Extractor Predicting: 169it [01:44,  1.59it/s]Extractor Predicting: 170it [01:44,  1.63it/s]Extractor Predicting: 171it [01:45,  1.66it/s]Extractor Predicting: 172it [01:46,  1.59it/s]Extractor Predicting: 173it [01:46,  1.64it/s]Extractor Predicting: 174it [01:47,  1.65it/s]Extractor Predicting: 175it [01:48,  1.62it/s]Extractor Predicting: 176it [01:48,  1.62it/s]Extractor Predicting: 177it [01:49,  1.60it/s]Extractor Predicting: 178it [01:49,  1.67it/s]Extractor Predicting: 179it [01:50,  1.79it/s]Extractor Predicting: 180it [01:50,  1.88it/s]Extractor Predicting: 181it [01:51,  1.82it/s]Extractor Predicting: 182it [01:51,  1.83it/s]Extractor Predicting: 183it [01:52,  1.72it/s]Extractor Predicting: 184it [01:53,  1.64it/s]Extractor Predicting: 185it [01:53,  1.66it/s]Extractor Predicting: 186it [01:54,  1.65it/s]Extractor Predicting: 187it [01:55,  1.63it/s]Extractor Predicting: 188it [01:55,  1.61it/s]Extractor Predicting: 189it [01:56,  1.59it/s]Extractor Predicting: 190it [01:56,  1.58it/s]Extractor Predicting: 191it [01:57,  1.56it/s]Extractor Predicting: 192it [01:58,  1.58it/s]Extractor Predicting: 193it [01:58,  1.66it/s]Extractor Predicting: 194it [01:59,  1.68it/s]Extractor Predicting: 195it [01:59,  1.70it/s]Extractor Predicting: 196it [02:00,  1.67it/s]Extractor Predicting: 197it [02:01,  1.66it/s]Extractor Predicting: 198it [02:01,  1.59it/s]Extractor Predicting: 199it [02:02,  1.60it/s]Extractor Predicting: 200it [02:03,  1.63it/s]Extractor Predicting: 201it [02:03,  1.63it/s]Extractor Predicting: 202it [02:04,  1.62it/s]Extractor Predicting: 203it [02:04,  1.63it/s]Extractor Predicting: 204it [02:05,  1.65it/s]Extractor Predicting: 205it [02:06,  1.67it/s]Extractor Predicting: 206it [02:06,  1.65it/s]Extractor Predicting: 207it [02:07,  1.65it/s]Extractor Predicting: 208it [02:07,  1.66it/s]Extractor Predicting: 209it [02:08,  1.66it/s]Extractor Predicting: 210it [02:09,  1.68it/s]Extractor Predicting: 211it [02:09,  1.65it/s]Extractor Predicting: 212it [02:10,  1.61it/s]Extractor Predicting: 213it [02:11,  1.59it/s]Extractor Predicting: 214it [02:11,  1.59it/s]Extractor Predicting: 215it [02:12,  1.60it/s]Extractor Predicting: 216it [02:12,  1.59it/s]Extractor Predicting: 217it [02:13,  1.65it/s]Extractor Predicting: 218it [02:14,  1.67it/s]Extractor Predicting: 219it [02:14,  1.66it/s]Extractor Predicting: 220it [02:15,  1.67it/s]Extractor Predicting: 221it [02:15,  1.66it/s]Extractor Predicting: 222it [02:16,  1.67it/s]Extractor Predicting: 223it [02:17,  1.62it/s]Extractor Predicting: 224it [02:17,  1.58it/s]Extractor Predicting: 225it [02:18,  1.59it/s]Extractor Predicting: 226it [02:18,  1.62it/s]Extractor Predicting: 227it [02:19,  1.62it/s]Extractor Predicting: 228it [02:20,  1.60it/s]Extractor Predicting: 229it [02:20,  1.60it/s]Extractor Predicting: 230it [02:21,  1.59it/s]Extractor Predicting: 231it [02:22,  1.56it/s]Extractor Predicting: 232it [02:22,  1.61it/s]Extractor Predicting: 233it [02:23,  1.58it/s]Extractor Predicting: 234it [02:24,  1.54it/s]Extractor Predicting: 235it [02:24,  1.57it/s]Extractor Predicting: 236it [02:25,  1.58it/s]Extractor Predicting: 237it [02:25,  1.59it/s]Extractor Predicting: 238it [02:26,  1.57it/s]Extractor Predicting: 239it [02:27,  1.58it/s]Extractor Predicting: 240it [02:27,  1.59it/s]Extractor Predicting: 241it [02:28,  1.62it/s]Extractor Predicting: 242it [02:29,  1.60it/s]Extractor Predicting: 243it [02:29,  1.63it/s]Extractor Predicting: 244it [02:30,  1.62it/s]Extractor Predicting: 245it [02:30,  1.58it/s]Extractor Predicting: 246it [02:31,  1.61it/s]Extractor Predicting: 247it [02:32,  1.63it/s]Extractor Predicting: 248it [02:32,  1.59it/s]Extractor Predicting: 249it [02:33,  1.59it/s]Extractor Predicting: 250it [02:33,  1.65it/s]Extractor Predicting: 251it [02:34,  1.67it/s]Extractor Predicting: 252it [02:35,  1.71it/s]Extractor Predicting: 253it [02:35,  1.70it/s]Extractor Predicting: 254it [02:36,  1.69it/s]Extractor Predicting: 255it [02:36,  1.67it/s]Extractor Predicting: 256it [02:37,  1.65it/s]Extractor Predicting: 257it [02:38,  1.65it/s]Extractor Predicting: 258it [02:38,  1.67it/s]Extractor Predicting: 259it [02:39,  1.66it/s]Extractor Predicting: 260it [02:39,  1.67it/s]Extractor Predicting: 261it [02:40,  1.70it/s]Extractor Predicting: 262it [02:41,  1.74it/s]Extractor Predicting: 263it [02:41,  1.73it/s]Extractor Predicting: 264it [02:42,  1.75it/s]Extractor Predicting: 265it [02:42,  1.67it/s]Extractor Predicting: 266it [02:43,  1.68it/s]Extractor Predicting: 267it [02:44,  1.67it/s]Extractor Predicting: 268it [02:44,  1.64it/s]Extractor Predicting: 269it [02:45,  1.67it/s]Extractor Predicting: 270it [02:45,  1.66it/s]Extractor Predicting: 271it [02:46,  1.68it/s]Extractor Predicting: 272it [02:47,  1.69it/s]Extractor Predicting: 273it [02:47,  1.65it/s]Extractor Predicting: 274it [02:48,  1.67it/s]Extractor Predicting: 275it [02:48,  1.66it/s]Extractor Predicting: 276it [02:49,  1.69it/s]Extractor Predicting: 277it [02:50,  1.69it/s]Extractor Predicting: 278it [02:50,  1.69it/s]Extractor Predicting: 279it [02:51,  1.67it/s]Extractor Predicting: 280it [02:51,  1.65it/s]Extractor Predicting: 281it [02:52,  1.64it/s]Extractor Predicting: 282it [02:53,  1.61it/s]Extractor Predicting: 283it [02:53,  1.61it/s]Extractor Predicting: 284it [02:54,  1.67it/s]Extractor Predicting: 285it [02:54,  1.65it/s]Extractor Predicting: 286it [02:55,  1.62it/s]Extractor Predicting: 287it [02:56,  1.60it/s]Extractor Predicting: 288it [02:56,  1.63it/s]Extractor Predicting: 289it [02:57,  1.58it/s]Extractor Predicting: 290it [02:58,  1.58it/s]Extractor Predicting: 291it [02:58,  1.61it/s]Extractor Predicting: 292it [02:59,  1.59it/s]Extractor Predicting: 293it [02:59,  1.60it/s]Extractor Predicting: 294it [03:00,  1.61it/s]Extractor Predicting: 295it [03:01,  1.63it/s]Extractor Predicting: 296it [03:01,  1.63it/s]Extractor Predicting: 297it [03:02,  1.62it/s]Extractor Predicting: 298it [03:02,  1.64it/s]Extractor Predicting: 299it [03:03,  1.61it/s]Extractor Predicting: 300it [03:04,  1.60it/s]Extractor Predicting: 301it [03:04,  1.59it/s]Extractor Predicting: 302it [03:05,  1.61it/s]Extractor Predicting: 303it [03:06,  1.63it/s]Extractor Predicting: 304it [03:06,  1.65it/s]Extractor Predicting: 305it [03:07,  1.68it/s]Extractor Predicting: 306it [03:07,  1.64it/s]Extractor Predicting: 307it [03:08,  1.64it/s]Extractor Predicting: 308it [03:09,  1.66it/s]Extractor Predicting: 309it [03:09,  1.64it/s]Extractor Predicting: 310it [03:10,  1.58it/s]Extractor Predicting: 311it [03:11,  1.36it/s]Extractor Predicting: 312it [03:12,  1.39it/s]Extractor Predicting: 313it [03:12,  1.40it/s]Extractor Predicting: 314it [03:13,  1.38it/s]Extractor Predicting: 315it [03:14,  1.39it/s]Extractor Predicting: 316it [03:14,  1.40it/s]Extractor Predicting: 317it [03:15,  1.42it/s]Extractor Predicting: 318it [03:16,  1.42it/s]Extractor Predicting: 319it [03:17,  1.42it/s]Extractor Predicting: 320it [03:17,  1.43it/s]Extractor Predicting: 321it [03:18,  1.39it/s]Extractor Predicting: 322it [03:19,  1.41it/s]Extractor Predicting: 323it [03:19,  1.42it/s]Extractor Predicting: 324it [03:20,  1.44it/s]Extractor Predicting: 325it [03:21,  1.43it/s]Extractor Predicting: 326it [03:21,  1.44it/s]Extractor Predicting: 327it [03:22,  1.50it/s]Extractor Predicting: 328it [03:23,  1.51it/s]Extractor Predicting: 329it [03:23,  1.54it/s]Extractor Predicting: 330it [03:24,  1.59it/s]Extractor Predicting: 331it [03:24,  1.61it/s]Extractor Predicting: 332it [03:25,  1.64it/s]Extractor Predicting: 333it [03:26,  1.64it/s]Extractor Predicting: 334it [03:26,  1.61it/s]Extractor Predicting: 335it [03:27,  1.62it/s]Extractor Predicting: 336it [03:28,  1.57it/s]Extractor Predicting: 337it [03:28,  1.62it/s]Extractor Predicting: 338it [03:29,  1.63it/s]Extractor Predicting: 339it [03:29,  1.63it/s]Extractor Predicting: 340it [03:30,  1.59it/s]Extractor Predicting: 341it [03:31,  1.56it/s]Extractor Predicting: 342it [03:31,  1.56it/s]Extractor Predicting: 343it [03:32,  1.56it/s]Extractor Predicting: 344it [03:33,  1.53it/s]Extractor Predicting: 345it [03:33,  1.51it/s]Extractor Predicting: 346it [03:34,  1.49it/s]Extractor Predicting: 347it [03:35,  1.50it/s]Extractor Predicting: 348it [03:35,  1.51it/s]Extractor Predicting: 349it [03:36,  1.53it/s]Extractor Predicting: 350it [03:37,  1.51it/s]Extractor Predicting: 351it [03:37,  1.53it/s]Extractor Predicting: 352it [03:38,  1.54it/s]Extractor Predicting: 353it [03:39,  1.51it/s]Extractor Predicting: 354it [03:39,  1.51it/s]Extractor Predicting: 355it [03:40,  1.54it/s]Extractor Predicting: 356it [03:41,  1.55it/s]Extractor Predicting: 357it [03:41,  1.56it/s]Extractor Predicting: 358it [03:42,  1.56it/s]Extractor Predicting: 359it [03:43,  1.53it/s]Extractor Predicting: 360it [03:43,  1.56it/s]Extractor Predicting: 361it [03:44,  1.56it/s]Extractor Predicting: 362it [03:44,  1.56it/s]Extractor Predicting: 363it [03:45,  1.57it/s]Extractor Predicting: 364it [03:46,  1.57it/s]Extractor Predicting: 365it [03:46,  1.62it/s]Extractor Predicting: 366it [03:47,  1.60it/s]Extractor Predicting: 367it [03:48,  1.60it/s]Extractor Predicting: 368it [03:48,  1.58it/s]Extractor Predicting: 369it [03:49,  1.55it/s]Extractor Predicting: 370it [03:49,  1.59it/s]Extractor Predicting: 371it [03:50,  1.58it/s]Extractor Predicting: 372it [03:51,  1.57it/s]Extractor Predicting: 373it [03:51,  1.56it/s]Extractor Predicting: 374it [03:52,  1.58it/s]Extractor Predicting: 375it [03:53,  1.60it/s]Extractor Predicting: 376it [03:53,  1.63it/s]Extractor Predicting: 377it [03:54,  1.59it/s]Extractor Predicting: 378it [03:54,  1.60it/s]Extractor Predicting: 379it [03:55,  1.57it/s]Extractor Predicting: 380it [03:56,  1.57it/s]Extractor Predicting: 381it [03:56,  1.58it/s]Extractor Predicting: 382it [03:57,  1.58it/s]Extractor Predicting: 383it [03:58,  1.59it/s]Extractor Predicting: 384it [03:58,  1.60it/s]Extractor Predicting: 385it [03:59,  1.60it/s]Extractor Predicting: 386it [03:59,  1.61it/s]Extractor Predicting: 387it [04:00,  1.60it/s]Extractor Predicting: 388it [04:01,  1.59it/s]Extractor Predicting: 389it [04:01,  1.63it/s]Extractor Predicting: 390it [04:02,  1.64it/s]Extractor Predicting: 391it [04:03,  1.65it/s]Extractor Predicting: 392it [04:03,  1.67it/s]Extractor Predicting: 393it [04:04,  1.66it/s]Extractor Predicting: 394it [04:04,  1.64it/s]Extractor Predicting: 395it [04:05,  1.65it/s]Extractor Predicting: 396it [04:06,  1.63it/s]Extractor Predicting: 397it [04:06,  1.63it/s]Extractor Predicting: 398it [04:07,  1.67it/s]Extractor Predicting: 399it [04:07,  1.67it/s]Extractor Predicting: 400it [04:08,  1.62it/s]Extractor Predicting: 401it [04:09,  1.58it/s]Extractor Predicting: 402it [04:09,  1.47it/s]Extractor Predicting: 403it [04:10,  1.50it/s]Extractor Predicting: 404it [04:11,  1.55it/s]Extractor Predicting: 405it [04:11,  1.57it/s]Extractor Predicting: 406it [04:12,  1.57it/s]Extractor Predicting: 407it [04:13,  1.61it/s]Extractor Predicting: 408it [04:13,  1.66it/s]Extractor Predicting: 409it [04:14,  1.69it/s]Extractor Predicting: 410it [04:14,  1.69it/s]Extractor Predicting: 411it [04:15,  1.70it/s]Extractor Predicting: 412it [04:15,  1.72it/s]Extractor Predicting: 413it [04:16,  1.77it/s]Extractor Predicting: 414it [04:16,  1.79it/s]Extractor Predicting: 415it [04:17,  1.70it/s]Extractor Predicting: 416it [04:18,  1.62it/s]Extractor Predicting: 417it [04:19,  1.55it/s]Extractor Predicting: 418it [04:20,  1.32it/s]Extractor Predicting: 419it [04:20,  1.36it/s]Extractor Predicting: 420it [04:21,  1.39it/s]Extractor Predicting: 421it [04:22,  1.40it/s]Extractor Predicting: 422it [04:22,  1.63it/s]Extractor Predicting: 422it [04:22,  1.61it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:09:57,505 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:09:57,534 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:09:57,534 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:09:57,534 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:09:57,534 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 11:09:58,387 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 11:09:58,389 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:09:58,688 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 11:09:59,851 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:09:59,851 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:10:01,766 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:10:01,788 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:10:01,789 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:10:01,789 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:10:01,789 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 11:10:02,281 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 11:10:02,282 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:10:02,589 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 11:10:02,822 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:10:02,822 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_out_filter_all_single_is_eval_True.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_in_all_single_is_eval_True.jsonl",
  "precision": 0.2315479241414659,
  "recall": 0.12845667164285207,
  "score": 0.16524164418636553,
  "mode": "all_single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/results_all_single_is_eval_True.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_in_single_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_out_filter_single_is_eval_False.jsonl'}}
predict vocab size: 13679
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 13779, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.63it/s]Extractor Predicting: 2it [00:01,  1.55it/s]Extractor Predicting: 3it [00:01,  1.57it/s]Extractor Predicting: 4it [00:02,  1.59it/s]Extractor Predicting: 5it [00:03,  1.59it/s]Extractor Predicting: 6it [00:03,  1.62it/s]Extractor Predicting: 7it [00:04,  1.63it/s]Extractor Predicting: 8it [00:04,  1.62it/s]Extractor Predicting: 9it [00:05,  1.60it/s]Extractor Predicting: 10it [00:06,  1.58it/s]Extractor Predicting: 11it [00:06,  1.59it/s]Extractor Predicting: 12it [00:07,  1.60it/s]Extractor Predicting: 13it [00:08,  1.62it/s]Extractor Predicting: 14it [00:08,  1.60it/s]Extractor Predicting: 15it [00:09,  1.62it/s]Extractor Predicting: 16it [00:09,  1.66it/s]Extractor Predicting: 17it [00:10,  1.65it/s]Extractor Predicting: 18it [00:11,  1.64it/s]Extractor Predicting: 19it [00:11,  1.59it/s]Extractor Predicting: 20it [00:12,  1.62it/s]Extractor Predicting: 21it [00:13,  1.62it/s]Extractor Predicting: 22it [00:13,  1.61it/s]Extractor Predicting: 23it [00:14,  1.60it/s]Extractor Predicting: 24it [00:14,  1.61it/s]Extractor Predicting: 25it [00:15,  1.64it/s]Extractor Predicting: 26it [00:16,  1.62it/s]Extractor Predicting: 27it [00:16,  1.62it/s]Extractor Predicting: 28it [00:17,  1.59it/s]Extractor Predicting: 29it [00:17,  1.62it/s]Extractor Predicting: 30it [00:18,  1.61it/s]Extractor Predicting: 31it [00:19,  1.59it/s]Extractor Predicting: 32it [00:19,  1.60it/s]Extractor Predicting: 33it [00:20,  1.60it/s]Extractor Predicting: 34it [00:21,  1.59it/s]Extractor Predicting: 35it [00:21,  1.57it/s]Extractor Predicting: 36it [00:22,  1.58it/s]Extractor Predicting: 37it [00:23,  1.58it/s]Extractor Predicting: 38it [00:23,  1.60it/s]Extractor Predicting: 39it [00:24,  1.59it/s]Extractor Predicting: 40it [00:24,  1.59it/s]Extractor Predicting: 41it [00:25,  1.59it/s]Extractor Predicting: 42it [00:26,  1.61it/s]Extractor Predicting: 43it [00:26,  1.64it/s]Extractor Predicting: 44it [00:27,  1.52it/s]Extractor Predicting: 45it [00:28,  1.52it/s]Extractor Predicting: 46it [00:28,  1.48it/s]Extractor Predicting: 47it [00:29,  1.50it/s]Extractor Predicting: 48it [00:30,  1.53it/s]Extractor Predicting: 49it [00:30,  1.52it/s]Extractor Predicting: 50it [00:31,  1.54it/s]Extractor Predicting: 51it [00:32,  1.50it/s]Extractor Predicting: 52it [00:32,  1.51it/s]Extractor Predicting: 53it [00:33,  1.52it/s]Extractor Predicting: 54it [00:34,  1.52it/s]Extractor Predicting: 55it [00:34,  1.52it/s]Extractor Predicting: 56it [00:35,  1.52it/s]Extractor Predicting: 57it [00:36,  1.53it/s]Extractor Predicting: 58it [00:36,  1.52it/s]Extractor Predicting: 59it [00:37,  1.51it/s]Extractor Predicting: 60it [00:38,  1.55it/s]Extractor Predicting: 61it [00:38,  1.55it/s]Extractor Predicting: 62it [00:39,  1.56it/s]Extractor Predicting: 63it [00:39,  1.56it/s]Extractor Predicting: 64it [00:40,  1.60it/s]Extractor Predicting: 65it [00:41,  1.65it/s]Extractor Predicting: 66it [00:41,  1.64it/s]Extractor Predicting: 67it [00:42,  1.62it/s]Extractor Predicting: 68it [00:42,  1.62it/s]Extractor Predicting: 69it [00:43,  1.64it/s]Extractor Predicting: 70it [00:44,  1.63it/s]Extractor Predicting: 71it [00:44,  1.61it/s]Extractor Predicting: 72it [00:45,  1.61it/s]Extractor Predicting: 73it [00:46,  1.62it/s]Extractor Predicting: 74it [00:46,  1.62it/s]Extractor Predicting: 75it [00:47,  1.60it/s]Extractor Predicting: 76it [00:47,  1.60it/s]Extractor Predicting: 77it [00:48,  1.65it/s]Extractor Predicting: 78it [00:49,  1.66it/s]Extractor Predicting: 79it [00:49,  1.65it/s]Extractor Predicting: 80it [00:50,  1.64it/s]Extractor Predicting: 81it [00:50,  1.68it/s]Extractor Predicting: 82it [00:51,  1.65it/s]Extractor Predicting: 83it [00:52,  1.61it/s]Extractor Predicting: 84it [00:52,  1.59it/s]Extractor Predicting: 85it [00:53,  1.58it/s]Extractor Predicting: 86it [00:54,  1.61it/s]Extractor Predicting: 87it [00:54,  1.64it/s]Extractor Predicting: 88it [00:55,  1.59it/s]Extractor Predicting: 89it [00:55,  1.59it/s]Extractor Predicting: 90it [00:56,  1.59it/s]Extractor Predicting: 91it [00:57,  1.62it/s]Extractor Predicting: 92it [00:57,  1.63it/s]Extractor Predicting: 93it [00:58,  1.64it/s]Extractor Predicting: 94it [00:58,  1.66it/s]Extractor Predicting: 95it [00:59,  1.66it/s]Extractor Predicting: 96it [01:00,  1.65it/s]Extractor Predicting: 97it [01:00,  1.68it/s]Extractor Predicting: 98it [01:01,  1.68it/s]Extractor Predicting: 99it [01:01,  1.68it/s]Extractor Predicting: 100it [01:02,  1.65it/s]Extractor Predicting: 101it [01:03,  1.61it/s]Extractor Predicting: 102it [01:03,  1.60it/s]Extractor Predicting: 103it [01:04,  1.61it/s]Extractor Predicting: 104it [01:05,  1.64it/s]Extractor Predicting: 105it [01:05,  1.62it/s]Extractor Predicting: 106it [01:06,  1.61it/s]Extractor Predicting: 107it [01:06,  1.64it/s]Extractor Predicting: 108it [01:07,  1.67it/s]Extractor Predicting: 109it [01:08,  1.62it/s]Extractor Predicting: 110it [01:08,  1.66it/s]Extractor Predicting: 111it [01:09,  1.66it/s]Extractor Predicting: 112it [01:09,  1.64it/s]Extractor Predicting: 113it [01:10,  1.63it/s]Extractor Predicting: 114it [01:11,  1.65it/s]Extractor Predicting: 115it [01:11,  1.64it/s]Extractor Predicting: 116it [01:12,  1.65it/s]Extractor Predicting: 117it [01:12,  1.66it/s]Extractor Predicting: 118it [01:13,  1.64it/s]Extractor Predicting: 119it [01:14,  1.65it/s]Extractor Predicting: 120it [01:14,  1.69it/s]Extractor Predicting: 121it [01:15,  1.69it/s]Extractor Predicting: 122it [01:16,  1.52it/s]Extractor Predicting: 123it [01:16,  1.55it/s]Extractor Predicting: 124it [01:17,  1.57it/s]Extractor Predicting: 125it [01:18,  1.53it/s]Extractor Predicting: 126it [01:18,  1.56it/s]Extractor Predicting: 127it [01:19,  1.60it/s]Extractor Predicting: 128it [01:19,  1.63it/s]Extractor Predicting: 129it [01:20,  1.64it/s]Extractor Predicting: 130it [01:21,  1.62it/s]Extractor Predicting: 131it [01:21,  1.59it/s]Extractor Predicting: 132it [01:22,  1.61it/s]Extractor Predicting: 133it [01:22,  1.62it/s]Extractor Predicting: 134it [01:23,  1.60it/s]Extractor Predicting: 135it [01:24,  1.62it/s]Extractor Predicting: 136it [01:24,  1.67it/s]Extractor Predicting: 137it [01:25,  1.68it/s]Extractor Predicting: 138it [01:25,  1.65it/s]Extractor Predicting: 139it [01:26,  1.63it/s]Extractor Predicting: 140it [01:27,  1.67it/s]Extractor Predicting: 141it [01:27,  1.69it/s]Extractor Predicting: 142it [01:28,  1.69it/s]Extractor Predicting: 143it [01:28,  1.73it/s]Extractor Predicting: 144it [01:29,  1.69it/s]Extractor Predicting: 145it [01:30,  1.71it/s]Extractor Predicting: 146it [01:30,  1.70it/s]Extractor Predicting: 147it [01:31,  1.70it/s]Extractor Predicting: 148it [01:31,  1.69it/s]Extractor Predicting: 149it [01:32,  1.70it/s]Extractor Predicting: 150it [01:33,  1.70it/s]Extractor Predicting: 151it [01:33,  1.66it/s]Extractor Predicting: 152it [01:34,  1.69it/s]Extractor Predicting: 153it [01:34,  1.68it/s]Extractor Predicting: 154it [01:35,  1.67it/s]Extractor Predicting: 155it [01:36,  1.67it/s]Extractor Predicting: 156it [01:36,  1.67it/s]Extractor Predicting: 157it [01:37,  1.66it/s]Extractor Predicting: 158it [01:37,  1.67it/s]Extractor Predicting: 159it [01:38,  1.68it/s]Extractor Predicting: 160it [01:38,  1.71it/s]Extractor Predicting: 161it [01:39,  1.65it/s]Extractor Predicting: 162it [01:40,  1.62it/s]Extractor Predicting: 163it [01:40,  1.63it/s]Extractor Predicting: 164it [01:41,  1.67it/s]Extractor Predicting: 165it [01:42,  1.67it/s]Extractor Predicting: 166it [01:42,  1.59it/s]Extractor Predicting: 167it [01:43,  1.56it/s]Extractor Predicting: 168it [01:44,  1.55it/s]Extractor Predicting: 169it [01:44,  1.56it/s]Extractor Predicting: 170it [01:45,  1.54it/s]Extractor Predicting: 170it [01:45,  1.61it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:11:57,767 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:11:57,801 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:11:57,802 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:11:57,802 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:11:57,802 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 11:11:58,733 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 11:11:58,734 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:11:59,060 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 11:12:00,187 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:12:00,187 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:12:01,702 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:12:01,704 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:12:01,704 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:12:01,704 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:12:01,704 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 11:12:02,264 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 11:12:02,266 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:12:02,597 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 11:12:02,814 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:12:02,814 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_out_filter_single_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_in_single_is_eval_False.jsonl",
  "precision": 0.29959514170040485,
  "recall": 0.1634355828220859,
  "score": 0.211495712924738,
  "mode": "single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/results_single_is_eval_False.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_in_multi_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_out_filter_multi_is_eval_False.jsonl'}}
predict vocab size: 3869
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 3969, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.54it/s]Extractor Predicting: 2it [00:01,  1.54it/s]Extractor Predicting: 3it [00:01,  1.56it/s]Extractor Predicting: 4it [00:02,  1.54it/s]Extractor Predicting: 5it [00:03,  1.55it/s]Extractor Predicting: 6it [00:03,  1.52it/s]Extractor Predicting: 7it [00:04,  1.50it/s]Extractor Predicting: 8it [00:05,  1.49it/s]Extractor Predicting: 9it [00:05,  1.54it/s]Extractor Predicting: 10it [00:06,  1.53it/s]Extractor Predicting: 11it [00:07,  1.50it/s]Extractor Predicting: 12it [00:07,  1.57it/s]Extractor Predicting: 13it [00:08,  1.58it/s]Extractor Predicting: 14it [00:09,  1.58it/s]Extractor Predicting: 15it [00:09,  1.58it/s]Extractor Predicting: 16it [00:10,  1.55it/s]Extractor Predicting: 17it [00:11,  1.54it/s]Extractor Predicting: 18it [00:11,  1.54it/s]Extractor Predicting: 19it [00:12,  1.55it/s]Extractor Predicting: 20it [00:13,  1.51it/s]Extractor Predicting: 21it [00:13,  1.55it/s]Extractor Predicting: 22it [00:14,  1.58it/s]Extractor Predicting: 23it [00:14,  1.57it/s]Extractor Predicting: 24it [00:15,  1.53it/s]Extractor Predicting: 25it [00:16,  1.57it/s]Extractor Predicting: 26it [00:16,  1.59it/s]Extractor Predicting: 27it [00:17,  1.58it/s]Extractor Predicting: 28it [00:18,  1.59it/s]Extractor Predicting: 29it [00:18,  1.58it/s]Extractor Predicting: 30it [00:19,  1.58it/s]Extractor Predicting: 31it [00:19,  1.58it/s]Extractor Predicting: 32it [00:20,  1.56it/s]Extractor Predicting: 33it [00:21,  1.50it/s]Extractor Predicting: 33it [00:21,  1.55it/s]
[INFO|configuration_utils.py:515] 2023-08-29 11:12:27,148 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 11:12:27,149 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 11:12:27,225 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 11:12:27,226 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|modeling_utils.py:1150] 2023-08-29 11:12:27,279 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 11:12:40,643 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.

[INFO|modeling_utils.py:1345] 2023-08-29 11:12:40,679 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.
[INFO|configuration_utils.py:515] 2023-08-29 11:12:40,875 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 11:12:40,876 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter1/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 11:12:40,993 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 11:12:41,074 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 11:12:41,074 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 11:12:41,074 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 11:12:41,074 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 11:12:41,074 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 11:12:41,074 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model/tokenizer_config.json
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_out_filter_multi_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/pred_in_multi_is_eval_False.jsonl",
  "precision": 0.55,
  "recall": 0.08771929824561403,
  "score": 0.1513067400275103,
  "mode": "multi",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/results_multi_is_eval_False.json"
}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
Generating:   0%|          | 0/10 [00:00<?, ?it/s][WARNING|generation_utils.py:914] 2023-08-29 11:12:41,698 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:42,667 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:43,240 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:43,833 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:44,394 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:44,921 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:45,427 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:45,938 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:46,375 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:46,854 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:47,385 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:47,872 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:48,420 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:48,927 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:49,457 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:50,042 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:50,675 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:51,190 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:51,706 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:52,435 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:52,965 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:53,512 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  10%|█         | 1/10 [00:12<01:52, 12.46s/it][WARNING|generation_utils.py:914] 2023-08-29 11:12:54,142 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:54,700 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:55,434 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:55,963 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:56,612 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:57,093 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:57,686 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:58,211 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:58,748 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:59,262 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:12:59,956 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:00,495 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:01,126 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:01,612 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:02,154 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:02,675 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:03,475 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:04,007 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:04,524 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:05,098 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:05,623 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  20%|██        | 2/10 [00:24<01:37, 12.25s/it][WARNING|generation_utils.py:914] 2023-08-29 11:13:06,243 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:06,719 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:07,167 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:07,593 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:08,076 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:08,571 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:08,995 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:09,419 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:10,081 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:10,520 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:10,981 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:11,499 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:11,985 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:12,407 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:12,827 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:13,260 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:13,645 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:14,127 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:14,702 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:15,225 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:15,749 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  30%|███       | 3/10 [00:34<01:18, 11.27s/it][WARNING|generation_utils.py:914] 2023-08-29 11:13:16,313 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:16,887 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:17,404 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:17,936 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:18,418 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:18,960 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:19,530 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:20,145 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:20,722 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:21,305 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:21,858 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:22,423 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:23,014 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:23,575 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:24,080 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:24,625 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:25,201 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:25,750 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:26,250 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:26,766 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  40%|████      | 4/10 [00:45<01:07, 11.19s/it][WARNING|generation_utils.py:914] 2023-08-29 11:13:27,389 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:27,957 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:28,539 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:29,137 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:29,689 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:30,220 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:31,005 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:31,550 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:32,095 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:32,640 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:33,255 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:33,789 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:34,320 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:34,827 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:35,408 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:35,897 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:36,464 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:36,977 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:37,509 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:38,026 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:38,530 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  50%|█████     | 5/10 [00:57<00:56, 11.36s/it][WARNING|generation_utils.py:914] 2023-08-29 11:13:39,039 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:39,573 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:40,175 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:40,635 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:41,094 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:41,584 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:42,202 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:42,735 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:43,180 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:43,713 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:44,245 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:44,741 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:45,188 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:45,638 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:46,092 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:46,608 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:47,130 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:47,655 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:48,107 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:48,562 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:49,085 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  60%|██████    | 6/10 [01:08<00:44, 11.12s/it][WARNING|generation_utils.py:914] 2023-08-29 11:13:49,696 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:50,274 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:50,848 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:51,449 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:51,949 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:52,469 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:52,958 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:53,526 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:53,989 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:54,527 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:55,067 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:55,608 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:56,165 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:56,691 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:57,227 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:57,732 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:58,197 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:58,789 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:59,340 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:13:59,854 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  70%|███████   | 7/10 [01:18<00:33, 11.00s/it][WARNING|generation_utils.py:914] 2023-08-29 11:14:00,488 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:01,067 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:01,647 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:02,195 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:02,693 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:03,162 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:03,670 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:04,298 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:04,833 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:05,372 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:05,906 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:06,482 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:07,058 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:07,590 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:08,121 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:08,852 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:09,413 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:10,024 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:10,568 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:11,047 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  80%|████████  | 8/10 [01:29<00:22, 11.06s/it][WARNING|generation_utils.py:914] 2023-08-29 11:14:11,631 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:12,206 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:12,782 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:13,345 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:13,912 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:14,524 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:15,090 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:15,630 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:16,174 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:16,762 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:17,269 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:17,846 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:18,373 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:18,906 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:19,393 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:19,882 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:20,370 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:20,919 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:21,485 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:22,076 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  90%|█████████ | 9/10 [01:40<00:11, 11.04s/it][WARNING|generation_utils.py:914] 2023-08-29 11:14:22,636 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:23,183 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:23,707 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:24,262 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:24,713 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:25,210 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:25,759 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:26,323 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:26,900 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:27,490 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:28,048 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:28,581 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:29,145 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:29,669 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:30,217 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:30,695 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:31,200 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:31,765 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:32,330 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 11:14:32,861 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating: 100%|██████████| 10/10 [01:51<00:00, 10.96s/it]Generating: 100%|██████████| 10/10 [01:51<00:00, 11.18s/it]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:39,838 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:39,881 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:39,882 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:39,882 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:39,882 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 11:14:40,621 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 11:14:40,622 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:14:41,026 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 11:14:42,230 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:14:42,230 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:44,265 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:44,355 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:44,355 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:44,356 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:14:44,356 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 11:14:44,984 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 11:14:44,985 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:14:45,305 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 11:14:45,544 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:14:45,544 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 55, 'raw': 64}
{'target': 600, 'success': 85, 'raw': 96}
{'target': 600, 'success': 114, 'raw': 128}
{'target': 600, 'success': 142, 'raw': 160}
{'target': 600, 'success': 171, 'raw': 192}
{'target': 600, 'success': 199, 'raw': 224}
{'target': 600, 'success': 230, 'raw': 256}
{'target': 600, 'success': 258, 'raw': 288}
{'target': 600, 'success': 288, 'raw': 320}
{'target': 600, 'success': 316, 'raw': 352}
{'target': 600, 'success': 341, 'raw': 384}
{'target': 600, 'success': 368, 'raw': 416}
{'target': 600, 'success': 392, 'raw': 448}
{'target': 600, 'success': 420, 'raw': 480}
{'target': 600, 'success': 450, 'raw': 512}
{'target': 600, 'success': 474, 'raw': 544}
{'target': 600, 'success': 502, 'raw': 576}
{'target': 600, 'success': 529, 'raw': 608}
{'target': 600, 'success': 557, 'raw': 640}
{'target': 600, 'success': 584, 'raw': 672}
{'target': 600, 'success': 612, 'raw': 704}
{'prompt': 'Relation : country .', 'success_rate': 0.8693181818181818, 'errors': {''}}
{'target': 600, 'success': 32, 'raw': 32}
{'target': 600, 'success': 60, 'raw': 64}
{'target': 600, 'success': 90, 'raw': 96}
{'target': 600, 'success': 120, 'raw': 128}
{'target': 600, 'success': 150, 'raw': 160}
{'target': 600, 'success': 181, 'raw': 192}
{'target': 600, 'success': 211, 'raw': 224}
{'target': 600, 'success': 241, 'raw': 256}
{'target': 600, 'success': 271, 'raw': 288}
{'target': 600, 'success': 301, 'raw': 320}
{'target': 600, 'success': 330, 'raw': 352}
{'target': 600, 'success': 360, 'raw': 384}
{'target': 600, 'success': 389, 'raw': 416}
{'target': 600, 'success': 420, 'raw': 448}
{'target': 600, 'success': 449, 'raw': 480}
{'target': 600, 'success': 479, 'raw': 512}
{'target': 600, 'success': 507, 'raw': 544}
{'target': 600, 'success': 538, 'raw': 576}
{'target': 600, 'success': 567, 'raw': 608}
{'target': 600, 'success': 599, 'raw': 640}
{'target': 600, 'success': 630, 'raw': 672}
{'prompt': 'Relation : part of .', 'success_rate': 0.9375, 'errors': {''}}
{'target': 600, 'success': 31, 'raw': 32}
{'target': 600, 'success': 58, 'raw': 64}
{'target': 600, 'success': 86, 'raw': 96}
{'target': 600, 'success': 116, 'raw': 128}
{'target': 600, 'success': 144, 'raw': 160}
{'target': 600, 'success': 175, 'raw': 192}
{'target': 600, 'success': 206, 'raw': 224}
{'target': 600, 'success': 235, 'raw': 256}
{'target': 600, 'success': 266, 'raw': 288}
{'target': 600, 'success': 293, 'raw': 320}
{'target': 600, 'success': 323, 'raw': 352}
{'target': 600, 'success': 353, 'raw': 384}
{'target': 600, 'success': 382, 'raw': 416}
{'target': 600, 'success': 413, 'raw': 448}
{'target': 600, 'success': 442, 'raw': 480}
{'target': 600, 'success': 473, 'raw': 512}
{'target': 600, 'success': 501, 'raw': 544}
{'target': 600, 'success': 529, 'raw': 576}
{'target': 600, 'success': 559, 'raw': 608}
{'target': 600, 'success': 590, 'raw': 640}
{'target': 600, 'success': 619, 'raw': 672}
{'prompt': 'Relation : platform .', 'success_rate': 0.9211309523809523, 'errors': {'', "('Microsoft Windows', 'platform', '', 'In March 1993 Microsoft released the first . 8 . 1 of Microsoft Windows .')"}}
{'target': 600, 'success': 30, 'raw': 32}
{'target': 600, 'success': 60, 'raw': 64}
{'target': 600, 'success': 92, 'raw': 96}
{'target': 600, 'success': 123, 'raw': 128}
{'target': 600, 'success': 155, 'raw': 160}
{'target': 600, 'success': 185, 'raw': 192}
{'target': 600, 'success': 216, 'raw': 224}
{'target': 600, 'success': 247, 'raw': 256}
{'target': 600, 'success': 279, 'raw': 288}
{'target': 600, 'success': 309, 'raw': 320}
{'target': 600, 'success': 340, 'raw': 352}
{'target': 600, 'success': 371, 'raw': 384}
{'target': 600, 'success': 400, 'raw': 416}
{'target': 600, 'success': 432, 'raw': 448}
{'target': 600, 'success': 462, 'raw': 480}
{'target': 600, 'success': 491, 'raw': 512}
{'target': 600, 'success': 522, 'raw': 544}
{'target': 600, 'success': 552, 'raw': 576}
{'target': 600, 'success': 584, 'raw': 608}
{'target': 600, 'success': 614, 'raw': 640}
{'prompt': 'Relation : publisher .', 'success_rate': 0.959375, 'errors': {''}}
{'target': 600, 'success': 31, 'raw': 32}
{'target': 600, 'success': 61, 'raw': 64}
{'target': 600, 'success': 88, 'raw': 96}
{'target': 600, 'success': 120, 'raw': 128}
{'target': 600, 'success': 146, 'raw': 160}
{'target': 600, 'success': 174, 'raw': 192}
{'target': 600, 'success': 202, 'raw': 224}
{'target': 600, 'success': 231, 'raw': 256}
{'target': 600, 'success': 260, 'raw': 288}
{'target': 600, 'success': 288, 'raw': 320}
{'target': 600, 'success': 315, 'raw': 352}
{'target': 600, 'success': 345, 'raw': 384}
{'target': 600, 'success': 372, 'raw': 416}
{'target': 600, 'success': 399, 'raw': 448}
{'target': 600, 'success': 427, 'raw': 480}
{'target': 600, 'success': 458, 'raw': 512}
{'target': 600, 'success': 488, 'raw': 544}
{'target': 600, 'success': 517, 'raw': 576}
{'target': 600, 'success': 545, 'raw': 608}
{'target': 600, 'success': 571, 'raw': 640}
{'target': 600, 'success': 600, 'raw': 672}
{'prompt': 'Relation : sport .', 'success_rate': 0.8928571428571429, 'errors': {'', "('Norwegian national team', 'sport', '', 'During the 1960s he competed regularly for the Norwegian national team with the team from 1967 , winning the gold medal in the event .')"}}
{'target': 600, 'success': 32, 'raw': 32}
{'target': 600, 'success': 60, 'raw': 64}
{'target': 600, 'success': 89, 'raw': 96}
{'target': 600, 'success': 118, 'raw': 128}
{'target': 600, 'success': 146, 'raw': 160}
{'target': 600, 'success': 173, 'raw': 192}
{'target': 600, 'success': 202, 'raw': 224}
{'target': 600, 'success': 226, 'raw': 256}
{'target': 600, 'success': 254, 'raw': 288}
{'target': 600, 'success': 285, 'raw': 320}
{'target': 600, 'success': 315, 'raw': 352}
{'target': 600, 'success': 346, 'raw': 384}
{'target': 600, 'success': 375, 'raw': 416}
{'target': 600, 'success': 404, 'raw': 448}
{'target': 600, 'success': 432, 'raw': 480}
{'target': 600, 'success': 463, 'raw': 512}
{'target': 600, 'success': 493, 'raw': 544}
{'target': 600, 'success': 525, 'raw': 576}
{'target': 600, 'success': 555, 'raw': 608}
{'target': 600, 'success': 584, 'raw': 640}
{'target': 600, 'success': 614, 'raw': 672}
{'prompt': 'Relation : continent .', 'success_rate': 0.9136904761904762, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 30, 'raw': 32}
{'target': 600, 'success': 61, 'raw': 64}
{'target': 600, 'success': 92, 'raw': 96}
{'target': 600, 'success': 123, 'raw': 128}
{'target': 600, 'success': 155, 'raw': 160}
{'target': 600, 'success': 185, 'raw': 192}
{'target': 600, 'success': 216, 'raw': 224}
{'target': 600, 'success': 247, 'raw': 256}
{'target': 600, 'success': 278, 'raw': 288}
{'target': 600, 'success': 310, 'raw': 320}
{'target': 600, 'success': 340, 'raw': 352}
{'target': 600, 'success': 371, 'raw': 384}
{'target': 600, 'success': 402, 'raw': 416}
{'target': 600, 'success': 434, 'raw': 448}
{'target': 600, 'success': 466, 'raw': 480}
{'target': 600, 'success': 497, 'raw': 512}
{'target': 600, 'success': 528, 'raw': 544}
{'target': 600, 'success': 558, 'raw': 576}
{'target': 600, 'success': 588, 'raw': 608}
{'target': 600, 'success': 618, 'raw': 640}
{'prompt': 'Relation : owned by .', 'success_rate': 0.965625, 'errors': {'', 'too many values to unpack (expected 2)'}}
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 60, 'raw': 64}
{'target': 600, 'success': 90, 'raw': 96}
{'target': 600, 'success': 122, 'raw': 128}
{'target': 600, 'success': 154, 'raw': 160}
{'target': 600, 'success': 184, 'raw': 192}
{'target': 600, 'success': 214, 'raw': 224}
{'target': 600, 'success': 241, 'raw': 256}
{'target': 600, 'success': 273, 'raw': 288}
{'target': 600, 'success': 303, 'raw': 320}
{'target': 600, 'success': 335, 'raw': 352}
{'target': 600, 'success': 366, 'raw': 384}
{'target': 600, 'success': 397, 'raw': 416}
{'target': 600, 'success': 426, 'raw': 448}
{'target': 600, 'success': 458, 'raw': 480}
{'target': 600, 'success': 489, 'raw': 512}
{'target': 600, 'success': 520, 'raw': 544}
{'target': 600, 'success': 552, 'raw': 576}
{'target': 600, 'success': 582, 'raw': 608}
{'target': 600, 'success': 614, 'raw': 640}
{'prompt': 'Relation : performer .', 'success_rate': 0.959375, 'errors': {''}}
{'target': 600, 'success': 31, 'raw': 32}
{'target': 600, 'success': 61, 'raw': 64}
{'target': 600, 'success': 91, 'raw': 96}
{'target': 600, 'success': 123, 'raw': 128}
{'target': 600, 'success': 153, 'raw': 160}
{'target': 600, 'success': 184, 'raw': 192}
{'target': 600, 'success': 216, 'raw': 224}
{'target': 600, 'success': 247, 'raw': 256}
{'target': 600, 'success': 278, 'raw': 288}
{'target': 600, 'success': 309, 'raw': 320}
{'target': 600, 'success': 340, 'raw': 352}
{'target': 600, 'success': 369, 'raw': 384}
{'target': 600, 'success': 399, 'raw': 416}
{'target': 600, 'success': 429, 'raw': 448}
{'target': 600, 'success': 459, 'raw': 480}
{'target': 600, 'success': 491, 'raw': 512}
{'target': 600, 'success': 523, 'raw': 544}
{'target': 600, 'success': 555, 'raw': 576}
{'target': 600, 'success': 586, 'raw': 608}
{'target': 600, 'success': 617, 'raw': 640}
{'prompt': 'Relation : producer .', 'success_rate': 0.9640625, 'errors': {''}}
{'target': 600, 'success': 31, 'raw': 32}
{'target': 600, 'success': 62, 'raw': 64}
{'target': 600, 'success': 93, 'raw': 96}
{'target': 600, 'success': 125, 'raw': 128}
{'target': 600, 'success': 157, 'raw': 160}
{'target': 600, 'success': 188, 'raw': 192}
{'target': 600, 'success': 217, 'raw': 224}
{'target': 600, 'success': 245, 'raw': 256}
{'target': 600, 'success': 277, 'raw': 288}
{'target': 600, 'success': 307, 'raw': 320}
{'target': 600, 'success': 338, 'raw': 352}
{'target': 600, 'success': 369, 'raw': 384}
{'target': 600, 'success': 399, 'raw': 416}
{'target': 600, 'success': 429, 'raw': 448}
{'target': 600, 'success': 457, 'raw': 480}
{'target': 600, 'success': 489, 'raw': 512}
{'target': 600, 'success': 517, 'raw': 544}
{'target': 600, 'success': 547, 'raw': 576}
{'target': 600, 'success': 578, 'raw': 608}
{'target': 600, 'success': 608, 'raw': 640}
{'prompt': 'Relation : replaces .', 'success_rate': 0.95, 'errors': {''}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/3.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/3_ext.jsonl'}}
estimate vocab size: 6486
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 6586, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/data/estimate.txt
Extractor Estimating: 0it [00:00, ?it/s]Extractor Estimating: 1it [00:00,  1.47it/s]Extractor Estimating: 2it [00:01,  1.53it/s]Extractor Estimating: 3it [00:01,  1.65it/s]Extractor Estimating: 4it [00:02,  1.64it/s]Extractor Estimating: 5it [00:03,  1.69it/s]Extractor Estimating: 6it [00:03,  1.71it/s]Extractor Estimating: 7it [00:04,  1.73it/s]Extractor Estimating: 8it [00:04,  1.72it/s]Extractor Estimating: 9it [00:05,  1.72it/s]Extractor Estimating: 10it [00:05,  1.75it/s]Extractor Estimating: 11it [00:06,  1.81it/s]Extractor Estimating: 12it [00:07,  1.74it/s]Extractor Estimating: 13it [00:07,  1.77it/s]Extractor Estimating: 14it [00:08,  1.75it/s]Extractor Estimating: 15it [00:08,  1.77it/s]Extractor Estimating: 16it [00:09,  1.75it/s]Extractor Estimating: 17it [00:09,  1.73it/s]Extractor Estimating: 18it [00:10,  1.77it/s]Extractor Estimating: 19it [00:11,  1.65it/s]Extractor Estimating: 20it [00:11,  1.66it/s]Extractor Estimating: 21it [00:12,  1.73it/s]Extractor Estimating: 22it [00:12,  1.65it/s]Extractor Estimating: 23it [00:13,  1.67it/s]Extractor Estimating: 24it [00:14,  1.71it/s]Extractor Estimating: 25it [00:14,  1.69it/s]Extractor Estimating: 26it [00:15,  1.73it/s]Extractor Estimating: 27it [00:15,  1.64it/s]Extractor Estimating: 28it [00:16,  1.69it/s]Extractor Estimating: 29it [00:17,  1.70it/s]Extractor Estimating: 30it [00:17,  1.65it/s]Extractor Estimating: 31it [00:18,  1.71it/s]Extractor Estimating: 32it [00:18,  1.71it/s]Extractor Estimating: 33it [00:19,  1.75it/s]Extractor Estimating: 34it [00:19,  1.71it/s]Extractor Estimating: 35it [00:20,  1.71it/s]Extractor Estimating: 36it [00:21,  1.74it/s]Extractor Estimating: 37it [00:21,  1.77it/s]Extractor Estimating: 38it [00:22,  1.67it/s]Extractor Estimating: 39it [00:22,  1.68it/s]Extractor Estimating: 40it [00:23,  1.63it/s]Extractor Estimating: 41it [00:24,  1.68it/s]Extractor Estimating: 42it [00:24,  1.68it/s]Extractor Estimating: 43it [00:25,  1.67it/s]Extractor Estimating: 44it [00:25,  1.70it/s]Extractor Estimating: 45it [00:26,  1.58it/s]Extractor Estimating: 46it [00:27,  1.61it/s]Extractor Estimating: 47it [00:27,  1.60it/s]Extractor Estimating: 48it [00:28,  1.66it/s]Extractor Estimating: 49it [00:28,  1.68it/s]Extractor Estimating: 50it [00:29,  1.69it/s]Extractor Estimating: 51it [00:30,  1.67it/s]Extractor Estimating: 52it [00:30,  1.77it/s]Extractor Estimating: 53it [00:31,  1.83it/s]Extractor Estimating: 54it [00:31,  1.90it/s]Extractor Estimating: 55it [00:32,  1.86it/s]Extractor Estimating: 56it [00:32,  1.94it/s]Extractor Estimating: 57it [00:33,  2.01it/s]Extractor Estimating: 58it [00:33,  2.06it/s]Extractor Estimating: 59it [00:34,  1.92it/s]Extractor Estimating: 60it [00:34,  2.04it/s]Extractor Estimating: 61it [00:35,  1.92it/s]Extractor Estimating: 62it [00:35,  1.95it/s]Extractor Estimating: 63it [00:36,  1.95it/s]Extractor Estimating: 64it [00:36,  2.00it/s]Extractor Estimating: 65it [00:37,  1.83it/s]Extractor Estimating: 66it [00:37,  1.89it/s]Extractor Estimating: 67it [00:38,  1.96it/s]Extractor Estimating: 68it [00:38,  1.99it/s]Extractor Estimating: 69it [00:39,  2.02it/s]Extractor Estimating: 70it [00:39,  2.03it/s]Extractor Estimating: 71it [00:40,  1.87it/s]Extractor Estimating: 72it [00:40,  1.88it/s]Extractor Estimating: 73it [00:41,  1.94it/s]Extractor Estimating: 74it [00:41,  1.98it/s]Extractor Estimating: 75it [00:42,  1.97it/s]Extractor Estimating: 76it [00:42,  1.86it/s]Extractor Estimating: 77it [00:43,  1.79it/s]Extractor Estimating: 78it [00:44,  1.73it/s]Extractor Estimating: 79it [00:44,  1.70it/s]Extractor Estimating: 80it [00:45,  1.69it/s]Extractor Estimating: 81it [00:45,  1.70it/s]Extractor Estimating: 82it [00:46,  1.65it/s]Extractor Estimating: 83it [00:47,  1.64it/s]Extractor Estimating: 84it [00:47,  1.67it/s]Extractor Estimating: 85it [00:48,  1.64it/s]Extractor Estimating: 86it [00:49,  1.65it/s]Extractor Estimating: 87it [00:49,  1.65it/s]Extractor Estimating: 88it [00:50,  1.67it/s]Extractor Estimating: 89it [00:50,  1.62it/s]Extractor Estimating: 90it [00:51,  1.66it/s]Extractor Estimating: 91it [00:52,  1.61it/s]Extractor Estimating: 92it [00:52,  1.65it/s]Extractor Estimating: 93it [00:53,  1.66it/s]Extractor Estimating: 94it [00:53,  1.67it/s]Extractor Estimating: 95it [00:54,  1.56it/s]Extractor Estimating: 96it [00:55,  1.58it/s]Extractor Estimating: 97it [00:55,  1.55it/s]Extractor Estimating: 98it [00:56,  1.61it/s]Extractor Estimating: 99it [00:57,  1.63it/s]Extractor Estimating: 100it [00:57,  1.65it/s]Extractor Estimating: 101it [00:58,  1.65it/s]Extractor Estimating: 102it [00:58,  1.68it/s]Extractor Estimating: 103it [00:59,  1.68it/s]Extractor Estimating: 104it [00:59,  1.70it/s]Extractor Estimating: 105it [01:00,  1.73it/s]Extractor Estimating: 106it [01:01,  1.71it/s]Extractor Estimating: 107it [01:01,  1.70it/s]Extractor Estimating: 108it [01:02,  1.71it/s]Extractor Estimating: 109it [01:02,  1.77it/s]Extractor Estimating: 110it [01:03,  1.75it/s]Extractor Estimating: 111it [01:04,  1.74it/s]Extractor Estimating: 112it [01:04,  1.74it/s]Extractor Estimating: 113it [01:05,  1.75it/s]Extractor Estimating: 114it [01:05,  1.75it/s]Extractor Estimating: 115it [01:06,  1.71it/s]Extractor Estimating: 116it [01:06,  1.71it/s]Extractor Estimating: 117it [01:07,  1.74it/s]Extractor Estimating: 118it [01:07,  1.79it/s]Extractor Estimating: 119it [01:08,  1.81it/s]Extractor Estimating: 120it [01:09,  1.80it/s]Extractor Estimating: 121it [01:09,  1.81it/s]Extractor Estimating: 122it [01:10,  1.81it/s]Extractor Estimating: 123it [01:10,  1.86it/s]Extractor Estimating: 124it [01:11,  1.79it/s]Extractor Estimating: 125it [01:11,  1.79it/s]Extractor Estimating: 126it [01:12,  1.87it/s]Extractor Estimating: 127it [01:12,  1.85it/s]Extractor Estimating: 128it [01:13,  1.90it/s]Extractor Estimating: 129it [01:13,  1.93it/s]Extractor Estimating: 130it [01:14,  1.94it/s]Extractor Estimating: 131it [01:14,  1.95it/s]Extractor Estimating: 132it [01:15,  1.93it/s]Extractor Estimating: 133it [01:15,  1.95it/s]Extractor Estimating: 134it [01:16,  1.93it/s]Extractor Estimating: 135it [01:17,  1.88it/s]Extractor Estimating: 136it [01:17,  1.85it/s]Extractor Estimating: 137it [01:18,  1.93it/s]Extractor Estimating: 138it [01:18,  1.93it/s]Extractor Estimating: 139it [01:19,  1.98it/s]Extractor Estimating: 140it [01:19,  1.99it/s]Extractor Estimating: 141it [01:20,  1.95it/s]Extractor Estimating: 142it [01:20,  1.99it/s]Extractor Estimating: 143it [01:21,  1.91it/s]Extractor Estimating: 144it [01:21,  1.86it/s]Extractor Estimating: 145it [01:22,  1.85it/s]Extractor Estimating: 146it [01:22,  1.91it/s]Extractor Estimating: 147it [01:23,  1.83it/s]Extractor Estimating: 148it [01:23,  1.91it/s]Extractor Estimating: 149it [01:24,  1.90it/s]Extractor Estimating: 150it [01:24,  1.85it/s]Extractor Estimating: 151it [01:25,  1.83it/s]Extractor Estimating: 152it [01:26,  1.80it/s]Extractor Estimating: 153it [01:26,  1.70it/s]Extractor Estimating: 154it [01:27,  1.75it/s]Extractor Estimating: 155it [01:27,  1.76it/s]Extractor Estimating: 156it [01:28,  1.81it/s]Extractor Estimating: 157it [01:28,  1.79it/s]Extractor Estimating: 158it [01:29,  1.80it/s]Extractor Estimating: 159it [01:30,  1.72it/s]Extractor Estimating: 160it [01:30,  1.76it/s]Extractor Estimating: 161it [01:31,  1.76it/s]Extractor Estimating: 162it [01:31,  1.73it/s]Extractor Estimating: 163it [01:32,  1.75it/s]Extractor Estimating: 164it [01:32,  1.71it/s]Extractor Estimating: 165it [01:33,  1.66it/s]Extractor Estimating: 166it [01:34,  1.67it/s]Extractor Estimating: 167it [01:34,  1.70it/s]Extractor Estimating: 168it [01:35,  1.72it/s]Extractor Estimating: 169it [01:35,  1.75it/s]Extractor Estimating: 170it [01:36,  1.77it/s]Extractor Estimating: 171it [01:37,  1.72it/s]Extractor Estimating: 172it [01:37,  1.73it/s]Extractor Estimating: 173it [01:38,  1.74it/s]Extractor Estimating: 174it [01:38,  1.75it/s]Extractor Estimating: 175it [01:39,  1.71it/s]Extractor Estimating: 176it [01:39,  1.71it/s]Extractor Estimating: 177it [01:40,  1.69it/s]Extractor Estimating: 178it [01:41,  1.71it/s]Extractor Estimating: 179it [01:41,  1.66it/s]Extractor Estimating: 180it [01:42,  1.66it/s]Extractor Estimating: 181it [01:42,  1.72it/s]Extractor Estimating: 182it [01:43,  1.75it/s]Extractor Estimating: 183it [01:44,  1.75it/s]Extractor Estimating: 184it [01:44,  1.57it/s]Extractor Estimating: 185it [01:45,  1.61it/s]Extractor Estimating: 186it [01:45,  1.65it/s]Extractor Estimating: 187it [01:46,  1.67it/s]Extractor Estimating: 188it [01:47,  1.66it/s]Extractor Estimating: 189it [01:47,  1.65it/s]Extractor Estimating: 190it [01:48,  1.65it/s]Extractor Estimating: 191it [01:48,  1.64it/s]Extractor Estimating: 192it [01:49,  1.66it/s]Extractor Estimating: 193it [01:50,  1.58it/s]Extractor Estimating: 194it [01:50,  1.58it/s]Extractor Estimating: 195it [01:51,  1.59it/s]Extractor Estimating: 196it [01:52,  1.54it/s]Extractor Estimating: 197it [01:52,  1.56it/s]Extractor Estimating: 198it [01:53,  1.61it/s]Extractor Estimating: 199it [01:53,  1.65it/s]Extractor Estimating: 200it [01:54,  1.68it/s]Extractor Estimating: 201it [01:55,  1.68it/s]Extractor Estimating: 202it [01:55,  1.66it/s]Extractor Estimating: 203it [01:56,  1.62it/s]Extractor Estimating: 204it [01:57,  1.63it/s]Extractor Estimating: 205it [01:57,  1.67it/s]Extractor Estimating: 206it [01:58,  1.58it/s]Extractor Estimating: 207it [01:58,  1.60it/s]Extractor Estimating: 208it [01:59,  1.64it/s]Extractor Estimating: 209it [02:00,  1.68it/s]Extractor Estimating: 210it [02:00,  1.70it/s]Extractor Estimating: 211it [02:01,  1.69it/s]Extractor Estimating: 212it [02:01,  1.68it/s]Extractor Estimating: 213it [02:02,  1.63it/s]Extractor Estimating: 214it [02:03,  1.65it/s]Extractor Estimating: 215it [02:03,  1.66it/s]Extractor Estimating: 216it [02:04,  1.59it/s]Extractor Estimating: 217it [02:04,  1.64it/s]Extractor Estimating: 218it [02:05,  1.67it/s]Extractor Estimating: 219it [02:06,  1.71it/s]Extractor Estimating: 220it [02:06,  1.74it/s]Extractor Estimating: 221it [02:07,  1.68it/s]Extractor Estimating: 222it [02:07,  1.66it/s]Extractor Estimating: 223it [02:08,  1.65it/s]Extractor Estimating: 224it [02:09,  1.65it/s]Extractor Estimating: 225it [02:09,  1.67it/s]Extractor Estimating: 226it [02:10,  1.71it/s]Extractor Estimating: 227it [02:10,  1.71it/s]Extractor Estimating: 228it [02:11,  1.77it/s]Extractor Estimating: 229it [02:11,  1.81it/s]Extractor Estimating: 230it [02:12,  1.84it/s]Extractor Estimating: 231it [02:12,  1.81it/s]Extractor Estimating: 232it [02:13,  1.71it/s]Extractor Estimating: 233it [02:14,  1.70it/s]Extractor Estimating: 234it [02:14,  1.71it/s]Extractor Estimating: 235it [02:15,  1.70it/s]Extractor Estimating: 236it [02:15,  1.69it/s]Extractor Estimating: 237it [02:16,  1.69it/s]Extractor Estimating: 238it [02:17,  1.71it/s]Extractor Estimating: 239it [02:17,  1.66it/s]Extractor Estimating: 240it [02:18,  1.71it/s]Extractor Estimating: 241it [02:18,  1.70it/s]Extractor Estimating: 242it [02:19,  1.71it/s]Extractor Estimating: 243it [02:20,  1.75it/s]Extractor Estimating: 244it [02:20,  1.80it/s]Extractor Estimating: 245it [02:21,  1.80it/s]Extractor Estimating: 246it [02:21,  1.76it/s]Extractor Estimating: 247it [02:22,  1.72it/s]Extractor Estimating: 248it [02:22,  1.68it/s]Extractor Estimating: 249it [02:23,  1.71it/s]Extractor Estimating: 250it [02:23,  1.93it/s]Extractor Estimating: 250it [02:23,  1.74it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:31,445 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:31,471 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:31,471 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:31,471 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:31,472 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 11:17:32,282 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 11:17:32,283 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:17:32,893 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 11:17:34,015 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:17:34,015 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:37,060 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:37,092 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:37,093 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:37,093 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 11:17:37,093 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 11:17:37,895 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 11:17:37,897 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 11:17:38,492 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 11:17:38,727 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 11:17:38,727 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1113: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[INFO|training_args.py:725] 2023-08-29 12:45:10,690 >> PyTorch: setting up devices
[INFO|training_args.py:625] 2023-08-29 12:45:10,988 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/3_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_5_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/3.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.8, 'with_train': False, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
{'num_pseudo': 4000, 'num_train': 999}
num of filtered data: 3991 mean pseudo reward: 0.9506961297400492
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/3.jsonl', 'path_dev': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl'}
train vocab size: 23556
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 23656, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/data/train.txt
{"train_model: args: ModelArguments(model_class='JointModel', model_read_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter3/model', model_write_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/model', pretrained_wv='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/data/train.txt', label_config=None, batch_size=24, evaluate_interval=500, max_steps=10000, max_epoches=20, decay_rate=0.05, token_emb_dim=100, char_encoder='lstm', char_emb_dim=30, cased=False, hidden_dim=200, num_layers=3, crf=None, loss_reduction='sum', maxlen=None, dropout=0.5, optimizer='adam', lr=0.001, vocab_size=23656, vocab_file=None, ner_tag_vocab_size=64, re_tag_vocab_size=250, lm_emb_dim=1024, lm_emb_path='albert-large-v2', head_emb_dim=384, tag_form='iob2', warm_steps=1000, grad_period=1, device='cuda', seed=42)"}
warm up: learning rate was adjusted to 1e-06
warm up: learning rate was adjusted to 1.1e-05
warm up: learning rate was adjusted to 2.1000000000000002e-05
warm up: learning rate was adjusted to 3.1e-05
warm up: learning rate was adjusted to 4.1e-05
warm up: learning rate was adjusted to 5.1000000000000006e-05
warm up: learning rate was adjusted to 6.1e-05
warm up: learning rate was adjusted to 7.1e-05
warm up: learning rate was adjusted to 8.1e-05
warm up: learning rate was adjusted to 9.1e-05
g_step 100, step 100, avg_time 0.944, loss:522.0523
warm up: learning rate was adjusted to 0.000101
warm up: learning rate was adjusted to 0.000111
warm up: learning rate was adjusted to 0.000121
warm up: learning rate was adjusted to 0.000131
warm up: learning rate was adjusted to 0.000141
warm up: learning rate was adjusted to 0.00015099999999999998
warm up: learning rate was adjusted to 0.000161
warm up: learning rate was adjusted to 0.000171
warm up: learning rate was adjusted to 0.00018099999999999998
warm up: learning rate was adjusted to 0.000191
g_step 200, step 33, avg_time 0.960, loss:500.8741
warm up: learning rate was adjusted to 0.000201
warm up: learning rate was adjusted to 0.000211
warm up: learning rate was adjusted to 0.000221
warm up: learning rate was adjusted to 0.000231
warm up: learning rate was adjusted to 0.000241
warm up: learning rate was adjusted to 0.000251
warm up: learning rate was adjusted to 0.000261
warm up: learning rate was adjusted to 0.00027100000000000003
warm up: learning rate was adjusted to 0.00028100000000000005
warm up: learning rate was adjusted to 0.00029099999999999997
g_step 300, step 133, avg_time 0.953, loss:489.6791
warm up: learning rate was adjusted to 0.000301
warm up: learning rate was adjusted to 0.000311
warm up: learning rate was adjusted to 0.000321
warm up: learning rate was adjusted to 0.000331
warm up: learning rate was adjusted to 0.00034100000000000005
warm up: learning rate was adjusted to 0.000351
warm up: learning rate was adjusted to 0.000361
warm up: learning rate was adjusted to 0.000371
warm up: learning rate was adjusted to 0.000381
warm up: learning rate was adjusted to 0.000391
g_step 400, step 66, avg_time 0.953, loss:465.0319
warm up: learning rate was adjusted to 0.00040100000000000004
warm up: learning rate was adjusted to 0.000411
warm up: learning rate was adjusted to 0.000421
warm up: learning rate was adjusted to 0.000431
warm up: learning rate was adjusted to 0.000441
warm up: learning rate was adjusted to 0.000451
warm up: learning rate was adjusted to 0.00046100000000000004
warm up: learning rate was adjusted to 0.000471
warm up: learning rate was adjusted to 0.000481
warm up: learning rate was adjusted to 0.000491
g_step 500, step 166, avg_time 0.945, loss:471.0135
>> valid entity prec:0.4471, rec:0.4716, f1:0.4590
>> valid relation prec:0.2174, rec:0.1188, f1:0.1536
>> valid relation with NER prec:0.2174, rec:0.1188, f1:0.1536
new max entity f1 on valid!
new max relation f1 on valid!
new max relation f1 with NER on valid!
new max averaged entity f1 and relation f1 on valid!
new max averaged entity f1 and relation f1 with NER on valid!
warm up: learning rate was adjusted to 0.000501
warm up: learning rate was adjusted to 0.0005110000000000001
warm up: learning rate was adjusted to 0.000521
warm up: learning rate was adjusted to 0.000531
warm up: learning rate was adjusted to 0.000541
warm up: learning rate was adjusted to 0.0005510000000000001
warm up: learning rate was adjusted to 0.0005610000000000001
warm up: learning rate was adjusted to 0.0005710000000000001
warm up: learning rate was adjusted to 0.0005809999999999999
warm up: learning rate was adjusted to 0.0005909999999999999
g_step 600, step 99, avg_time 4.524, loss:429.9619
warm up: learning rate was adjusted to 0.000601
warm up: learning rate was adjusted to 0.000611
warm up: learning rate was adjusted to 0.000621
warm up: learning rate was adjusted to 0.000631
warm up: learning rate was adjusted to 0.000641
warm up: learning rate was adjusted to 0.000651
warm up: learning rate was adjusted to 0.000661
warm up: learning rate was adjusted to 0.000671
warm up: learning rate was adjusted to 0.0006810000000000001
warm up: learning rate was adjusted to 0.0006910000000000001
g_step 700, step 32, avg_time 0.927, loss:432.9746
warm up: learning rate was adjusted to 0.000701
warm up: learning rate was adjusted to 0.0007109999999999999
warm up: learning rate was adjusted to 0.000721
warm up: learning rate was adjusted to 0.000731
warm up: learning rate was adjusted to 0.000741
warm up: learning rate was adjusted to 0.000751
warm up: learning rate was adjusted to 0.000761
warm up: learning rate was adjusted to 0.000771
warm up: learning rate was adjusted to 0.000781
warm up: learning rate was adjusted to 0.000791
g_step 800, step 132, avg_time 0.943, loss:447.9744
warm up: learning rate was adjusted to 0.0008010000000000001
warm up: learning rate was adjusted to 0.0008110000000000001
warm up: learning rate was adjusted to 0.0008210000000000001
warm up: learning rate was adjusted to 0.000831
warm up: learning rate was adjusted to 0.000841
warm up: learning rate was adjusted to 0.000851
warm up: learning rate was adjusted to 0.000861
warm up: learning rate was adjusted to 0.000871
warm up: learning rate was adjusted to 0.0008810000000000001
warm up: learning rate was adjusted to 0.000891
g_step 900, step 65, avg_time 0.932, loss:424.4907
warm up: learning rate was adjusted to 0.000901
warm up: learning rate was adjusted to 0.000911
warm up: learning rate was adjusted to 0.000921
warm up: learning rate was adjusted to 0.0009310000000000001
warm up: learning rate was adjusted to 0.0009410000000000001
warm up: learning rate was adjusted to 0.000951
warm up: learning rate was adjusted to 0.0009609999999999999
warm up: learning rate was adjusted to 0.000971
warm up: learning rate was adjusted to 0.0009809999999999999
warm up: learning rate was adjusted to 0.000991
g_step 1000, step 165, avg_time 0.915, loss:440.2438
learning rate was adjusted to 0.0009523809523809524
>> valid entity prec:0.4183, rec:0.4028, f1:0.4104
>> valid relation prec:0.2051, rec:0.0848, f1:0.1200
>> valid relation with NER prec:0.2051, rec:0.0848, f1:0.1200
g_step 1100, step 98, avg_time 4.440, loss:412.0155
g_step 1200, step 31, avg_time 0.930, loss:430.8194
g_step 1300, step 131, avg_time 0.939, loss:393.5594
g_step 1400, step 64, avg_time 0.933, loss:368.1625
g_step 1500, step 164, avg_time 0.940, loss:394.4639
>> valid entity prec:0.4225, rec:0.3608, f1:0.3892
>> valid relation prec:0.2152, rec:0.1034, f1:0.1397
>> valid relation with NER prec:0.2152, rec:0.1034, f1:0.1397
g_step 1600, step 97, avg_time 4.443, loss:362.7804
g_step 1700, step 30, avg_time 0.931, loss:362.1447
g_step 1800, step 130, avg_time 0.935, loss:343.6598
g_step 1900, step 63, avg_time 0.956, loss:347.1629
g_step 2000, step 163, avg_time 0.934, loss:344.6063
learning rate was adjusted to 0.0009090909090909091
>> valid entity prec:0.3924, rec:0.2894, f1:0.3331
>> valid relation prec:0.1721, rec:0.0607, f1:0.0897
>> valid relation with NER prec:0.1721, rec:0.0607, f1:0.0897
g_step 2100, step 96, avg_time 4.438, loss:324.4027
g_step 2200, step 29, avg_time 0.933, loss:313.0345
g_step 2300, step 129, avg_time 0.941, loss:300.1873
g_step 2400, step 62, avg_time 0.938, loss:298.2232
g_step 2500, step 162, avg_time 0.931, loss:294.8769
>> valid entity prec:0.4625, rec:0.3774, f1:0.4157
>> valid relation prec:0.1901, rec:0.0820, f1:0.1145
>> valid relation with NER prec:0.1901, rec:0.0820, f1:0.1145
g_step 2600, step 95, avg_time 4.455, loss:273.7903
g_step 2700, step 28, avg_time 0.928, loss:277.4490
g_step 2800, step 128, avg_time 0.943, loss:275.0355
g_step 2900, step 61, avg_time 0.943, loss:261.0867
g_step 3000, step 161, avg_time 0.942, loss:268.1851
learning rate was adjusted to 0.0008695652173913044
>> valid entity prec:0.4305, rec:0.3250, f1:0.3704
>> valid relation prec:0.1300, rec:0.0612, f1:0.0833
>> valid relation with NER prec:0.1300, rec:0.0612, f1:0.0833
g_step 3100, step 94, avg_time 4.428, loss:246.4793
g_step 3200, step 27, avg_time 0.933, loss:241.6551
g_step 3300, step 127, avg_time 0.939, loss:246.0859
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
08/29/2023 12:45:10 - WARNING - transformer_base.run_clm_rl -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True
08/29/2023 12:45:10 - INFO - transformer_base.run_clm_rl -   Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=2,
greater_is_better=False,
group_by_length=False,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_on_each_node=True,
logging_dir=runs/Aug29_12-45-10_ctolab07.scc.idea,
logging_first_step=False,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
output_dir=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
08/29/2023 12:45:12 - WARNING - datasets.builder -   Using custom data configuration default-af8b8dc01ba2d979
Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/xuting/.cache/huggingface/datasets/json/default-af8b8dc01ba2d979/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...
0 tables [00:00, ? tables/s]                            0 tables [00:00, ? tables/s]                            [INFO|configuration_utils.py:515] 2023-08-29 12:45:14,008 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 12:45:14,027 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 12:45:14,028 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 12:45:14,029 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 12:45:14,100 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 12:45:14,135 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 12:45:14,135 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 12:45:14,135 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 12:45:14,135 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 12:45:14,136 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 12:45:14,136 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/tokenizer_config.json
[INFO|modeling_utils.py:1150] 2023-08-29 12:45:14,448 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 12:45:17,594 >> All model checkpoint weights were used when initializing Model.

[INFO|modeling_utils.py:1345] 2023-08-29 12:45:17,622 >> All the weights of Model were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Model for predictions without further training.
Dataset json downloaded and prepared to /home/xuting/.cache/huggingface/datasets/json/default-af8b8dc01ba2d979/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.
PreTrainedTokenizerFast(name_or_path='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'})
  0%|          | 0/4 [00:00<?, ?ba/s] 25%|██▌       | 1/4 [00:00<00:01,  2.64ba/s] 50%|█████     | 2/4 [00:00<00:00,  2.85ba/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.60ba/s]100%|██████████| 4/4 [00:01<00:00,  4.12ba/s]100%|██████████| 4/4 [00:01<00:00,  3.67ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:04,  3.42ba/s] 13%|█▎        | 2/15 [00:00<00:03,  4.19ba/s] 20%|██        | 3/15 [00:00<00:02,  4.53ba/s] 27%|██▋       | 4/15 [00:00<00:02,  4.67ba/s] 33%|███▎      | 5/15 [00:01<00:02,  4.76ba/s] 40%|████      | 6/15 [00:01<00:01,  4.83ba/s] 47%|████▋     | 7/15 [00:01<00:01,  4.88ba/s] 53%|█████▎    | 8/15 [00:01<00:01,  4.89ba/s] 60%|██████    | 9/15 [00:01<00:01,  4.92ba/s] 67%|██████▋   | 10/15 [00:02<00:01,  4.90ba/s] 73%|███████▎  | 11/15 [00:02<00:00,  4.93ba/s] 80%|████████  | 12/15 [00:02<00:00,  4.09ba/s] 87%|████████▋ | 13/15 [00:02<00:00,  4.32ba/s] 93%|█████████▎| 14/15 [00:03<00:00,  4.49ba/s]100%|██████████| 15/15 [00:03<00:00,  4.88ba/s]
  0%|          | 0/4 [00:00<?, ?ba/s] 25%|██▌       | 1/4 [00:00<00:00,  4.20ba/s] 75%|███████▌  | 3/4 [00:00<00:00,  7.59ba/s]100%|██████████| 4/4 [00:00<00:00,  7.64ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:02,  4.99ba/s] 20%|██        | 3/15 [00:00<00:01,  8.20ba/s] 27%|██▋       | 4/15 [00:00<00:01,  7.93ba/s] 40%|████      | 6/15 [00:00<00:01,  8.97ba/s] 53%|█████▎    | 8/15 [00:00<00:00,  9.53ba/s] 67%|██████▋   | 10/15 [00:01<00:00,  9.83ba/s] 80%|████████  | 12/15 [00:01<00:00, 10.00ba/s] 93%|█████████▎| 14/15 [00:01<00:00, 10.15ba/s]100%|██████████| 15/15 [00:01<00:00, 10.04ba/s]
[INFO|trainer.py:414] 2023-08-29 12:45:25,682 >> Using amp fp16 backend
[INFO|trainer.py:1147] 2023-08-29 12:45:25,903 >> ***** Running training *****
[INFO|trainer.py:1148] 2023-08-29 12:45:25,903 >>   Num examples = 4000
[INFO|trainer.py:1149] 2023-08-29 12:45:25,903 >>   Num Epochs = 5
[INFO|trainer.py:1150] 2023-08-29 12:45:25,903 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1151] 2023-08-29 12:45:25,903 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1152] 2023-08-29 12:45:25,903 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1153] 2023-08-29 12:45:25,903 >>   Total optimization steps = 310
  0%|          | 0/310 [00:00<?, ?it/s]  0%|          | 1/310 [00:01<07:07,  1.38s/it]  1%|          | 2/310 [00:01<04:31,  1.13it/s]  1%|          | 3/310 [00:02<03:14,  1.58it/s]  1%|▏         | 4/310 [00:02<02:39,  1.92it/s]  2%|▏         | 5/310 [00:02<02:13,  2.28it/s]  2%|▏         | 6/310 [00:03<02:10,  2.33it/s]  2%|▏         | 7/310 [00:03<01:56,  2.60it/s]  3%|▎         | 8/310 [00:03<01:47,  2.82it/s]  3%|▎         | 9/310 [00:04<01:40,  2.98it/s]  3%|▎         | 10/310 [00:04<01:36,  3.11it/s]  4%|▎         | 11/310 [00:04<01:33,  3.20it/s]  4%|▍         | 12/310 [00:05<01:30,  3.28it/s]  4%|▍         | 13/310 [00:05<01:30,  3.29it/s]  5%|▍         | 14/310 [00:05<01:28,  3.34it/s]  5%|▍         | 15/310 [00:05<01:27,  3.39it/s]  5%|▌         | 16/310 [00:06<01:26,  3.41it/s]  5%|▌         | 17/310 [00:06<01:25,  3.43it/s]  6%|▌         | 18/310 [00:06<01:24,  3.45it/s]  6%|▌         | 19/310 [00:07<01:24,  3.45it/s]  6%|▋         | 20/310 [00:07<01:23,  3.46it/s]  7%|▋         | 21/310 [00:07<01:23,  3.46it/s]  7%|▋         | 22/310 [00:07<01:23,  3.47it/s]  7%|▋         | 23/310 [00:08<01:22,  3.47it/s]  8%|▊         | 24/310 [00:08<01:26,  3.29it/s]  8%|▊         | 25/310 [00:08<01:25,  3.34it/s]  8%|▊         | 26/310 [00:09<01:23,  3.38it/s]  9%|▊         | 27/310 [00:09<01:23,  3.41it/s]  9%|▉         | 28/310 [00:09<01:22,  3.43it/s]  9%|▉         | 29/310 [00:10<01:21,  3.44it/s] 10%|▉         | 30/310 [00:10<01:21,  3.45it/s] 10%|█         | 31/310 [00:10<01:20,  3.45it/s] 10%|█         | 32/310 [00:10<01:20,  3.46it/s] 11%|█         | 33/310 [00:11<01:20,  3.46it/s] 11%|█         | 34/310 [00:11<01:19,  3.47it/s] 11%|█▏        | 35/310 [00:11<01:19,  3.46it/s] 12%|█▏        | 36/310 [00:12<01:19,  3.46it/s] 12%|█▏        | 37/310 [00:12<01:18,  3.46it/s] 12%|█▏        | 38/310 [00:12<01:18,  3.46it/s] 13%|█▎        | 39/310 [00:12<01:18,  3.47it/s] 13%|█▎        | 40/310 [00:13<01:17,  3.47it/s] 13%|█▎        | 41/310 [00:13<01:19,  3.38it/s] 14%|█▎        | 42/310 [00:13<01:18,  3.41it/s] 14%|█▍        | 43/310 [00:14<01:17,  3.43it/s] 14%|█▍        | 44/310 [00:14<01:17,  3.44it/s] 15%|█▍        | 45/310 [00:14<01:16,  3.45it/s] 15%|█▍        | 46/310 [00:14<01:16,  3.45it/s] 15%|█▌        | 47/310 [00:15<01:16,  3.46it/s] 15%|█▌        | 48/310 [00:15<01:19,  3.29it/s] 16%|█▌        | 49/310 [00:15<01:18,  3.34it/s] 16%|█▌        | 50/310 [00:16<01:17,  3.37it/s] 16%|█▋        | 51/310 [00:16<01:16,  3.40it/s] 17%|█▋        | 52/310 [00:16<01:15,  3.43it/s] 17%|█▋        | 53/310 [00:17<01:14,  3.44it/s] 17%|█▋        | 54/310 [00:17<01:14,  3.45it/s] 18%|█▊        | 55/310 [00:17<01:13,  3.46it/s] 18%|█▊        | 56/310 [00:17<01:13,  3.46it/s] 18%|█▊        | 57/310 [00:18<01:13,  3.46it/s] 19%|█▊        | 58/310 [00:18<01:12,  3.47it/s] 19%|█▉        | 59/310 [00:18<01:13,  3.39it/s] 19%|█▉        | 60/310 [00:19<01:13,  3.41it/s] 20%|█▉        | 61/310 [00:19<01:12,  3.43it/s] 20%|██        | 62/310 [00:19<01:12,  3.44it/s][INFO|trainer.py:2140] 2023-08-29 12:45:45,658 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 12:45:45,658 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 12:45:45,659 >>   Batch size = 8

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:30, 56.73it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.24it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.36it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.33it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 45.90it/s][A
  2%|▏         | 32/1759 [00:00<00:40, 42.63it/s][A
  2%|▏         | 37/1759 [00:00<00:39, 43.58it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 44.10it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 44.58it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 44.93it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.15it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.17it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.07it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 44.75it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 44.78it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 44.85it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 45.03it/s][A
  5%|▌         | 92/1759 [00:02<00:36, 45.19it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 45.36it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.45it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.46it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.22it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.00it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 44.82it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 44.93it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 45.04it/s][A
  8%|▊         | 137/1759 [00:03<00:35, 45.18it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.29it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.44it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.42it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.27it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 45.04it/s][A
  9%|▉         | 167/1759 [00:03<00:37, 42.30it/s][A
 10%|▉         | 172/1759 [00:03<00:36, 43.30it/s][A
 10%|█         | 177/1759 [00:03<00:36, 43.93it/s][A
 10%|█         | 182/1759 [00:04<00:35, 44.45it/s][A
 11%|█         | 187/1759 [00:04<00:35, 44.77it/s][A
 11%|█         | 192/1759 [00:04<00:34, 45.04it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.07it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 44.99it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 44.71it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 44.69it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 44.89it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 45.07it/s][A
 13%|█▎        | 227/1759 [00:05<00:33, 45.26it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 45.40it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.45it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.34it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.13it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 44.92it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 44.82it/s][A
 15%|█▍        | 262/1759 [00:05<00:38, 39.26it/s][A
 15%|█▌        | 267/1759 [00:05<00:36, 40.99it/s][A
 15%|█▌        | 272/1759 [00:06<00:35, 42.25it/s][A
 16%|█▌        | 277/1759 [00:06<00:34, 43.16it/s][A
 16%|█▌        | 282/1759 [00:06<00:33, 43.84it/s][A
 16%|█▋        | 287/1759 [00:06<00:33, 44.29it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 44.67it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 44.89it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 44.66it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 44.68it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 44.80it/s][A
 18%|█▊        | 317/1759 [00:07<00:32, 45.00it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 45.16it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.26it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 45.21it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 45.29it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 45.19it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 44.96it/s][A
 20%|██        | 352/1759 [00:07<00:31, 44.84it/s][A
 20%|██        | 357/1759 [00:07<00:31, 44.89it/s][A
 21%|██        | 362/1759 [00:08<00:30, 45.07it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.23it/s][A
 21%|██        | 372/1759 [00:08<00:30, 45.26it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.30it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 45.20it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 45.08it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 45.07it/s][A
 23%|██▎       | 397/1759 [00:08<00:32, 42.31it/s][A
 23%|██▎       | 402/1759 [00:08<00:31, 43.26it/s][A
 23%|██▎       | 407/1759 [00:09<00:30, 43.98it/s][A
 23%|██▎       | 412/1759 [00:09<00:30, 44.36it/s][A
 24%|██▎       | 417/1759 [00:09<00:30, 44.71it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 44.94it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 45.11it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 45.10it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 44.77it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 44.81it/s][A
 25%|██▌       | 447/1759 [00:09<00:29, 44.94it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 45.02it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 45.16it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.27it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.26it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 45.24it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 45.13it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 44.93it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 44.87it/s][A
 28%|██▊       | 492/1759 [00:10<00:28, 44.93it/s][A
 28%|██▊       | 497/1759 [00:11<00:28, 45.06it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.18it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 45.31it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 45.33it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 45.31it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 45.17it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 45.02it/s][A
 30%|███       | 532/1759 [00:11<00:27, 44.94it/s][A
 31%|███       | 537/1759 [00:11<00:27, 44.91it/s][A
 31%|███       | 542/1759 [00:12<00:27, 45.03it/s][A
 31%|███       | 547/1759 [00:12<00:26, 45.16it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.29it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 45.32it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 45.27it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 45.06it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 44.98it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 44.93it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 45.02it/s][A
 33%|███▎      | 587/1759 [00:13<00:25, 45.11it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.18it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.30it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 45.29it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 45.21it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 45.05it/s][A
 35%|███▌      | 617/1759 [00:13<00:25, 44.92it/s][A
 35%|███▌      | 622/1759 [00:13<00:25, 44.98it/s][A
 36%|███▌      | 627/1759 [00:13<00:25, 44.18it/s][A
 36%|███▌      | 632/1759 [00:14<00:25, 44.53it/s][A
 36%|███▌      | 637/1759 [00:14<00:25, 44.86it/s][A
 36%|███▋      | 642/1759 [00:14<00:24, 45.04it/s][A
 37%|███▋      | 647/1759 [00:14<00:24, 45.15it/s][A
 37%|███▋      | 652/1759 [00:14<00:24, 45.00it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 44.91it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 45.00it/s][A
 38%|███▊      | 667/1759 [00:14<00:24, 44.89it/s][A
 38%|███▊      | 672/1759 [00:14<00:24, 44.98it/s][A
 38%|███▊      | 677/1759 [00:15<00:24, 45.05it/s][A
 39%|███▉      | 682/1759 [00:15<00:23, 45.21it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 45.29it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 45.15it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 45.15it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 45.05it/s][A
 40%|████      | 707/1759 [00:15<00:23, 44.98it/s][A
 40%|████      | 712/1759 [00:15<00:23, 44.90it/s][A
 41%|████      | 717/1759 [00:16<00:23, 45.02it/s][A
 41%|████      | 722/1759 [00:16<00:23, 43.61it/s][A
 41%|████▏     | 727/1759 [00:16<00:23, 44.25it/s][A
 42%|████▏     | 732/1759 [00:16<00:23, 44.64it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 44.84it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 44.90it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 44.87it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 44.88it/s][A
 43%|████▎     | 757/1759 [00:16<00:22, 44.84it/s][A
 43%|████▎     | 762/1759 [00:16<00:22, 44.79it/s][A
 44%|████▎     | 767/1759 [00:17<00:22, 44.83it/s][A
 44%|████▍     | 772/1759 [00:17<00:21, 44.95it/s][A
 44%|████▍     | 777/1759 [00:17<00:21, 45.09it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 45.26it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 45.37it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 45.30it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 45.14it/s][A
 46%|████▌     | 802/1759 [00:17<00:21, 44.99it/s][A
 46%|████▌     | 807/1759 [00:17<00:21, 45.01it/s][A
 46%|████▌     | 812/1759 [00:18<00:21, 44.97it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 44.96it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 45.05it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 45.21it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 45.34it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 45.30it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 45.18it/s][A
 48%|████▊     | 847/1759 [00:18<00:20, 45.00it/s][A
 48%|████▊     | 852/1759 [00:19<00:20, 44.98it/s][A
 49%|████▊     | 857/1759 [00:19<00:20, 43.10it/s][A
 49%|████▉     | 862/1759 [00:19<00:20, 43.83it/s][A
 49%|████▉     | 867/1759 [00:19<00:20, 44.32it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 44.65it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 44.93it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 44.91it/s][A
 50%|█████     | 887/1759 [00:19<00:19, 44.91it/s][A
 51%|█████     | 892/1759 [00:19<00:19, 44.90it/s][A
 51%|█████     | 897/1759 [00:19<00:19, 44.71it/s][A
 51%|█████▏    | 902/1759 [00:20<00:19, 44.74it/s][A
 52%|█████▏    | 907/1759 [00:20<00:18, 44.89it/s][A
 52%|█████▏    | 912/1759 [00:20<00:18, 45.09it/s][A
 52%|█████▏    | 917/1759 [00:20<00:18, 45.20it/s][A
 52%|█████▏    | 922/1759 [00:20<00:18, 45.32it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 45.37it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 45.30it/s][A
 53%|█████▎    | 937/1759 [00:20<00:18, 45.18it/s][A
 54%|█████▎    | 942/1759 [00:20<00:18, 45.01it/s][A
 54%|█████▍    | 947/1759 [00:21<00:18, 44.91it/s][A
 54%|█████▍    | 952/1759 [00:21<00:18, 44.61it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 44.89it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 45.07it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 45.18it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 45.17it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 45.04it/s][A
 56%|█████▌    | 982/1759 [00:21<00:17, 45.04it/s][A
 56%|█████▌    | 987/1759 [00:21<00:17, 44.91it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 44.87it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 44.88it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 45.01it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.15it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 45.23it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 45.27it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:17, 42.22it/s][A
 58%|█████▊    | 1027/1759 [00:22<00:16, 43.20it/s][A
 59%|█████▊    | 1032/1759 [00:23<00:16, 43.75it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:16, 44.12it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:16, 44.39it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:15, 44.67it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:15, 44.80it/s][A
 60%|██████    | 1057/1759 [00:23<00:15, 44.98it/s][A
 60%|██████    | 1062/1759 [00:23<00:15, 44.91it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 44.69it/s][A
 61%|██████    | 1072/1759 [00:23<00:15, 44.90it/s][A
 61%|██████    | 1077/1759 [00:24<00:15, 44.97it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:15, 45.01it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:15, 42.00it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:15, 42.97it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:15, 43.72it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 44.24it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 44.51it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 44.63it/s][A
 64%|██████▎   | 1117/1759 [00:24<00:14, 44.80it/s][A
 64%|██████▍   | 1122/1759 [00:25<00:14, 44.85it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:24, 25.52it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:21, 29.47it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:18, 33.00it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:17, 36.01it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:15, 38.44it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:15, 40.33it/s][A
 66%|██████▌   | 1157/1759 [00:26<00:14, 41.77it/s][A
 66%|██████▌   | 1162/1759 [00:26<00:13, 42.89it/s][A
 66%|██████▋   | 1167/1759 [00:26<00:14, 41.70it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 42.37it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:13, 42.96it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:13, 43.68it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 44.19it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:12, 44.58it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 44.78it/s][A
 68%|██████▊   | 1202/1759 [00:27<00:12, 44.96it/s][A
 69%|██████▊   | 1207/1759 [00:27<00:12, 45.06it/s][A
 69%|██████▉   | 1212/1759 [00:27<00:12, 45.03it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 44.93it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:11, 44.88it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 44.89it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 45.01it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 45.08it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 45.16it/s][A
 71%|███████   | 1247/1759 [00:28<00:11, 45.19it/s][A
 71%|███████   | 1252/1759 [00:28<00:11, 45.14it/s][A
 71%|███████▏  | 1257/1759 [00:28<00:11, 45.02it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:11, 44.95it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:10, 44.92it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 44.96it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 45.04it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 45.11it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 45.18it/s][A
 73%|███████▎  | 1292/1759 [00:29<00:10, 45.18it/s][A
 74%|███████▎  | 1297/1759 [00:29<00:10, 45.14it/s][A
 74%|███████▍  | 1302/1759 [00:29<00:10, 43.69it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 44.15it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:10, 44.32it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:09, 44.53it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 44.67it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 44.85it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 45.00it/s][A
 76%|███████▌  | 1337/1759 [00:30<00:09, 45.12it/s][A
 76%|███████▋  | 1342/1759 [00:30<00:09, 44.95it/s][A
 77%|███████▋  | 1347/1759 [00:30<00:09, 44.85it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 44.97it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:08, 44.97it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 45.00it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 45.04it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:08, 45.09it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:08, 45.18it/s][A
 79%|███████▊  | 1382/1759 [00:31<00:08, 45.11it/s][A
 79%|███████▉  | 1387/1759 [00:31<00:08, 45.03it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 44.95it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 44.99it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:07, 45.01it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 45.00it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 45.04it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 45.10it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 45.13it/s][A
 81%|████████  | 1427/1759 [00:32<00:07, 45.07it/s][A
 81%|████████▏ | 1432/1759 [00:32<00:07, 45.02it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 44.91it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 44.97it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 44.97it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 45.04it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 45.01it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 45.08it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 45.05it/s][A
 84%|████████▎ | 1472/1759 [00:33<00:06, 45.20it/s][A
 84%|████████▍ | 1477/1759 [00:33<00:06, 45.10it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 45.12it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 45.08it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 45.03it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 45.07it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 45.01it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 45.05it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 45.01it/s][A
 86%|████████▌ | 1517/1759 [00:34<00:05, 45.12it/s][A
 87%|████████▋ | 1522/1759 [00:34<00:05, 45.07it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 45.07it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 43.71it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:05, 44.21it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 44.39it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 44.65it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 44.74it/s][A
 89%|████████▊ | 1557/1759 [00:35<00:04, 44.87it/s][A
 89%|████████▉ | 1562/1759 [00:35<00:04, 44.90it/s][A
 89%|████████▉ | 1567/1759 [00:35<00:04, 44.97it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 44.83it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 44.82it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 45.01it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 45.05it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 45.16it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 45.19it/s][A
 91%|█████████ | 1602/1759 [00:36<00:03, 45.17it/s][A
 91%|█████████▏| 1607/1759 [00:36<00:03, 45.19it/s][A
 92%|█████████▏| 1612/1759 [00:36<00:03, 45.12it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 44.97it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 44.90it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 44.88it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 45.00it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 45.12it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 45.12it/s][A
 94%|█████████▎| 1647/1759 [00:36<00:02, 45.20it/s][A
 94%|█████████▍| 1652/1759 [00:37<00:02, 45.20it/s][A
 94%|█████████▍| 1657/1759 [00:37<00:02, 45.14it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 45.00it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 44.87it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 44.92it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 45.04it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 45.12it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 45.14it/s][A
 96%|█████████▌| 1692/1759 [00:37<00:01, 45.20it/s][A
 96%|█████████▋| 1697/1759 [00:38<00:01, 45.19it/s][A
 97%|█████████▋| 1702/1759 [00:38<00:01, 45.13it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 44.93it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 44.90it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 44.74it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 44.97it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 45.11it/s][A
 98%|█████████▊| 1732/1759 [00:38<00:00, 45.14it/s][A
 99%|█████████▊| 1737/1759 [00:38<00:00, 45.24it/s][A
 99%|█████████▉| 1742/1759 [00:39<00:00, 45.15it/s][A
 99%|█████████▉| 1747/1759 [00:39<00:00, 45.12it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 44.92it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 44.85it/s][A
                                                   [A                                                
100%|██████████| 1759/1759 [00:39<00:00, 44.85it/s][A 20%|██        | 62/310 [00:59<01:12,  3.44it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 12:46:25,795 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-62
[INFO|configuration_utils.py:351] 2023-08-29 12:46:26,087 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-62/config.json
[INFO|modeling_utils.py:886] 2023-08-29 12:46:30,181 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-62/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 12:46:30,423 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-62/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 12:46:30,568 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-62/special_tokens_map.json
 20%|██        | 63/310 [01:17<1:12:06, 17.52s/it] 21%|██        | 64/310 [01:17<50:42, 12.37s/it]   21%|██        | 65/310 [01:17<35:42,  8.75s/it] 21%|██▏       | 66/310 [01:18<25:15,  6.21s/it] 22%|██▏       | 67/310 [01:18<17:57,  4.43s/it] 22%|██▏       | 68/310 [01:18<12:52,  3.19s/it] 22%|██▏       | 69/310 [01:19<09:19,  2.32s/it] 23%|██▎       | 70/310 [01:19<06:51,  1.71s/it] 23%|██▎       | 71/310 [01:19<05:07,  1.29s/it] 23%|██▎       | 72/310 [01:20<03:55,  1.01it/s] 24%|██▎       | 73/310 [01:20<03:05,  1.28it/s] 24%|██▍       | 74/310 [01:20<02:29,  1.58it/s] 24%|██▍       | 75/310 [01:20<02:07,  1.84it/s] 25%|██▍       | 76/310 [01:21<01:49,  2.13it/s] 25%|██▍       | 77/310 [01:21<01:36,  2.40it/s] 25%|██▌       | 78/310 [01:21<01:27,  2.64it/s] 25%|██▌       | 79/310 [01:22<01:21,  2.83it/s] 26%|██▌       | 80/310 [01:22<01:17,  2.98it/s] 26%|██▌       | 81/310 [01:22<01:13,  3.10it/s] 26%|██▋       | 82/310 [01:23<01:11,  3.18it/s] 27%|██▋       | 83/310 [01:23<01:09,  3.25it/s] 27%|██▋       | 84/310 [01:23<01:08,  3.30it/s] 27%|██▋       | 85/310 [01:23<01:07,  3.33it/s] 28%|██▊       | 86/310 [01:24<01:11,  3.14it/s] 28%|██▊       | 87/310 [01:24<01:09,  3.21it/s] 28%|██▊       | 88/310 [01:24<01:07,  3.27it/s] 29%|██▊       | 89/310 [01:25<01:06,  3.31it/s] 29%|██▉       | 90/310 [01:25<01:05,  3.34it/s] 29%|██▉       | 91/310 [01:25<01:05,  3.35it/s] 30%|██▉       | 92/310 [01:26<01:04,  3.37it/s] 30%|███       | 93/310 [01:26<01:04,  3.38it/s] 30%|███       | 94/310 [01:26<01:03,  3.38it/s] 31%|███       | 95/310 [01:26<01:03,  3.39it/s] 31%|███       | 96/310 [01:27<01:06,  3.20it/s] 31%|███▏      | 97/310 [01:27<01:05,  3.25it/s] 32%|███▏      | 98/310 [01:27<01:04,  3.29it/s] 32%|███▏      | 99/310 [01:28<01:03,  3.33it/s] 32%|███▏      | 100/310 [01:28<01:02,  3.35it/s] 33%|███▎      | 101/310 [01:28<01:02,  3.36it/s] 33%|███▎      | 102/310 [01:29<01:01,  3.38it/s] 33%|███▎      | 103/310 [01:29<01:01,  3.38it/s] 34%|███▎      | 104/310 [01:29<01:00,  3.39it/s] 34%|███▍      | 105/310 [01:29<01:00,  3.40it/s] 34%|███▍      | 106/310 [01:30<00:59,  3.40it/s] 35%|███▍      | 107/310 [01:30<01:01,  3.32it/s] 35%|███▍      | 108/310 [01:30<01:00,  3.35it/s] 35%|███▌      | 109/310 [01:31<00:59,  3.36it/s] 35%|███▌      | 110/310 [01:31<00:59,  3.38it/s] 36%|███▌      | 111/310 [01:31<00:58,  3.39it/s] 36%|███▌      | 112/310 [01:31<00:58,  3.39it/s] 36%|███▋      | 113/310 [01:32<00:57,  3.40it/s] 37%|███▋      | 114/310 [01:32<00:57,  3.40it/s] 37%|███▋      | 115/310 [01:32<00:57,  3.40it/s] 37%|███▋      | 116/310 [01:33<00:57,  3.40it/s] 38%|███▊      | 117/310 [01:33<00:56,  3.40it/s] 38%|███▊      | 118/310 [01:33<00:58,  3.30it/s] 38%|███▊      | 119/310 [01:34<00:57,  3.33it/s] 39%|███▊      | 120/310 [01:34<00:56,  3.35it/s] 39%|███▉      | 121/310 [01:34<00:56,  3.37it/s] 39%|███▉      | 122/310 [01:34<00:55,  3.38it/s] 40%|███▉      | 123/310 [01:35<00:55,  3.38it/s] 40%|████      | 124/310 [01:35<00:54,  3.40it/s][INFO|trainer.py:2140] 2023-08-29 12:47:01,568 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 12:47:01,568 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 12:47:01,568 >>   Batch size = 8
{'eval_loss': 0.9541099071502686, 'eval_runtime': 39.5348, 'eval_samples_per_second': 355.813, 'eval_steps_per_second': 44.492, 'epoch': 0.99}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.26it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.42it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.90it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.81it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 46.10it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 45.75it/s][A
  2%|▏         | 37/1759 [00:00<00:37, 45.44it/s][A
  2%|▏         | 42/1759 [00:00<00:39, 43.67it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 44.21it/s][A
  3%|▎         | 52/1759 [00:01<00:38, 44.75it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 44.99it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.16it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.07it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.06it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 44.99it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 44.88it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.88it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 45.00it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 45.15it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.27it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.42it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.33it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.24it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 45.13it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 45.01it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 44.92it/s][A
  8%|▊         | 137/1759 [00:03<00:36, 45.04it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.21it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.36it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.43it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.36it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 45.33it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 45.08it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 45.01it/s][A
 10%|█         | 177/1759 [00:03<00:36, 43.88it/s][A
 10%|█         | 182/1759 [00:04<00:35, 44.35it/s][A
 11%|█         | 187/1759 [00:04<00:35, 44.74it/s][A
 11%|█         | 192/1759 [00:04<00:34, 45.02it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.15it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 45.15it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 45.06it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 45.06it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 44.90it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 44.91it/s][A
 13%|█▎        | 227/1759 [00:05<00:34, 45.00it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 45.14it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.36it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.40it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.28it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 45.23it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 45.10it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 44.98it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 44.86it/s][A
 15%|█▌        | 272/1759 [00:06<00:33, 45.03it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.15it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.36it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.36it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.40it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 45.32it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 45.21it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 44.96it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 43.87it/s][A
 18%|█▊        | 317/1759 [00:07<00:33, 42.97it/s][A
 18%|█▊        | 322/1759 [00:07<00:32, 43.77it/s][A
 19%|█▊        | 327/1759 [00:07<00:32, 44.32it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 44.74it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 44.98it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 44.86it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 44.95it/s][A
 20%|██        | 352/1759 [00:07<00:31, 44.75it/s][A
 20%|██        | 357/1759 [00:07<00:31, 44.53it/s][A
 21%|██        | 362/1759 [00:08<00:31, 44.89it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.02it/s][A
 21%|██        | 372/1759 [00:08<00:30, 45.18it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.26it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 45.40it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 45.37it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 45.34it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 45.17it/s][A
 23%|██▎       | 402/1759 [00:08<00:30, 45.07it/s][A
 23%|██▎       | 407/1759 [00:09<00:30, 45.04it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.09it/s][A
 24%|██▎       | 417/1759 [00:09<00:49, 26.89it/s][A
 24%|██▍       | 423/1759 [00:09<00:41, 31.91it/s][A
 24%|██▍       | 428/1759 [00:09<00:38, 34.94it/s][A
 25%|██▍       | 433/1759 [00:09<00:35, 37.55it/s][A
 25%|██▍       | 438/1759 [00:09<00:33, 39.62it/s][A
 25%|██▌       | 443/1759 [00:10<00:32, 40.88it/s][A
 25%|██▌       | 448/1759 [00:10<00:31, 42.19it/s][A
 26%|██▌       | 453/1759 [00:10<00:30, 43.23it/s][A
 26%|██▌       | 458/1759 [00:10<00:29, 43.44it/s][A
 26%|██▋       | 463/1759 [00:10<00:29, 43.74it/s][A
 27%|██▋       | 468/1759 [00:10<00:29, 43.89it/s][A
 27%|██▋       | 473/1759 [00:10<00:29, 44.20it/s][A
 27%|██▋       | 478/1759 [00:10<00:28, 44.60it/s][A
 27%|██▋       | 483/1759 [00:10<00:28, 44.91it/s][A
 28%|██▊       | 488/1759 [00:11<00:28, 45.12it/s][A
 28%|██▊       | 493/1759 [00:11<00:27, 45.29it/s][A
 28%|██▊       | 498/1759 [00:11<00:27, 45.40it/s][A
 29%|██▊       | 503/1759 [00:11<00:27, 45.24it/s][A
 29%|██▉       | 508/1759 [00:11<00:27, 44.98it/s][A
 29%|██▉       | 513/1759 [00:11<00:27, 44.80it/s][A
 29%|██▉       | 518/1759 [00:11<00:27, 44.80it/s][A
 30%|██▉       | 523/1759 [00:11<00:27, 44.93it/s][A
 30%|███       | 528/1759 [00:11<00:27, 45.03it/s][A
 30%|███       | 533/1759 [00:12<00:27, 45.14it/s][A
 31%|███       | 538/1759 [00:12<00:26, 45.30it/s][A
 31%|███       | 543/1759 [00:12<00:26, 45.44it/s][A
 31%|███       | 548/1759 [00:12<00:26, 45.35it/s][A
 31%|███▏      | 553/1759 [00:12<00:26, 45.15it/s][A
 32%|███▏      | 558/1759 [00:12<00:26, 44.96it/s][A
 32%|███▏      | 563/1759 [00:12<00:26, 44.99it/s][A
 32%|███▏      | 568/1759 [00:12<00:26, 44.95it/s][A
 33%|███▎      | 573/1759 [00:12<00:26, 45.04it/s][A
 33%|███▎      | 578/1759 [00:13<00:26, 45.21it/s][A
 33%|███▎      | 583/1759 [00:13<00:27, 43.28it/s][A
 33%|███▎      | 588/1759 [00:13<00:26, 43.98it/s][A
 34%|███▎      | 593/1759 [00:13<00:26, 44.47it/s][A
 34%|███▍      | 598/1759 [00:13<00:26, 44.55it/s][A
 34%|███▍      | 603/1759 [00:13<00:25, 44.63it/s][A
 35%|███▍      | 608/1759 [00:13<00:25, 44.65it/s][A
 35%|███▍      | 613/1759 [00:13<00:25, 44.71it/s][A
 35%|███▌      | 618/1759 [00:13<00:25, 44.95it/s][A
 35%|███▌      | 623/1759 [00:14<00:25, 44.84it/s][A
 36%|███▌      | 628/1759 [00:14<00:25, 44.98it/s][A
 36%|███▌      | 633/1759 [00:14<00:24, 45.08it/s][A
 36%|███▋      | 638/1759 [00:14<00:24, 45.24it/s][A
 37%|███▋      | 643/1759 [00:14<00:24, 45.26it/s][A
 37%|███▋      | 648/1759 [00:14<00:24, 45.13it/s][A
 37%|███▋      | 653/1759 [00:14<00:24, 45.00it/s][A
 37%|███▋      | 658/1759 [00:14<00:24, 45.00it/s][A
 38%|███▊      | 663/1759 [00:14<00:24, 45.08it/s][A
 38%|███▊      | 668/1759 [00:15<00:24, 45.02it/s][A
 38%|███▊      | 673/1759 [00:15<00:24, 45.10it/s][A
 39%|███▊      | 678/1759 [00:15<00:23, 45.16it/s][A
 39%|███▉      | 683/1759 [00:15<00:23, 45.30it/s][A
 39%|███▉      | 688/1759 [00:15<00:23, 45.26it/s][A
 39%|███▉      | 693/1759 [00:15<00:23, 45.15it/s][A
 40%|███▉      | 698/1759 [00:15<00:23, 45.09it/s][A
 40%|███▉      | 703/1759 [00:15<00:23, 45.05it/s][A
 40%|████      | 708/1759 [00:15<00:23, 45.05it/s][A
 41%|████      | 713/1759 [00:16<00:23, 45.06it/s][A
 41%|████      | 718/1759 [00:16<00:23, 44.33it/s][A
 41%|████      | 723/1759 [00:16<00:23, 44.72it/s][A
 41%|████▏     | 728/1759 [00:16<00:22, 44.94it/s][A
 42%|████▏     | 733/1759 [00:16<00:22, 45.03it/s][A
 42%|████▏     | 738/1759 [00:16<00:22, 44.98it/s][A
 42%|████▏     | 743/1759 [00:16<00:22, 44.99it/s][A
 43%|████▎     | 748/1759 [00:16<00:22, 44.99it/s][A
 43%|████▎     | 753/1759 [00:16<00:22, 44.97it/s][A
 43%|████▎     | 758/1759 [00:17<00:22, 44.95it/s][A
 43%|████▎     | 763/1759 [00:17<00:22, 45.10it/s][A
 44%|████▎     | 768/1759 [00:17<00:21, 45.26it/s][A
 44%|████▍     | 773/1759 [00:17<00:21, 45.26it/s][A
 44%|████▍     | 778/1759 [00:17<00:21, 45.24it/s][A
 45%|████▍     | 783/1759 [00:17<00:21, 45.20it/s][A
 45%|████▍     | 788/1759 [00:17<00:21, 45.10it/s][A
 45%|████▌     | 793/1759 [00:17<00:21, 45.08it/s][A
 45%|████▌     | 798/1759 [00:17<00:21, 44.98it/s][A
 46%|████▌     | 803/1759 [00:18<00:21, 44.86it/s][A
 46%|████▌     | 808/1759 [00:18<00:21, 45.00it/s][A
 46%|████▌     | 813/1759 [00:18<00:20, 45.16it/s][A
 47%|████▋     | 818/1759 [00:18<00:20, 45.20it/s][A
 47%|████▋     | 823/1759 [00:18<00:20, 45.16it/s][A
 47%|████▋     | 828/1759 [00:18<00:20, 45.25it/s][A
 47%|████▋     | 833/1759 [00:18<00:20, 45.26it/s][A
 48%|████▊     | 838/1759 [00:18<00:20, 45.26it/s][A
 48%|████▊     | 843/1759 [00:18<00:20, 45.11it/s][A
 48%|████▊     | 848/1759 [00:19<00:20, 45.10it/s][A
 48%|████▊     | 853/1759 [00:19<00:20, 45.09it/s][A
 49%|████▉     | 858/1759 [00:19<00:21, 42.78it/s][A
 49%|████▉     | 863/1759 [00:19<00:20, 43.50it/s][A
 49%|████▉     | 868/1759 [00:19<00:20, 44.15it/s][A
 50%|████▉     | 873/1759 [00:19<00:19, 44.52it/s][A
 50%|████▉     | 878/1759 [00:19<00:19, 44.67it/s][A
 50%|█████     | 883/1759 [00:19<00:19, 44.79it/s][A
 50%|█████     | 888/1759 [00:19<00:19, 44.84it/s][A
 51%|█████     | 893/1759 [00:20<00:19, 44.87it/s][A
 51%|█████     | 898/1759 [00:20<00:19, 44.66it/s][A
 51%|█████▏    | 903/1759 [00:20<00:19, 44.77it/s][A
 52%|█████▏    | 908/1759 [00:20<00:18, 44.89it/s][A
 52%|█████▏    | 913/1759 [00:20<00:18, 45.11it/s][A
 52%|█████▏    | 918/1759 [00:20<00:18, 45.27it/s][A
 52%|█████▏    | 923/1759 [00:20<00:18, 45.35it/s][A
 53%|█████▎    | 928/1759 [00:20<00:18, 45.30it/s][A
 53%|█████▎    | 933/1759 [00:20<00:18, 45.21it/s][A
 53%|█████▎    | 938/1759 [00:21<00:18, 45.08it/s][A
 54%|█████▎    | 943/1759 [00:21<00:18, 44.82it/s][A
 54%|█████▍    | 948/1759 [00:21<00:18, 44.88it/s][A
 54%|█████▍    | 953/1759 [00:21<00:17, 44.90it/s][A
 54%|█████▍    | 958/1759 [00:21<00:17, 45.09it/s][A
 55%|█████▍    | 963/1759 [00:21<00:17, 45.24it/s][A
 55%|█████▌    | 968/1759 [00:21<00:17, 45.37it/s][A
 55%|█████▌    | 973/1759 [00:21<00:17, 45.34it/s][A
 56%|█████▌    | 978/1759 [00:21<00:17, 45.25it/s][A
 56%|█████▌    | 983/1759 [00:22<00:17, 44.91it/s][A
 56%|█████▌    | 988/1759 [00:22<00:17, 44.78it/s][A
 56%|█████▋    | 993/1759 [00:22<00:17, 44.73it/s][A
 57%|█████▋    | 998/1759 [00:22<00:16, 44.88it/s][A
 57%|█████▋    | 1003/1759 [00:22<00:16, 44.81it/s][A
 57%|█████▋    | 1008/1759 [00:22<00:16, 45.12it/s][A
 58%|█████▊    | 1013/1759 [00:22<00:16, 45.33it/s][A
 58%|█████▊    | 1018/1759 [00:22<00:16, 45.32it/s][A
 58%|█████▊    | 1023/1759 [00:22<00:16, 45.15it/s][A
 58%|█████▊    | 1028/1759 [00:23<00:16, 45.12it/s][A
 59%|█████▊    | 1033/1759 [00:23<00:16, 44.82it/s][A
 59%|█████▉    | 1038/1759 [00:23<00:16, 44.91it/s][A
 59%|█████▉    | 1043/1759 [00:23<00:15, 45.01it/s][A
 60%|█████▉    | 1048/1759 [00:23<00:15, 45.10it/s][A
 60%|█████▉    | 1053/1759 [00:23<00:15, 45.25it/s][A
 60%|██████    | 1058/1759 [00:23<00:15, 45.34it/s][A
 60%|██████    | 1063/1759 [00:23<00:15, 45.26it/s][A
 61%|██████    | 1068/1759 [00:23<00:15, 45.23it/s][A
 61%|██████    | 1073/1759 [00:24<00:15, 45.02it/s][A
 61%|██████▏   | 1078/1759 [00:24<00:15, 44.84it/s][A
 62%|██████▏   | 1083/1759 [00:24<00:15, 44.89it/s][A
 62%|██████▏   | 1088/1759 [00:24<00:14, 44.89it/s][A
 62%|██████▏   | 1093/1759 [00:24<00:14, 45.10it/s][A
 62%|██████▏   | 1098/1759 [00:24<00:14, 45.14it/s][A
 63%|██████▎   | 1103/1759 [00:24<00:14, 45.31it/s][A
 63%|██████▎   | 1108/1759 [00:24<00:14, 45.23it/s][A
 63%|██████▎   | 1113/1759 [00:24<00:14, 45.19it/s][A
 64%|██████▎   | 1118/1759 [00:25<00:15, 41.35it/s][A
 64%|██████▍   | 1123/1759 [00:25<00:14, 42.54it/s][A
 64%|██████▍   | 1128/1759 [00:25<00:14, 43.38it/s][A
 64%|██████▍   | 1133/1759 [00:25<00:14, 43.95it/s][A
 65%|██████▍   | 1138/1759 [00:25<00:13, 44.38it/s][A
 65%|██████▍   | 1143/1759 [00:25<00:13, 44.67it/s][A
 65%|██████▌   | 1148/1759 [00:25<00:13, 44.93it/s][A
 66%|██████▌   | 1153/1759 [00:25<00:13, 44.98it/s][A
 66%|██████▌   | 1158/1759 [00:25<00:13, 44.67it/s][A
 66%|██████▌   | 1163/1759 [00:26<00:13, 44.66it/s][A
 66%|██████▋   | 1168/1759 [00:26<00:13, 44.78it/s][A
 67%|██████▋   | 1173/1759 [00:26<00:13, 44.94it/s][A
 67%|██████▋   | 1178/1759 [00:26<00:12, 45.03it/s][A
 67%|██████▋   | 1183/1759 [00:26<00:12, 45.21it/s][A
 68%|██████▊   | 1188/1759 [00:26<00:12, 45.24it/s][A
 68%|██████▊   | 1193/1759 [00:26<00:12, 45.35it/s][A
 68%|██████▊   | 1198/1759 [00:26<00:12, 45.27it/s][A
 68%|██████▊   | 1203/1759 [00:26<00:12, 44.96it/s][A
 69%|██████▊   | 1208/1759 [00:27<00:12, 44.87it/s][A
 69%|██████▉   | 1213/1759 [00:27<00:12, 44.79it/s][A
 69%|██████▉   | 1218/1759 [00:27<00:12, 44.95it/s][A
 70%|██████▉   | 1223/1759 [00:27<00:11, 45.08it/s][A
 70%|██████▉   | 1228/1759 [00:27<00:11, 45.18it/s][A
 70%|███████   | 1233/1759 [00:27<00:11, 45.25it/s][A
 70%|███████   | 1238/1759 [00:27<00:11, 45.26it/s][A
 71%|███████   | 1243/1759 [00:27<00:11, 45.20it/s][A
 71%|███████   | 1248/1759 [00:28<00:11, 44.98it/s][A
 71%|███████   | 1253/1759 [00:28<00:12, 40.14it/s][A
 72%|███████▏  | 1258/1759 [00:28<00:12, 41.60it/s][A
 72%|███████▏  | 1263/1759 [00:28<00:11, 42.67it/s][A
 72%|███████▏  | 1268/1759 [00:28<00:11, 43.49it/s][A
 72%|███████▏  | 1273/1759 [00:28<00:11, 44.06it/s][A
 73%|███████▎  | 1278/1759 [00:28<00:10, 44.47it/s][A
 73%|███████▎  | 1283/1759 [00:28<00:10, 44.81it/s][A
 73%|███████▎  | 1288/1759 [00:28<00:10, 44.93it/s][A
 74%|███████▎  | 1293/1759 [00:29<00:10, 44.64it/s][A
 74%|███████▍  | 1298/1759 [00:29<00:10, 44.65it/s][A
 74%|███████▍  | 1303/1759 [00:29<00:10, 44.74it/s][A
 74%|███████▍  | 1308/1759 [00:29<00:10, 44.98it/s][A
 75%|███████▍  | 1313/1759 [00:29<00:09, 45.11it/s][A
 75%|███████▍  | 1318/1759 [00:29<00:09, 45.21it/s][A
 75%|███████▌  | 1323/1759 [00:29<00:09, 45.26it/s][A
 75%|███████▌  | 1328/1759 [00:29<00:09, 45.30it/s][A
 76%|███████▌  | 1333/1759 [00:29<00:09, 45.17it/s][A
 76%|███████▌  | 1338/1759 [00:30<00:09, 44.85it/s][A
 76%|███████▋  | 1343/1759 [00:30<00:09, 44.79it/s][A
 77%|███████▋  | 1348/1759 [00:30<00:09, 44.85it/s][A
 77%|███████▋  | 1353/1759 [00:30<00:09, 44.96it/s][A
 77%|███████▋  | 1358/1759 [00:30<00:08, 45.06it/s][A
 77%|███████▋  | 1363/1759 [00:30<00:08, 45.18it/s][A
 78%|███████▊  | 1368/1759 [00:30<00:08, 45.33it/s][A
 78%|███████▊  | 1373/1759 [00:30<00:08, 45.32it/s][A
 78%|███████▊  | 1378/1759 [00:30<00:08, 45.08it/s][A
 79%|███████▊  | 1383/1759 [00:31<00:08, 44.94it/s][A
 79%|███████▉  | 1388/1759 [00:31<00:08, 41.71it/s][A
 79%|███████▉  | 1393/1759 [00:31<00:08, 42.76it/s][A
 79%|███████▉  | 1398/1759 [00:31<00:08, 43.54it/s][A
 80%|███████▉  | 1403/1759 [00:31<00:08, 44.08it/s][A
 80%|████████  | 1408/1759 [00:31<00:07, 44.51it/s][A
 80%|████████  | 1413/1759 [00:31<00:07, 44.74it/s][A
 81%|████████  | 1418/1759 [00:31<00:07, 44.99it/s][A
 81%|████████  | 1423/1759 [00:31<00:07, 45.04it/s][A
 81%|████████  | 1428/1759 [00:32<00:07, 44.68it/s][A
 81%|████████▏ | 1433/1759 [00:32<00:07, 44.77it/s][A
 82%|████████▏ | 1438/1759 [00:32<00:07, 44.82it/s][A
 82%|████████▏ | 1443/1759 [00:32<00:07, 45.02it/s][A
 82%|████████▏ | 1448/1759 [00:32<00:06, 45.03it/s][A
 83%|████████▎ | 1453/1759 [00:32<00:06, 45.17it/s][A
 83%|████████▎ | 1458/1759 [00:32<00:06, 45.29it/s][A
 83%|████████▎ | 1463/1759 [00:32<00:06, 45.31it/s][A
 83%|████████▎ | 1468/1759 [00:32<00:06, 45.15it/s][A
 84%|████████▎ | 1473/1759 [00:33<00:06, 44.93it/s][A
 84%|████████▍ | 1478/1759 [00:33<00:06, 44.89it/s][A
 84%|████████▍ | 1483/1759 [00:33<00:06, 44.93it/s][A
 85%|████████▍ | 1488/1759 [00:33<00:06, 40.85it/s][A
 85%|████████▍ | 1493/1759 [00:33<00:06, 42.45it/s][A
 85%|████████▌ | 1498/1759 [00:33<00:06, 43.34it/s][A
 85%|████████▌ | 1503/1759 [00:33<00:05, 43.99it/s][A
 86%|████████▌ | 1508/1759 [00:33<00:05, 44.47it/s][A
 86%|████████▌ | 1513/1759 [00:33<00:05, 44.75it/s][A
 86%|████████▋ | 1518/1759 [00:34<00:05, 44.76it/s][A
 87%|████████▋ | 1523/1759 [00:34<00:05, 41.47it/s][A
 87%|████████▋ | 1528/1759 [00:34<00:05, 42.26it/s][A
 87%|████████▋ | 1533/1759 [00:34<00:05, 43.14it/s][A
 87%|████████▋ | 1538/1759 [00:34<00:05, 43.76it/s][A
 88%|████████▊ | 1543/1759 [00:34<00:04, 44.30it/s][A
 88%|████████▊ | 1548/1759 [00:34<00:04, 44.67it/s][A
 88%|████████▊ | 1553/1759 [00:34<00:04, 45.02it/s][A
 89%|████████▊ | 1558/1759 [00:34<00:04, 44.97it/s][A
 89%|████████▉ | 1563/1759 [00:35<00:04, 44.71it/s][A
 89%|████████▉ | 1568/1759 [00:35<00:04, 44.55it/s][A
 89%|████████▉ | 1573/1759 [00:35<00:04, 44.51it/s][A
 90%|████████▉ | 1578/1759 [00:35<00:04, 44.70it/s][A
 90%|████████▉ | 1583/1759 [00:35<00:03, 44.87it/s][A
 90%|█████████ | 1588/1759 [00:35<00:03, 45.09it/s][A
 91%|█████████ | 1593/1759 [00:35<00:03, 45.21it/s][A
 91%|█████████ | 1598/1759 [00:35<00:03, 45.37it/s][A
 91%|█████████ | 1603/1759 [00:35<00:03, 45.31it/s][A
 91%|█████████▏| 1608/1759 [00:36<00:03, 45.10it/s][A
 92%|█████████▏| 1613/1759 [00:36<00:03, 44.81it/s][A
 92%|█████████▏| 1618/1759 [00:36<00:03, 44.69it/s][A
 92%|█████████▏| 1623/1759 [00:36<00:03, 44.82it/s][A
 93%|█████████▎| 1628/1759 [00:36<00:02, 44.97it/s][A
 93%|█████████▎| 1633/1759 [00:36<00:02, 45.09it/s][A
 93%|█████████▎| 1638/1759 [00:36<00:02, 45.26it/s][A
 93%|█████████▎| 1643/1759 [00:36<00:02, 45.32it/s][A
 94%|█████████▎| 1648/1759 [00:36<00:02, 45.31it/s][A
 94%|█████████▍| 1653/1759 [00:37<00:02, 45.04it/s][A
 94%|█████████▍| 1658/1759 [00:37<00:02, 43.90it/s][A
 95%|█████████▍| 1663/1759 [00:37<00:02, 44.15it/s][A
 95%|█████████▍| 1668/1759 [00:37<00:02, 44.42it/s][A
 95%|█████████▌| 1673/1759 [00:37<00:01, 44.61it/s][A
 95%|█████████▌| 1678/1759 [00:37<00:01, 44.72it/s][A
 96%|█████████▌| 1683/1759 [00:37<00:01, 44.93it/s][A
 96%|█████████▌| 1688/1759 [00:37<00:01, 45.13it/s][A
 96%|█████████▌| 1693/1759 [00:37<00:01, 45.24it/s][A
 97%|█████████▋| 1698/1759 [00:38<00:01, 44.92it/s][A
 97%|█████████▋| 1703/1759 [00:38<00:01, 44.87it/s][A
 97%|█████████▋| 1708/1759 [00:38<00:01, 44.88it/s][A
 97%|█████████▋| 1713/1759 [00:38<00:01, 44.91it/s][A
 98%|█████████▊| 1718/1759 [00:38<00:00, 44.94it/s][A
 98%|█████████▊| 1723/1759 [00:38<00:00, 45.06it/s][A
 98%|█████████▊| 1728/1759 [00:38<00:00, 45.16it/s][A
 99%|█████████▊| 1733/1759 [00:38<00:00, 45.23it/s][A
 99%|█████████▉| 1738/1759 [00:38<00:00, 45.21it/s][A
 99%|█████████▉| 1743/1759 [00:39<00:00, 45.00it/s][A
 99%|█████████▉| 1748/1759 [00:39<00:00, 44.95it/s][A
100%|█████████▉| 1753/1759 [00:39<00:00, 44.92it/s][A
100%|█████████▉| 1758/1759 [00:39<00:00, 44.96it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 44.96it/s][A 40%|████      | 124/310 [02:15<00:54,  3.40it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 12:47:41,189 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-124
[INFO|configuration_utils.py:351] 2023-08-29 12:47:41,341 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-124/config.json
[INFO|modeling_utils.py:886] 2023-08-29 12:47:44,416 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-124/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 12:47:44,530 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-124/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 12:47:44,610 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-124/special_tokens_map.json
 40%|████      | 125/310 [02:26<47:32, 15.42s/it] 41%|████      | 126/310 [02:26<33:23, 10.89s/it] 41%|████      | 127/310 [02:26<23:31,  7.71s/it] 41%|████▏     | 128/310 [02:27<16:38,  5.49s/it] 42%|████▏     | 129/310 [02:27<11:50,  3.93s/it] 42%|████▏     | 130/310 [02:27<08:30,  2.84s/it] 42%|████▏     | 131/310 [02:28<06:11,  2.07s/it] 43%|████▎     | 132/310 [02:28<04:34,  1.54s/it] 43%|████▎     | 133/310 [02:28<03:26,  1.17s/it] 43%|████▎     | 134/310 [02:28<02:39,  1.11it/s] 44%|████▎     | 135/310 [02:29<02:06,  1.39it/s] 44%|████▍     | 136/310 [02:29<01:43,  1.69it/s] 44%|████▍     | 137/310 [02:29<01:26,  1.99it/s] 45%|████▍     | 138/310 [02:30<01:15,  2.27it/s] 45%|████▍     | 139/310 [02:30<01:07,  2.53it/s] 45%|████▌     | 140/310 [02:30<01:02,  2.74it/s] 45%|████▌     | 141/310 [02:30<00:58,  2.91it/s] 46%|████▌     | 142/310 [02:31<00:55,  3.05it/s] 46%|████▌     | 143/310 [02:31<00:53,  3.15it/s] 46%|████▋     | 144/310 [02:31<00:53,  3.10it/s] 47%|████▋     | 145/310 [02:32<00:51,  3.19it/s] 47%|████▋     | 146/310 [02:32<00:50,  3.26it/s] 47%|████▋     | 147/310 [02:32<00:49,  3.30it/s] 48%|████▊     | 148/310 [02:33<00:48,  3.33it/s] 48%|████▊     | 149/310 [02:33<00:47,  3.36it/s] 48%|████▊     | 150/310 [02:33<00:47,  3.37it/s] 49%|████▊     | 151/310 [02:33<00:46,  3.39it/s] 49%|████▉     | 152/310 [02:34<00:46,  3.39it/s] 49%|████▉     | 153/310 [02:34<00:46,  3.40it/s] 50%|████▉     | 154/310 [02:34<00:45,  3.40it/s] 50%|█████     | 155/310 [02:35<00:47,  3.27it/s] 50%|█████     | 156/310 [02:35<00:46,  3.31it/s] 51%|█████     | 157/310 [02:35<00:45,  3.34it/s] 51%|█████     | 158/310 [02:36<00:45,  3.36it/s] 51%|█████▏    | 159/310 [02:36<00:44,  3.37it/s] 52%|█████▏    | 160/310 [02:36<00:44,  3.38it/s] 52%|█████▏    | 161/310 [02:36<00:43,  3.39it/s] 52%|█████▏    | 162/310 [02:37<00:43,  3.40it/s] 53%|█████▎    | 163/310 [02:37<00:43,  3.40it/s] 53%|█████▎    | 164/310 [02:37<00:42,  3.41it/s] 53%|█████▎    | 165/310 [02:38<00:42,  3.41it/s] 54%|█████▎    | 166/310 [02:38<00:44,  3.27it/s] 54%|█████▍    | 167/310 [02:38<00:43,  3.31it/s] 54%|█████▍    | 168/310 [02:38<00:42,  3.34it/s] 55%|█████▍    | 169/310 [02:39<00:42,  3.35it/s] 55%|█████▍    | 170/310 [02:39<00:41,  3.37it/s] 55%|█████▌    | 171/310 [02:39<00:41,  3.38it/s] 55%|█████▌    | 172/310 [02:40<00:40,  3.39it/s] 56%|█████▌    | 173/310 [02:40<00:40,  3.40it/s] 56%|█████▌    | 174/310 [02:40<00:39,  3.40it/s] 56%|█████▋    | 175/310 [02:41<00:39,  3.40it/s] 57%|█████▋    | 176/310 [02:41<00:39,  3.41it/s] 57%|█████▋    | 177/310 [02:41<00:40,  3.30it/s] 57%|█████▋    | 178/310 [02:41<00:39,  3.33it/s] 58%|█████▊    | 179/310 [02:42<00:39,  3.36it/s] 58%|█████▊    | 180/310 [02:42<00:39,  3.27it/s] 58%|█████▊    | 181/310 [02:42<00:38,  3.31it/s] 59%|█████▊    | 182/310 [02:43<00:38,  3.33it/s] 59%|█████▉    | 183/310 [02:43<00:37,  3.35it/s] 59%|█████▉    | 184/310 [02:43<00:37,  3.37it/s] 60%|█████▉    | 185/310 [02:44<00:36,  3.38it/s] 60%|██████    | 186/310 [02:44<00:36,  3.39it/s][INFO|trainer.py:2140] 2023-08-29 12:48:10,403 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 12:48:10,403 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 12:48:10,403 >>   Batch size = 8
{'eval_loss': 0.9573898911476135, 'eval_runtime': 39.4659, 'eval_samples_per_second': 356.434, 'eval_steps_per_second': 44.57, 'epoch': 1.99}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.31it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.51it/s][A
  1%|          | 18/1759 [00:00<00:40, 42.86it/s][A
  1%|▏         | 23/1759 [00:00<01:00, 28.73it/s][A
  2%|▏         | 28/1759 [00:00<00:52, 33.27it/s][A
  2%|▏         | 33/1759 [00:00<00:47, 36.50it/s][A
  2%|▏         | 38/1759 [00:01<00:44, 38.98it/s][A
  2%|▏         | 43/1759 [00:01<00:41, 40.90it/s][A
  3%|▎         | 48/1759 [00:01<00:40, 42.27it/s][A
  3%|▎         | 53/1759 [00:01<00:39, 43.26it/s][A
  3%|▎         | 58/1759 [00:01<00:38, 44.01it/s][A
  4%|▎         | 63/1759 [00:01<00:38, 44.15it/s][A
  4%|▍         | 68/1759 [00:01<00:38, 44.09it/s][A
  4%|▍         | 73/1759 [00:01<00:38, 44.10it/s][A
  4%|▍         | 78/1759 [00:01<00:37, 44.29it/s][A
  5%|▍         | 83/1759 [00:02<00:37, 44.60it/s][A
  5%|▌         | 88/1759 [00:02<00:37, 44.78it/s][A
  5%|▌         | 93/1759 [00:02<00:36, 45.11it/s][A
  6%|▌         | 98/1759 [00:02<00:36, 45.22it/s][A
  6%|▌         | 103/1759 [00:02<00:36, 45.35it/s][A
  6%|▌         | 108/1759 [00:02<00:36, 45.28it/s][A
  6%|▋         | 113/1759 [00:02<00:36, 44.99it/s][A
  7%|▋         | 118/1759 [00:02<00:36, 44.82it/s][A
  7%|▋         | 123/1759 [00:02<00:36, 44.72it/s][A
  7%|▋         | 128/1759 [00:03<00:37, 43.10it/s][A
  8%|▊         | 133/1759 [00:03<00:37, 43.87it/s][A
  8%|▊         | 138/1759 [00:03<00:36, 44.38it/s][A
  8%|▊         | 143/1759 [00:03<00:36, 44.81it/s][A
  8%|▊         | 148/1759 [00:03<00:35, 45.04it/s][A
  9%|▊         | 153/1759 [00:03<00:35, 45.00it/s][A
  9%|▉         | 158/1759 [00:03<00:35, 44.82it/s][A
  9%|▉         | 163/1759 [00:03<00:35, 44.65it/s][A
 10%|▉         | 168/1759 [00:03<00:35, 44.58it/s][A
 10%|▉         | 173/1759 [00:04<00:35, 44.56it/s][A
 10%|█         | 178/1759 [00:04<00:35, 44.77it/s][A
 10%|█         | 183/1759 [00:04<00:34, 45.03it/s][A
 11%|█         | 188/1759 [00:04<00:34, 45.14it/s][A
 11%|█         | 193/1759 [00:04<00:34, 45.25it/s][A
 11%|█▏        | 198/1759 [00:04<00:34, 45.31it/s][A
 12%|█▏        | 203/1759 [00:04<00:34, 45.25it/s][A
 12%|█▏        | 208/1759 [00:04<00:34, 45.14it/s][A
 12%|█▏        | 213/1759 [00:04<00:34, 45.02it/s][A
 12%|█▏        | 218/1759 [00:05<00:34, 44.90it/s][A
 13%|█▎        | 223/1759 [00:05<00:34, 45.00it/s][A
 13%|█▎        | 228/1759 [00:05<00:33, 45.11it/s][A
 13%|█▎        | 233/1759 [00:05<00:33, 45.26it/s][A
 14%|█▎        | 238/1759 [00:05<00:33, 45.30it/s][A
 14%|█▍        | 243/1759 [00:05<00:33, 45.29it/s][A
 14%|█▍        | 248/1759 [00:05<00:33, 45.21it/s][A
 14%|█▍        | 253/1759 [00:05<00:33, 45.09it/s][A
 15%|█▍        | 258/1759 [00:05<00:33, 44.98it/s][A
 15%|█▍        | 263/1759 [00:06<00:34, 43.65it/s][A
 15%|█▌        | 268/1759 [00:06<00:33, 44.12it/s][A
 16%|█▌        | 273/1759 [00:06<00:33, 44.56it/s][A
 16%|█▌        | 278/1759 [00:06<00:33, 44.79it/s][A
 16%|█▌        | 283/1759 [00:06<00:32, 44.98it/s][A
 16%|█▋        | 288/1759 [00:06<00:32, 44.94it/s][A
 17%|█▋        | 293/1759 [00:06<00:32, 45.05it/s][A
 17%|█▋        | 298/1759 [00:06<00:32, 44.97it/s][A
 17%|█▋        | 303/1759 [00:06<00:32, 44.81it/s][A
 18%|█▊        | 308/1759 [00:07<00:32, 44.84it/s][A
 18%|█▊        | 313/1759 [00:07<00:32, 44.95it/s][A
 18%|█▊        | 318/1759 [00:07<00:31, 45.18it/s][A
 18%|█▊        | 323/1759 [00:07<00:31, 45.30it/s][A
 19%|█▊        | 328/1759 [00:07<00:31, 45.31it/s][A
 19%|█▉        | 333/1759 [00:07<00:31, 45.21it/s][A
 19%|█▉        | 338/1759 [00:07<00:31, 45.15it/s][A
 19%|█▉        | 343/1759 [00:07<00:31, 44.96it/s][A
 20%|█▉        | 348/1759 [00:07<00:31, 44.91it/s][A
 20%|██        | 353/1759 [00:08<00:31, 44.87it/s][A
 20%|██        | 358/1759 [00:08<00:31, 44.97it/s][A
 21%|██        | 363/1759 [00:08<00:30, 45.16it/s][A
 21%|██        | 368/1759 [00:08<00:30, 45.28it/s][A
 21%|██        | 373/1759 [00:08<00:30, 45.36it/s][A
 21%|██▏       | 378/1759 [00:08<00:30, 45.19it/s][A
 22%|██▏       | 383/1759 [00:08<00:30, 45.11it/s][A
 22%|██▏       | 388/1759 [00:08<00:30, 45.01it/s][A
 22%|██▏       | 393/1759 [00:08<00:30, 44.92it/s][A
 23%|██▎       | 398/1759 [00:09<00:31, 43.52it/s][A
 23%|██▎       | 403/1759 [00:09<00:30, 44.08it/s][A
 23%|██▎       | 408/1759 [00:09<00:30, 44.52it/s][A
 23%|██▎       | 413/1759 [00:09<00:30, 44.82it/s][A
 24%|██▍       | 418/1759 [00:09<00:29, 45.00it/s][A
 24%|██▍       | 423/1759 [00:09<00:29, 45.05it/s][A
 24%|██▍       | 428/1759 [00:09<00:29, 45.00it/s][A
 25%|██▍       | 433/1759 [00:09<00:29, 44.95it/s][A
 25%|██▍       | 438/1759 [00:09<00:29, 44.75it/s][A
 25%|██▌       | 443/1759 [00:10<00:29, 44.76it/s][A
 25%|██▌       | 448/1759 [00:10<00:29, 44.97it/s][A
 26%|██▌       | 453/1759 [00:10<00:28, 45.14it/s][A
 26%|██▌       | 458/1759 [00:10<00:28, 45.24it/s][A
 26%|██▋       | 463/1759 [00:10<00:28, 45.32it/s][A
 27%|██▋       | 468/1759 [00:10<00:28, 45.29it/s][A
 27%|██▋       | 473/1759 [00:10<00:28, 45.23it/s][A
 27%|██▋       | 478/1759 [00:10<00:28, 45.07it/s][A
 27%|██▋       | 483/1759 [00:10<00:28, 44.87it/s][A
 28%|██▊       | 488/1759 [00:11<00:28, 44.81it/s][A
 28%|██▊       | 493/1759 [00:11<00:28, 44.84it/s][A
 28%|██▊       | 498/1759 [00:11<00:27, 45.09it/s][A
 29%|██▊       | 503/1759 [00:11<00:27, 45.18it/s][A
 29%|██▉       | 508/1759 [00:11<00:27, 45.32it/s][A
 29%|██▉       | 513/1759 [00:11<00:27, 45.29it/s][A
 29%|██▉       | 518/1759 [00:11<00:27, 45.23it/s][A
 30%|██▉       | 523/1759 [00:11<00:27, 45.09it/s][A
 30%|███       | 528/1759 [00:11<00:27, 44.94it/s][A
 30%|███       | 533/1759 [00:12<00:28, 43.52it/s][A
 31%|███       | 538/1759 [00:12<00:27, 44.12it/s][A
 31%|███       | 543/1759 [00:12<00:27, 44.44it/s][A
 31%|███       | 548/1759 [00:12<00:27, 44.78it/s][A
 31%|███▏      | 553/1759 [00:12<00:26, 44.98it/s][A
 32%|███▏      | 558/1759 [00:12<00:26, 45.10it/s][A
 32%|███▏      | 563/1759 [00:12<00:26, 45.12it/s][A
 32%|███▏      | 568/1759 [00:12<00:26, 45.17it/s][A
 33%|███▎      | 573/1759 [00:12<00:26, 44.89it/s][A
 33%|███▎      | 578/1759 [00:13<00:26, 44.82it/s][A
 33%|███▎      | 583/1759 [00:13<00:26, 44.80it/s][A
 33%|███▎      | 588/1759 [00:13<00:26, 45.02it/s][A
 34%|███▎      | 593/1759 [00:13<00:25, 45.18it/s][A
 34%|███▍      | 598/1759 [00:13<00:25, 45.24it/s][A
 34%|███▍      | 603/1759 [00:13<00:25, 45.29it/s][A
 35%|███▍      | 608/1759 [00:13<00:25, 45.20it/s][A
 35%|███▍      | 613/1759 [00:13<00:25, 44.97it/s][A
 35%|███▌      | 618/1759 [00:13<00:25, 44.92it/s][A
 35%|███▌      | 623/1759 [00:14<00:25, 44.78it/s][A
 36%|███▌      | 628/1759 [00:14<00:25, 44.92it/s][A
 36%|███▌      | 633/1759 [00:14<00:24, 45.07it/s][A
 36%|███▋      | 638/1759 [00:14<00:24, 45.16it/s][A
 37%|███▋      | 643/1759 [00:14<00:24, 45.26it/s][A
 37%|███▋      | 648/1759 [00:14<00:24, 45.25it/s][A
 37%|███▋      | 653/1759 [00:14<00:25, 43.93it/s][A
 37%|███▋      | 658/1759 [00:14<00:24, 44.28it/s][A
 38%|███▊      | 663/1759 [00:14<00:24, 44.36it/s][A
 38%|███▊      | 668/1759 [00:15<00:24, 44.46it/s][A
 38%|███▊      | 673/1759 [00:15<00:24, 44.66it/s][A
 39%|███▊      | 678/1759 [00:15<00:24, 44.81it/s][A
 39%|███▉      | 683/1759 [00:15<00:23, 45.05it/s][A
 39%|███▉      | 688/1759 [00:15<00:23, 45.17it/s][A
 39%|███▉      | 693/1759 [00:15<00:23, 45.04it/s][A
 40%|███▉      | 698/1759 [00:15<00:23, 45.06it/s][A
 40%|███▉      | 703/1759 [00:15<00:23, 44.99it/s][A
 40%|████      | 708/1759 [00:15<00:23, 44.99it/s][A
 41%|████      | 713/1759 [00:16<00:23, 44.90it/s][A
 41%|████      | 718/1759 [00:16<00:23, 44.64it/s][A
 41%|████      | 723/1759 [00:16<00:23, 45.02it/s][A
 41%|████▏     | 728/1759 [00:16<00:22, 45.11it/s][A
 42%|████▏     | 733/1759 [00:16<00:22, 45.16it/s][A
 42%|████▏     | 738/1759 [00:16<00:22, 45.14it/s][A
 42%|████▏     | 743/1759 [00:16<00:22, 45.10it/s][A
 43%|████▎     | 748/1759 [00:16<00:22, 45.06it/s][A
 43%|████▎     | 753/1759 [00:16<00:22, 45.07it/s][A
 43%|████▎     | 758/1759 [00:17<00:22, 44.95it/s][A
 43%|████▎     | 763/1759 [00:17<00:22, 45.03it/s][A
 44%|████▎     | 768/1759 [00:17<00:22, 45.02it/s][A
 44%|████▍     | 773/1759 [00:17<00:21, 45.02it/s][A
 44%|████▍     | 778/1759 [00:17<00:21, 45.13it/s][A
 45%|████▍     | 783/1759 [00:17<00:21, 45.15it/s][A
 45%|████▍     | 788/1759 [00:17<00:24, 39.41it/s][A
 45%|████▌     | 793/1759 [00:17<00:23, 41.12it/s][A
 45%|████▌     | 798/1759 [00:17<00:22, 42.36it/s][A
 46%|████▌     | 803/1759 [00:18<00:22, 43.33it/s][A
 46%|████▌     | 808/1759 [00:18<00:21, 44.05it/s][A
 46%|████▌     | 813/1759 [00:18<00:21, 44.52it/s][A
 47%|████▋     | 818/1759 [00:18<00:20, 44.85it/s][A
 47%|████▋     | 823/1759 [00:18<00:20, 44.91it/s][A
 47%|████▋     | 828/1759 [00:18<00:20, 44.57it/s][A
 47%|████▋     | 833/1759 [00:18<00:20, 44.38it/s][A
 48%|████▊     | 838/1759 [00:18<00:20, 44.48it/s][A
 48%|████▊     | 843/1759 [00:18<00:20, 44.73it/s][A
 48%|████▊     | 848/1759 [00:19<00:20, 44.93it/s][A
 48%|████▊     | 853/1759 [00:19<00:20, 45.13it/s][A
 49%|████▉     | 858/1759 [00:19<00:19, 45.29it/s][A
 49%|████▉     | 863/1759 [00:19<00:19, 45.33it/s][A
 49%|████▉     | 868/1759 [00:19<00:19, 45.28it/s][A
 50%|████▉     | 873/1759 [00:19<00:19, 44.93it/s][A
 50%|████▉     | 878/1759 [00:19<00:19, 44.77it/s][A
 50%|█████     | 883/1759 [00:19<00:19, 44.68it/s][A
 50%|█████     | 888/1759 [00:19<00:19, 44.76it/s][A
 51%|█████     | 893/1759 [00:20<00:19, 44.97it/s][A
 51%|█████     | 898/1759 [00:20<00:19, 45.10it/s][A
 51%|█████▏    | 903/1759 [00:20<00:18, 45.32it/s][A
 52%|█████▏    | 908/1759 [00:20<00:18, 45.39it/s][A
 52%|█████▏    | 913/1759 [00:20<00:18, 45.39it/s][A
 52%|█████▏    | 918/1759 [00:20<00:18, 45.11it/s][A
 52%|█████▏    | 923/1759 [00:20<00:21, 38.68it/s][A
 53%|█████▎    | 928/1759 [00:20<00:20, 40.54it/s][A
 53%|█████▎    | 933/1759 [00:21<00:19, 41.92it/s][A
 53%|█████▎    | 938/1759 [00:21<00:19, 42.87it/s][A
 54%|█████▎    | 943/1759 [00:21<00:18, 43.65it/s][A
 54%|█████▍    | 948/1759 [00:21<00:18, 44.16it/s][A
 54%|█████▍    | 953/1759 [00:21<00:18, 44.54it/s][A
 54%|█████▍    | 958/1759 [00:21<00:17, 44.79it/s][A
 55%|█████▍    | 963/1759 [00:21<00:17, 44.51it/s][A
 55%|█████▌    | 968/1759 [00:21<00:17, 44.63it/s][A
 55%|█████▌    | 973/1759 [00:21<00:17, 44.84it/s][A
 56%|█████▌    | 978/1759 [00:22<00:17, 44.98it/s][A
 56%|█████▌    | 983/1759 [00:22<00:17, 45.05it/s][A
 56%|█████▌    | 988/1759 [00:22<00:17, 45.17it/s][A
 56%|█████▋    | 993/1759 [00:22<00:16, 45.15it/s][A
 57%|█████▋    | 998/1759 [00:22<00:16, 45.25it/s][A
 57%|█████▋    | 1003/1759 [00:22<00:16, 45.03it/s][A
 57%|█████▋    | 1008/1759 [00:22<00:16, 44.84it/s][A
 58%|█████▊    | 1013/1759 [00:22<00:16, 44.86it/s][A
 58%|█████▊    | 1018/1759 [00:22<00:16, 44.96it/s][A
 58%|█████▊    | 1023/1759 [00:23<00:16, 45.12it/s][A
 58%|█████▊    | 1028/1759 [00:23<00:16, 45.10it/s][A
 59%|█████▊    | 1033/1759 [00:23<00:16, 45.22it/s][A
 59%|█████▉    | 1038/1759 [00:23<00:15, 45.20it/s][A
 59%|█████▉    | 1043/1759 [00:23<00:15, 45.19it/s][A
 60%|█████▉    | 1048/1759 [00:23<00:15, 44.99it/s][A
 60%|█████▉    | 1053/1759 [00:23<00:15, 44.88it/s][A
 60%|██████    | 1058/1759 [00:23<00:18, 38.48it/s][A
 60%|██████    | 1063/1759 [00:23<00:17, 40.38it/s][A
 61%|██████    | 1068/1759 [00:24<00:16, 41.84it/s][A
 61%|██████    | 1073/1759 [00:24<00:15, 42.89it/s][A
 61%|██████▏   | 1078/1759 [00:24<00:15, 43.71it/s][A
 62%|██████▏   | 1083/1759 [00:24<00:15, 44.35it/s][A
 62%|██████▏   | 1088/1759 [00:24<00:16, 39.97it/s][A
 62%|██████▏   | 1094/1759 [00:24<00:15, 42.84it/s][A
 62%|██████▏   | 1099/1759 [00:24<00:15, 43.13it/s][A
 63%|██████▎   | 1104/1759 [00:24<00:14, 43.68it/s][A
 63%|██████▎   | 1109/1759 [00:25<00:14, 44.12it/s][A
 63%|██████▎   | 1114/1759 [00:25<00:14, 44.51it/s][A
 64%|██████▎   | 1119/1759 [00:25<00:14, 44.82it/s][A
 64%|██████▍   | 1124/1759 [00:25<00:14, 45.05it/s][A
 64%|██████▍   | 1129/1759 [00:25<00:13, 45.14it/s][A
 64%|██████▍   | 1134/1759 [00:25<00:13, 45.01it/s][A
 65%|██████▍   | 1139/1759 [00:25<00:13, 44.83it/s][A
 65%|██████▌   | 1144/1759 [00:25<00:13, 44.74it/s][A
 65%|██████▌   | 1149/1759 [00:25<00:13, 44.78it/s][A
 66%|██████▌   | 1154/1759 [00:26<00:13, 44.86it/s][A
 66%|██████▌   | 1159/1759 [00:26<00:13, 44.98it/s][A
 66%|██████▌   | 1164/1759 [00:26<00:13, 45.05it/s][A
 66%|██████▋   | 1169/1759 [00:26<00:13, 45.23it/s][A
 67%|██████▋   | 1174/1759 [00:26<00:12, 45.31it/s][A
 67%|██████▋   | 1179/1759 [00:26<00:12, 45.20it/s][A
 67%|██████▋   | 1184/1759 [00:26<00:12, 45.04it/s][A
 68%|██████▊   | 1189/1759 [00:26<00:12, 44.88it/s][A
 68%|██████▊   | 1194/1759 [00:26<00:14, 40.25it/s][A
 68%|██████▊   | 1199/1759 [00:27<00:13, 41.69it/s][A
 68%|██████▊   | 1204/1759 [00:27<00:12, 42.76it/s][A
 69%|██████▊   | 1209/1759 [00:27<00:12, 43.54it/s][A
 69%|██████▉   | 1214/1759 [00:27<00:12, 44.07it/s][A
 69%|██████▉   | 1219/1759 [00:27<00:12, 44.51it/s][A
 70%|██████▉   | 1224/1759 [00:27<00:11, 44.80it/s][A
 70%|██████▉   | 1229/1759 [00:27<00:11, 44.97it/s][A
 70%|███████   | 1234/1759 [00:27<00:11, 44.63it/s][A
 70%|███████   | 1239/1759 [00:27<00:11, 44.57it/s][A
 71%|███████   | 1244/1759 [00:28<00:11, 44.65it/s][A
 71%|███████   | 1249/1759 [00:28<00:11, 44.90it/s][A
 71%|███████▏  | 1254/1759 [00:28<00:11, 45.06it/s][A
 72%|███████▏  | 1259/1759 [00:28<00:11, 45.17it/s][A
 72%|███████▏  | 1264/1759 [00:28<00:10, 45.22it/s][A
 72%|███████▏  | 1269/1759 [00:28<00:10, 45.36it/s][A
 72%|███████▏  | 1274/1759 [00:28<00:10, 45.27it/s][A
 73%|███████▎  | 1279/1759 [00:28<00:10, 44.97it/s][A
 73%|███████▎  | 1284/1759 [00:28<00:10, 44.92it/s][A
 73%|███████▎  | 1289/1759 [00:29<00:10, 44.73it/s][A
 74%|███████▎  | 1294/1759 [00:29<00:10, 44.90it/s][A
 74%|███████▍  | 1299/1759 [00:29<00:10, 45.06it/s][A
 74%|███████▍  | 1304/1759 [00:29<00:10, 45.20it/s][A
 74%|███████▍  | 1309/1759 [00:29<00:09, 45.27it/s][A
 75%|███████▍  | 1314/1759 [00:29<00:09, 45.31it/s][A
 75%|███████▍  | 1319/1759 [00:29<00:09, 45.17it/s][A
 75%|███████▌  | 1324/1759 [00:29<00:09, 44.99it/s][A
 76%|███████▌  | 1329/1759 [00:29<00:10, 39.14it/s][A
 76%|███████▌  | 1334/1759 [00:30<00:10, 40.96it/s][A
 76%|███████▌  | 1339/1759 [00:30<00:09, 42.19it/s][A
 76%|███████▋  | 1344/1759 [00:30<00:09, 43.18it/s][A
 77%|███████▋  | 1349/1759 [00:30<00:09, 43.84it/s][A
 77%|███████▋  | 1354/1759 [00:30<00:09, 44.39it/s][A
 77%|███████▋  | 1359/1759 [00:30<00:08, 44.72it/s][A
 78%|███████▊  | 1364/1759 [00:30<00:08, 44.84it/s][A
 78%|███████▊  | 1369/1759 [00:30<00:08, 44.56it/s][A
 78%|███████▊  | 1374/1759 [00:30<00:08, 44.35it/s][A
 78%|███████▊  | 1379/1759 [00:31<00:08, 44.46it/s][A
 79%|███████▊  | 1384/1759 [00:31<00:08, 44.62it/s][A
 79%|███████▉  | 1389/1759 [00:31<00:08, 44.83it/s][A
 79%|███████▉  | 1394/1759 [00:31<00:08, 45.05it/s][A
 80%|███████▉  | 1399/1759 [00:31<00:07, 45.20it/s][A
 80%|███████▉  | 1404/1759 [00:31<00:07, 45.25it/s][A
 80%|████████  | 1409/1759 [00:31<00:07, 45.22it/s][A
 80%|████████  | 1414/1759 [00:31<00:07, 44.96it/s][A
 81%|████████  | 1419/1759 [00:31<00:07, 44.78it/s][A
 81%|████████  | 1424/1759 [00:32<00:07, 44.71it/s][A
 81%|████████  | 1429/1759 [00:32<00:07, 44.68it/s][A
 82%|████████▏ | 1434/1759 [00:32<00:07, 44.86it/s][A
 82%|████████▏ | 1439/1759 [00:32<00:07, 45.01it/s][A
 82%|████████▏ | 1444/1759 [00:32<00:06, 45.17it/s][A
 82%|████████▏ | 1449/1759 [00:32<00:06, 45.25it/s][A
 83%|████████▎ | 1454/1759 [00:32<00:06, 45.28it/s][A
 83%|████████▎ | 1459/1759 [00:32<00:06, 45.16it/s][A
 83%|████████▎ | 1464/1759 [00:32<00:06, 43.62it/s][A
 84%|████████▎ | 1469/1759 [00:33<00:06, 43.97it/s][A
 84%|████████▍ | 1474/1759 [00:33<00:06, 44.25it/s][A
 84%|████████▍ | 1479/1759 [00:33<00:06, 44.43it/s][A
 84%|████████▍ | 1484/1759 [00:33<00:06, 44.69it/s][A
 85%|████████▍ | 1489/1759 [00:33<00:06, 44.77it/s][A
 85%|████████▍ | 1494/1759 [00:33<00:05, 45.06it/s][A
 85%|████████▌ | 1499/1759 [00:33<00:05, 45.16it/s][A
 86%|████████▌ | 1504/1759 [00:33<00:05, 44.98it/s][A
 86%|████████▌ | 1509/1759 [00:33<00:05, 44.89it/s][A
 86%|████████▌ | 1514/1759 [00:34<00:05, 44.74it/s][A
 86%|████████▋ | 1519/1759 [00:34<00:05, 44.91it/s][A
 87%|████████▋ | 1524/1759 [00:34<00:05, 44.92it/s][A
 87%|████████▋ | 1529/1759 [00:34<00:05, 45.03it/s][A
 87%|████████▋ | 1534/1759 [00:34<00:04, 45.06it/s][A
 87%|████████▋ | 1539/1759 [00:34<00:04, 45.11it/s][A
 88%|████████▊ | 1544/1759 [00:34<00:04, 45.12it/s][A
 88%|████████▊ | 1549/1759 [00:34<00:04, 45.02it/s][A
 88%|████████▊ | 1554/1759 [00:34<00:04, 44.99it/s][A
 89%|████████▊ | 1559/1759 [00:35<00:04, 44.87it/s][A
 89%|████████▉ | 1564/1759 [00:35<00:04, 44.97it/s][A
 89%|████████▉ | 1569/1759 [00:35<00:04, 44.94it/s][A
 89%|████████▉ | 1574/1759 [00:35<00:04, 45.03it/s][A
 90%|████████▉ | 1579/1759 [00:35<00:03, 45.01it/s][A
 90%|█████████ | 1584/1759 [00:35<00:03, 45.11it/s][A
 90%|█████████ | 1589/1759 [00:35<00:03, 45.18it/s][A
 91%|█████████ | 1594/1759 [00:35<00:03, 45.15it/s][A
 91%|█████████ | 1599/1759 [00:35<00:03, 43.79it/s][A
 91%|█████████ | 1604/1759 [00:36<00:03, 44.17it/s][A
 91%|█████████▏| 1609/1759 [00:36<00:03, 44.44it/s][A
 92%|█████████▏| 1614/1759 [00:36<00:03, 44.63it/s][A
 92%|█████████▏| 1619/1759 [00:36<00:03, 44.66it/s][A
 92%|█████████▏| 1624/1759 [00:36<00:03, 44.85it/s][A
 93%|█████████▎| 1629/1759 [00:36<00:02, 44.95it/s][A
 93%|█████████▎| 1634/1759 [00:36<00:02, 45.03it/s][A
 93%|█████████▎| 1639/1759 [00:36<00:02, 44.93it/s][A
 93%|█████████▎| 1644/1759 [00:36<00:02, 44.91it/s][A
 94%|█████████▎| 1649/1759 [00:37<00:02, 44.98it/s][A
 94%|█████████▍| 1654/1759 [00:37<00:02, 44.99it/s][A
 94%|█████████▍| 1659/1759 [00:37<00:02, 44.94it/s][A
 95%|█████████▍| 1664/1759 [00:37<00:02, 44.98it/s][A
 95%|█████████▍| 1669/1759 [00:37<00:01, 45.07it/s][A
 95%|█████████▌| 1674/1759 [00:37<00:01, 45.08it/s][A
 95%|█████████▌| 1679/1759 [00:37<00:01, 45.09it/s][A
 96%|█████████▌| 1684/1759 [00:37<00:01, 45.00it/s][A
 96%|█████████▌| 1689/1759 [00:37<00:01, 45.03it/s][A
 96%|█████████▋| 1694/1759 [00:38<00:01, 45.04it/s][A
 97%|█████████▋| 1699/1759 [00:38<00:01, 44.97it/s][A
 97%|█████████▋| 1704/1759 [00:38<00:01, 44.98it/s][A
 97%|█████████▋| 1709/1759 [00:38<00:01, 44.96it/s][A
 97%|█████████▋| 1714/1759 [00:38<00:00, 45.06it/s][A
 98%|█████████▊| 1719/1759 [00:38<00:00, 45.08it/s][A
 98%|█████████▊| 1724/1759 [00:38<00:00, 45.11it/s][A
 98%|█████████▊| 1729/1759 [00:38<00:00, 45.03it/s][A
 99%|█████████▊| 1734/1759 [00:39<00:00, 43.17it/s][A
 99%|█████████▉| 1739/1759 [00:39<00:00, 43.79it/s][A
 99%|█████████▉| 1744/1759 [00:39<00:00, 44.19it/s][A
 99%|█████████▉| 1749/1759 [00:39<00:00, 44.41it/s][A
100%|█████████▉| 1754/1759 [00:39<00:00, 44.58it/s][A
100%|██████████| 1759/1759 [00:39<00:00, 44.82it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 44.82it/s][A 60%|██████    | 186/310 [03:24<00:36,  3.39it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 12:48:50,193 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-186
[INFO|configuration_utils.py:351] 2023-08-29 12:48:50,350 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-186/config.json
[INFO|modeling_utils.py:886] 2023-08-29 12:48:52,882 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-186/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 12:48:52,990 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-186/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 12:48:53,049 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-186/special_tokens_map.json
 60%|██████    | 187/310 [03:34<31:31, 15.38s/it] 61%|██████    | 188/310 [03:35<22:05, 10.86s/it] 61%|██████    | 189/310 [03:35<15:30,  7.69s/it] 61%|██████▏   | 190/310 [03:35<10:56,  5.47s/it] 62%|██████▏   | 191/310 [03:36<07:46,  3.92s/it] 62%|██████▏   | 192/310 [03:36<05:34,  2.83s/it] 62%|██████▏   | 193/310 [03:36<04:02,  2.07s/it] 63%|██████▎   | 194/310 [03:37<02:58,  1.54s/it] 63%|██████▎   | 195/310 [03:37<02:13,  1.16s/it] 63%|██████▎   | 196/310 [03:37<01:42,  1.11it/s] 64%|██████▎   | 197/310 [03:37<01:21,  1.39it/s] 64%|██████▍   | 198/310 [03:38<01:06,  1.69it/s] 64%|██████▍   | 199/310 [03:38<00:56,  1.95it/s] 65%|██████▍   | 200/310 [03:38<00:49,  2.24it/s] 65%|██████▍   | 201/310 [03:39<00:43,  2.49it/s] 65%|██████▌   | 202/310 [03:39<00:39,  2.71it/s] 65%|██████▌   | 203/310 [03:39<00:37,  2.89it/s] 66%|██████▌   | 204/310 [03:39<00:35,  3.03it/s] 66%|██████▌   | 205/310 [03:40<00:33,  3.14it/s] 66%|██████▋   | 206/310 [03:40<00:32,  3.21it/s] 67%|██████▋   | 207/310 [03:40<00:31,  3.27it/s] 67%|██████▋   | 208/310 [03:41<00:30,  3.31it/s] 67%|██████▋   | 209/310 [03:41<00:30,  3.34it/s] 68%|██████▊   | 210/310 [03:41<00:30,  3.25it/s] 68%|██████▊   | 211/310 [03:42<00:30,  3.30it/s] 68%|██████▊   | 212/310 [03:42<00:29,  3.33it/s] 69%|██████▊   | 213/310 [03:42<00:29,  3.26it/s] 69%|██████▉   | 214/310 [03:42<00:29,  3.30it/s] 69%|██████▉   | 215/310 [03:43<00:28,  3.33it/s] 70%|██████▉   | 216/310 [03:43<00:28,  3.35it/s] 70%|███████   | 217/310 [03:43<00:27,  3.37it/s] 70%|███████   | 218/310 [03:44<00:27,  3.38it/s] 71%|███████   | 219/310 [03:44<00:26,  3.39it/s] 71%|███████   | 220/310 [03:44<00:26,  3.40it/s] 71%|███████▏  | 221/310 [03:45<00:33,  2.64it/s] 72%|███████▏  | 222/310 [03:45<00:31,  2.83it/s] 72%|███████▏  | 223/310 [03:45<00:29,  2.97it/s] 72%|███████▏  | 224/310 [03:46<00:27,  3.09it/s] 73%|███████▎  | 225/310 [03:46<00:26,  3.18it/s] 73%|███████▎  | 226/310 [03:46<00:25,  3.25it/s] 73%|███████▎  | 227/310 [03:47<00:25,  3.30it/s] 74%|███████▎  | 228/310 [03:47<00:24,  3.33it/s] 74%|███████▍  | 229/310 [03:47<00:24,  3.35it/s] 74%|███████▍  | 230/310 [03:47<00:23,  3.37it/s] 75%|███████▍  | 231/310 [03:48<00:24,  3.28it/s] 75%|███████▍  | 232/310 [03:48<00:23,  3.33it/s] 75%|███████▌  | 233/310 [03:48<00:22,  3.38it/s] 75%|███████▌  | 234/310 [03:49<00:22,  3.40it/s] 76%|███████▌  | 235/310 [03:49<00:21,  3.42it/s] 76%|███████▌  | 236/310 [03:49<00:21,  3.43it/s] 76%|███████▋  | 237/310 [03:49<00:21,  3.44it/s] 77%|███████▋  | 238/310 [03:50<00:20,  3.45it/s] 77%|███████▋  | 239/310 [03:50<00:20,  3.45it/s] 77%|███████▋  | 240/310 [03:50<00:20,  3.46it/s] 78%|███████▊  | 241/310 [03:51<00:19,  3.46it/s] 78%|███████▊  | 242/310 [03:51<00:20,  3.36it/s] 78%|███████▊  | 243/310 [03:51<00:19,  3.40it/s] 79%|███████▊  | 244/310 [03:52<00:19,  3.41it/s] 79%|███████▉  | 245/310 [03:52<00:18,  3.43it/s] 79%|███████▉  | 246/310 [03:52<00:18,  3.44it/s] 80%|███████▉  | 247/310 [03:52<00:18,  3.45it/s] 80%|████████  | 248/310 [03:53<00:17,  3.45it/s][INFO|trainer.py:2140] 2023-08-29 12:49:19,246 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 12:49:19,246 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 12:49:19,246 >>   Batch size = 8
{'eval_loss': 0.9767495393753052, 'eval_runtime': 39.579, 'eval_samples_per_second': 355.416, 'eval_steps_per_second': 44.443, 'epoch': 2.99}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:30, 56.70it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.25it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.35it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.48it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 45.77it/s][A
  2%|▏         | 32/1759 [00:00<00:38, 45.45it/s][A
  2%|▏         | 37/1759 [00:00<00:38, 45.19it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 45.15it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 44.08it/s][A
  3%|▎         | 52/1759 [00:01<00:38, 44.61it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 44.95it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.14it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 44.98it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.00it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 44.91it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 44.91it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.79it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.78it/s][A
  6%|▌         | 97/1759 [00:02<00:39, 42.36it/s][A
  6%|▌         | 102/1759 [00:02<00:38, 43.33it/s][A
  6%|▌         | 107/1759 [00:02<00:37, 44.02it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 44.52it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 44.71it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 44.77it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 44.83it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 44.77it/s][A
  8%|▊         | 137/1759 [00:03<00:36, 44.60it/s][A
  8%|▊         | 142/1759 [00:03<00:36, 44.73it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 44.84it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.05it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.20it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 45.36it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 45.35it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 45.20it/s][A
 10%|█         | 177/1759 [00:03<00:35, 45.07it/s][A
 10%|█         | 182/1759 [00:04<00:35, 44.89it/s][A
 11%|█         | 187/1759 [00:04<00:35, 44.80it/s][A
 11%|█         | 192/1759 [00:04<00:34, 44.85it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.04it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 45.16it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 45.30it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 45.35it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 45.27it/s][A
 13%|█▎        | 222/1759 [00:04<00:34, 44.95it/s][A
 13%|█▎        | 227/1759 [00:05<00:34, 44.97it/s][A
 13%|█▎        | 232/1759 [00:05<00:35, 43.61it/s][A
 13%|█▎        | 237/1759 [00:05<00:34, 44.22it/s][A
 14%|█▍        | 242/1759 [00:05<00:34, 44.55it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 44.87it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 45.05it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 45.11it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 45.21it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 45.18it/s][A
 15%|█▌        | 272/1759 [00:06<00:33, 44.85it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 44.96it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.05it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.12it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.20it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 45.19it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 45.26it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 45.22it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 45.08it/s][A
 18%|█▊        | 317/1759 [00:07<00:32, 44.95it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 44.98it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.06it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 45.14it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 45.13it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 45.24it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 45.22it/s][A
 20%|██        | 352/1759 [00:07<00:31, 45.14it/s][A
 20%|██        | 357/1759 [00:07<00:31, 45.04it/s][A
 21%|██        | 362/1759 [00:08<00:31, 44.98it/s][A
 21%|██        | 367/1759 [00:08<00:32, 43.07it/s][A
 21%|██        | 372/1759 [00:08<00:31, 43.87it/s][A
 21%|██▏       | 377/1759 [00:08<00:31, 44.34it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 44.64it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 44.82it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 44.92it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 44.93it/s][A
 23%|██▎       | 402/1759 [00:08<00:30, 44.90it/s][A
 23%|██▎       | 407/1759 [00:09<00:30, 44.66it/s][A
 23%|██▎       | 412/1759 [00:09<00:30, 44.78it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.00it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.06it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 45.24it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 45.30it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 45.28it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 45.16it/s][A
 25%|██▌       | 447/1759 [00:09<00:29, 45.14it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 44.94it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 44.97it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.04it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.14it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 45.25it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 45.17it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 45.20it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 45.13it/s][A
 28%|██▊       | 492/1759 [00:10<00:28, 45.01it/s][A
 28%|██▊       | 497/1759 [00:11<00:28, 44.95it/s][A
 29%|██▊       | 502/1759 [00:11<00:29, 42.67it/s][A
 29%|██▉       | 507/1759 [00:11<00:28, 43.44it/s][A
 29%|██▉       | 512/1759 [00:11<00:28, 44.04it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 44.39it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 44.77it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 44.91it/s][A
 30%|███       | 532/1759 [00:11<00:27, 45.07it/s][A
 31%|███       | 537/1759 [00:11<00:27, 45.07it/s][A
 31%|███       | 542/1759 [00:12<00:27, 44.83it/s][A
 31%|███       | 547/1759 [00:12<00:27, 44.81it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 44.91it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 45.12it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 45.13it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 45.21it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 45.24it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 45.13it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 45.06it/s][A
 33%|███▎      | 587/1759 [00:13<00:26, 44.87it/s][A
 34%|███▎      | 592/1759 [00:13<00:26, 44.88it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 44.92it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 45.08it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 45.24it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 45.29it/s][A
 35%|███▌      | 617/1759 [00:13<00:25, 45.23it/s][A
 35%|███▌      | 622/1759 [00:13<00:25, 45.20it/s][A
 36%|███▌      | 627/1759 [00:13<00:25, 45.06it/s][A
 36%|███▌      | 632/1759 [00:14<00:25, 44.94it/s][A
 36%|███▌      | 637/1759 [00:14<00:28, 39.82it/s][A
 36%|███▋      | 642/1759 [00:14<00:26, 41.43it/s][A
 37%|███▋      | 647/1759 [00:14<00:26, 42.66it/s][A
 37%|███▋      | 652/1759 [00:14<00:25, 43.54it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 44.17it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 44.55it/s][A
 38%|███▊      | 667/1759 [00:14<00:24, 44.86it/s][A
 38%|███▊      | 672/1759 [00:14<00:24, 44.88it/s][A
 38%|███▊      | 677/1759 [00:15<00:24, 44.56it/s][A
 39%|███▉      | 682/1759 [00:15<00:24, 44.38it/s][A
 39%|███▉      | 687/1759 [00:15<00:24, 44.55it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 44.75it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 44.93it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 45.05it/s][A
 40%|████      | 707/1759 [00:15<00:24, 42.17it/s][A
 40%|████      | 712/1759 [00:15<00:24, 43.14it/s][A
 41%|████      | 717/1759 [00:16<00:23, 43.85it/s][A
 41%|████      | 722/1759 [00:16<00:23, 44.13it/s][A
 41%|████▏     | 727/1759 [00:16<00:23, 44.36it/s][A
 42%|████▏     | 732/1759 [00:16<00:23, 44.50it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 44.70it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 44.87it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 44.88it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 44.93it/s][A
 43%|████▎     | 757/1759 [00:16<00:22, 45.00it/s][A
 43%|████▎     | 762/1759 [00:17<00:22, 45.21it/s][A
 44%|████▎     | 767/1759 [00:17<00:21, 45.11it/s][A
 44%|████▍     | 772/1759 [00:17<00:25, 38.34it/s][A
 44%|████▍     | 777/1759 [00:17<00:24, 40.30it/s][A
 44%|████▍     | 782/1759 [00:17<00:23, 41.80it/s][A
 45%|████▍     | 787/1759 [00:17<00:22, 42.89it/s][A
 45%|████▌     | 792/1759 [00:17<00:22, 43.73it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 44.29it/s][A
 46%|████▌     | 802/1759 [00:17<00:21, 44.70it/s][A
 46%|████▌     | 807/1759 [00:18<00:21, 44.87it/s][A
 46%|████▌     | 812/1759 [00:18<00:21, 44.58it/s][A
 46%|████▋     | 817/1759 [00:18<00:21, 44.35it/s][A
 47%|████▋     | 822/1759 [00:18<00:21, 44.37it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 44.66it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 44.85it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 45.07it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 45.22it/s][A
 48%|████▊     | 847/1759 [00:18<00:20, 45.19it/s][A
 48%|████▊     | 852/1759 [00:19<00:19, 45.42it/s][A
 49%|████▊     | 857/1759 [00:19<00:20, 45.09it/s][A
 49%|████▉     | 862/1759 [00:19<00:20, 44.76it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 44.67it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 44.84it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 45.00it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 45.21it/s][A
 50%|█████     | 887/1759 [00:19<00:19, 45.31it/s][A
 51%|█████     | 892/1759 [00:19<00:19, 45.27it/s][A
 51%|█████     | 897/1759 [00:20<00:19, 45.26it/s][A
 51%|█████▏    | 902/1759 [00:20<00:18, 45.11it/s][A
 52%|█████▏    | 907/1759 [00:20<00:21, 40.25it/s][A
 52%|█████▏    | 912/1759 [00:20<00:20, 41.68it/s][A
 52%|█████▏    | 917/1759 [00:20<00:19, 42.80it/s][A
 52%|█████▏    | 922/1759 [00:20<00:19, 43.56it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 44.15it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 44.53it/s][A
 53%|█████▎    | 937/1759 [00:20<00:18, 44.80it/s][A
 54%|█████▎    | 942/1759 [00:21<00:18, 44.92it/s][A
 54%|█████▍    | 947/1759 [00:21<00:18, 44.66it/s][A
 54%|█████▍    | 952/1759 [00:21<00:18, 44.61it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 44.73it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 44.93it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 45.11it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 45.24it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 45.28it/s][A
 56%|█████▌    | 982/1759 [00:21<00:17, 45.35it/s][A
 56%|█████▌    | 987/1759 [00:22<00:17, 45.13it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 44.92it/s][A
 57%|█████▋    | 997/1759 [00:22<00:17, 44.82it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 44.84it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.02it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 45.15it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 45.28it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:16, 45.30it/s][A
 58%|█████▊    | 1027/1759 [00:22<00:16, 45.35it/s][A
 59%|█████▊    | 1032/1759 [00:23<00:16, 45.14it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:16, 44.98it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:17, 42.11it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:16, 43.01it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:16, 43.77it/s][A
 60%|██████    | 1057/1759 [00:23<00:15, 44.26it/s][A
 60%|██████    | 1062/1759 [00:23<00:15, 44.59it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 44.89it/s][A
 61%|██████    | 1072/1759 [00:24<00:15, 45.06it/s][A
 61%|██████    | 1077/1759 [00:24<00:15, 45.07it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:15, 44.76it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:15, 44.77it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 44.87it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 45.03it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 45.15it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 45.26it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 45.30it/s][A
 64%|██████▎   | 1117/1759 [00:25<00:14, 45.28it/s][A
 64%|██████▍   | 1122/1759 [00:25<00:14, 45.10it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 44.75it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:14, 44.74it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 44.89it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 45.03it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 45.22it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 45.22it/s][A
 66%|██████▌   | 1157/1759 [00:25<00:13, 45.32it/s][A
 66%|██████▌   | 1162/1759 [00:26<00:13, 45.23it/s][A
 66%|██████▋   | 1167/1759 [00:26<00:13, 45.08it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 44.90it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:13, 42.31it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:13, 43.33it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:13, 43.99it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:12, 44.44it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 44.71it/s][A
 68%|██████▊   | 1202/1759 [00:26<00:12, 44.93it/s][A
 69%|██████▊   | 1207/1759 [00:27<00:12, 44.91it/s][A
 69%|██████▉   | 1212/1759 [00:27<00:12, 44.81it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 44.57it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:12, 44.58it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 44.70it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 44.94it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 45.10it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 45.26it/s][A
 71%|███████   | 1247/1759 [00:27<00:11, 45.36it/s][A
 71%|███████   | 1252/1759 [00:28<00:11, 45.23it/s][A
 71%|███████▏  | 1257/1759 [00:28<00:11, 44.99it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:11, 44.85it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:11, 44.72it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 44.86it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 44.96it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 45.14it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 45.25it/s][A
 73%|███████▎  | 1292/1759 [00:28<00:10, 45.36it/s][A
 74%|███████▎  | 1297/1759 [00:29<00:10, 45.16it/s][A
 74%|███████▍  | 1302/1759 [00:29<00:10, 45.02it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 44.87it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:10, 42.92it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:10, 43.65it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 44.17it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 44.56it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 44.87it/s][A
 76%|███████▌  | 1337/1759 [00:29<00:09, 44.99it/s][A
 76%|███████▋  | 1342/1759 [00:30<00:09, 45.11it/s][A
 77%|███████▋  | 1347/1759 [00:30<00:09, 44.99it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 44.76it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:08, 44.82it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 44.87it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 45.10it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:08, 45.19it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:08, 45.32it/s][A
 79%|███████▊  | 1382/1759 [00:30<00:08, 45.26it/s][A
 79%|███████▉  | 1387/1759 [00:31<00:08, 45.21it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 45.05it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 44.83it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:07, 44.79it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 44.79it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 45.01it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 45.15it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 45.29it/s][A
 81%|████████  | 1427/1759 [00:31<00:07, 45.27it/s][A
 81%|████████▏ | 1432/1759 [00:32<00:07, 45.21it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 45.05it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 44.92it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:07, 44.23it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 44.54it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 44.73it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 44.87it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 45.10it/s][A
 84%|████████▎ | 1472/1759 [00:32<00:06, 45.18it/s][A
 84%|████████▍ | 1477/1759 [00:33<00:06, 45.10it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 44.99it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 44.88it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 44.91it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 44.93it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 44.98it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 45.08it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 45.25it/s][A
 86%|████████▌ | 1517/1759 [00:33<00:05, 45.32it/s][A
 87%|████████▋ | 1522/1759 [00:34<00:05, 45.18it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 45.09it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 44.93it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 44.90it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 44.89it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 44.96it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 45.09it/s][A
 89%|████████▊ | 1557/1759 [00:34<00:04, 45.21it/s][A
 89%|████████▉ | 1562/1759 [00:34<00:04, 45.17it/s][A
 89%|████████▉ | 1567/1759 [00:35<00:04, 45.22it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 45.00it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 44.91it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 44.88it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 44.80it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 44.93it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 45.11it/s][A
 91%|█████████ | 1602/1759 [00:35<00:03, 45.29it/s][A
 91%|█████████▏| 1607/1759 [00:35<00:03, 40.59it/s][A
 92%|█████████▏| 1612/1759 [00:36<00:03, 42.00it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 43.02it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 43.72it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 44.07it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 44.44it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 44.64it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 44.77it/s][A
 94%|█████████▎| 1647/1759 [00:36<00:02, 44.51it/s][A
 94%|█████████▍| 1652/1759 [00:36<00:02, 44.53it/s][A
 94%|█████████▍| 1657/1759 [00:37<00:02, 44.74it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 44.90it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 45.01it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 45.13it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 45.23it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 45.32it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 45.13it/s][A
 96%|█████████▌| 1692/1759 [00:37<00:01, 45.00it/s][A
 96%|█████████▋| 1697/1759 [00:37<00:01, 44.93it/s][A
 97%|█████████▋| 1702/1759 [00:38<00:01, 44.93it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 44.96it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 45.10it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 45.16it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 45.22it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 45.21it/s][A
 98%|█████████▊| 1732/1759 [00:38<00:00, 45.11it/s][A
 99%|█████████▊| 1737/1759 [00:38<00:00, 45.00it/s][A
 99%|█████████▉| 1742/1759 [00:38<00:00, 41.72it/s][A
 99%|█████████▉| 1747/1759 [00:39<00:00, 42.70it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 43.53it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 44.08it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 44.08it/s][A 80%|████████  | 248/310 [04:32<00:17,  3.45it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 12:49:58,937 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-248
[INFO|configuration_utils.py:351] 2023-08-29 12:49:59,197 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-248/config.json
[INFO|modeling_utils.py:886] 2023-08-29 12:50:03,655 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-248/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 12:50:03,881 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-248/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 12:50:03,999 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-248/special_tokens_map.json
 80%|████████  | 249/310 [04:47<16:49, 16.55s/it] 81%|████████  | 250/310 [04:48<11:40, 11.68s/it] 81%|████████  | 251/310 [04:48<08:07,  8.26s/it] 81%|████████▏ | 252/310 [04:48<05:40,  5.87s/it] 82%|████████▏ | 253/310 [04:48<03:59,  4.20s/it] 82%|████████▏ | 254/310 [04:49<02:49,  3.03s/it] 82%|████████▏ | 255/310 [04:49<02:01,  2.21s/it] 83%|████████▎ | 256/310 [04:49<01:28,  1.63s/it] 83%|████████▎ | 257/310 [04:50<01:05,  1.23s/it] 83%|████████▎ | 258/310 [04:50<00:49,  1.05it/s] 84%|████████▎ | 259/310 [04:50<00:38,  1.33it/s] 84%|████████▍ | 260/310 [04:50<00:30,  1.63it/s] 84%|████████▍ | 261/310 [04:51<00:26,  1.88it/s] 85%|████████▍ | 262/310 [04:51<00:22,  2.17it/s] 85%|████████▍ | 263/310 [04:51<00:19,  2.44it/s] 85%|████████▌ | 264/310 [04:52<00:17,  2.67it/s] 85%|████████▌ | 265/310 [04:52<00:15,  2.85it/s] 86%|████████▌ | 266/310 [04:52<00:14,  3.00it/s] 86%|████████▌ | 267/310 [04:53<00:13,  3.11it/s] 86%|████████▋ | 268/310 [04:53<00:13,  3.20it/s] 87%|████████▋ | 269/310 [04:53<00:12,  3.26it/s] 87%|████████▋ | 270/310 [04:53<00:12,  3.30it/s] 87%|████████▋ | 271/310 [04:54<00:11,  3.34it/s] 88%|████████▊ | 272/310 [04:54<00:11,  3.21it/s] 88%|████████▊ | 273/310 [04:54<00:11,  3.26it/s] 88%|████████▊ | 274/310 [04:55<00:10,  3.31it/s] 89%|████████▊ | 275/310 [04:55<00:10,  3.34it/s] 89%|████████▉ | 276/310 [04:55<00:10,  3.36it/s] 89%|████████▉ | 277/310 [04:56<00:09,  3.38it/s] 90%|████████▉ | 278/310 [04:56<00:09,  3.39it/s] 90%|█████████ | 279/310 [04:56<00:09,  3.39it/s] 90%|█████████ | 280/310 [04:56<00:08,  3.40it/s] 91%|█████████ | 281/310 [04:57<00:08,  3.31it/s] 91%|█████████ | 282/310 [04:57<00:08,  3.34it/s] 91%|█████████▏| 283/310 [04:57<00:08,  3.36it/s] 92%|█████████▏| 284/310 [04:58<00:07,  3.38it/s] 92%|█████████▏| 285/310 [04:58<00:07,  3.38it/s] 92%|█████████▏| 286/310 [04:58<00:07,  3.39it/s] 93%|█████████▎| 287/310 [04:58<00:06,  3.40it/s] 93%|█████████▎| 288/310 [04:59<00:06,  3.40it/s] 93%|█████████▎| 289/310 [04:59<00:06,  3.40it/s] 94%|█████████▎| 290/310 [04:59<00:05,  3.39it/s] 94%|█████████▍| 291/310 [05:00<00:05,  3.29it/s] 94%|█████████▍| 292/310 [05:00<00:05,  3.32it/s] 95%|█████████▍| 293/310 [05:00<00:05,  3.35it/s] 95%|█████████▍| 294/310 [05:01<00:04,  3.37it/s] 95%|█████████▌| 295/310 [05:01<00:04,  3.38it/s] 95%|█████████▌| 296/310 [05:01<00:04,  3.39it/s] 96%|█████████▌| 297/310 [05:01<00:03,  3.39it/s] 96%|█████████▌| 298/310 [05:02<00:03,  3.40it/s] 96%|█████████▋| 299/310 [05:02<00:03,  3.40it/s] 97%|█████████▋| 300/310 [05:02<00:02,  3.41it/s] 97%|█████████▋| 301/310 [05:03<00:02,  3.41it/s] 97%|█████████▋| 302/310 [05:03<00:02,  3.29it/s] 98%|█████████▊| 303/310 [05:03<00:02,  3.32it/s] 98%|█████████▊| 304/310 [05:04<00:01,  3.35it/s] 98%|█████████▊| 305/310 [05:04<00:01,  3.37it/s] 99%|█████████▊| 306/310 [05:04<00:01,  3.38it/s] 99%|█████████▉| 307/310 [05:04<00:00,  3.39it/s] 99%|█████████▉| 308/310 [05:05<00:00,  3.40it/s]100%|█████████▉| 309/310 [05:05<00:00,  3.40it/s]100%|██████████| 310/310 [05:05<00:00,  3.40it/s][INFO|trainer.py:2140] 2023-08-29 12:50:31,687 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 12:50:31,687 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 12:50:31,687 >>   Batch size = 8
{'eval_loss': 0.9870747327804565, 'eval_runtime': 39.3739, 'eval_samples_per_second': 357.267, 'eval_steps_per_second': 44.674, 'epoch': 3.99}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.35it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.41it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.74it/s][A
  1%|▏         | 22/1759 [00:00<00:43, 39.88it/s][A
  2%|▏         | 27/1759 [00:00<00:41, 41.76it/s][A
  2%|▏         | 32/1759 [00:00<00:40, 42.91it/s][A
  2%|▏         | 37/1759 [00:00<00:39, 43.71it/s][A
  2%|▏         | 42/1759 [00:00<00:38, 44.20it/s][A
  3%|▎         | 47/1759 [00:01<00:38, 44.59it/s][A
  3%|▎         | 52/1759 [00:01<00:38, 44.89it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.09it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 44.73it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 44.73it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 44.91it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 45.11it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 45.20it/s][A
  5%|▍         | 87/1759 [00:01<00:36, 45.20it/s][A
  5%|▌         | 92/1759 [00:02<00:36, 45.32it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 45.37it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.18it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.01it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 44.88it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.02it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 45.17it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 45.27it/s][A
  8%|▊         | 132/1759 [00:02<00:35, 45.27it/s][A
  8%|▊         | 137/1759 [00:03<00:35, 45.25it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.31it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.24it/s][A
  9%|▊         | 152/1759 [00:03<00:41, 38.50it/s][A
  9%|▉         | 157/1759 [00:03<00:45, 35.13it/s][A
  9%|▉         | 162/1759 [00:03<00:42, 37.77it/s][A
  9%|▉         | 167/1759 [00:03<00:40, 39.73it/s][A
 10%|▉         | 172/1759 [00:03<00:38, 41.37it/s][A
 10%|█         | 177/1759 [00:04<00:37, 42.53it/s][A
 10%|█         | 182/1759 [00:04<00:36, 43.39it/s][A
 11%|█         | 187/1759 [00:04<00:35, 43.99it/s][A
 11%|█         | 192/1759 [00:04<00:35, 44.47it/s][A
 11%|█         | 197/1759 [00:04<00:35, 44.32it/s][A
 11%|█▏        | 202/1759 [00:04<00:35, 44.43it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 44.57it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 44.86it/s][A
 12%|█▏        | 217/1759 [00:04<00:34, 45.08it/s][A
 13%|█▎        | 222/1759 [00:05<00:33, 45.21it/s][A
 13%|█▎        | 227/1759 [00:05<00:33, 45.23it/s][A
 13%|█▎        | 232/1759 [00:05<00:33, 45.34it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 45.23it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 44.92it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 44.88it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 44.92it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 45.04it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 45.21it/s][A
 15%|█▌        | 267/1759 [00:06<00:32, 45.22it/s][A
 15%|█▌        | 272/1759 [00:06<00:32, 45.38it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.36it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.20it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 44.99it/s][A
 17%|█▋        | 292/1759 [00:06<00:36, 39.90it/s][A
 17%|█▋        | 297/1759 [00:06<00:35, 41.31it/s][A
 17%|█▋        | 302/1759 [00:06<00:34, 42.70it/s][A
 17%|█▋        | 307/1759 [00:06<00:33, 43.61it/s][A
 18%|█▊        | 312/1759 [00:07<00:32, 44.23it/s][A
 18%|█▊        | 317/1759 [00:07<00:32, 44.67it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 44.99it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 44.96it/s][A
 19%|█▉        | 332/1759 [00:07<00:32, 44.54it/s][A
 19%|█▉        | 337/1759 [00:07<00:32, 44.37it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 44.55it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 44.79it/s][A
 20%|██        | 352/1759 [00:07<00:31, 44.99it/s][A
 20%|██        | 357/1759 [00:08<00:31, 45.21it/s][A
 21%|██        | 362/1759 [00:08<00:30, 45.35it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.51it/s][A
 21%|██        | 372/1759 [00:08<00:30, 45.38it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.03it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 44.79it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 44.83it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 44.89it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 44.98it/s][A
 23%|██▎       | 402/1759 [00:09<00:30, 45.16it/s][A
 23%|██▎       | 407/1759 [00:09<00:29, 45.36it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.38it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.38it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.17it/s][A
 24%|██▍       | 427/1759 [00:09<00:32, 40.52it/s][A
 25%|██▍       | 432/1759 [00:09<00:31, 41.95it/s][A
 25%|██▍       | 437/1759 [00:09<00:30, 43.04it/s][A
 25%|██▌       | 442/1759 [00:10<00:30, 43.77it/s][A
 25%|██▌       | 447/1759 [00:10<00:29, 44.40it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 44.71it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 45.00it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 44.99it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 44.66it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 44.50it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 44.59it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 44.83it/s][A
 28%|██▊       | 487/1759 [00:11<00:28, 45.05it/s][A
 28%|██▊       | 492/1759 [00:11<00:27, 45.25it/s][A
 28%|██▊       | 497/1759 [00:11<00:27, 45.41it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.49it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 45.34it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 45.01it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 44.79it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 44.66it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 44.72it/s][A
 30%|███       | 532/1759 [00:12<00:27, 44.98it/s][A
 31%|███       | 537/1759 [00:12<00:27, 45.10it/s][A
 31%|███       | 542/1759 [00:12<00:26, 45.22it/s][A
 31%|███       | 547/1759 [00:12<00:26, 45.42it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.43it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 45.17it/s][A
 32%|███▏      | 562/1759 [00:12<00:28, 42.74it/s][A
 32%|███▏      | 567/1759 [00:12<00:27, 43.42it/s][A
 33%|███▎      | 572/1759 [00:12<00:27, 43.92it/s][A
 33%|███▎      | 577/1759 [00:13<00:26, 44.32it/s][A
 33%|███▎      | 582/1759 [00:13<00:26, 44.65it/s][A
 33%|███▎      | 587/1759 [00:13<00:26, 44.91it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.15it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.09it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 44.88it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 44.81it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 44.85it/s][A
 35%|███▌      | 617/1759 [00:13<00:25, 44.95it/s][A
 35%|███▌      | 622/1759 [00:14<00:25, 45.06it/s][A
 36%|███▌      | 627/1759 [00:14<00:25, 45.20it/s][A
 36%|███▌      | 632/1759 [00:14<00:24, 45.31it/s][A
 36%|███▌      | 637/1759 [00:14<00:24, 45.34it/s][A
 36%|███▋      | 642/1759 [00:14<00:24, 45.24it/s][A
 37%|███▋      | 647/1759 [00:14<00:24, 45.05it/s][A
 37%|███▋      | 652/1759 [00:14<00:24, 44.90it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 44.89it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 45.01it/s][A
 38%|███▊      | 667/1759 [00:15<00:24, 45.15it/s][A
 38%|███▊      | 672/1759 [00:15<00:24, 45.25it/s][A
 38%|███▊      | 677/1759 [00:15<00:23, 45.28it/s][A
 39%|███▉      | 682/1759 [00:15<00:23, 45.32it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 45.22it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 45.09it/s][A
 40%|███▉      | 697/1759 [00:15<00:24, 44.05it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 44.37it/s][A
 40%|████      | 707/1759 [00:15<00:23, 44.64it/s][A
 40%|████      | 712/1759 [00:16<00:23, 44.93it/s][A
 41%|████      | 717/1759 [00:16<00:23, 45.04it/s][A
 41%|████      | 722/1759 [00:16<00:22, 45.22it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 45.25it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 45.17it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 44.98it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 44.81it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 44.88it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 44.99it/s][A
 43%|████▎     | 757/1759 [00:17<00:22, 45.19it/s][A
 43%|████▎     | 762/1759 [00:17<00:22, 45.29it/s][A
 44%|████▎     | 767/1759 [00:17<00:21, 45.36it/s][A
 44%|████▍     | 772/1759 [00:17<00:21, 45.36it/s][A
 44%|████▍     | 777/1759 [00:17<00:21, 45.11it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 45.04it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 44.91it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 44.89it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 44.98it/s][A
 46%|████▌     | 802/1759 [00:18<00:21, 45.05it/s][A
 46%|████▌     | 807/1759 [00:18<00:21, 45.17it/s][A
 46%|████▌     | 812/1759 [00:18<00:20, 45.28it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 45.35it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 45.16it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 45.02it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 44.34it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 44.55it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 44.74it/s][A
 48%|████▊     | 847/1759 [00:19<00:20, 44.93it/s][A
 48%|████▊     | 852/1759 [00:19<00:20, 45.05it/s][A
 49%|████▊     | 857/1759 [00:19<00:19, 45.22it/s][A
 49%|████▉     | 862/1759 [00:19<00:19, 45.29it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 45.19it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 45.07it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 44.91it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 45.02it/s][A
 50%|█████     | 887/1759 [00:19<00:19, 45.05it/s][A
 51%|█████     | 892/1759 [00:20<00:19, 45.24it/s][A
 51%|█████     | 897/1759 [00:20<00:19, 45.28it/s][A
 51%|█████▏    | 902/1759 [00:20<00:18, 45.31it/s][A
 52%|█████▏    | 907/1759 [00:20<00:18, 45.35it/s][A
 52%|█████▏    | 912/1759 [00:20<00:18, 45.22it/s][A
 52%|█████▏    | 917/1759 [00:20<00:18, 45.15it/s][A
 52%|█████▏    | 922/1759 [00:20<00:18, 45.06it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 45.05it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 45.01it/s][A
 53%|█████▎    | 937/1759 [00:21<00:18, 45.08it/s][A
 54%|█████▎    | 942/1759 [00:21<00:18, 45.10it/s][A
 54%|█████▍    | 947/1759 [00:21<00:17, 45.22it/s][A
 54%|█████▍    | 952/1759 [00:21<00:17, 45.23it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 45.11it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 45.11it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 45.06it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 44.45it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 44.68it/s][A
 56%|█████▌    | 982/1759 [00:22<00:17, 44.82it/s][A
 56%|█████▌    | 987/1759 [00:22<00:17, 44.90it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 44.99it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 45.12it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 45.20it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.08it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 44.97it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 44.97it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:16, 44.95it/s][A
 58%|█████▊    | 1027/1759 [00:23<00:16, 44.96it/s][A
 59%|█████▊    | 1032/1759 [00:23<00:16, 45.02it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:16, 45.11it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:15, 45.18it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:15, 45.23it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:15, 45.15it/s][A
 60%|██████    | 1057/1759 [00:23<00:15, 45.01it/s][A
 60%|██████    | 1062/1759 [00:23<00:15, 45.03it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 44.97it/s][A
 61%|██████    | 1072/1759 [00:24<00:15, 45.04it/s][A
 61%|██████    | 1077/1759 [00:24<00:15, 45.01it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:14, 45.15it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:14, 45.22it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 45.22it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 45.16it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 44.97it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 44.95it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 43.62it/s][A
 64%|██████▎   | 1117/1759 [00:25<00:14, 44.16it/s][A
 64%|██████▍   | 1122/1759 [00:25<00:14, 44.56it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 44.78it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:13, 44.99it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 44.91it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 45.01it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 44.94it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 44.72it/s][A
 66%|██████▌   | 1157/1759 [00:25<00:13, 44.80it/s][A
 66%|██████▌   | 1162/1759 [00:26<00:13, 44.92it/s][A
 66%|██████▋   | 1167/1759 [00:26<00:13, 45.14it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:12, 45.22it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:12, 45.29it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:12, 45.24it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 45.16it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:12, 45.01it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 44.80it/s][A
 68%|██████▊   | 1202/1759 [00:26<00:12, 44.83it/s][A
 69%|██████▊   | 1207/1759 [00:27<00:12, 44.88it/s][A
 69%|██████▉   | 1212/1759 [00:27<00:12, 45.02it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 45.15it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:11, 45.31it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 45.28it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 45.21it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 45.03it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 44.92it/s][A
 71%|███████   | 1247/1759 [00:27<00:11, 43.28it/s][A
 71%|███████   | 1252/1759 [00:28<00:11, 43.91it/s][A
 71%|███████▏  | 1257/1759 [00:28<00:11, 44.36it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:11, 44.76it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:10, 44.99it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 45.09it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 45.01it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 44.85it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 44.72it/s][A
 73%|███████▎  | 1292/1759 [00:28<00:10, 44.72it/s][A
 74%|███████▎  | 1297/1759 [00:29<00:10, 44.94it/s][A
 74%|███████▍  | 1302/1759 [00:29<00:10, 45.09it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:09, 45.21it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:09, 45.32it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:09, 45.28it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 45.13it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 44.96it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 44.82it/s][A
 76%|███████▌  | 1337/1759 [00:29<00:09, 44.86it/s][A
 76%|███████▋  | 1342/1759 [00:30<00:09, 44.98it/s][A
 77%|███████▋  | 1347/1759 [00:30<00:09, 45.11it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:08, 45.29it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:08, 45.36it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 45.34it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 45.14it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:08, 44.95it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:08, 44.77it/s][A
 79%|███████▊  | 1382/1759 [00:30<00:08, 41.99it/s][A
 79%|███████▉  | 1387/1759 [00:31<00:08, 43.06it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 43.76it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 44.36it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:07, 44.71it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 44.94it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 44.90it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 44.76it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 44.57it/s][A
 81%|████████  | 1427/1759 [00:31<00:07, 44.54it/s][A
 81%|████████▏ | 1432/1759 [00:32<00:07, 44.79it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 45.04it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 45.21it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 45.39it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 45.36it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 45.19it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 44.94it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 44.80it/s][A
 84%|████████▎ | 1472/1759 [00:32<00:06, 44.74it/s][A
 84%|████████▍ | 1477/1759 [00:33<00:06, 44.85it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 45.07it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 45.27it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 45.36it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 45.38it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 45.18it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 44.93it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 44.85it/s][A
 86%|████████▌ | 1517/1759 [00:33<00:05, 42.16it/s][A
 87%|████████▋ | 1522/1759 [00:34<00:05, 43.16it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 43.76it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 44.33it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 44.69it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 44.96it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 44.98it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 44.76it/s][A
 89%|████████▊ | 1557/1759 [00:34<00:04, 44.51it/s][A
 89%|████████▉ | 1562/1759 [00:34<00:04, 44.50it/s][A
 89%|████████▉ | 1567/1759 [00:35<00:04, 44.77it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 45.02it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 45.14it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 45.32it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 45.33it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 45.15it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 44.98it/s][A
 91%|█████████ | 1602/1759 [00:35<00:03, 44.70it/s][A
 91%|█████████▏| 1607/1759 [00:35<00:03, 44.71it/s][A
 92%|█████████▏| 1612/1759 [00:36<00:03, 44.83it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 45.05it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 45.23it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 45.35it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 45.37it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 45.22it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 44.99it/s][A
 94%|█████████▎| 1647/1759 [00:36<00:02, 44.81it/s][A
 94%|█████████▍| 1652/1759 [00:36<00:02, 43.10it/s][A
 94%|█████████▍| 1657/1759 [00:37<00:02, 43.77it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 44.26it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 44.54it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 44.85it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 44.95it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 44.97it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 45.00it/s][A
 96%|█████████▌| 1692/1759 [00:37<00:01, 44.77it/s][A
 96%|█████████▋| 1697/1759 [00:37<00:01, 44.84it/s][A
 97%|█████████▋| 1702/1759 [00:38<00:01, 45.02it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 45.03it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 45.05it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 45.23it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 45.25it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 45.25it/s][A
 98%|█████████▊| 1732/1759 [00:38<00:00, 45.02it/s][A
 99%|█████████▊| 1737/1759 [00:38<00:00, 44.84it/s][A
 99%|█████████▉| 1742/1759 [00:38<00:00, 44.80it/s][A
 99%|█████████▉| 1747/1759 [00:39<00:00, 44.97it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 45.06it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 45.09it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 45.09it/s][A100%|██████████| 310/310 [05:45<00:00,  3.40it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 12:51:11,277 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-310
[INFO|configuration_utils.py:351] 2023-08-29 12:51:11,504 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-310/config.json
[INFO|modeling_utils.py:886] 2023-08-29 12:51:15,032 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-310/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 12:51:15,288 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-310/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 12:51:15,383 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-310/special_tokens_map.json
[INFO|trainer.py:1343] 2023-08-29 12:51:23,657 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:1352] 2023-08-29 12:51:23,694 >> Loading best model from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-62 (score: 0.9541099071502686).
                                                 100%|██████████| 310/310 [06:12<00:00,  3.40it/s]100%|██████████| 310/310 [06:12<00:00,  1.20s/it]
[INFO|trainer.py:1894] 2023-08-29 12:51:38,438 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model
[INFO|configuration_utils.py:351] 2023-08-29 12:51:38,790 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/config.json
[INFO|modeling_utils.py:886] 2023-08-29 12:51:44,099 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 12:51:44,379 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 12:51:44,561 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/special_tokens_map.json
[INFO|trainer_pt_utils.py:908] 2023-08-29 12:51:45,545 >> ***** train metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:51:45,545 >>   epoch                    =       4.99
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:51:45,545 >>   train_loss               =     0.3809
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:51:45,545 >>   train_runtime            = 0:06:12.40
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:51:45,545 >>   train_samples            =       4000
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:51:45,545 >>   train_samples_per_second =     53.706
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:51:45,545 >>   train_steps_per_second   =      0.832
{'eval_loss': 0.9904730319976807, 'eval_runtime': 39.3476, 'eval_samples_per_second': 357.506, 'eval_steps_per_second': 44.704, 'epoch': 4.99}
{'train_runtime': 372.4003, 'train_samples_per_second': 53.706, 'train_steps_per_second': 0.832, 'train_loss': 0.38087091753559726, 'epoch': 4.99}
08/29/2023 12:51:45 - INFO - transformer_base.run_clm_rl -   *** Evaluate ***
[INFO|trainer.py:2140] 2023-08-29 12:51:45,867 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 12:51:45,867 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 12:51:45,867 >>   Batch size = 8
  0%|          | 0/1759 [00:00<?, ?it/s]  0%|          | 6/1759 [00:00<00:31, 55.94it/s]  1%|          | 12/1759 [00:00<00:35, 49.87it/s]  1%|          | 18/1759 [00:00<00:36, 47.99it/s]  1%|▏         | 23/1759 [00:00<00:36, 47.31it/s]  2%|▏         | 28/1759 [00:00<00:36, 46.89it/s]  2%|▏         | 33/1759 [00:00<00:37, 46.56it/s]  2%|▏         | 38/1759 [00:00<00:37, 46.31it/s]  2%|▏         | 43/1759 [00:00<00:37, 45.82it/s]  3%|▎         | 48/1759 [00:01<00:37, 45.29it/s]  3%|▎         | 53/1759 [00:01<00:37, 45.08it/s]  3%|▎         | 58/1759 [00:01<00:37, 45.18it/s]  4%|▎         | 63/1759 [00:01<00:38, 43.64it/s]  4%|▍         | 68/1759 [00:01<00:38, 44.28it/s]  4%|▍         | 73/1759 [00:01<00:37, 44.78it/s]  4%|▍         | 78/1759 [00:01<00:37, 45.10it/s]  5%|▍         | 83/1759 [00:01<00:36, 45.31it/s]  5%|▌         | 88/1759 [00:01<00:36, 45.35it/s]  5%|▌         | 93/1759 [00:02<00:36, 45.10it/s]  6%|▌         | 98/1759 [00:02<00:36, 45.02it/s]  6%|▌         | 103/1759 [00:02<00:36, 44.88it/s]  6%|▌         | 108/1759 [00:02<00:36, 44.99it/s]  6%|▋         | 113/1759 [00:02<00:36, 45.17it/s]  7%|▋         | 118/1759 [00:02<00:36, 45.34it/s]  7%|▋         | 123/1759 [00:02<00:35, 45.49it/s]  7%|▋         | 128/1759 [00:02<00:35, 45.58it/s]  8%|▊         | 133/1759 [00:02<00:35, 45.55it/s]  8%|▊         | 138/1759 [00:03<00:35, 45.44it/s]  8%|▊         | 143/1759 [00:03<00:35, 45.14it/s]  8%|▊         | 148/1759 [00:03<00:35, 45.02it/s]  9%|▊         | 153/1759 [00:03<00:35, 45.08it/s]  9%|▉         | 158/1759 [00:03<00:35, 45.22it/s]  9%|▉         | 163/1759 [00:03<00:35, 45.35it/s] 10%|▉         | 168/1759 [00:03<00:34, 45.49it/s] 10%|▉         | 173/1759 [00:03<00:34, 45.57it/s] 10%|█         | 178/1759 [00:03<00:34, 45.58it/s] 10%|█         | 183/1759 [00:04<00:34, 45.29it/s] 11%|█         | 188/1759 [00:04<00:34, 45.16it/s] 11%|█         | 193/1759 [00:04<00:34, 45.03it/s] 11%|█▏        | 198/1759 [00:04<00:34, 45.04it/s] 12%|█▏        | 203/1759 [00:04<00:35, 43.72it/s] 12%|█▏        | 208/1759 [00:04<00:34, 44.34it/s] 12%|█▏        | 213/1759 [00:04<00:34, 44.79it/s] 12%|█▏        | 218/1759 [00:04<00:34, 45.07it/s] 13%|█▎        | 223/1759 [00:04<00:33, 45.21it/s] 13%|█▎        | 228/1759 [00:05<00:33, 45.23it/s] 13%|█▎        | 233/1759 [00:05<00:33, 45.05it/s] 14%|█▎        | 238/1759 [00:05<00:33, 45.07it/s] 14%|█▍        | 243/1759 [00:05<00:33, 44.86it/s] 14%|█▍        | 248/1759 [00:05<00:33, 44.96it/s] 14%|█▍        | 253/1759 [00:05<00:33, 45.17it/s] 15%|█▍        | 258/1759 [00:05<00:33, 45.35it/s] 15%|█▍        | 263/1759 [00:05<00:32, 45.46it/s] 15%|█▌        | 268/1759 [00:05<00:32, 45.57it/s] 16%|█▌        | 273/1759 [00:06<00:32, 45.47it/s] 16%|█▌        | 278/1759 [00:06<00:32, 45.37it/s] 16%|█▌        | 283/1759 [00:06<00:32, 45.06it/s] 16%|█▋        | 288/1759 [00:06<00:32, 44.99it/s] 17%|█▋        | 293/1759 [00:06<00:32, 45.01it/s] 17%|█▋        | 298/1759 [00:06<00:32, 45.10it/s] 17%|█▋        | 303/1759 [00:06<00:32, 45.26it/s] 18%|█▊        | 308/1759 [00:06<00:31, 45.40it/s] 18%|█▊        | 313/1759 [00:06<00:31, 45.54it/s] 18%|█▊        | 318/1759 [00:07<00:31, 45.53it/s] 18%|█▊        | 323/1759 [00:07<00:31, 45.39it/s] 19%|█▊        | 328/1759 [00:07<00:31, 45.13it/s] 19%|█▉        | 333/1759 [00:07<00:31, 45.05it/s] 19%|█▉        | 338/1759 [00:07<00:31, 44.98it/s] 19%|█▉        | 343/1759 [00:07<00:33, 41.98it/s] 20%|█▉        | 348/1759 [00:07<00:32, 43.10it/s] 20%|██        | 353/1759 [00:07<00:32, 43.86it/s] 20%|██        | 358/1759 [00:07<00:31, 44.40it/s] 21%|██        | 363/1759 [00:08<00:31, 44.81it/s] 21%|██        | 368/1759 [00:08<00:30, 45.08it/s] 21%|██        | 373/1759 [00:08<00:30, 45.11it/s] 21%|██▏       | 378/1759 [00:08<00:30, 44.94it/s] 22%|██▏       | 383/1759 [00:08<00:30, 44.71it/s] 22%|██▏       | 388/1759 [00:08<00:30, 44.75it/s] 22%|██▏       | 393/1759 [00:08<00:30, 44.85it/s] 23%|██▎       | 398/1759 [00:08<00:30, 45.11it/s] 23%|██▎       | 403/1759 [00:08<00:29, 45.25it/s] 23%|██▎       | 408/1759 [00:09<00:29, 45.42it/s] 23%|██▎       | 413/1759 [00:09<00:31, 43.35it/s] 24%|██▍       | 418/1759 [00:09<00:30, 43.94it/s] 24%|██▍       | 423/1759 [00:09<00:30, 44.28it/s] 24%|██▍       | 428/1759 [00:09<00:29, 44.49it/s] 25%|██▍       | 433/1759 [00:09<00:29, 44.53it/s] 25%|██▍       | 438/1759 [00:09<00:29, 44.77it/s] 25%|██▌       | 443/1759 [00:09<00:29, 44.94it/s] 25%|██▌       | 448/1759 [00:09<00:29, 45.16it/s] 26%|██▌       | 453/1759 [00:10<00:28, 45.11it/s] 26%|██▌       | 458/1759 [00:10<00:28, 45.12it/s] 26%|██▋       | 463/1759 [00:10<00:28, 45.27it/s] 27%|██▋       | 468/1759 [00:10<00:28, 45.31it/s] 27%|██▋       | 473/1759 [00:10<00:28, 45.26it/s] 27%|██▋       | 478/1759 [00:10<00:28, 45.09it/s] 27%|██▋       | 483/1759 [00:10<00:28, 45.11it/s] 28%|██▊       | 488/1759 [00:10<00:28, 45.16it/s] 28%|██▊       | 493/1759 [00:10<00:28, 45.20it/s] 28%|██▊       | 498/1759 [00:11<00:27, 45.20it/s] 29%|██▊       | 503/1759 [00:11<00:27, 45.21it/s] 29%|██▉       | 508/1759 [00:11<00:27, 45.26it/s] 29%|██▉       | 513/1759 [00:11<00:27, 45.25it/s] 29%|██▉       | 518/1759 [00:11<00:27, 45.17it/s] 30%|██▉       | 523/1759 [00:11<00:27, 45.12it/s] 30%|███       | 528/1759 [00:11<00:27, 45.11it/s] 30%|███       | 533/1759 [00:11<00:27, 45.18it/s] 31%|███       | 538/1759 [00:11<00:27, 45.17it/s] 31%|███       | 543/1759 [00:12<00:26, 45.22it/s] 31%|███       | 548/1759 [00:12<00:27, 43.58it/s] 31%|███▏      | 553/1759 [00:12<00:27, 44.22it/s] 32%|███▏      | 558/1759 [00:12<00:26, 44.55it/s] 32%|███▏      | 563/1759 [00:12<00:26, 44.80it/s] 32%|███▏      | 568/1759 [00:12<00:26, 44.85it/s] 33%|███▎      | 573/1759 [00:12<00:26, 44.94it/s] 33%|███▎      | 578/1759 [00:12<00:26, 45.14it/s] 33%|███▎      | 583/1759 [00:12<00:25, 45.25it/s] 33%|███▎      | 588/1759 [00:13<00:25, 45.04it/s] 34%|███▎      | 593/1759 [00:13<00:25, 45.00it/s] 34%|███▍      | 598/1759 [00:13<00:25, 45.09it/s] 34%|███▍      | 603/1759 [00:13<00:25, 45.20it/s] 35%|███▍      | 608/1759 [00:13<00:25, 45.26it/s] 35%|███▍      | 613/1759 [00:13<00:25, 45.13it/s] 35%|███▌      | 618/1759 [00:13<00:25, 45.19it/s] 35%|███▌      | 623/1759 [00:13<00:25, 45.19it/s] 36%|███▌      | 628/1759 [00:13<00:25, 45.20it/s] 36%|███▌      | 633/1759 [00:14<00:24, 45.05it/s] 36%|███▋      | 638/1759 [00:14<00:24, 45.02it/s] 37%|███▋      | 643/1759 [00:14<00:24, 45.06it/s] 37%|███▋      | 648/1759 [00:14<00:24, 45.20it/s] 37%|███▋      | 653/1759 [00:14<00:24, 45.23it/s] 37%|███▋      | 658/1759 [00:14<00:24, 45.13it/s] 38%|███▊      | 663/1759 [00:14<00:24, 45.18it/s] 38%|███▊      | 668/1759 [00:14<00:24, 45.22it/s] 38%|███▊      | 673/1759 [00:14<00:24, 45.21it/s] 39%|███▊      | 678/1759 [00:15<00:24, 45.00it/s] 39%|███▉      | 683/1759 [00:15<00:24, 43.71it/s] 39%|███▉      | 688/1759 [00:15<00:24, 44.28it/s] 39%|███▉      | 693/1759 [00:15<00:23, 44.66it/s] 40%|███▉      | 698/1759 [00:15<00:23, 44.87it/s] 40%|███▉      | 703/1759 [00:15<00:23, 44.95it/s] 40%|████      | 708/1759 [00:15<00:23, 45.08it/s] 41%|████      | 713/1759 [00:15<00:23, 44.97it/s] 41%|████      | 718/1759 [00:15<00:23, 45.02it/s] 41%|████      | 723/1759 [00:16<00:23, 44.79it/s] 41%|████▏     | 728/1759 [00:16<00:22, 44.84it/s] 42%|████▏     | 733/1759 [00:16<00:22, 45.13it/s] 42%|████▏     | 738/1759 [00:16<00:22, 45.21it/s] 42%|████▏     | 743/1759 [00:16<00:22, 45.31it/s] 43%|████▎     | 748/1759 [00:16<00:22, 45.26it/s] 43%|████▎     | 753/1759 [00:16<00:22, 45.16it/s] 43%|████▎     | 758/1759 [00:16<00:22, 45.15it/s] 43%|████▎     | 763/1759 [00:16<00:22, 45.05it/s] 44%|████▎     | 768/1759 [00:17<00:22, 44.90it/s] 44%|████▍     | 773/1759 [00:17<00:21, 44.91it/s] 44%|████▍     | 778/1759 [00:17<00:21, 45.09it/s] 45%|████▍     | 783/1759 [00:17<00:21, 45.21it/s] 45%|████▍     | 788/1759 [00:17<00:21, 45.32it/s] 45%|████▌     | 793/1759 [00:17<00:21, 45.28it/s] 45%|████▌     | 798/1759 [00:17<00:21, 45.22it/s] 46%|████▌     | 803/1759 [00:17<00:21, 45.11it/s] 46%|████▌     | 808/1759 [00:17<00:21, 45.04it/s] 46%|████▌     | 813/1759 [00:18<00:21, 44.98it/s] 47%|████▋     | 818/1759 [00:18<00:21, 43.94it/s] 47%|████▋     | 823/1759 [00:18<00:21, 44.41it/s] 47%|████▋     | 828/1759 [00:18<00:20, 44.70it/s] 47%|████▋     | 833/1759 [00:18<00:20, 44.96it/s] 48%|████▊     | 838/1759 [00:18<00:20, 45.09it/s] 48%|████▊     | 843/1759 [00:18<00:20, 45.10it/s] 48%|████▊     | 848/1759 [00:18<00:20, 45.13it/s] 48%|████▊     | 853/1759 [00:18<00:20, 45.11it/s] 49%|████▉     | 858/1759 [00:19<00:20, 44.87it/s] 49%|████▉     | 863/1759 [00:19<00:19, 44.86it/s] 49%|████▉     | 868/1759 [00:19<00:19, 45.05it/s] 50%|████▉     | 873/1759 [00:19<00:19, 45.17it/s] 50%|████▉     | 878/1759 [00:19<00:19, 45.20it/s] 50%|█████     | 883/1759 [00:19<00:19, 45.28it/s] 50%|█████     | 888/1759 [00:19<00:19, 45.32it/s] 51%|█████     | 893/1759 [00:19<00:19, 45.26it/s] 51%|█████     | 898/1759 [00:19<00:19, 45.20it/s] 51%|█████▏    | 903/1759 [00:20<00:18, 45.08it/s] 52%|█████▏    | 908/1759 [00:20<00:18, 45.03it/s] 52%|█████▏    | 913/1759 [00:20<00:18, 45.11it/s] 52%|█████▏    | 918/1759 [00:20<00:18, 45.23it/s] 52%|█████▏    | 923/1759 [00:20<00:18, 45.33it/s] 53%|█████▎    | 928/1759 [00:20<00:18, 45.35it/s] 53%|█████▎    | 933/1759 [00:20<00:18, 45.38it/s] 53%|█████▎    | 938/1759 [00:20<00:18, 45.34it/s] 54%|█████▎    | 943/1759 [00:20<00:18, 45.25it/s] 54%|█████▍    | 948/1759 [00:21<00:17, 45.14it/s] 54%|█████▍    | 953/1759 [00:21<00:17, 45.17it/s] 54%|█████▍    | 958/1759 [00:21<00:19, 41.14it/s] 55%|█████▍    | 963/1759 [00:21<00:18, 42.25it/s] 55%|█████▌    | 968/1759 [00:21<00:18, 43.32it/s] 55%|█████▌    | 973/1759 [00:21<00:17, 44.01it/s] 56%|█████▌    | 978/1759 [00:21<00:17, 44.56it/s] 56%|█████▌    | 983/1759 [00:21<00:17, 44.86it/s] 56%|█████▌    | 988/1759 [00:21<00:17, 45.07it/s] 56%|█████▋    | 993/1759 [00:22<00:16, 45.08it/s] 57%|█████▋    | 998/1759 [00:22<00:16, 44.83it/s] 57%|█████▋    | 1003/1759 [00:22<00:16, 44.72it/s] 57%|█████▋    | 1008/1759 [00:22<00:16, 44.79it/s] 58%|█████▊    | 1013/1759 [00:22<00:16, 45.11it/s] 58%|█████▊    | 1018/1759 [00:22<00:16, 45.30it/s] 58%|█████▊    | 1023/1759 [00:22<00:16, 45.47it/s] 58%|█████▊    | 1028/1759 [00:22<00:16, 45.53it/s] 59%|█████▊    | 1033/1759 [00:22<00:15, 45.51it/s] 59%|█████▉    | 1038/1759 [00:23<00:15, 45.32it/s] 59%|█████▉    | 1043/1759 [00:23<00:15, 45.06it/s] 60%|█████▉    | 1048/1759 [00:23<00:15, 44.93it/s] 60%|█████▉    | 1053/1759 [00:23<00:15, 44.87it/s] 60%|██████    | 1058/1759 [00:23<00:15, 45.14it/s] 60%|██████    | 1063/1759 [00:23<00:15, 45.34it/s] 61%|██████    | 1068/1759 [00:23<00:15, 45.42it/s] 61%|██████    | 1073/1759 [00:23<00:15, 45.49it/s] 61%|██████▏   | 1078/1759 [00:23<00:14, 45.51it/s] 62%|██████▏   | 1083/1759 [00:24<00:14, 45.29it/s] 62%|██████▏   | 1088/1759 [00:24<00:14, 45.09it/s] 62%|██████▏   | 1093/1759 [00:24<00:15, 42.18it/s] 62%|██████▏   | 1098/1759 [00:24<00:15, 43.22it/s] 63%|██████▎   | 1103/1759 [00:24<00:14, 43.91it/s] 63%|██████▎   | 1108/1759 [00:24<00:14, 44.46it/s] 63%|██████▎   | 1113/1759 [00:24<00:14, 44.86it/s] 64%|██████▎   | 1118/1759 [00:24<00:14, 45.09it/s] 64%|██████▍   | 1123/1759 [00:24<00:14, 45.17it/s] 64%|██████▍   | 1128/1759 [00:25<00:13, 45.08it/s] 64%|██████▍   | 1133/1759 [00:25<00:13, 44.77it/s] 65%|██████▍   | 1138/1759 [00:25<00:13, 44.69it/s] 65%|██████▍   | 1143/1759 [00:25<00:13, 44.97it/s] 65%|██████▌   | 1148/1759 [00:25<00:13, 45.23it/s] 66%|██████▌   | 1153/1759 [00:25<00:13, 45.39it/s] 66%|██████▌   | 1158/1759 [00:25<00:13, 45.48it/s] 66%|██████▌   | 1163/1759 [00:25<00:13, 45.51it/s] 66%|██████▋   | 1168/1759 [00:25<00:12, 45.47it/s] 67%|██████▋   | 1173/1759 [00:26<00:12, 45.24it/s] 67%|██████▋   | 1178/1759 [00:26<00:12, 44.96it/s] 67%|██████▋   | 1183/1759 [00:26<00:12, 44.88it/s] 68%|██████▊   | 1188/1759 [00:26<00:12, 44.97it/s] 68%|██████▊   | 1193/1759 [00:26<00:12, 45.17it/s] 68%|██████▊   | 1198/1759 [00:26<00:12, 45.23it/s] 68%|██████▊   | 1203/1759 [00:26<00:12, 45.43it/s] 69%|██████▊   | 1208/1759 [00:26<00:12, 45.52it/s] 69%|██████▉   | 1213/1759 [00:26<00:12, 45.50it/s] 69%|██████▉   | 1218/1759 [00:27<00:11, 45.26it/s] 70%|██████▉   | 1223/1759 [00:27<00:11, 45.02it/s] 70%|██████▉   | 1228/1759 [00:27<00:12, 42.81it/s] 70%|███████   | 1233/1759 [00:27<00:12, 43.63it/s] 70%|███████   | 1238/1759 [00:27<00:11, 44.24it/s] 71%|███████   | 1243/1759 [00:27<00:11, 44.68it/s] 71%|███████   | 1248/1759 [00:27<00:11, 44.93it/s] 71%|███████   | 1253/1759 [00:27<00:11, 45.17it/s] 72%|███████▏  | 1258/1759 [00:27<00:11, 45.27it/s] 72%|███████▏  | 1263/1759 [00:28<00:10, 45.21it/s] 72%|███████▏  | 1268/1759 [00:28<00:10, 44.94it/s] 72%|███████▏  | 1273/1759 [00:28<00:10, 44.85it/s] 73%|███████▎  | 1278/1759 [00:28<00:10, 45.06it/s] 73%|███████▎  | 1283/1759 [00:28<00:10, 45.15it/s] 73%|███████▎  | 1288/1759 [00:28<00:10, 45.36it/s] 74%|███████▎  | 1293/1759 [00:28<00:10, 45.40it/s] 74%|███████▍  | 1298/1759 [00:28<00:10, 45.48it/s] 74%|███████▍  | 1303/1759 [00:28<00:10, 45.41it/s] 74%|███████▍  | 1308/1759 [00:29<00:09, 45.24it/s] 75%|███████▍  | 1313/1759 [00:29<00:09, 44.99it/s] 75%|███████▍  | 1318/1759 [00:29<00:10, 42.99it/s] 75%|███████▌  | 1323/1759 [00:29<00:09, 43.75it/s] 75%|███████▌  | 1328/1759 [00:29<00:09, 44.35it/s] 76%|███████▌  | 1333/1759 [00:29<00:09, 44.76it/s] 76%|███████▌  | 1338/1759 [00:29<00:09, 45.01it/s] 76%|███████▋  | 1343/1759 [00:29<00:09, 45.23it/s] 77%|███████▋  | 1348/1759 [00:29<00:09, 45.28it/s] 77%|███████▋  | 1353/1759 [00:30<00:16, 24.48it/s] 77%|███████▋  | 1357/1759 [00:30<00:15, 26.54it/s] 77%|███████▋  | 1362/1759 [00:30<00:12, 30.58it/s] 78%|███████▊  | 1367/1759 [00:30<00:11, 34.07it/s] 78%|███████▊  | 1372/1759 [00:30<00:10, 36.98it/s] 78%|███████▊  | 1377/1759 [00:30<00:09, 39.28it/s] 79%|███████▊  | 1382/1759 [00:31<00:09, 41.04it/s] 79%|███████▉  | 1387/1759 [00:31<00:08, 42.33it/s] 79%|███████▉  | 1392/1759 [00:31<00:08, 43.09it/s] 79%|███████▉  | 1397/1759 [00:31<00:08, 43.39it/s] 80%|███████▉  | 1402/1759 [00:31<00:08, 43.64it/s] 80%|███████▉  | 1407/1759 [00:31<00:07, 44.02it/s] 80%|████████  | 1412/1759 [00:31<00:07, 44.43it/s] 81%|████████  | 1417/1759 [00:31<00:07, 44.82it/s] 81%|████████  | 1422/1759 [00:31<00:07, 45.13it/s] 81%|████████  | 1427/1759 [00:32<00:07, 45.22it/s] 81%|████████▏ | 1432/1759 [00:32<00:07, 45.43it/s] 82%|████████▏ | 1437/1759 [00:32<00:07, 45.31it/s] 82%|████████▏ | 1442/1759 [00:32<00:07, 45.06it/s] 82%|████████▏ | 1447/1759 [00:32<00:06, 44.85it/s] 83%|████████▎ | 1452/1759 [00:32<00:06, 44.85it/s] 83%|████████▎ | 1457/1759 [00:32<00:06, 44.99it/s] 83%|████████▎ | 1462/1759 [00:32<00:06, 45.16it/s] 83%|████████▎ | 1467/1759 [00:32<00:06, 45.30it/s] 84%|████████▎ | 1472/1759 [00:33<00:06, 45.41it/s] 84%|████████▍ | 1477/1759 [00:33<00:06, 45.50it/s] 84%|████████▍ | 1482/1759 [00:33<00:06, 45.35it/s] 85%|████████▍ | 1487/1759 [00:33<00:06, 45.17it/s] 85%|████████▍ | 1492/1759 [00:33<00:05, 45.02it/s] 85%|████████▌ | 1497/1759 [00:33<00:05, 44.04it/s] 85%|████████▌ | 1502/1759 [00:33<00:05, 44.40it/s] 86%|████████▌ | 1507/1759 [00:33<00:05, 44.75it/s] 86%|████████▌ | 1512/1759 [00:33<00:05, 44.94it/s] 86%|████████▌ | 1517/1759 [00:34<00:05, 45.17it/s] 87%|████████▋ | 1522/1759 [00:34<00:05, 45.26it/s] 87%|████████▋ | 1527/1759 [00:34<00:05, 45.24it/s] 87%|████████▋ | 1532/1759 [00:34<00:05, 45.05it/s] 87%|████████▋ | 1537/1759 [00:34<00:04, 44.94it/s] 88%|████████▊ | 1542/1759 [00:34<00:04, 44.94it/s] 88%|████████▊ | 1547/1759 [00:34<00:04, 45.01it/s] 88%|████████▊ | 1552/1759 [00:34<00:04, 45.12it/s] 89%|████████▊ | 1557/1759 [00:34<00:04, 45.21it/s] 89%|████████▉ | 1562/1759 [00:35<00:04, 45.34it/s] 89%|████████▉ | 1567/1759 [00:35<00:04, 45.43it/s] 89%|████████▉ | 1572/1759 [00:35<00:04, 45.31it/s] 90%|████████▉ | 1577/1759 [00:35<00:04, 45.19it/s] 90%|████████▉ | 1582/1759 [00:35<00:03, 45.04it/s] 90%|█████████ | 1587/1759 [00:35<00:03, 44.94it/s] 91%|█████████ | 1592/1759 [00:35<00:03, 45.00it/s] 91%|█████████ | 1597/1759 [00:35<00:03, 45.13it/s] 91%|█████████ | 1602/1759 [00:35<00:03, 45.18it/s] 91%|█████████▏| 1607/1759 [00:36<00:03, 45.34it/s] 92%|█████████▏| 1612/1759 [00:36<00:03, 45.40it/s] 92%|█████████▏| 1617/1759 [00:36<00:03, 45.36it/s] 92%|█████████▏| 1622/1759 [00:36<00:03, 45.25it/s] 92%|█████████▏| 1627/1759 [00:36<00:02, 45.08it/s] 93%|█████████▎| 1632/1759 [00:36<00:02, 44.97it/s] 93%|█████████▎| 1637/1759 [00:36<00:02, 43.55it/s] 93%|█████████▎| 1642/1759 [00:36<00:02, 44.17it/s] 94%|█████████▎| 1647/1759 [00:36<00:02, 44.61it/s] 94%|█████████▍| 1652/1759 [00:37<00:02, 44.89it/s] 94%|█████████▍| 1657/1759 [00:37<00:02, 45.06it/s] 94%|█████████▍| 1662/1759 [00:37<00:02, 45.10it/s] 95%|█████████▍| 1667/1759 [00:37<00:02, 45.06it/s] 95%|█████████▌| 1672/1759 [00:37<00:01, 45.04it/s] 95%|█████████▌| 1677/1759 [00:37<00:01, 44.80it/s] 96%|█████████▌| 1682/1759 [00:37<00:01, 44.77it/s] 96%|█████████▌| 1687/1759 [00:37<00:01, 44.99it/s] 96%|█████████▌| 1692/1759 [00:37<00:01, 45.15it/s] 96%|█████████▋| 1697/1759 [00:38<00:01, 45.31it/s] 97%|█████████▋| 1702/1759 [00:38<00:01, 45.41it/s] 97%|█████████▋| 1707/1759 [00:38<00:01, 45.45it/s] 97%|█████████▋| 1712/1759 [00:38<00:01, 45.23it/s] 98%|█████████▊| 1717/1759 [00:38<00:00, 45.04it/s] 98%|█████████▊| 1722/1759 [00:38<00:00, 44.92it/s] 98%|█████████▊| 1727/1759 [00:38<00:00, 44.91it/s] 98%|█████████▊| 1732/1759 [00:38<00:00, 44.99it/s] 99%|█████████▊| 1737/1759 [00:38<00:00, 45.02it/s] 99%|█████████▉| 1742/1759 [00:39<00:00, 45.29it/s] 99%|█████████▉| 1747/1759 [00:39<00:00, 45.45it/s]100%|█████████▉| 1752/1759 [00:39<00:00, 45.49it/s]100%|█████████▉| 1757/1759 [00:39<00:00, 45.39it/s]100%|██████████| 1759/1759 [00:39<00:00, 44.64it/s]
[INFO|trainer_pt_utils.py:908] 2023-08-29 12:52:25,289 >> ***** eval metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:52:25,290 >>   epoch                   =       4.99
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:52:25,290 >>   eval_loss               =     0.9541
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:52:25,290 >>   eval_runtime            = 0:00:39.42
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:52:25,290 >>   eval_samples            =      14067
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:52:25,290 >>   eval_samples_per_second =    356.829
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:52:25,290 >>   eval_steps_per_second   =      44.62
[INFO|trainer_pt_utils.py:913] 2023-08-29 12:52:25,290 >>   perplexity              =     2.5964
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:38,803 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:38,848 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:38,848 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:38,848 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:38,848 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 12:52:39,873 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 12:52:39,874 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 12:52:40,577 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 12:52:41,768 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 12:52:41,768 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:45,138 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:45,175 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:45,175 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:45,175 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:52:45,175 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 12:52:46,027 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 12:52:46,028 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 12:52:46,659 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 12:52:46,905 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 12:52:46,905 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-248
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-310
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-124
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-186
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/checkpoint-62
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl', 'labels': ['country', 'part of', 'platform', 'publisher', 'sport'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_in_all_single_is_eval_True.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_out_filter_all_single_is_eval_True.jsonl'}}
predict vocab size: 22024
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 22124, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.47it/s]Extractor Predicting: 2it [00:01,  1.55it/s]Extractor Predicting: 3it [00:01,  1.56it/s]Extractor Predicting: 4it [00:02,  1.63it/s]Extractor Predicting: 5it [00:03,  1.65it/s]Extractor Predicting: 6it [00:03,  1.68it/s]Extractor Predicting: 7it [00:04,  1.69it/s]Extractor Predicting: 8it [00:04,  1.67it/s]Extractor Predicting: 9it [00:05,  1.65it/s]Extractor Predicting: 10it [00:06,  1.60it/s]Extractor Predicting: 11it [00:06,  1.56it/s]Extractor Predicting: 12it [00:07,  1.55it/s]Extractor Predicting: 13it [00:08,  1.53it/s]Extractor Predicting: 14it [00:08,  1.52it/s]Extractor Predicting: 15it [00:09,  1.48it/s]Extractor Predicting: 16it [00:10,  1.47it/s]Extractor Predicting: 17it [00:10,  1.48it/s]Extractor Predicting: 18it [00:11,  1.49it/s]Extractor Predicting: 19it [00:12,  1.51it/s]Extractor Predicting: 20it [00:12,  1.50it/s]Extractor Predicting: 21it [00:13,  1.48it/s]Extractor Predicting: 22it [00:14,  1.49it/s]Extractor Predicting: 23it [00:14,  1.48it/s]Extractor Predicting: 24it [00:15,  1.51it/s]Extractor Predicting: 25it [00:16,  1.56it/s]Extractor Predicting: 26it [00:16,  1.52it/s]Extractor Predicting: 27it [00:17,  1.53it/s]Extractor Predicting: 28it [00:18,  1.59it/s]Extractor Predicting: 29it [00:18,  1.63it/s]Extractor Predicting: 30it [00:19,  1.64it/s]Extractor Predicting: 31it [00:19,  1.66it/s]Extractor Predicting: 32it [00:20,  1.61it/s]Extractor Predicting: 33it [00:21,  1.64it/s]Extractor Predicting: 34it [00:21,  1.65it/s]Extractor Predicting: 35it [00:22,  1.65it/s]Extractor Predicting: 36it [00:22,  1.63it/s]Extractor Predicting: 37it [00:23,  1.64it/s]Extractor Predicting: 38it [00:24,  1.66it/s]Extractor Predicting: 39it [00:24,  1.64it/s]Extractor Predicting: 40it [00:25,  1.66it/s]Extractor Predicting: 41it [00:25,  1.59it/s]Extractor Predicting: 42it [00:26,  1.63it/s]Extractor Predicting: 43it [00:27,  1.66it/s]Extractor Predicting: 44it [00:27,  1.67it/s]Extractor Predicting: 45it [00:28,  1.68it/s]Extractor Predicting: 46it [00:28,  1.67it/s]Extractor Predicting: 47it [00:29,  1.67it/s]Extractor Predicting: 48it [00:30,  1.65it/s]Extractor Predicting: 49it [00:30,  1.69it/s]Extractor Predicting: 50it [00:31,  1.68it/s]Extractor Predicting: 51it [00:31,  1.68it/s]Extractor Predicting: 52it [00:32,  1.68it/s]Extractor Predicting: 53it [00:33,  1.69it/s]Extractor Predicting: 54it [00:33,  1.71it/s]Extractor Predicting: 55it [00:34,  1.71it/s]Extractor Predicting: 56it [00:34,  1.71it/s]Extractor Predicting: 57it [00:35,  1.68it/s]Extractor Predicting: 58it [00:36,  1.66it/s]Extractor Predicting: 59it [00:36,  1.47it/s]Extractor Predicting: 60it [00:37,  1.54it/s]Extractor Predicting: 61it [00:38,  1.58it/s]Extractor Predicting: 62it [00:38,  1.58it/s]Extractor Predicting: 63it [00:39,  1.59it/s]Extractor Predicting: 64it [00:39,  1.59it/s]Extractor Predicting: 65it [00:40,  1.59it/s]Extractor Predicting: 66it [00:41,  1.59it/s]Extractor Predicting: 67it [00:41,  1.60it/s]Extractor Predicting: 68it [00:42,  1.54it/s]Extractor Predicting: 69it [00:43,  1.59it/s]Extractor Predicting: 70it [00:43,  1.64it/s]Extractor Predicting: 71it [00:44,  1.65it/s]Extractor Predicting: 72it [00:44,  1.62it/s]Extractor Predicting: 73it [00:45,  1.56it/s]Extractor Predicting: 74it [00:46,  1.57it/s]Extractor Predicting: 75it [00:46,  1.56it/s]Extractor Predicting: 76it [00:47,  1.55it/s]Extractor Predicting: 77it [00:48,  1.55it/s]Extractor Predicting: 78it [00:48,  1.59it/s]Extractor Predicting: 79it [00:49,  1.57it/s]Extractor Predicting: 80it [00:50,  1.55it/s]Extractor Predicting: 81it [00:50,  1.56it/s]Extractor Predicting: 82it [00:51,  1.60it/s]Extractor Predicting: 83it [00:51,  1.61it/s]Extractor Predicting: 84it [00:52,  1.66it/s]Extractor Predicting: 85it [00:53,  1.56it/s]Extractor Predicting: 86it [00:53,  1.56it/s]Extractor Predicting: 87it [00:54,  1.57it/s]Extractor Predicting: 88it [00:55,  1.50it/s]Extractor Predicting: 89it [00:55,  1.56it/s]Extractor Predicting: 90it [00:56,  1.58it/s]Extractor Predicting: 91it [00:57,  1.62it/s]Extractor Predicting: 92it [00:57,  1.57it/s]Extractor Predicting: 93it [00:58,  1.54it/s]Extractor Predicting: 94it [00:59,  1.57it/s]Extractor Predicting: 95it [00:59,  1.61it/s]Extractor Predicting: 96it [01:00,  1.64it/s]Extractor Predicting: 97it [01:00,  1.70it/s]Extractor Predicting: 98it [01:01,  1.73it/s]Extractor Predicting: 99it [01:01,  1.71it/s]Extractor Predicting: 100it [01:02,  1.79it/s]Extractor Predicting: 101it [01:02,  1.74it/s]Extractor Predicting: 102it [01:03,  1.72it/s]Extractor Predicting: 103it [01:04,  1.74it/s]Extractor Predicting: 104it [01:04,  1.74it/s]Extractor Predicting: 105it [01:05,  1.77it/s]Extractor Predicting: 106it [01:05,  1.75it/s]Extractor Predicting: 107it [01:06,  1.70it/s]Extractor Predicting: 108it [01:07,  1.70it/s]Extractor Predicting: 109it [01:07,  1.70it/s]Extractor Predicting: 110it [01:08,  1.70it/s]Extractor Predicting: 111it [01:08,  1.73it/s]Extractor Predicting: 112it [01:09,  1.74it/s]Extractor Predicting: 113it [01:09,  1.73it/s]Extractor Predicting: 114it [01:10,  1.76it/s]Extractor Predicting: 115it [01:11,  1.76it/s]Extractor Predicting: 116it [01:11,  1.79it/s]Extractor Predicting: 117it [01:12,  1.77it/s]Extractor Predicting: 118it [01:12,  1.77it/s]Extractor Predicting: 119it [01:13,  1.74it/s]Extractor Predicting: 120it [01:13,  1.78it/s]Extractor Predicting: 121it [01:14,  1.75it/s]Extractor Predicting: 122it [01:15,  1.72it/s]Extractor Predicting: 123it [01:15,  1.72it/s]Extractor Predicting: 124it [01:16,  1.70it/s]Extractor Predicting: 125it [01:16,  1.68it/s]Extractor Predicting: 126it [01:17,  1.69it/s]Extractor Predicting: 127it [01:17,  1.76it/s]Extractor Predicting: 128it [01:18,  1.76it/s]Extractor Predicting: 129it [01:19,  1.77it/s]Extractor Predicting: 130it [01:19,  1.76it/s]Extractor Predicting: 131it [01:20,  1.72it/s]Extractor Predicting: 132it [01:20,  1.75it/s]Extractor Predicting: 133it [01:21,  1.71it/s]Extractor Predicting: 134it [01:21,  1.75it/s]Extractor Predicting: 135it [01:22,  1.75it/s]Extractor Predicting: 136it [01:23,  1.73it/s]Extractor Predicting: 137it [01:23,  1.73it/s]Extractor Predicting: 138it [01:24,  1.70it/s]Extractor Predicting: 139it [01:24,  1.71it/s]Extractor Predicting: 140it [01:25,  1.70it/s]Extractor Predicting: 141it [01:26,  1.72it/s]Extractor Predicting: 142it [01:26,  1.76it/s]Extractor Predicting: 143it [01:27,  1.78it/s]Extractor Predicting: 144it [01:27,  1.74it/s]Extractor Predicting: 145it [01:28,  1.70it/s]Extractor Predicting: 146it [01:28,  1.68it/s]Extractor Predicting: 147it [01:29,  1.70it/s]Extractor Predicting: 148it [01:30,  1.68it/s]Extractor Predicting: 149it [01:30,  1.57it/s]Extractor Predicting: 150it [01:31,  1.61it/s]Extractor Predicting: 151it [01:32,  1.57it/s]Extractor Predicting: 152it [01:32,  1.53it/s]Extractor Predicting: 153it [01:33,  1.51it/s]Extractor Predicting: 154it [01:34,  1.51it/s]Extractor Predicting: 155it [01:34,  1.53it/s]Extractor Predicting: 156it [01:35,  1.52it/s]Extractor Predicting: 157it [01:36,  1.57it/s]Extractor Predicting: 158it [01:36,  1.56it/s]Extractor Predicting: 159it [01:37,  1.58it/s]Extractor Predicting: 160it [01:37,  1.62it/s]Extractor Predicting: 161it [01:38,  1.65it/s]Extractor Predicting: 162it [01:39,  1.66it/s]Extractor Predicting: 163it [01:39,  1.63it/s]Extractor Predicting: 164it [01:40,  1.65it/s]Extractor Predicting: 165it [01:40,  1.63it/s]Extractor Predicting: 166it [01:41,  1.61it/s]Extractor Predicting: 167it [01:42,  1.64it/s]Extractor Predicting: 168it [01:42,  1.63it/s]Extractor Predicting: 169it [01:43,  1.62it/s]Extractor Predicting: 170it [01:43,  1.66it/s]Extractor Predicting: 171it [01:44,  1.69it/s]Extractor Predicting: 172it [01:45,  1.67it/s]Extractor Predicting: 173it [01:45,  1.71it/s]Extractor Predicting: 174it [01:46,  1.70it/s]Extractor Predicting: 175it [01:47,  1.62it/s]Extractor Predicting: 176it [01:47,  1.62it/s]Extractor Predicting: 177it [01:48,  1.60it/s]Extractor Predicting: 178it [01:48,  1.68it/s]Extractor Predicting: 179it [01:49,  1.80it/s]Extractor Predicting: 180it [01:50,  1.64it/s]Extractor Predicting: 181it [01:50,  1.66it/s]Extractor Predicting: 182it [01:51,  1.71it/s]Extractor Predicting: 183it [01:51,  1.64it/s]Extractor Predicting: 184it [01:52,  1.59it/s]Extractor Predicting: 185it [01:53,  1.62it/s]Extractor Predicting: 186it [01:53,  1.62it/s]Extractor Predicting: 187it [01:54,  1.62it/s]Extractor Predicting: 188it [01:54,  1.57it/s]Extractor Predicting: 189it [01:55,  1.59it/s]Extractor Predicting: 190it [01:56,  1.57it/s]Extractor Predicting: 191it [01:56,  1.56it/s]Extractor Predicting: 192it [01:57,  1.59it/s]Extractor Predicting: 193it [01:58,  1.62it/s]Extractor Predicting: 194it [01:58,  1.65it/s]Extractor Predicting: 195it [01:59,  1.68it/s]Extractor Predicting: 196it [01:59,  1.66it/s]Extractor Predicting: 197it [02:00,  1.65it/s]Extractor Predicting: 198it [02:01,  1.61it/s]Extractor Predicting: 199it [02:01,  1.59it/s]Extractor Predicting: 200it [02:02,  1.62it/s]Extractor Predicting: 201it [02:02,  1.63it/s]Extractor Predicting: 202it [02:03,  1.62it/s]Extractor Predicting: 203it [02:04,  1.63it/s]Extractor Predicting: 204it [02:04,  1.64it/s]Extractor Predicting: 205it [02:05,  1.66it/s]Extractor Predicting: 206it [02:05,  1.66it/s]Extractor Predicting: 207it [02:06,  1.66it/s]Extractor Predicting: 208it [02:07,  1.67it/s]Extractor Predicting: 209it [02:07,  1.67it/s]Extractor Predicting: 210it [02:08,  1.66it/s]Extractor Predicting: 211it [02:09,  1.64it/s]Extractor Predicting: 212it [02:09,  1.61it/s]Extractor Predicting: 213it [02:10,  1.60it/s]Extractor Predicting: 214it [02:10,  1.60it/s]Extractor Predicting: 215it [02:11,  1.60it/s]Extractor Predicting: 216it [02:12,  1.59it/s]Extractor Predicting: 217it [02:12,  1.66it/s]Extractor Predicting: 218it [02:13,  1.68it/s]Extractor Predicting: 219it [02:13,  1.67it/s]Extractor Predicting: 220it [02:14,  1.68it/s]Extractor Predicting: 221it [02:15,  1.66it/s]Extractor Predicting: 222it [02:15,  1.67it/s]Extractor Predicting: 223it [02:16,  1.64it/s]Extractor Predicting: 224it [02:16,  1.60it/s]Extractor Predicting: 225it [02:17,  1.61it/s]Extractor Predicting: 226it [02:18,  1.61it/s]Extractor Predicting: 227it [02:18,  1.63it/s]Extractor Predicting: 228it [02:19,  1.60it/s]Extractor Predicting: 229it [02:20,  1.61it/s]Extractor Predicting: 230it [02:20,  1.59it/s]Extractor Predicting: 231it [02:21,  1.55it/s]Extractor Predicting: 232it [02:21,  1.60it/s]Extractor Predicting: 233it [02:22,  1.58it/s]Extractor Predicting: 234it [02:23,  1.57it/s]Extractor Predicting: 235it [02:23,  1.60it/s]Extractor Predicting: 236it [02:24,  1.60it/s]Extractor Predicting: 237it [02:25,  1.61it/s]Extractor Predicting: 238it [02:25,  1.57it/s]Extractor Predicting: 239it [02:26,  1.60it/s]Extractor Predicting: 240it [02:27,  1.61it/s]Extractor Predicting: 241it [02:27,  1.63it/s]Extractor Predicting: 242it [02:28,  1.62it/s]Extractor Predicting: 243it [02:28,  1.62it/s]Extractor Predicting: 244it [02:29,  1.63it/s]Extractor Predicting: 245it [02:30,  1.59it/s]Extractor Predicting: 246it [02:30,  1.62it/s]Extractor Predicting: 247it [02:31,  1.65it/s]Extractor Predicting: 248it [02:31,  1.59it/s]Extractor Predicting: 249it [02:32,  1.59it/s]Extractor Predicting: 250it [02:33,  1.66it/s]Extractor Predicting: 251it [02:33,  1.68it/s]Extractor Predicting: 252it [02:34,  1.72it/s]Extractor Predicting: 253it [02:34,  1.71it/s]Extractor Predicting: 254it [02:35,  1.69it/s]Extractor Predicting: 255it [02:36,  1.67it/s]Extractor Predicting: 256it [02:36,  1.66it/s]Extractor Predicting: 257it [02:37,  1.66it/s]Extractor Predicting: 258it [02:37,  1.67it/s]Extractor Predicting: 259it [02:38,  1.65it/s]Extractor Predicting: 260it [02:39,  1.67it/s]Extractor Predicting: 261it [02:39,  1.70it/s]Extractor Predicting: 262it [02:40,  1.75it/s]Extractor Predicting: 263it [02:40,  1.74it/s]Extractor Predicting: 264it [02:41,  1.76it/s]Extractor Predicting: 265it [02:41,  1.71it/s]Extractor Predicting: 266it [02:42,  1.71it/s]Extractor Predicting: 267it [02:43,  1.71it/s]Extractor Predicting: 268it [02:43,  1.68it/s]Extractor Predicting: 269it [02:44,  1.71it/s]Extractor Predicting: 270it [02:44,  1.69it/s]Extractor Predicting: 271it [02:45,  1.68it/s]Extractor Predicting: 272it [02:46,  1.70it/s]Extractor Predicting: 273it [02:46,  1.68it/s]Extractor Predicting: 274it [02:47,  1.69it/s]Extractor Predicting: 275it [02:47,  1.68it/s]Extractor Predicting: 276it [02:48,  1.70it/s]Extractor Predicting: 277it [02:49,  1.67it/s]Extractor Predicting: 278it [02:49,  1.67it/s]Extractor Predicting: 279it [02:50,  1.66it/s]Extractor Predicting: 280it [02:50,  1.65it/s]Extractor Predicting: 281it [02:51,  1.64it/s]Extractor Predicting: 282it [02:52,  1.59it/s]Extractor Predicting: 283it [02:52,  1.61it/s]Extractor Predicting: 284it [02:53,  1.67it/s]Extractor Predicting: 285it [02:53,  1.66it/s]Extractor Predicting: 286it [02:54,  1.64it/s]Extractor Predicting: 287it [02:55,  1.62it/s]Extractor Predicting: 288it [02:55,  1.64it/s]Extractor Predicting: 289it [02:56,  1.54it/s]Extractor Predicting: 290it [02:57,  1.57it/s]Extractor Predicting: 291it [02:57,  1.60it/s]Extractor Predicting: 292it [02:58,  1.59it/s]Extractor Predicting: 293it [02:59,  1.60it/s]Extractor Predicting: 294it [02:59,  1.59it/s]Extractor Predicting: 295it [03:00,  1.61it/s]Extractor Predicting: 296it [03:00,  1.62it/s]Extractor Predicting: 297it [03:01,  1.61it/s]Extractor Predicting: 298it [03:02,  1.65it/s]Extractor Predicting: 299it [03:02,  1.60it/s]Extractor Predicting: 300it [03:03,  1.59it/s]Extractor Predicting: 301it [03:03,  1.59it/s]Extractor Predicting: 302it [03:04,  1.61it/s]Extractor Predicting: 303it [03:05,  1.64it/s]Extractor Predicting: 304it [03:05,  1.63it/s]Extractor Predicting: 305it [03:06,  1.66it/s]Extractor Predicting: 306it [03:07,  1.63it/s]Extractor Predicting: 307it [03:07,  1.66it/s]Extractor Predicting: 308it [03:08,  1.67it/s]Extractor Predicting: 309it [03:08,  1.63it/s]Extractor Predicting: 310it [03:09,  1.57it/s]Extractor Predicting: 311it [03:10,  1.52it/s]Extractor Predicting: 312it [03:10,  1.50it/s]Extractor Predicting: 313it [03:11,  1.48it/s]Extractor Predicting: 314it [03:12,  1.44it/s]Extractor Predicting: 315it [03:13,  1.29it/s]Extractor Predicting: 316it [03:13,  1.33it/s]Extractor Predicting: 317it [03:14,  1.37it/s]Extractor Predicting: 318it [03:15,  1.36it/s]Extractor Predicting: 319it [03:16,  1.38it/s]Extractor Predicting: 320it [03:16,  1.40it/s]Extractor Predicting: 321it [03:17,  1.40it/s]Extractor Predicting: 322it [03:18,  1.41it/s]Extractor Predicting: 323it [03:19,  1.19it/s]Extractor Predicting: 324it [03:20,  1.26it/s]Extractor Predicting: 325it [03:20,  1.30it/s]Extractor Predicting: 326it [03:21,  1.35it/s]Extractor Predicting: 327it [03:22,  1.42it/s]Extractor Predicting: 328it [03:22,  1.45it/s]Extractor Predicting: 329it [03:23,  1.51it/s]Extractor Predicting: 330it [03:23,  1.57it/s]Extractor Predicting: 331it [03:24,  1.60it/s]Extractor Predicting: 332it [03:25,  1.63it/s]Extractor Predicting: 333it [03:25,  1.63it/s]Extractor Predicting: 334it [03:26,  1.61it/s]Extractor Predicting: 335it [03:26,  1.60it/s]Extractor Predicting: 336it [03:27,  1.56it/s]Extractor Predicting: 337it [03:28,  1.61it/s]Extractor Predicting: 338it [03:28,  1.63it/s]Extractor Predicting: 339it [03:29,  1.62it/s]Extractor Predicting: 340it [03:30,  1.58it/s]Extractor Predicting: 341it [03:30,  1.55it/s]Extractor Predicting: 342it [03:31,  1.56it/s]Extractor Predicting: 343it [03:32,  1.56it/s]Extractor Predicting: 344it [03:32,  1.54it/s]Extractor Predicting: 345it [03:33,  1.49it/s]Extractor Predicting: 346it [03:34,  1.49it/s]Extractor Predicting: 347it [03:34,  1.50it/s]Extractor Predicting: 348it [03:35,  1.52it/s]Extractor Predicting: 349it [03:36,  1.54it/s]Extractor Predicting: 350it [03:36,  1.50it/s]Extractor Predicting: 351it [03:37,  1.52it/s]Extractor Predicting: 352it [03:38,  1.54it/s]Extractor Predicting: 353it [03:38,  1.53it/s]Extractor Predicting: 354it [03:39,  1.54it/s]Extractor Predicting: 355it [03:39,  1.51it/s]Extractor Predicting: 356it [03:40,  1.54it/s]Extractor Predicting: 357it [03:41,  1.56it/s]Extractor Predicting: 358it [03:41,  1.56it/s]Extractor Predicting: 359it [03:42,  1.54it/s]Extractor Predicting: 360it [03:43,  1.54it/s]Extractor Predicting: 361it [03:43,  1.60it/s]Extractor Predicting: 362it [03:44,  1.60it/s]Extractor Predicting: 363it [03:45,  1.60it/s]Extractor Predicting: 364it [03:45,  1.59it/s]Extractor Predicting: 365it [03:46,  1.61it/s]Extractor Predicting: 366it [03:46,  1.59it/s]Extractor Predicting: 367it [03:47,  1.59it/s]Extractor Predicting: 368it [03:48,  1.59it/s]Extractor Predicting: 369it [03:48,  1.59it/s]Extractor Predicting: 370it [03:49,  1.58it/s]Extractor Predicting: 371it [03:50,  1.57it/s]Extractor Predicting: 372it [03:50,  1.57it/s]Extractor Predicting: 373it [03:51,  1.56it/s]Extractor Predicting: 374it [03:51,  1.59it/s]Extractor Predicting: 375it [03:52,  1.54it/s]Extractor Predicting: 376it [03:53,  1.59it/s]Extractor Predicting: 377it [03:53,  1.60it/s]Extractor Predicting: 378it [03:54,  1.57it/s]Extractor Predicting: 379it [03:55,  1.55it/s]Extractor Predicting: 380it [03:55,  1.56it/s]Extractor Predicting: 381it [03:56,  1.58it/s]Extractor Predicting: 382it [03:57,  1.58it/s]Extractor Predicting: 383it [03:57,  1.57it/s]Extractor Predicting: 384it [03:58,  1.58it/s]Extractor Predicting: 385it [03:58,  1.61it/s]Extractor Predicting: 386it [03:59,  1.62it/s]Extractor Predicting: 387it [04:00,  1.61it/s]Extractor Predicting: 388it [04:00,  1.55it/s]Extractor Predicting: 389it [04:01,  1.60it/s]Extractor Predicting: 390it [04:02,  1.62it/s]Extractor Predicting: 391it [04:02,  1.63it/s]Extractor Predicting: 392it [04:03,  1.66it/s]Extractor Predicting: 393it [04:03,  1.61it/s]Extractor Predicting: 394it [04:04,  1.62it/s]Extractor Predicting: 395it [04:05,  1.64it/s]Extractor Predicting: 396it [04:05,  1.62it/s]Extractor Predicting: 397it [04:06,  1.63it/s]Extractor Predicting: 398it [04:06,  1.65it/s]Extractor Predicting: 399it [04:07,  1.66it/s]Extractor Predicting: 400it [04:08,  1.62it/s]Extractor Predicting: 401it [04:08,  1.59it/s]Extractor Predicting: 402it [04:09,  1.56it/s]Extractor Predicting: 403it [04:10,  1.56it/s]Extractor Predicting: 404it [04:10,  1.59it/s]Extractor Predicting: 405it [04:11,  1.60it/s]Extractor Predicting: 406it [04:11,  1.60it/s]Extractor Predicting: 407it [04:12,  1.63it/s]Extractor Predicting: 408it [04:13,  1.64it/s]Extractor Predicting: 409it [04:13,  1.69it/s]Extractor Predicting: 410it [04:14,  1.71it/s]Extractor Predicting: 411it [04:14,  1.72it/s]Extractor Predicting: 412it [04:15,  1.74it/s]Extractor Predicting: 413it [04:15,  1.78it/s]Extractor Predicting: 414it [04:16,  1.76it/s]Extractor Predicting: 415it [04:17,  1.67it/s]Extractor Predicting: 416it [04:17,  1.60it/s]Extractor Predicting: 417it [04:18,  1.54it/s]Extractor Predicting: 418it [04:19,  1.51it/s]Extractor Predicting: 419it [04:19,  1.48it/s]Extractor Predicting: 420it [04:20,  1.49it/s]Extractor Predicting: 421it [04:21,  1.48it/s]Extractor Predicting: 422it [04:21,  1.70it/s]Extractor Predicting: 422it [04:21,  1.61it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:27,132 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:27,192 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:27,193 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:27,193 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:27,193 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 12:57:28,335 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 12:57:28,336 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 12:57:28,958 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 12:57:30,117 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 12:57:30,117 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:33,163 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:33,200 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:33,200 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:33,200 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:57:33,201 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 12:57:34,007 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 12:57:34,008 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 12:57:34,671 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 12:57:34,900 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 12:57:34,900 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_out_filter_all_single_is_eval_True.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_in_all_single_is_eval_True.jsonl",
  "precision": 0.22622555585320117,
  "recall": 0.12006824482832161,
  "score": 0.15687549342869087,
  "mode": "all_single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/results_all_single_is_eval_True.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_in_single_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_out_filter_single_is_eval_False.jsonl'}}
predict vocab size: 13679
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 13779, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.62it/s]Extractor Predicting: 2it [00:01,  1.58it/s]Extractor Predicting: 3it [00:01,  1.59it/s]Extractor Predicting: 4it [00:02,  1.60it/s]Extractor Predicting: 5it [00:03,  1.60it/s]Extractor Predicting: 6it [00:03,  1.63it/s]Extractor Predicting: 7it [00:04,  1.64it/s]Extractor Predicting: 8it [00:04,  1.63it/s]Extractor Predicting: 9it [00:05,  1.61it/s]Extractor Predicting: 10it [00:06,  1.62it/s]Extractor Predicting: 11it [00:06,  1.58it/s]Extractor Predicting: 12it [00:07,  1.59it/s]Extractor Predicting: 13it [00:08,  1.61it/s]Extractor Predicting: 14it [00:08,  1.60it/s]Extractor Predicting: 15it [00:09,  1.61it/s]Extractor Predicting: 16it [00:09,  1.62it/s]Extractor Predicting: 17it [00:10,  1.63it/s]Extractor Predicting: 18it [00:11,  1.62it/s]Extractor Predicting: 19it [00:11,  1.61it/s]Extractor Predicting: 20it [00:12,  1.63it/s]Extractor Predicting: 21it [00:12,  1.63it/s]Extractor Predicting: 22it [00:13,  1.63it/s]Extractor Predicting: 23it [00:14,  1.61it/s]Extractor Predicting: 24it [00:14,  1.61it/s]Extractor Predicting: 25it [00:15,  1.63it/s]Extractor Predicting: 26it [00:16,  1.62it/s]Extractor Predicting: 27it [00:16,  1.65it/s]Extractor Predicting: 28it [00:17,  1.62it/s]Extractor Predicting: 29it [00:17,  1.61it/s]Extractor Predicting: 30it [00:18,  1.63it/s]Extractor Predicting: 31it [00:19,  1.60it/s]Extractor Predicting: 32it [00:19,  1.61it/s]Extractor Predicting: 33it [00:20,  1.62it/s]Extractor Predicting: 34it [00:21,  1.60it/s]Extractor Predicting: 35it [00:21,  1.60it/s]Extractor Predicting: 36it [00:22,  1.60it/s]Extractor Predicting: 37it [00:22,  1.60it/s]Extractor Predicting: 38it [00:23,  1.62it/s]Extractor Predicting: 39it [00:24,  1.58it/s]Extractor Predicting: 40it [00:24,  1.59it/s]Extractor Predicting: 41it [00:25,  1.59it/s]Extractor Predicting: 42it [00:26,  1.62it/s]Extractor Predicting: 43it [00:26,  1.56it/s]Extractor Predicting: 44it [00:27,  1.53it/s]Extractor Predicting: 45it [00:28,  1.54it/s]Extractor Predicting: 46it [00:28,  1.51it/s]Extractor Predicting: 47it [00:29,  1.53it/s]Extractor Predicting: 48it [00:30,  1.55it/s]Extractor Predicting: 49it [00:30,  1.52it/s]Extractor Predicting: 50it [00:31,  1.54it/s]Extractor Predicting: 51it [00:31,  1.54it/s]Extractor Predicting: 52it [00:32,  1.54it/s]Extractor Predicting: 53it [00:33,  1.56it/s]Extractor Predicting: 54it [00:33,  1.50it/s]Extractor Predicting: 55it [00:34,  1.51it/s]Extractor Predicting: 56it [00:35,  1.52it/s]Extractor Predicting: 57it [00:35,  1.53it/s]Extractor Predicting: 58it [00:36,  1.53it/s]Extractor Predicting: 59it [00:37,  1.52it/s]Extractor Predicting: 60it [00:37,  1.57it/s]Extractor Predicting: 61it [00:38,  1.57it/s]Extractor Predicting: 62it [00:39,  1.58it/s]Extractor Predicting: 63it [00:39,  1.58it/s]Extractor Predicting: 64it [00:40,  1.61it/s]Extractor Predicting: 65it [00:40,  1.65it/s]Extractor Predicting: 66it [00:41,  1.65it/s]Extractor Predicting: 67it [00:42,  1.63it/s]Extractor Predicting: 68it [00:42,  1.62it/s]Extractor Predicting: 69it [00:43,  1.64it/s]Extractor Predicting: 70it [00:43,  1.63it/s]Extractor Predicting: 71it [00:44,  1.61it/s]Extractor Predicting: 72it [00:45,  1.62it/s]Extractor Predicting: 73it [00:45,  1.61it/s]Extractor Predicting: 74it [00:46,  1.61it/s]Extractor Predicting: 75it [00:47,  1.62it/s]Extractor Predicting: 76it [00:47,  1.61it/s]Extractor Predicting: 77it [00:48,  1.65it/s]Extractor Predicting: 78it [00:48,  1.65it/s]Extractor Predicting: 79it [00:49,  1.64it/s]Extractor Predicting: 80it [00:50,  1.65it/s]Extractor Predicting: 81it [00:50,  1.68it/s]Extractor Predicting: 82it [00:51,  1.65it/s]Extractor Predicting: 83it [00:51,  1.59it/s]Extractor Predicting: 84it [00:52,  1.60it/s]Extractor Predicting: 85it [00:53,  1.60it/s]Extractor Predicting: 86it [00:53,  1.62it/s]Extractor Predicting: 87it [00:54,  1.65it/s]Extractor Predicting: 88it [00:55,  1.57it/s]Extractor Predicting: 89it [00:55,  1.56it/s]Extractor Predicting: 90it [00:56,  1.58it/s]Extractor Predicting: 91it [00:56,  1.62it/s]Extractor Predicting: 92it [00:57,  1.66it/s]Extractor Predicting: 93it [00:58,  1.64it/s]Extractor Predicting: 94it [00:58,  1.67it/s]Extractor Predicting: 95it [00:59,  1.67it/s]Extractor Predicting: 96it [00:59,  1.66it/s]Extractor Predicting: 97it [01:00,  1.69it/s]Extractor Predicting: 98it [01:01,  1.69it/s]Extractor Predicting: 99it [01:01,  1.68it/s]Extractor Predicting: 100it [01:02,  1.65it/s]Extractor Predicting: 101it [01:02,  1.61it/s]Extractor Predicting: 102it [01:03,  1.61it/s]Extractor Predicting: 103it [01:04,  1.62it/s]Extractor Predicting: 104it [01:04,  1.63it/s]Extractor Predicting: 105it [01:05,  1.62it/s]Extractor Predicting: 106it [01:06,  1.61it/s]Extractor Predicting: 107it [01:06,  1.64it/s]Extractor Predicting: 108it [01:07,  1.67it/s]Extractor Predicting: 109it [01:07,  1.62it/s]Extractor Predicting: 110it [01:08,  1.66it/s]Extractor Predicting: 111it [01:09,  1.67it/s]Extractor Predicting: 112it [01:09,  1.64it/s]Extractor Predicting: 113it [01:10,  1.50it/s]Extractor Predicting: 114it [01:11,  1.52it/s]Extractor Predicting: 115it [01:11,  1.55it/s]Extractor Predicting: 116it [01:12,  1.58it/s]Extractor Predicting: 117it [01:12,  1.65it/s]Extractor Predicting: 118it [01:13,  1.64it/s]Extractor Predicting: 119it [01:14,  1.66it/s]Extractor Predicting: 120it [01:14,  1.70it/s]Extractor Predicting: 121it [01:15,  1.70it/s]Extractor Predicting: 122it [01:15,  1.68it/s]Extractor Predicting: 123it [01:16,  1.64it/s]Extractor Predicting: 124it [01:17,  1.63it/s]Extractor Predicting: 125it [01:17,  1.60it/s]Extractor Predicting: 126it [01:18,  1.61it/s]Extractor Predicting: 127it [01:18,  1.64it/s]Extractor Predicting: 128it [01:19,  1.64it/s]Extractor Predicting: 129it [01:20,  1.65it/s]Extractor Predicting: 130it [01:20,  1.64it/s]Extractor Predicting: 131it [01:21,  1.62it/s]Extractor Predicting: 132it [01:22,  1.63it/s]Extractor Predicting: 133it [01:22,  1.61it/s]Extractor Predicting: 134it [01:23,  1.62it/s]Extractor Predicting: 135it [01:23,  1.64it/s]Extractor Predicting: 136it [01:24,  1.69it/s]Extractor Predicting: 137it [01:24,  1.70it/s]Extractor Predicting: 138it [01:25,  1.67it/s]Extractor Predicting: 139it [01:26,  1.63it/s]Extractor Predicting: 140it [01:26,  1.67it/s]Extractor Predicting: 141it [01:27,  1.69it/s]Extractor Predicting: 142it [01:27,  1.70it/s]Extractor Predicting: 143it [01:28,  1.74it/s]Extractor Predicting: 144it [01:29,  1.70it/s]Extractor Predicting: 145it [01:29,  1.69it/s]Extractor Predicting: 146it [01:30,  1.69it/s]Extractor Predicting: 147it [01:30,  1.69it/s]Extractor Predicting: 148it [01:31,  1.68it/s]Extractor Predicting: 149it [01:32,  1.69it/s]Extractor Predicting: 150it [01:32,  1.69it/s]Extractor Predicting: 151it [01:33,  1.66it/s]Extractor Predicting: 152it [01:33,  1.70it/s]Extractor Predicting: 153it [01:34,  1.69it/s]Extractor Predicting: 154it [01:35,  1.68it/s]Extractor Predicting: 155it [01:35,  1.68it/s]Extractor Predicting: 156it [01:36,  1.68it/s]Extractor Predicting: 157it [01:36,  1.65it/s]Extractor Predicting: 158it [01:37,  1.67it/s]Extractor Predicting: 159it [01:38,  1.71it/s]Extractor Predicting: 160it [01:38,  1.74it/s]Extractor Predicting: 161it [01:39,  1.67it/s]Extractor Predicting: 162it [01:39,  1.64it/s]Extractor Predicting: 163it [01:40,  1.62it/s]Extractor Predicting: 164it [01:41,  1.67it/s]Extractor Predicting: 165it [01:41,  1.68it/s]Extractor Predicting: 166it [01:42,  1.60it/s]Extractor Predicting: 167it [01:42,  1.58it/s]Extractor Predicting: 168it [01:43,  1.57it/s]Extractor Predicting: 169it [01:44,  1.59it/s]Extractor Predicting: 170it [01:44,  1.54it/s]Extractor Predicting: 170it [01:44,  1.62it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:29,002 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:29,028 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:29,029 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:29,029 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:29,029 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 12:59:29,644 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 12:59:29,645 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 12:59:30,367 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 12:59:31,511 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 12:59:31,511 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:33,468 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:33,513 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:33,513 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:33,513 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 12:59:33,514 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 12:59:34,052 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 12:59:34,053 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 12:59:34,431 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 12:59:34,679 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 12:59:34,679 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_out_filter_single_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_in_single_is_eval_False.jsonl",
  "precision": 0.3225806451612903,
  "recall": 0.13987730061349693,
  "score": 0.1951386511468675,
  "mode": "single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/results_single_is_eval_False.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_in_multi_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_out_filter_multi_is_eval_False.jsonl'}}
predict vocab size: 3869
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 3969, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.57it/s]Extractor Predicting: 2it [00:01,  1.57it/s]Extractor Predicting: 3it [00:01,  1.57it/s]Extractor Predicting: 4it [00:02,  1.55it/s]Extractor Predicting: 5it [00:03,  1.57it/s]Extractor Predicting: 6it [00:03,  1.50it/s]Extractor Predicting: 7it [00:04,  1.50it/s]Extractor Predicting: 8it [00:05,  1.53it/s]Extractor Predicting: 9it [00:05,  1.57it/s]Extractor Predicting: 10it [00:06,  1.56it/s]Extractor Predicting: 11it [00:07,  1.50it/s]Extractor Predicting: 12it [00:07,  1.58it/s]Extractor Predicting: 13it [00:08,  1.59it/s]Extractor Predicting: 14it [00:08,  1.60it/s]Extractor Predicting: 15it [00:09,  1.60it/s]Extractor Predicting: 16it [00:10,  1.54it/s]Extractor Predicting: 17it [00:10,  1.54it/s]Extractor Predicting: 18it [00:11,  1.55it/s]Extractor Predicting: 19it [00:12,  1.47it/s]Extractor Predicting: 20it [00:13,  1.46it/s]Extractor Predicting: 21it [00:13,  1.44it/s]Extractor Predicting: 22it [00:14,  1.50it/s]Extractor Predicting: 23it [00:15,  1.42it/s]Extractor Predicting: 24it [00:15,  1.46it/s]Extractor Predicting: 25it [00:16,  1.53it/s]Extractor Predicting: 26it [00:16,  1.56it/s]Extractor Predicting: 27it [00:17,  1.55it/s]Extractor Predicting: 28it [00:18,  1.50it/s]Extractor Predicting: 29it [00:18,  1.52it/s]Extractor Predicting: 30it [00:19,  1.55it/s]Extractor Predicting: 31it [00:20,  1.57it/s]Extractor Predicting: 32it [00:20,  1.58it/s]Extractor Predicting: 33it [00:21,  1.47it/s]Extractor Predicting: 33it [00:21,  1.53it/s]
[INFO|configuration_utils.py:515] 2023-08-29 13:00:00,089 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 13:00:00,090 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 13:00:00,249 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 13:00:00,250 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|modeling_utils.py:1150] 2023-08-29 13:00:00,325 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 13:00:19,881 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.

[INFO|modeling_utils.py:1345] 2023-08-29 13:00:19,946 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.
[INFO|configuration_utils.py:515] 2023-08-29 13:00:20,280 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 13:00:20,281 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter2/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 13:00:20,713 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 13:00:20,836 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 13:00:20,836 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 13:00:20,836 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 13:00:20,836 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 13:00:20,836 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 13:00:20,836 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model/tokenizer_config.json
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_out_filter_multi_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/pred_in_multi_is_eval_False.jsonl",
  "precision": 0.5136612021857924,
  "recall": 0.049973418394471024,
  "score": 0.09108527131782947,
  "mode": "multi",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/results_multi_is_eval_False.json"
}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
Generating:   0%|          | 0/10 [00:00<?, ?it/s][WARNING|generation_utils.py:914] 2023-08-29 13:00:21,295 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:21,846 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:22,389 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:22,925 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:23,448 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:23,888 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:24,461 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:25,522 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:26,061 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:26,578 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:27,093 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:27,578 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:28,127 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:28,651 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:29,234 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:29,827 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:30,328 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:30,903 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:31,402 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:31,995 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:32,546 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  10%|█         | 1/10 [00:11<01:46, 11.79s/it][WARNING|generation_utils.py:914] 2023-08-29 13:00:33,081 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:33,567 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:34,101 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:34,585 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:35,085 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:35,708 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:36,276 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:36,848 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:37,377 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:37,969 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:38,497 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:39,054 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:39,671 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:40,219 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:40,717 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:41,199 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:41,724 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:42,298 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:42,824 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:43,324 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  20%|██        | 2/10 [00:22<01:29, 11.21s/it][WARNING|generation_utils.py:914] 2023-08-29 13:00:43,888 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:44,332 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:44,754 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:45,377 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:45,811 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:46,296 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:46,770 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:47,289 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:47,738 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:48,151 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:48,646 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:49,070 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:49,586 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:50,041 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:50,408 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:50,825 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:51,265 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:51,812 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:52,353 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:52,788 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  30%|███       | 3/10 [00:32<01:12, 10.40s/it][WARNING|generation_utils.py:914] 2023-08-29 13:00:53,326 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:53,902 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:54,444 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:54,993 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:55,577 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:56,146 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:56,656 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:57,183 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:57,749 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:58,250 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:58,862 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:00:59,957 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:00,468 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:01,037 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:01,558 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:02,084 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:02,632 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:03,167 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:03,718 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:04,286 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  40%|████      | 4/10 [00:43<01:05, 10.84s/it][WARNING|generation_utils.py:914] 2023-08-29 13:01:04,831 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:05,368 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:05,926 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:06,409 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:06,925 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:07,436 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:08,013 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:08,574 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:09,136 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:09,618 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:10,228 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:10,755 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:11,314 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:11,788 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:12,346 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:12,852 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:13,387 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:13,879 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:14,369 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:14,886 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:15,456 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  50%|█████     | 5/10 [00:54<00:54, 10.97s/it][WARNING|generation_utils.py:914] 2023-08-29 13:01:16,024 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:16,549 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:16,999 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:17,577 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:18,043 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:18,544 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:19,009 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:19,578 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:20,068 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:20,545 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:20,994 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:21,460 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:21,920 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:22,437 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:22,905 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:23,377 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:23,878 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:24,446 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:24,948 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:25,449 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:25,957 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  60%|██████    | 6/10 [01:05<00:43, 10.77s/it][WARNING|generation_utils.py:914] 2023-08-29 13:01:26,446 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:26,962 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:27,486 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:28,036 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:28,563 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:29,125 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:29,652 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:30,166 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:30,641 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:31,125 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:31,608 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:32,220 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:32,764 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:33,239 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:33,741 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:34,301 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:34,785 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:35,269 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:35,829 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:36,395 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  70%|███████   | 7/10 [01:15<00:32, 10.68s/it][WARNING|generation_utils.py:914] 2023-08-29 13:01:36,923 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:37,441 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:37,980 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:38,556 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:39,098 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:39,659 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:40,233 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:40,752 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:41,356 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:41,975 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:42,560 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:43,066 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:43,661 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:44,229 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:44,856 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:45,451 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:45,993 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:46,568 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:47,157 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:47,690 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  80%|████████  | 8/10 [01:26<00:21, 10.88s/it][WARNING|generation_utils.py:914] 2023-08-29 13:01:48,234 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:48,760 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:49,236 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:49,814 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:50,383 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:50,966 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:51,510 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:52,052 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:52,587 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:53,177 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:53,797 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:54,336 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:54,859 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:55,402 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:55,947 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:56,516 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:57,153 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:57,799 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:58,342 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:58,885 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  90%|█████████ | 9/10 [01:38<00:10, 10.98s/it][WARNING|generation_utils.py:914] 2023-08-29 13:01:59,438 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:01:59,944 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:00,521 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:01,070 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:01,639 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:02,166 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:02,709 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:03,243 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:03,767 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:04,309 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:04,861 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:05,490 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:06,074 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:06,574 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:07,109 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:07,618 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:08,160 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:08,687 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:09,238 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 13:02:09,780 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating: 100%|██████████| 10/10 [01:49<00:00, 10.98s/it]Generating: 100%|██████████| 10/10 [01:49<00:00, 10.91s/it]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:15,876 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:15,906 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:15,906 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:15,906 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:15,906 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 13:02:16,553 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 13:02:16,554 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 13:02:16,964 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 13:02:18,044 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 13:02:18,044 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:19,931 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:19,959 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:19,959 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:19,959 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:02:19,959 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 13:02:20,310 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 13:02:20,311 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 13:02:20,584 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 13:02:20,739 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 13:02:20,739 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 59, 'raw': 64}
{'target': 600, 'success': 86, 'raw': 96}
{'target': 600, 'success': 115, 'raw': 128}
{'target': 600, 'success': 143, 'raw': 160}
{'target': 600, 'success': 171, 'raw': 192}
{'target': 600, 'success': 198, 'raw': 224}
{'target': 600, 'success': 226, 'raw': 256}
{'target': 600, 'success': 255, 'raw': 288}
{'target': 600, 'success': 285, 'raw': 320}
{'target': 600, 'success': 314, 'raw': 352}
{'target': 600, 'success': 343, 'raw': 384}
{'target': 600, 'success': 372, 'raw': 416}
{'target': 600, 'success': 400, 'raw': 448}
{'target': 600, 'success': 429, 'raw': 480}
{'target': 600, 'success': 461, 'raw': 512}
{'target': 600, 'success': 487, 'raw': 544}
{'target': 600, 'success': 516, 'raw': 576}
{'target': 600, 'success': 546, 'raw': 608}
{'target': 600, 'success': 573, 'raw': 640}
{'target': 600, 'success': 602, 'raw': 672}
{'prompt': 'Relation : country .', 'success_rate': 0.8958333333333334, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 30, 'raw': 32}
{'target': 600, 'success': 60, 'raw': 64}
{'target': 600, 'success': 91, 'raw': 96}
{'target': 600, 'success': 123, 'raw': 128}
{'target': 600, 'success': 154, 'raw': 160}
{'target': 600, 'success': 184, 'raw': 192}
{'target': 600, 'success': 215, 'raw': 224}
{'target': 600, 'success': 244, 'raw': 256}
{'target': 600, 'success': 275, 'raw': 288}
{'target': 600, 'success': 307, 'raw': 320}
{'target': 600, 'success': 339, 'raw': 352}
{'target': 600, 'success': 370, 'raw': 384}
{'target': 600, 'success': 401, 'raw': 416}
{'target': 600, 'success': 432, 'raw': 448}
{'target': 600, 'success': 463, 'raw': 480}
{'target': 600, 'success': 494, 'raw': 512}
{'target': 600, 'success': 524, 'raw': 544}
{'target': 600, 'success': 556, 'raw': 576}
{'target': 600, 'success': 588, 'raw': 608}
{'target': 600, 'success': 618, 'raw': 640}
{'prompt': 'Relation : part of .', 'success_rate': 0.965625, 'errors': {''}}
{'target': 600, 'success': 31, 'raw': 32}
{'target': 600, 'success': 62, 'raw': 64}
{'target': 600, 'success': 92, 'raw': 96}
{'target': 600, 'success': 123, 'raw': 128}
{'target': 600, 'success': 152, 'raw': 160}
{'target': 600, 'success': 183, 'raw': 192}
{'target': 600, 'success': 214, 'raw': 224}
{'target': 600, 'success': 246, 'raw': 256}
{'target': 600, 'success': 276, 'raw': 288}
{'target': 600, 'success': 305, 'raw': 320}
{'target': 600, 'success': 337, 'raw': 352}
{'target': 600, 'success': 369, 'raw': 384}
{'target': 600, 'success': 399, 'raw': 416}
{'target': 600, 'success': 430, 'raw': 448}
{'target': 600, 'success': 461, 'raw': 480}
{'target': 600, 'success': 491, 'raw': 512}
{'target': 600, 'success': 520, 'raw': 544}
{'target': 600, 'success': 550, 'raw': 576}
{'target': 600, 'success': 581, 'raw': 608}
{'target': 600, 'success': 613, 'raw': 640}
{'prompt': 'Relation : platform .', 'success_rate': 0.9578125, 'errors': {''}}
{'target': 600, 'success': 31, 'raw': 32}
{'target': 600, 'success': 62, 'raw': 64}
{'target': 600, 'success': 91, 'raw': 96}
{'target': 600, 'success': 121, 'raw': 128}
{'target': 600, 'success': 153, 'raw': 160}
{'target': 600, 'success': 185, 'raw': 192}
{'target': 600, 'success': 217, 'raw': 224}
{'target': 600, 'success': 249, 'raw': 256}
{'target': 600, 'success': 279, 'raw': 288}
{'target': 600, 'success': 311, 'raw': 320}
{'target': 600, 'success': 341, 'raw': 352}
{'target': 600, 'success': 373, 'raw': 384}
{'target': 600, 'success': 404, 'raw': 416}
{'target': 600, 'success': 435, 'raw': 448}
{'target': 600, 'success': 467, 'raw': 480}
{'target': 600, 'success': 497, 'raw': 512}
{'target': 600, 'success': 526, 'raw': 544}
{'target': 600, 'success': 557, 'raw': 576}
{'target': 600, 'success': 588, 'raw': 608}
{'target': 600, 'success': 620, 'raw': 640}
{'prompt': 'Relation : publisher .', 'success_rate': 0.96875, 'errors': {''}}
{'target': 600, 'success': 32, 'raw': 32}
{'target': 600, 'success': 63, 'raw': 64}
{'target': 600, 'success': 93, 'raw': 96}
{'target': 600, 'success': 123, 'raw': 128}
{'target': 600, 'success': 153, 'raw': 160}
{'target': 600, 'success': 182, 'raw': 192}
{'target': 600, 'success': 209, 'raw': 224}
{'target': 600, 'success': 239, 'raw': 256}
{'target': 600, 'success': 269, 'raw': 288}
{'target': 600, 'success': 299, 'raw': 320}
{'target': 600, 'success': 329, 'raw': 352}
{'target': 600, 'success': 355, 'raw': 384}
{'target': 600, 'success': 386, 'raw': 416}
{'target': 600, 'success': 412, 'raw': 448}
{'target': 600, 'success': 444, 'raw': 480}
{'target': 600, 'success': 475, 'raw': 512}
{'target': 600, 'success': 506, 'raw': 544}
{'target': 600, 'success': 534, 'raw': 576}
{'target': 600, 'success': 564, 'raw': 608}
{'target': 600, 'success': 595, 'raw': 640}
{'target': 600, 'success': 626, 'raw': 672}
{'prompt': 'Relation : sport .', 'success_rate': 0.9315476190476191, 'errors': {''}}
{'target': 600, 'success': 30, 'raw': 32}
{'target': 600, 'success': 60, 'raw': 64}
{'target': 600, 'success': 87, 'raw': 96}
{'target': 600, 'success': 116, 'raw': 128}
{'target': 600, 'success': 147, 'raw': 160}
{'target': 600, 'success': 175, 'raw': 192}
{'target': 600, 'success': 207, 'raw': 224}
{'target': 600, 'success': 237, 'raw': 256}
{'target': 600, 'success': 263, 'raw': 288}
{'target': 600, 'success': 293, 'raw': 320}
{'target': 600, 'success': 325, 'raw': 352}
{'target': 600, 'success': 354, 'raw': 384}
{'target': 600, 'success': 383, 'raw': 416}
{'target': 600, 'success': 413, 'raw': 448}
{'target': 600, 'success': 443, 'raw': 480}
{'target': 600, 'success': 473, 'raw': 512}
{'target': 600, 'success': 505, 'raw': 544}
{'target': 600, 'success': 535, 'raw': 576}
{'target': 600, 'success': 563, 'raw': 608}
{'target': 600, 'success': 593, 'raw': 640}
{'target': 600, 'success': 624, 'raw': 672}
{'prompt': 'Relation : continent .', 'success_rate': 0.9285714285714286, 'errors': {'', "('Brazil', 'continent', '', 'The first recorded human remains were found from Brazil in 1996 , and were discovered by the Portuguese government on 26 December 1996 .')"}}
{'target': 600, 'success': 31, 'raw': 32}
{'target': 600, 'success': 62, 'raw': 64}
{'target': 600, 'success': 93, 'raw': 96}
{'target': 600, 'success': 123, 'raw': 128}
{'target': 600, 'success': 155, 'raw': 160}
{'target': 600, 'success': 187, 'raw': 192}
{'target': 600, 'success': 217, 'raw': 224}
{'target': 600, 'success': 247, 'raw': 256}
{'target': 600, 'success': 279, 'raw': 288}
{'target': 600, 'success': 311, 'raw': 320}
{'target': 600, 'success': 341, 'raw': 352}
{'target': 600, 'success': 372, 'raw': 384}
{'target': 600, 'success': 401, 'raw': 416}
{'target': 600, 'success': 432, 'raw': 448}
{'target': 600, 'success': 461, 'raw': 480}
{'target': 600, 'success': 493, 'raw': 512}
{'target': 600, 'success': 521, 'raw': 544}
{'target': 600, 'success': 551, 'raw': 576}
{'target': 600, 'success': 583, 'raw': 608}
{'target': 600, 'success': 612, 'raw': 640}
{'prompt': 'Relation : owned by .', 'success_rate': 0.95625, 'errors': {''}}
{'target': 600, 'success': 32, 'raw': 32}
{'target': 600, 'success': 62, 'raw': 64}
{'target': 600, 'success': 93, 'raw': 96}
{'target': 600, 'success': 123, 'raw': 128}
{'target': 600, 'success': 155, 'raw': 160}
{'target': 600, 'success': 185, 'raw': 192}
{'target': 600, 'success': 217, 'raw': 224}
{'target': 600, 'success': 249, 'raw': 256}
{'target': 600, 'success': 278, 'raw': 288}
{'target': 600, 'success': 309, 'raw': 320}
{'target': 600, 'success': 341, 'raw': 352}
{'target': 600, 'success': 373, 'raw': 384}
{'target': 600, 'success': 405, 'raw': 416}
{'target': 600, 'success': 436, 'raw': 448}
{'target': 600, 'success': 468, 'raw': 480}
{'target': 600, 'success': 499, 'raw': 512}
{'target': 600, 'success': 529, 'raw': 544}
{'target': 600, 'success': 559, 'raw': 576}
{'target': 600, 'success': 591, 'raw': 608}
{'target': 600, 'success': 622, 'raw': 640}
{'prompt': 'Relation : performer .', 'success_rate': 0.971875, 'errors': {''}}
{'target': 600, 'success': 32, 'raw': 32}
{'target': 600, 'success': 64, 'raw': 64}
{'target': 600, 'success': 96, 'raw': 96}
{'target': 600, 'success': 128, 'raw': 128}
{'target': 600, 'success': 159, 'raw': 160}
{'target': 600, 'success': 191, 'raw': 192}
{'target': 600, 'success': 222, 'raw': 224}
{'target': 600, 'success': 252, 'raw': 256}
{'target': 600, 'success': 281, 'raw': 288}
{'target': 600, 'success': 312, 'raw': 320}
{'target': 600, 'success': 344, 'raw': 352}
{'target': 600, 'success': 376, 'raw': 384}
{'target': 600, 'success': 406, 'raw': 416}
{'target': 600, 'success': 437, 'raw': 448}
{'target': 600, 'success': 468, 'raw': 480}
{'target': 600, 'success': 499, 'raw': 512}
{'target': 600, 'success': 530, 'raw': 544}
{'target': 600, 'success': 561, 'raw': 576}
{'target': 600, 'success': 592, 'raw': 608}
{'target': 600, 'success': 624, 'raw': 640}
{'prompt': 'Relation : producer .', 'success_rate': 0.975, 'errors': {''}}
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 59, 'raw': 64}
{'target': 600, 'success': 89, 'raw': 96}
{'target': 600, 'success': 121, 'raw': 128}
{'target': 600, 'success': 153, 'raw': 160}
{'target': 600, 'success': 185, 'raw': 192}
{'target': 600, 'success': 215, 'raw': 224}
{'target': 600, 'success': 245, 'raw': 256}
{'target': 600, 'success': 274, 'raw': 288}
{'target': 600, 'success': 306, 'raw': 320}
{'target': 600, 'success': 336, 'raw': 352}
{'target': 600, 'success': 366, 'raw': 384}
{'target': 600, 'success': 396, 'raw': 416}
{'target': 600, 'success': 425, 'raw': 448}
{'target': 600, 'success': 456, 'raw': 480}
{'target': 600, 'success': 484, 'raw': 512}
{'target': 600, 'success': 516, 'raw': 544}
{'target': 600, 'success': 545, 'raw': 576}
{'target': 600, 'success': 577, 'raw': 608}
{'target': 600, 'success': 609, 'raw': 640}
{'prompt': 'Relation : replaces .', 'success_rate': 0.9515625, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/4.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/4_ext.jsonl'}}
estimate vocab size: 5517
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 5617, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/data/estimate.txt
Extractor Estimating: 0it [00:00, ?it/s]Extractor Estimating: 1it [00:00,  1.75it/s]Extractor Estimating: 2it [00:01,  1.62it/s]Extractor Estimating: 3it [00:01,  1.67it/s]Extractor Estimating: 4it [00:02,  1.74it/s]Extractor Estimating: 5it [00:02,  1.74it/s]Extractor Estimating: 6it [00:03,  1.79it/s]Extractor Estimating: 7it [00:04,  1.77it/s]Extractor Estimating: 8it [00:04,  1.74it/s]Extractor Estimating: 9it [00:05,  1.80it/s]Extractor Estimating: 10it [00:05,  1.76it/s]Extractor Estimating: 11it [00:06,  1.80it/s]Extractor Estimating: 12it [00:06,  1.79it/s]Extractor Estimating: 13it [00:07,  1.82it/s]Extractor Estimating: 14it [00:07,  1.72it/s]Extractor Estimating: 15it [00:08,  1.77it/s]Extractor Estimating: 16it [00:09,  1.74it/s]Extractor Estimating: 17it [00:09,  1.74it/s]Extractor Estimating: 18it [00:10,  1.75it/s]Extractor Estimating: 19it [00:10,  1.74it/s]Extractor Estimating: 20it [00:11,  1.81it/s]Extractor Estimating: 21it [00:11,  1.77it/s]Extractor Estimating: 22it [00:12,  1.74it/s]Extractor Estimating: 23it [00:13,  1.67it/s]Extractor Estimating: 24it [00:13,  1.71it/s]Extractor Estimating: 25it [00:14,  1.73it/s]Extractor Estimating: 26it [00:14,  1.75it/s]Extractor Estimating: 27it [00:15,  1.77it/s]Extractor Estimating: 28it [00:16,  1.70it/s]Extractor Estimating: 29it [00:16,  1.72it/s]Extractor Estimating: 30it [00:17,  1.75it/s]Extractor Estimating: 31it [00:17,  1.69it/s]Extractor Estimating: 32it [00:18,  1.67it/s]Extractor Estimating: 33it [00:19,  1.58it/s]Extractor Estimating: 34it [00:19,  1.60it/s]Extractor Estimating: 35it [00:20,  1.62it/s]Extractor Estimating: 36it [00:21,  1.56it/s]Extractor Estimating: 37it [00:21,  1.60it/s]Extractor Estimating: 38it [00:22,  1.63it/s]Extractor Estimating: 39it [00:22,  1.65it/s]Extractor Estimating: 40it [00:23,  1.65it/s]Extractor Estimating: 41it [00:24,  1.63it/s]Extractor Estimating: 42it [00:24,  1.64it/s]Extractor Estimating: 43it [00:25,  1.64it/s]Extractor Estimating: 44it [00:25,  1.69it/s]Extractor Estimating: 45it [00:26,  1.70it/s]Extractor Estimating: 46it [00:27,  1.65it/s]Extractor Estimating: 47it [00:27,  1.63it/s]Extractor Estimating: 48it [00:28,  1.58it/s]Extractor Estimating: 49it [00:28,  1.63it/s]Extractor Estimating: 50it [00:29,  1.66it/s]Extractor Estimating: 51it [00:29,  1.78it/s]Extractor Estimating: 52it [00:30,  1.87it/s]Extractor Estimating: 53it [00:30,  1.94it/s]Extractor Estimating: 54it [00:31,  1.79it/s]Extractor Estimating: 55it [00:31,  1.90it/s]Extractor Estimating: 56it [00:32,  1.90it/s]Extractor Estimating: 57it [00:32,  1.98it/s]Extractor Estimating: 58it [00:33,  1.99it/s]Extractor Estimating: 59it [00:34,  1.92it/s]Extractor Estimating: 60it [00:34,  1.94it/s]Extractor Estimating: 61it [00:35,  2.00it/s]Extractor Estimating: 62it [00:35,  2.05it/s]Extractor Estimating: 63it [00:35,  2.14it/s]Extractor Estimating: 64it [00:36,  2.10it/s]Extractor Estimating: 65it [00:36,  2.03it/s]Extractor Estimating: 66it [00:37,  2.10it/s]Extractor Estimating: 67it [00:37,  2.08it/s]Extractor Estimating: 68it [00:38,  2.09it/s]Extractor Estimating: 69it [00:38,  2.13it/s]Extractor Estimating: 70it [00:39,  2.11it/s]Extractor Estimating: 71it [00:39,  2.03it/s]Extractor Estimating: 72it [00:40,  2.02it/s]Extractor Estimating: 73it [00:40,  1.99it/s]Extractor Estimating: 74it [00:41,  2.01it/s]Extractor Estimating: 75it [00:41,  1.84it/s]Extractor Estimating: 76it [00:42,  1.69it/s]Extractor Estimating: 77it [00:43,  1.66it/s]Extractor Estimating: 78it [00:43,  1.67it/s]Extractor Estimating: 79it [00:44,  1.67it/s]Extractor Estimating: 80it [00:45,  1.60it/s]Extractor Estimating: 81it [00:45,  1.59it/s]Extractor Estimating: 82it [00:46,  1.59it/s]Extractor Estimating: 83it [00:47,  1.59it/s]Extractor Estimating: 84it [00:47,  1.59it/s]Extractor Estimating: 85it [00:48,  1.57it/s]Extractor Estimating: 86it [00:48,  1.63it/s]Extractor Estimating: 87it [00:49,  1.61it/s]Extractor Estimating: 88it [00:50,  1.61it/s]Extractor Estimating: 89it [00:50,  1.63it/s]Extractor Estimating: 90it [00:51,  1.63it/s]Extractor Estimating: 91it [00:51,  1.64it/s]Extractor Estimating: 92it [00:52,  1.60it/s]Extractor Estimating: 93it [00:53,  1.61it/s]Extractor Estimating: 94it [00:53,  1.62it/s]Extractor Estimating: 95it [00:54,  1.67it/s]Extractor Estimating: 96it [00:55,  1.66it/s]Extractor Estimating: 97it [00:55,  1.63it/s]Extractor Estimating: 98it [00:56,  1.60it/s]Extractor Estimating: 99it [00:56,  1.63it/s]Extractor Estimating: 100it [00:57,  1.64it/s]Extractor Estimating: 101it [00:57,  1.72it/s]Extractor Estimating: 102it [00:58,  1.69it/s]Extractor Estimating: 103it [00:59,  1.73it/s]Extractor Estimating: 104it [00:59,  1.79it/s]Extractor Estimating: 105it [01:00,  1.78it/s]Extractor Estimating: 106it [01:00,  1.75it/s]Extractor Estimating: 107it [01:01,  1.70it/s]Extractor Estimating: 108it [01:02,  1.68it/s]Extractor Estimating: 109it [01:02,  1.51it/s]Extractor Estimating: 110it [01:03,  1.63it/s]Extractor Estimating: 111it [01:03,  1.69it/s]Extractor Estimating: 112it [01:04,  1.71it/s]Extractor Estimating: 113it [01:05,  1.73it/s]Extractor Estimating: 114it [01:05,  1.72it/s]Extractor Estimating: 115it [01:06,  1.74it/s]Extractor Estimating: 116it [01:06,  1.73it/s]Extractor Estimating: 117it [01:07,  1.70it/s]Extractor Estimating: 118it [01:08,  1.68it/s]Extractor Estimating: 119it [01:08,  1.70it/s]Extractor Estimating: 120it [01:09,  1.75it/s]Extractor Estimating: 121it [01:09,  1.75it/s]Extractor Estimating: 122it [01:10,  1.75it/s]Extractor Estimating: 123it [01:10,  1.68it/s]Extractor Estimating: 124it [01:11,  1.72it/s]Extractor Estimating: 125it [01:12,  1.75it/s]Extractor Estimating: 126it [01:12,  1.83it/s]Extractor Estimating: 127it [01:12,  1.89it/s]Extractor Estimating: 128it [01:13,  1.87it/s]Extractor Estimating: 129it [01:14,  1.91it/s]Extractor Estimating: 130it [01:14,  1.92it/s]Extractor Estimating: 131it [01:15,  1.96it/s]Extractor Estimating: 132it [01:15,  1.98it/s]Extractor Estimating: 133it [01:16,  1.96it/s]Extractor Estimating: 134it [01:16,  2.00it/s]Extractor Estimating: 135it [01:17,  1.96it/s]Extractor Estimating: 136it [01:17,  1.90it/s]Extractor Estimating: 137it [01:18,  1.97it/s]Extractor Estimating: 138it [01:18,  1.94it/s]Extractor Estimating: 139it [01:19,  2.00it/s]Extractor Estimating: 140it [01:19,  1.98it/s]Extractor Estimating: 141it [01:20,  1.97it/s]Extractor Estimating: 142it [01:20,  1.92it/s]Extractor Estimating: 143it [01:21,  1.90it/s]Extractor Estimating: 144it [01:21,  1.95it/s]Extractor Estimating: 145it [01:22,  1.93it/s]Extractor Estimating: 146it [01:22,  1.93it/s]Extractor Estimating: 147it [01:23,  1.95it/s]Extractor Estimating: 148it [01:23,  1.89it/s]Extractor Estimating: 149it [01:24,  1.91it/s]Extractor Estimating: 150it [01:24,  1.93it/s]Extractor Estimating: 151it [01:25,  1.89it/s]Extractor Estimating: 152it [01:25,  1.82it/s]Extractor Estimating: 153it [01:26,  1.76it/s]Extractor Estimating: 154it [01:27,  1.77it/s]Extractor Estimating: 155it [01:27,  1.76it/s]Extractor Estimating: 156it [01:28,  1.72it/s]Extractor Estimating: 157it [01:28,  1.73it/s]Extractor Estimating: 158it [01:29,  1.79it/s]Extractor Estimating: 159it [01:30,  1.76it/s]Extractor Estimating: 160it [01:30,  1.70it/s]Extractor Estimating: 161it [01:31,  1.74it/s]Extractor Estimating: 162it [01:31,  1.73it/s]Extractor Estimating: 163it [01:32,  1.69it/s]Extractor Estimating: 164it [01:32,  1.73it/s]Extractor Estimating: 165it [01:33,  1.70it/s]Extractor Estimating: 166it [01:34,  1.72it/s]Extractor Estimating: 167it [01:34,  1.72it/s]Extractor Estimating: 168it [01:35,  1.75it/s]Extractor Estimating: 169it [01:35,  1.73it/s]Extractor Estimating: 170it [01:36,  1.72it/s]Extractor Estimating: 171it [01:36,  1.75it/s]Extractor Estimating: 172it [01:37,  1.72it/s]Extractor Estimating: 173it [01:38,  1.72it/s]Extractor Estimating: 174it [01:38,  1.69it/s]Extractor Estimating: 175it [01:39,  1.57it/s]Extractor Estimating: 176it [01:40,  1.59it/s]Extractor Estimating: 177it [01:40,  1.62it/s]Extractor Estimating: 178it [01:41,  1.60it/s]Extractor Estimating: 179it [01:41,  1.62it/s]Extractor Estimating: 180it [01:42,  1.63it/s]Extractor Estimating: 181it [01:43,  1.64it/s]Extractor Estimating: 182it [01:43,  1.62it/s]Extractor Estimating: 183it [01:44,  1.67it/s]Extractor Estimating: 184it [01:44,  1.69it/s]Extractor Estimating: 185it [01:45,  1.64it/s]Extractor Estimating: 186it [01:46,  1.65it/s]Extractor Estimating: 187it [01:46,  1.64it/s]Extractor Estimating: 188it [01:47,  1.61it/s]Extractor Estimating: 189it [01:48,  1.66it/s]Extractor Estimating: 190it [01:48,  1.61it/s]Extractor Estimating: 191it [01:49,  1.64it/s]Extractor Estimating: 192it [01:49,  1.65it/s]Extractor Estimating: 193it [01:50,  1.59it/s]Extractor Estimating: 194it [01:51,  1.64it/s]Extractor Estimating: 195it [01:51,  1.66it/s]Extractor Estimating: 196it [01:52,  1.68it/s]Extractor Estimating: 197it [01:52,  1.65it/s]Extractor Estimating: 198it [01:53,  1.61it/s]Extractor Estimating: 199it [01:54,  1.64it/s]Extractor Estimating: 200it [01:54,  1.67it/s]Extractor Estimating: 201it [01:55,  1.69it/s]Extractor Estimating: 202it [01:55,  1.71it/s]Extractor Estimating: 203it [01:56,  1.67it/s]Extractor Estimating: 204it [01:57,  1.67it/s]Extractor Estimating: 205it [01:57,  1.70it/s]Extractor Estimating: 206it [01:58,  1.63it/s]Extractor Estimating: 207it [01:58,  1.66it/s]Extractor Estimating: 208it [01:59,  1.70it/s]Extractor Estimating: 209it [02:00,  1.68it/s]Extractor Estimating: 210it [02:00,  1.66it/s]Extractor Estimating: 211it [02:01,  1.63it/s]Extractor Estimating: 212it [02:01,  1.63it/s]Extractor Estimating: 213it [02:02,  1.66it/s]Extractor Estimating: 214it [02:03,  1.66it/s]Extractor Estimating: 215it [02:03,  1.64it/s]Extractor Estimating: 216it [02:04,  1.67it/s]Extractor Estimating: 217it [02:04,  1.67it/s]Extractor Estimating: 218it [02:05,  1.64it/s]Extractor Estimating: 219it [02:06,  1.64it/s]Extractor Estimating: 220it [02:06,  1.60it/s]Extractor Estimating: 221it [02:07,  1.60it/s]Extractor Estimating: 222it [02:08,  1.63it/s]Extractor Estimating: 223it [02:08,  1.59it/s]Extractor Estimating: 224it [02:09,  1.62it/s]Extractor Estimating: 225it [02:09,  1.66it/s]Extractor Estimating: 226it [02:10,  1.71it/s]Extractor Estimating: 227it [02:11,  1.69it/s]Extractor Estimating: 228it [02:11,  1.71it/s]Extractor Estimating: 229it [02:12,  1.68it/s]Extractor Estimating: 230it [02:12,  1.68it/s]Extractor Estimating: 231it [02:13,  1.70it/s]Extractor Estimating: 232it [02:13,  1.71it/s]Extractor Estimating: 233it [02:14,  1.74it/s]Extractor Estimating: 234it [02:15,  1.76it/s]Extractor Estimating: 235it [02:15,  1.79it/s]Extractor Estimating: 236it [02:16,  1.77it/s]Extractor Estimating: 237it [02:16,  1.78it/s]Extractor Estimating: 238it [02:17,  1.74it/s]Extractor Estimating: 239it [02:17,  1.72it/s]Extractor Estimating: 240it [02:18,  1.72it/s]Extractor Estimating: 241it [02:19,  1.69it/s]Extractor Estimating: 242it [02:19,  1.68it/s]Extractor Estimating: 243it [02:20,  1.69it/s]Extractor Estimating: 244it [02:20,  1.71it/s]Extractor Estimating: 245it [02:21,  1.70it/s]Extractor Estimating: 246it [02:22,  1.73it/s]Extractor Estimating: 247it [02:22,  1.72it/s]Extractor Estimating: 248it [02:23,  1.74it/s]Extractor Estimating: 249it [02:23,  1.77it/s]Extractor Estimating: 250it [02:27,  1.47s/it]Extractor Estimating: 250it [02:27,  1.70it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:07,080 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:07,099 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:07,099 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:07,100 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:07,100 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 13:05:07,400 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 13:05:07,401 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 13:05:08,092 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 13:05:09,129 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 13:05:09,129 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:12,082 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:12,118 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:12,118 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:12,118 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 13:05:12,118 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 13:05:12,761 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 13:05:12,762 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 13:05:13,341 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 13:05:13,505 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 13:05:13,505 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1113: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[INFO|training_args.py:725] 2023-08-29 14:54:10,537 >> PyTorch: setting up devices
[INFO|training_args.py:625] 2023-08-29 14:54:10,961 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/synthetic/4_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_5_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/4.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 1.0, 'with_train': False, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
{'num_pseudo': 5000, 'num_train': 0}
num of filtered data: 4984 mean pseudo reward: 0.9267568561886408
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/filtered/4.jsonl', 'path_dev': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl'}
train vocab size: 23501
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 23601, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/data/train.txt
{"train_model: args: ModelArguments(model_class='JointModel', model_read_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter4/model', model_write_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/model', pretrained_wv='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/data/train.txt', label_config=None, batch_size=24, evaluate_interval=500, max_steps=10000, max_epoches=20, decay_rate=0.05, token_emb_dim=100, char_encoder='lstm', char_emb_dim=30, cased=False, hidden_dim=200, num_layers=3, crf=None, loss_reduction='sum', maxlen=None, dropout=0.5, optimizer='adam', lr=0.001, vocab_size=23601, vocab_file=None, ner_tag_vocab_size=64, re_tag_vocab_size=250, lm_emb_dim=1024, lm_emb_path='albert-large-v2', head_emb_dim=384, tag_form='iob2', warm_steps=1000, grad_period=1, device='cuda', seed=42)"}
warm up: learning rate was adjusted to 1e-06
warm up: learning rate was adjusted to 1.1e-05
warm up: learning rate was adjusted to 2.1000000000000002e-05
warm up: learning rate was adjusted to 3.1e-05
warm up: learning rate was adjusted to 4.1e-05
warm up: learning rate was adjusted to 5.1000000000000006e-05
warm up: learning rate was adjusted to 6.1e-05
warm up: learning rate was adjusted to 7.1e-05
warm up: learning rate was adjusted to 8.1e-05
warm up: learning rate was adjusted to 9.1e-05
g_step 100, step 100, avg_time 0.942, loss:575.6983
warm up: learning rate was adjusted to 0.000101
warm up: learning rate was adjusted to 0.000111
warm up: learning rate was adjusted to 0.000121
warm up: learning rate was adjusted to 0.000131
warm up: learning rate was adjusted to 0.000141
warm up: learning rate was adjusted to 0.00015099999999999998
warm up: learning rate was adjusted to 0.000161
warm up: learning rate was adjusted to 0.000171
warm up: learning rate was adjusted to 0.00018099999999999998
warm up: learning rate was adjusted to 0.000191
g_step 200, step 200, avg_time 0.932, loss:550.1390
warm up: learning rate was adjusted to 0.000201
warm up: learning rate was adjusted to 0.000211
warm up: learning rate was adjusted to 0.000221
warm up: learning rate was adjusted to 0.000231
warm up: learning rate was adjusted to 0.000241
warm up: learning rate was adjusted to 0.000251
warm up: learning rate was adjusted to 0.000261
warm up: learning rate was adjusted to 0.00027100000000000003
warm up: learning rate was adjusted to 0.00028100000000000005
warm up: learning rate was adjusted to 0.00029099999999999997
g_step 300, step 92, avg_time 0.922, loss:524.8215
warm up: learning rate was adjusted to 0.000301
warm up: learning rate was adjusted to 0.000311
warm up: learning rate was adjusted to 0.000321
warm up: learning rate was adjusted to 0.000331
warm up: learning rate was adjusted to 0.00034100000000000005
warm up: learning rate was adjusted to 0.000351
warm up: learning rate was adjusted to 0.000361
warm up: learning rate was adjusted to 0.000371
warm up: learning rate was adjusted to 0.000381
warm up: learning rate was adjusted to 0.000391
g_step 400, step 192, avg_time 0.928, loss:542.6345
warm up: learning rate was adjusted to 0.00040100000000000004
warm up: learning rate was adjusted to 0.000411
warm up: learning rate was adjusted to 0.000421
warm up: learning rate was adjusted to 0.000431
warm up: learning rate was adjusted to 0.000441
warm up: learning rate was adjusted to 0.000451
warm up: learning rate was adjusted to 0.00046100000000000004
warm up: learning rate was adjusted to 0.000471
warm up: learning rate was adjusted to 0.000481
warm up: learning rate was adjusted to 0.000491
g_step 500, step 84, avg_time 0.926, loss:499.0297
>> valid entity prec:0.4203, rec:0.4151, f1:0.4177
>> valid relation prec:0.1923, rec:0.0882, f1:0.1210
>> valid relation with NER prec:0.1923, rec:0.0882, f1:0.1210
new max entity f1 on valid!
new max relation f1 on valid!
new max relation f1 with NER on valid!
new max averaged entity f1 and relation f1 on valid!
new max averaged entity f1 and relation f1 with NER on valid!
warm up: learning rate was adjusted to 0.000501
warm up: learning rate was adjusted to 0.0005110000000000001
warm up: learning rate was adjusted to 0.000521
warm up: learning rate was adjusted to 0.000531
warm up: learning rate was adjusted to 0.000541
warm up: learning rate was adjusted to 0.0005510000000000001
warm up: learning rate was adjusted to 0.0005610000000000001
warm up: learning rate was adjusted to 0.0005710000000000001
warm up: learning rate was adjusted to 0.0005809999999999999
warm up: learning rate was adjusted to 0.0005909999999999999
g_step 600, step 184, avg_time 4.371, loss:531.2592
warm up: learning rate was adjusted to 0.000601
warm up: learning rate was adjusted to 0.000611
warm up: learning rate was adjusted to 0.000621
warm up: learning rate was adjusted to 0.000631
warm up: learning rate was adjusted to 0.000641
warm up: learning rate was adjusted to 0.000651
warm up: learning rate was adjusted to 0.000661
warm up: learning rate was adjusted to 0.000671
warm up: learning rate was adjusted to 0.0006810000000000001
warm up: learning rate was adjusted to 0.0006910000000000001
g_step 700, step 76, avg_time 0.928, loss:498.8961
warm up: learning rate was adjusted to 0.000701
warm up: learning rate was adjusted to 0.0007109999999999999
warm up: learning rate was adjusted to 0.000721
warm up: learning rate was adjusted to 0.000731
warm up: learning rate was adjusted to 0.000741
warm up: learning rate was adjusted to 0.000751
warm up: learning rate was adjusted to 0.000761
warm up: learning rate was adjusted to 0.000771
warm up: learning rate was adjusted to 0.000781
warm up: learning rate was adjusted to 0.000791
g_step 800, step 176, avg_time 0.923, loss:520.0401
warm up: learning rate was adjusted to 0.0008010000000000001
warm up: learning rate was adjusted to 0.0008110000000000001
warm up: learning rate was adjusted to 0.0008210000000000001
warm up: learning rate was adjusted to 0.000831
warm up: learning rate was adjusted to 0.000841
warm up: learning rate was adjusted to 0.000851
warm up: learning rate was adjusted to 0.000861
warm up: learning rate was adjusted to 0.000871
warm up: learning rate was adjusted to 0.0008810000000000001
warm up: learning rate was adjusted to 0.000891
g_step 900, step 68, avg_time 1.028, loss:501.1688
warm up: learning rate was adjusted to 0.000901
warm up: learning rate was adjusted to 0.000911
warm up: learning rate was adjusted to 0.000921
warm up: learning rate was adjusted to 0.0009310000000000001
warm up: learning rate was adjusted to 0.0009410000000000001
warm up: learning rate was adjusted to 0.000951
warm up: learning rate was adjusted to 0.0009609999999999999
warm up: learning rate was adjusted to 0.000971
warm up: learning rate was adjusted to 0.0009809999999999999
warm up: learning rate was adjusted to 0.000991
g_step 1000, step 168, avg_time 0.904, loss:514.4854
learning rate was adjusted to 0.0009523809523809524
>> valid entity prec:0.3777, rec:0.3243, f1:0.3490
>> valid relation prec:0.1178, rec:0.0435, f1:0.0635
>> valid relation with NER prec:0.1178, rec:0.0435, f1:0.0635
g_step 1100, step 60, avg_time 4.272, loss:490.4505
g_step 1200, step 160, avg_time 0.913, loss:505.2857
g_step 1300, step 52, avg_time 0.904, loss:481.9363
g_step 1400, step 152, avg_time 0.915, loss:462.4164
g_step 1500, step 44, avg_time 0.891, loss:458.6483
>> valid entity prec:0.4095, rec:0.3515, f1:0.3783
>> valid relation prec:0.1723, rec:0.0607, f1:0.0898
>> valid relation with NER prec:0.1723, rec:0.0607, f1:0.0898
g_step 1600, step 144, avg_time 4.282, loss:447.0032
g_step 1700, step 36, avg_time 0.914, loss:446.4613
g_step 1800, step 136, avg_time 0.908, loss:427.2531
g_step 1900, step 28, avg_time 0.900, loss:427.0733
g_step 2000, step 128, avg_time 0.912, loss:409.2290
learning rate was adjusted to 0.0009090909090909091
>> valid entity prec:0.4082, rec:0.4308, f1:0.4192
>> valid relation prec:0.1073, rec:0.0494, f1:0.0677
>> valid relation with NER prec:0.1073, rec:0.0494, f1:0.0677
new max entity f1 on valid!
g_step 2100, step 20, avg_time 4.309, loss:417.9448
g_step 2200, step 120, avg_time 0.913, loss:383.2595
g_step 2300, step 12, avg_time 0.901, loss:406.7969
g_step 2400, step 112, avg_time 0.911, loss:376.2032
g_step 2500, step 4, avg_time 0.905, loss:386.3391
>> valid entity prec:0.4044, rec:0.2994, f1:0.3441
>> valid relation prec:0.1283, rec:0.0503, f1:0.0723
>> valid relation with NER prec:0.1283, rec:0.0503, f1:0.0723
g_step 2600, step 104, avg_time 4.297, loss:360.2430
g_step 2700, step 204, avg_time 0.920, loss:379.7821
g_step 2800, step 96, avg_time 0.920, loss:351.9312
g_step 2900, step 196, avg_time 0.910, loss:369.4092
g_step 3000, step 88, avg_time 0.915, loss:337.3588
learning rate was adjusted to 0.0008695652173913044
>> valid entity prec:0.4189, rec:0.3786, f1:0.3977
>> valid relation prec:0.1400, rec:0.0700, f1:0.0933
>> valid relation with NER prec:0.1400, rec:0.0700, f1:0.0933
g_step 3100, step 188, avg_time 4.382, loss:342.6763
g_step 3200, step 80, avg_time 0.925, loss:324.3416
g_step 3300, step 180, avg_time 0.913, loss:337.1208
g_step 3400, step 72, avg_time 0.913, loss:314.2476
g_step 3500, step 172, avg_time 0.919, loss:324.9221
>> valid entity prec:0.3891, rec:0.2953, f1:0.3358
>> valid relation prec:0.1068, rec:0.0437, f1:0.0620
>> valid relation with NER prec:0.1068, rec:0.0437, f1:0.0620
g_step 3600, step 64, avg_time 4.275, loss:310.7242
g_step 3700, step 164, avg_time 0.916, loss:303.7950
g_step 3800, step 56, avg_time 0.903, loss:304.5986
g_step 3900, step 156, avg_time 0.918, loss:298.9515
g_step 4000, step 48, avg_time 0.905, loss:298.1391
learning rate was adjusted to 0.0008333333333333334
>> valid entity prec:0.3961, rec:0.3363, f1:0.3637
>> valid relation prec:0.1430, rec:0.0568, f1:0.0813
>> valid relation with NER prec:0.1430, rec:0.0568, f1:0.0813
g_step 4100, step 148, avg_time 4.279, loss:278.4739
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
08/29/2023 14:54:10 - WARNING - transformer_base.run_clm_rl -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True
08/29/2023 14:54:10 - INFO - transformer_base.run_clm_rl -   Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=2,
greater_is_better=False,
group_by_length=False,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_on_each_node=True,
logging_dir=runs/Aug29_14-54-10_ctolab07.scc.idea,
logging_first_step=False,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
output_dir=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
08/29/2023 14:54:12 - WARNING - datasets.builder -   Using custom data configuration default-fc46d377d008269e
Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/xuting/.cache/huggingface/datasets/json/default-fc46d377d008269e/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...
0 tables [00:00, ? tables/s]1 tables [00:01,  1.10s/ tables]                                0 tables [00:00, ? tables/s]                            [INFO|configuration_utils.py:515] 2023-08-29 14:54:16,292 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 14:54:16,293 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 14:54:16,293 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 14:54:16,294 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter3/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 14:54:16,376 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:54:16,425 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:54:16,425 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:54:16,425 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:54:16,425 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:54:16,425 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:54:16,425 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/tokenizer_config.json
[INFO|modeling_utils.py:1150] 2023-08-29 14:54:16,907 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 14:54:19,978 >> All model checkpoint weights were used when initializing Model.

[INFO|modeling_utils.py:1345] 2023-08-29 14:54:20,004 >> All the weights of Model were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Model for predictions without further training.
Dataset json downloaded and prepared to /home/xuting/.cache/huggingface/datasets/json/default-fc46d377d008269e/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.
PreTrainedTokenizerFast(name_or_path='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter4/model', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'})
  0%|          | 0/5 [00:00<?, ?ba/s] 20%|██        | 1/5 [00:00<00:02,  1.77ba/s] 40%|████      | 2/5 [00:00<00:01,  2.36ba/s] 60%|██████    | 3/5 [00:01<00:00,  3.20ba/s] 80%|████████  | 4/5 [00:01<00:00,  3.87ba/s]100%|██████████| 5/5 [00:01<00:00,  4.35ba/s]100%|██████████| 5/5 [00:01<00:00,  3.51ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:04,  3.16ba/s] 13%|█▎        | 2/15 [00:00<00:03,  4.18ba/s] 20%|██        | 3/15 [00:00<00:02,  4.60ba/s] 27%|██▋       | 4/15 [00:00<00:02,  4.86ba/s] 33%|███▎      | 5/15 [00:01<00:01,  5.02ba/s] 40%|████      | 6/15 [00:01<00:01,  5.10ba/s] 47%|████▋     | 7/15 [00:01<00:01,  5.17ba/s] 53%|█████▎    | 8/15 [00:01<00:01,  5.20ba/s] 60%|██████    | 9/15 [00:01<00:01,  5.23ba/s] 67%|██████▋   | 10/15 [00:02<00:00,  5.25ba/s] 73%|███████▎  | 11/15 [00:02<00:00,  5.28ba/s] 80%|████████  | 12/15 [00:02<00:00,  5.26ba/s] 87%|████████▋ | 13/15 [00:02<00:00,  4.28ba/s] 93%|█████████▎| 14/15 [00:02<00:00,  4.51ba/s]100%|██████████| 15/15 [00:02<00:00,  5.10ba/s]
  0%|          | 0/5 [00:00<?, ?ba/s] 20%|██        | 1/5 [00:00<00:01,  2.78ba/s] 60%|██████    | 3/5 [00:00<00:00,  6.26ba/s]100%|██████████| 5/5 [00:00<00:00,  8.13ba/s]100%|██████████| 5/5 [00:00<00:00,  6.98ba/s]
  0%|          | 0/15 [00:00<?, ?ba/s]  7%|▋         | 1/15 [00:00<00:04,  3.07ba/s] 20%|██        | 3/15 [00:00<00:01,  6.62ba/s] 33%|███▎      | 5/15 [00:00<00:01,  8.38ba/s] 47%|████▋     | 7/15 [00:00<00:00,  9.43ba/s] 60%|██████    | 9/15 [00:01<00:00, 10.05ba/s] 73%|███████▎  | 11/15 [00:01<00:00, 10.43ba/s] 87%|████████▋ | 13/15 [00:01<00:00, 10.73ba/s]100%|██████████| 15/15 [00:01<00:00, 10.08ba/s]
[INFO|trainer.py:414] 2023-08-29 14:54:29,193 >> Using amp fp16 backend
[INFO|trainer.py:1147] 2023-08-29 14:54:29,579 >> ***** Running training *****
[INFO|trainer.py:1148] 2023-08-29 14:54:29,579 >>   Num examples = 5000
[INFO|trainer.py:1149] 2023-08-29 14:54:29,579 >>   Num Epochs = 5
[INFO|trainer.py:1150] 2023-08-29 14:54:29,579 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1151] 2023-08-29 14:54:29,580 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1152] 2023-08-29 14:54:29,580 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1153] 2023-08-29 14:54:29,580 >>   Total optimization steps = 390
  0%|          | 0/390 [00:00<?, ?it/s]  0%|          | 1/390 [00:03<21:23,  3.30s/it]  1%|          | 2/390 [00:04<11:42,  1.81s/it]  1%|          | 3/390 [00:04<08:12,  1.27s/it]  1%|          | 4/390 [00:05<05:51,  1.10it/s]  1%|▏         | 5/390 [00:05<04:24,  1.45it/s]  2%|▏         | 6/390 [00:05<03:48,  1.68it/s]  2%|▏         | 7/390 [00:06<03:09,  2.02it/s]  2%|▏         | 8/390 [00:06<02:44,  2.33it/s]  2%|▏         | 9/390 [00:06<02:27,  2.59it/s]  3%|▎         | 10/390 [00:06<02:23,  2.65it/s]  3%|▎         | 11/390 [00:07<02:13,  2.85it/s]  3%|▎         | 12/390 [00:07<02:17,  2.76it/s]  3%|▎         | 13/390 [00:07<02:08,  2.93it/s]  4%|▎         | 14/390 [00:08<02:02,  3.07it/s]  4%|▍         | 15/390 [00:08<01:58,  3.18it/s]  4%|▍         | 16/390 [00:08<01:54,  3.25it/s]  4%|▍         | 17/390 [00:09<01:52,  3.31it/s]  5%|▍         | 18/390 [00:09<01:51,  3.35it/s]  5%|▍         | 19/390 [00:09<01:50,  3.37it/s]  5%|▌         | 20/390 [00:09<01:49,  3.39it/s]  5%|▌         | 21/390 [00:10<01:48,  3.40it/s]  6%|▌         | 22/390 [00:10<01:47,  3.42it/s]  6%|▌         | 23/390 [00:10<01:47,  3.43it/s]  6%|▌         | 24/390 [00:11<01:46,  3.43it/s]  6%|▋         | 25/390 [00:11<01:46,  3.44it/s]  7%|▋         | 26/390 [00:11<01:45,  3.44it/s]  7%|▋         | 27/390 [00:12<01:45,  3.44it/s]  7%|▋         | 28/390 [00:12<01:45,  3.44it/s]  7%|▋         | 29/390 [00:12<01:44,  3.44it/s]  8%|▊         | 30/390 [00:12<01:44,  3.44it/s]  8%|▊         | 31/390 [00:13<01:44,  3.44it/s]  8%|▊         | 32/390 [00:13<01:43,  3.44it/s]  8%|▊         | 33/390 [00:13<01:43,  3.44it/s]  9%|▊         | 34/390 [00:14<01:43,  3.44it/s]  9%|▉         | 35/390 [00:14<01:43,  3.44it/s]  9%|▉         | 36/390 [00:14<01:42,  3.44it/s]  9%|▉         | 37/390 [00:14<01:42,  3.44it/s] 10%|▉         | 38/390 [00:15<01:42,  3.44it/s] 10%|█         | 39/390 [00:15<01:42,  3.44it/s] 10%|█         | 40/390 [00:15<01:41,  3.44it/s] 11%|█         | 41/390 [00:16<01:41,  3.44it/s] 11%|█         | 42/390 [00:16<01:41,  3.44it/s] 11%|█         | 43/390 [00:16<01:40,  3.44it/s] 11%|█▏        | 44/390 [00:16<01:40,  3.44it/s] 12%|█▏        | 45/390 [00:17<01:40,  3.44it/s] 12%|█▏        | 46/390 [00:17<01:40,  3.44it/s] 12%|█▏        | 47/390 [00:17<01:39,  3.44it/s] 12%|█▏        | 48/390 [00:18<01:39,  3.44it/s] 13%|█▎        | 49/390 [00:18<01:39,  3.43it/s] 13%|█▎        | 50/390 [00:18<01:38,  3.44it/s] 13%|█▎        | 51/390 [00:19<01:38,  3.44it/s] 13%|█▎        | 52/390 [00:19<01:38,  3.44it/s] 14%|█▎        | 53/390 [00:19<01:38,  3.44it/s] 14%|█▍        | 54/390 [00:19<01:37,  3.44it/s] 14%|█▍        | 55/390 [00:20<01:37,  3.44it/s] 14%|█▍        | 56/390 [00:20<01:37,  3.44it/s] 15%|█▍        | 57/390 [00:20<01:36,  3.44it/s] 15%|█▍        | 58/390 [00:21<01:36,  3.44it/s] 15%|█▌        | 59/390 [00:21<01:36,  3.44it/s] 15%|█▌        | 60/390 [00:21<01:36,  3.44it/s] 16%|█▌        | 61/390 [00:21<01:35,  3.43it/s] 16%|█▌        | 62/390 [00:22<01:35,  3.43it/s] 16%|█▌        | 63/390 [00:22<01:35,  3.43it/s] 16%|█▋        | 64/390 [00:22<01:34,  3.44it/s] 17%|█▋        | 65/390 [00:23<01:34,  3.44it/s] 17%|█▋        | 66/390 [00:23<01:34,  3.44it/s] 17%|█▋        | 67/390 [00:23<01:34,  3.43it/s] 17%|█▋        | 68/390 [00:23<01:33,  3.44it/s] 18%|█▊        | 69/390 [00:24<01:33,  3.43it/s] 18%|█▊        | 70/390 [00:24<01:33,  3.43it/s] 18%|█▊        | 71/390 [00:24<01:32,  3.43it/s] 18%|█▊        | 72/390 [00:25<01:32,  3.43it/s] 19%|█▊        | 73/390 [00:25<01:32,  3.43it/s] 19%|█▉        | 74/390 [00:25<01:32,  3.43it/s] 19%|█▉        | 75/390 [00:25<01:31,  3.43it/s] 19%|█▉        | 76/390 [00:26<01:31,  3.43it/s] 20%|█▉        | 77/390 [00:26<01:31,  3.43it/s] 20%|██        | 78/390 [00:26<01:39,  3.13it/s][INFO|trainer.py:2140] 2023-08-29 14:54:56,713 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:54:56,713 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 14:54:56,713 >>   Batch size = 8

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.19it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.39it/s][A
  1%|          | 17/1759 [00:00<00:36, 48.00it/s][A
  1%|▏         | 22/1759 [00:00<00:36, 47.21it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 46.71it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 46.39it/s][A
  2%|▏         | 37/1759 [00:00<00:37, 46.22it/s][A
  2%|▏         | 42/1759 [00:00<00:37, 45.60it/s][A
  3%|▎         | 47/1759 [00:01<00:37, 45.28it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.25it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.29it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.40it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.50it/s][A
  4%|▍         | 72/1759 [00:01<00:36, 45.64it/s][A
  4%|▍         | 77/1759 [00:01<00:36, 45.67it/s][A
  5%|▍         | 82/1759 [00:01<00:36, 45.63it/s][A
  5%|▍         | 87/1759 [00:01<00:36, 45.35it/s][A
  5%|▌         | 92/1759 [00:01<00:36, 45.11it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 45.06it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.05it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.22it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.35it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.49it/s][A
  7%|▋         | 122/1759 [00:02<00:35, 45.62it/s][A
  7%|▋         | 127/1759 [00:02<00:35, 45.62it/s][A
  8%|▊         | 132/1759 [00:02<00:35, 45.44it/s][A
  8%|▊         | 137/1759 [00:02<00:35, 45.20it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.07it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.15it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.22it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.34it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 45.44it/s][A
  9%|▉         | 167/1759 [00:03<00:34, 45.57it/s][A
 10%|▉         | 172/1759 [00:03<00:34, 45.56it/s][A
 10%|█         | 177/1759 [00:03<00:34, 45.43it/s][A
 10%|█         | 182/1759 [00:03<00:34, 45.22it/s][A
 11%|█         | 187/1759 [00:04<00:34, 45.19it/s][A
 11%|█         | 192/1759 [00:04<00:34, 45.14it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.16it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 45.32it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 45.45it/s][A
 12%|█▏        | 212/1759 [00:04<00:38, 40.37it/s][A
 12%|█▏        | 217/1759 [00:04<00:36, 41.89it/s][A
 13%|█▎        | 222/1759 [00:04<00:35, 42.99it/s][A
 13%|█▎        | 227/1759 [00:05<00:34, 43.84it/s][A
 13%|█▎        | 232/1759 [00:05<00:34, 44.33it/s][A
 13%|█▎        | 237/1759 [00:05<00:34, 44.66it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 44.87it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.06it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 44.76it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 44.72it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 44.93it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 45.10it/s][A
 15%|█▌        | 272/1759 [00:06<00:32, 45.34it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.46it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.55it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.52it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.41it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 45.13it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 45.01it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 45.11it/s][A
 18%|█▊        | 312/1759 [00:06<00:31, 45.24it/s][A
 18%|█▊        | 317/1759 [00:07<00:31, 45.41it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 45.54it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.62it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 45.56it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 45.35it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 45.17it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 45.07it/s][A
 20%|██        | 352/1759 [00:07<00:31, 45.08it/s][A
 20%|██        | 357/1759 [00:07<00:31, 45.20it/s][A
 21%|██        | 362/1759 [00:07<00:30, 45.34it/s][A
 21%|██        | 367/1759 [00:08<00:30, 45.49it/s][A
 21%|██        | 372/1759 [00:08<00:30, 45.60it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.57it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 45.38it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 45.14it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 45.05it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 45.14it/s][A
 23%|██▎       | 402/1759 [00:08<00:30, 45.19it/s][A
 23%|██▎       | 407/1759 [00:08<00:29, 45.33it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.42it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.57it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.56it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 45.45it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 45.21it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 45.09it/s][A
 25%|██▌       | 442/1759 [00:09<00:31, 41.98it/s][A
 25%|██▌       | 447/1759 [00:09<00:30, 43.07it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 43.89it/s][A
 26%|██▌       | 457/1759 [00:10<00:29, 44.42it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 44.87it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.11it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 45.23it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 45.06it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 44.84it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 44.78it/s][A
 28%|██▊       | 492/1759 [00:10<00:28, 44.88it/s][A
 28%|██▊       | 497/1759 [00:11<00:27, 45.09it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.22it/s][A
 29%|██▉       | 507/1759 [00:11<00:28, 43.49it/s][A
 29%|██▉       | 512/1759 [00:11<00:28, 44.21it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 44.72it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 44.99it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 44.94it/s][A
 30%|███       | 532/1759 [00:11<00:27, 44.87it/s][A
 31%|███       | 537/1759 [00:11<00:27, 44.89it/s][A
 31%|███       | 542/1759 [00:12<00:27, 45.02it/s][A
 31%|███       | 547/1759 [00:12<00:26, 44.98it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.06it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 45.21it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 45.30it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 45.52it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 45.41it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 45.20it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 45.25it/s][A
 33%|███▎      | 587/1759 [00:13<00:25, 45.18it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.12it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.14it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 45.17it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 45.39it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 45.51it/s][A
 35%|███▌      | 617/1759 [00:13<00:25, 45.56it/s][A
 35%|███▌      | 622/1759 [00:13<00:25, 45.39it/s][A
 36%|███▌      | 627/1759 [00:13<00:28, 40.25it/s][A
 36%|███▌      | 632/1759 [00:14<00:41, 27.15it/s][A
 36%|███▌      | 637/1759 [00:14<00:36, 31.06it/s][A
 36%|███▋      | 642/1759 [00:14<00:32, 34.38it/s][A
 37%|███▋      | 647/1759 [00:14<00:29, 37.17it/s][A
 37%|███▋      | 652/1759 [00:14<00:28, 39.37it/s][A
 37%|███▋      | 657/1759 [00:14<00:26, 41.15it/s][A
 38%|███▊      | 662/1759 [00:14<00:26, 42.02it/s][A
 38%|███▊      | 667/1759 [00:15<00:25, 43.08it/s][A
 38%|███▊      | 672/1759 [00:15<00:25, 43.47it/s][A
 38%|███▊      | 677/1759 [00:15<00:24, 43.66it/s][A
 39%|███▉      | 682/1759 [00:15<00:24, 44.03it/s][A
 39%|███▉      | 687/1759 [00:15<00:24, 44.38it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 44.72it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 45.03it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 45.28it/s][A
 40%|████      | 707/1759 [00:15<00:23, 45.45it/s][A
 40%|████      | 712/1759 [00:16<00:23, 45.48it/s][A
 41%|████      | 717/1759 [00:16<00:23, 45.26it/s][A
 41%|████      | 722/1759 [00:16<00:23, 45.02it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 44.96it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 44.98it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 45.10it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 45.22it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 45.35it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 45.43it/s][A
 43%|████▎     | 757/1759 [00:17<00:21, 45.57it/s][A
 43%|████▎     | 762/1759 [00:17<00:21, 45.47it/s][A
 44%|████▎     | 767/1759 [00:17<00:21, 45.25it/s][A
 44%|████▍     | 772/1759 [00:17<00:21, 45.06it/s][A
 44%|████▍     | 777/1759 [00:17<00:21, 44.93it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 45.14it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 45.25it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 45.37it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 45.41it/s][A
 46%|████▌     | 802/1759 [00:18<00:21, 45.54it/s][A
 46%|████▌     | 807/1759 [00:18<00:20, 45.42it/s][A
 46%|████▌     | 812/1759 [00:18<00:20, 45.30it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 45.10it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 45.03it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 45.15it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 45.27it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 45.40it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 45.50it/s][A
 48%|████▊     | 847/1759 [00:19<00:20, 45.55it/s][A
 48%|████▊     | 852/1759 [00:19<00:19, 45.47it/s][A
 49%|████▊     | 857/1759 [00:19<00:19, 45.32it/s][A
 49%|████▉     | 862/1759 [00:19<00:19, 45.12it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 45.08it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 45.08it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 45.24it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 45.35it/s][A
 50%|█████     | 887/1759 [00:19<00:19, 45.46it/s][A
 51%|█████     | 892/1759 [00:20<00:22, 38.63it/s][A
 51%|█████     | 897/1759 [00:20<00:21, 40.56it/s][A
 51%|█████▏    | 902/1759 [00:20<00:20, 41.97it/s][A
 52%|█████▏    | 907/1759 [00:20<00:19, 43.07it/s][A
 52%|█████▏    | 912/1759 [00:20<00:19, 43.84it/s][A
 52%|█████▏    | 917/1759 [00:20<00:18, 44.47it/s][A
 52%|█████▏    | 922/1759 [00:20<00:18, 44.84it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 45.08it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 44.76it/s][A
 53%|█████▎    | 937/1759 [00:21<00:18, 44.56it/s][A
 54%|█████▎    | 942/1759 [00:21<00:18, 44.65it/s][A
 54%|█████▍    | 947/1759 [00:21<00:18, 44.83it/s][A
 54%|█████▍    | 952/1759 [00:21<00:17, 45.09it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 45.31it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 45.49it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 45.56it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 45.57it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 45.31it/s][A
 56%|█████▌    | 982/1759 [00:22<00:17, 45.02it/s][A
 56%|█████▌    | 987/1759 [00:22<00:17, 44.90it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 45.01it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 45.14it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 45.35it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.49it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 45.59it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 45.51it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:16, 45.35it/s][A
 58%|█████▊    | 1027/1759 [00:23<00:16, 45.13it/s][A
 59%|█████▊    | 1032/1759 [00:23<00:16, 45.02it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:16, 44.95it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:15, 45.10it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:15, 45.23it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:15, 45.43it/s][A
 60%|██████    | 1057/1759 [00:23<00:15, 45.52it/s][A
 60%|██████    | 1062/1759 [00:23<00:15, 45.58it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 45.35it/s][A
 61%|██████    | 1072/1759 [00:24<00:15, 45.20it/s][A
 61%|██████    | 1077/1759 [00:24<00:15, 45.11it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:15, 45.06it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:14, 45.11it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 45.17it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 45.37it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 45.51it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 45.55it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 45.37it/s][A
 64%|██████▎   | 1117/1759 [00:25<00:14, 45.23it/s][A
 64%|██████▍   | 1122/1759 [00:25<00:14, 43.09it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 43.80it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:14, 44.30it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 44.62it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 44.92it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 45.14it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 45.30it/s][A
 66%|██████▌   | 1157/1759 [00:25<00:13, 45.35it/s][A
 66%|██████▌   | 1162/1759 [00:26<00:13, 45.05it/s][A
 66%|██████▋   | 1167/1759 [00:26<00:13, 45.02it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 45.05it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:12, 45.22it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:12, 45.24it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 45.35it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:12, 45.42it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 45.50it/s][A
 68%|██████▊   | 1202/1759 [00:26<00:12, 45.40it/s][A
 69%|██████▊   | 1207/1759 [00:27<00:12, 45.29it/s][A
 69%|██████▉   | 1212/1759 [00:27<00:12, 45.20it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:12, 45.15it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:11, 45.20it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 44.91it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 45.29it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 45.38it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 45.42it/s][A
 71%|███████   | 1247/1759 [00:27<00:11, 45.27it/s][A
 71%|███████   | 1252/1759 [00:28<00:11, 45.29it/s][A
 71%|███████▏  | 1257/1759 [00:28<00:11, 45.13it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:10, 45.18it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:10, 45.16it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 45.24it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 45.27it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 45.36it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 45.37it/s][A
 73%|███████▎  | 1292/1759 [00:28<00:10, 45.28it/s][A
 74%|███████▎  | 1297/1759 [00:29<00:10, 45.22it/s][A
 74%|███████▍  | 1302/1759 [00:29<00:10, 45.13it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 45.12it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:09, 45.17it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:09, 45.23it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 45.28it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 45.29it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 45.36it/s][A
 76%|███████▌  | 1337/1759 [00:29<00:09, 45.33it/s][A
 76%|███████▋  | 1342/1759 [00:30<00:09, 45.26it/s][A
 77%|███████▋  | 1347/1759 [00:30<00:09, 45.13it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:13, 29.86it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:12, 33.39it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:10, 36.34it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:10, 38.73it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:09, 40.63it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:09, 42.07it/s][A
 79%|███████▊  | 1382/1759 [00:31<00:08, 43.13it/s][A
 79%|███████▉  | 1387/1759 [00:31<00:08, 43.77it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 43.88it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 43.97it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:08, 44.22it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 44.55it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 44.83it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 45.07it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 45.20it/s][A
 81%|████████  | 1427/1759 [00:32<00:07, 45.34it/s][A
 81%|████████▏ | 1432/1759 [00:32<00:07, 45.46it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 45.40it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 45.18it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 45.09it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 45.08it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 45.15it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 45.30it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 45.33it/s][A
 84%|████████▎ | 1472/1759 [00:33<00:06, 45.34it/s][A
 84%|████████▍ | 1477/1759 [00:33<00:06, 45.35it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 45.33it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 45.19it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 45.16it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 45.13it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 45.10it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 45.28it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 45.31it/s][A
 86%|████████▌ | 1517/1759 [00:34<00:05, 45.39it/s][A
 87%|████████▋ | 1522/1759 [00:34<00:05, 45.32it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 45.30it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 45.21it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 45.19it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 45.10it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 45.20it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 45.26it/s][A
 89%|████████▊ | 1557/1759 [00:34<00:04, 45.39it/s][A
 89%|████████▉ | 1562/1759 [00:35<00:04, 45.35it/s][A
 89%|████████▉ | 1567/1759 [00:35<00:04, 45.34it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 45.31it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 45.18it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 45.14it/s][A
 90%|█████████ | 1587/1759 [00:35<00:05, 28.73it/s][A
 91%|█████████ | 1592/1759 [00:35<00:05, 32.36it/s][A
 91%|█████████ | 1597/1759 [00:36<00:04, 35.51it/s][A
 91%|█████████ | 1602/1759 [00:36<00:04, 38.07it/s][A
 91%|█████████▏| 1607/1759 [00:36<00:03, 40.11it/s][A
 92%|█████████▏| 1612/1759 [00:36<00:03, 41.66it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 42.84it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 43.54it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:03, 43.71it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 43.76it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 44.08it/s][A
 93%|█████████▎| 1642/1759 [00:37<00:02, 44.47it/s][A
 94%|█████████▎| 1647/1759 [00:37<00:02, 44.77it/s][A
 94%|█████████▍| 1652/1759 [00:37<00:02, 45.04it/s][A
 94%|█████████▍| 1657/1759 [00:37<00:02, 45.23it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 45.36it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 45.39it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 45.31it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 45.12it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 45.07it/s][A
 96%|█████████▌| 1687/1759 [00:38<00:01, 45.06it/s][A
 96%|█████████▌| 1692/1759 [00:38<00:01, 45.18it/s][A
 96%|█████████▋| 1697/1759 [00:38<00:01, 45.35it/s][A
 97%|█████████▋| 1702/1759 [00:38<00:01, 45.42it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 45.47it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 45.40it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 45.25it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 45.08it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 45.03it/s][A
 98%|█████████▊| 1732/1759 [00:39<00:00, 45.10it/s][A
 99%|█████████▊| 1737/1759 [00:39<00:00, 45.22it/s][A
 99%|█████████▉| 1742/1759 [00:39<00:00, 45.34it/s][A
 99%|█████████▉| 1747/1759 [00:39<00:00, 45.45it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 45.47it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 45.40it/s][A
                                                   [A                                                
100%|██████████| 1759/1759 [00:39<00:00, 45.40it/s][A 20%|██        | 78/390 [01:06<01:39,  3.13it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 14:55:37,026 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-78
[INFO|configuration_utils.py:351] 2023-08-29 14:55:37,648 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-78/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:55:43,614 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-78/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:55:43,942 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-78/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:55:44,147 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-78/special_tokens_map.json
 20%|██        | 79/390 [01:23<1:29:08, 17.20s/it] 21%|██        | 80/390 [01:23<1:02:43, 12.14s/it] 21%|██        | 81/390 [01:24<44:13,  8.59s/it]   21%|██        | 82/390 [01:24<31:18,  6.10s/it] 21%|██▏       | 83/390 [01:24<22:17,  4.36s/it] 22%|██▏       | 84/390 [01:25<15:59,  3.14s/it] 22%|██▏       | 85/390 [01:25<11:36,  2.28s/it] 22%|██▏       | 86/390 [01:25<08:32,  1.68s/it] 22%|██▏       | 87/390 [01:25<06:23,  1.27s/it] 23%|██▎       | 88/390 [01:26<04:54,  1.03it/s] 23%|██▎       | 89/390 [01:26<03:51,  1.30it/s] 23%|██▎       | 90/390 [01:26<03:06,  1.61it/s] 23%|██▎       | 91/390 [01:27<02:40,  1.86it/s] 24%|██▎       | 92/390 [01:27<02:17,  2.17it/s] 24%|██▍       | 93/390 [01:27<02:01,  2.45it/s] 24%|██▍       | 94/390 [01:27<01:49,  2.70it/s] 24%|██▍       | 95/390 [01:28<01:41,  2.90it/s] 25%|██▍       | 96/390 [01:28<01:36,  3.06it/s] 25%|██▍       | 97/390 [01:28<01:32,  3.18it/s] 25%|██▌       | 98/390 [01:29<01:29,  3.28it/s] 25%|██▌       | 99/390 [01:29<01:27,  3.34it/s] 26%|██▌       | 100/390 [01:29<01:25,  3.39it/s] 26%|██▌       | 101/390 [01:29<01:24,  3.43it/s] 26%|██▌       | 102/390 [01:30<01:29,  3.22it/s] 26%|██▋       | 103/390 [01:30<01:26,  3.31it/s] 27%|██▋       | 104/390 [01:30<01:24,  3.37it/s] 27%|██▋       | 105/390 [01:31<01:23,  3.41it/s] 27%|██▋       | 106/390 [01:31<01:22,  3.44it/s] 27%|██▋       | 107/390 [01:31<01:21,  3.46it/s] 28%|██▊       | 108/390 [01:32<01:21,  3.48it/s] 28%|██▊       | 109/390 [01:32<01:20,  3.49it/s] 28%|██▊       | 110/390 [01:32<01:20,  3.50it/s] 28%|██▊       | 111/390 [01:32<01:19,  3.50it/s] 29%|██▊       | 112/390 [01:33<01:19,  3.51it/s] 29%|██▉       | 113/390 [01:33<01:23,  3.33it/s] 29%|██▉       | 114/390 [01:33<01:21,  3.38it/s] 29%|██▉       | 115/390 [01:34<01:20,  3.42it/s] 30%|██▉       | 116/390 [01:34<01:19,  3.45it/s] 30%|███       | 117/390 [01:34<01:18,  3.47it/s] 30%|███       | 118/390 [01:34<01:18,  3.48it/s] 31%|███       | 119/390 [01:35<01:17,  3.49it/s] 31%|███       | 120/390 [01:35<01:17,  3.50it/s] 31%|███       | 121/390 [01:35<01:16,  3.51it/s] 31%|███▏      | 122/390 [01:36<01:16,  3.51it/s] 32%|███▏      | 123/390 [01:36<01:16,  3.51it/s] 32%|███▏      | 124/390 [01:36<01:19,  3.35it/s] 32%|███▏      | 125/390 [01:36<01:17,  3.40it/s] 32%|███▏      | 126/390 [01:37<01:16,  3.43it/s] 33%|███▎      | 127/390 [01:37<01:16,  3.45it/s] 33%|███▎      | 128/390 [01:37<01:15,  3.47it/s] 33%|███▎      | 129/390 [01:38<01:14,  3.48it/s] 33%|███▎      | 130/390 [01:38<01:17,  3.36it/s] 34%|███▎      | 131/390 [01:38<01:16,  3.41it/s] 34%|███▍      | 132/390 [01:38<01:15,  3.44it/s] 34%|███▍      | 133/390 [01:39<01:14,  3.46it/s] 34%|███▍      | 134/390 [01:39<01:13,  3.47it/s] 35%|███▍      | 135/390 [01:39<01:13,  3.48it/s] 35%|███▍      | 136/390 [01:40<01:12,  3.49it/s] 35%|███▌      | 137/390 [01:40<01:12,  3.50it/s] 35%|███▌      | 138/390 [01:40<01:11,  3.50it/s] 36%|███▌      | 139/390 [01:40<01:11,  3.50it/s] 36%|███▌      | 140/390 [01:41<01:38,  2.53it/s] 36%|███▌      | 141/390 [01:41<01:31,  2.71it/s] 36%|███▋      | 142/390 [01:42<01:25,  2.91it/s] 37%|███▋      | 143/390 [01:42<01:20,  3.07it/s] 37%|███▋      | 144/390 [01:42<01:17,  3.19it/s] 37%|███▋      | 145/390 [01:43<01:14,  3.28it/s] 37%|███▋      | 146/390 [01:43<01:12,  3.35it/s] 38%|███▊      | 147/390 [01:43<01:11,  3.40it/s] 38%|███▊      | 148/390 [01:43<01:10,  3.43it/s] 38%|███▊      | 149/390 [01:44<01:09,  3.45it/s] 38%|███▊      | 150/390 [01:44<01:09,  3.47it/s] 39%|███▊      | 151/390 [01:44<01:08,  3.48it/s] 39%|███▉      | 152/390 [01:45<01:11,  3.33it/s] 39%|███▉      | 153/390 [01:45<01:10,  3.38it/s] 39%|███▉      | 154/390 [01:45<01:09,  3.42it/s] 40%|███▉      | 155/390 [01:45<01:08,  3.44it/s] 40%|████      | 156/390 [01:46<01:07,  3.46it/s][INFO|trainer.py:2140] 2023-08-29 14:56:15,869 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:56:15,869 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 14:56:15,869 >>   Batch size = 8
{'eval_loss': 0.9683729410171509, 'eval_runtime': 39.6352, 'eval_samples_per_second': 354.912, 'eval_steps_per_second': 44.38, 'epoch': 0.99}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:31, 56.51it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.22it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.45it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.47it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 46.10it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 45.72it/s][A
  2%|▏         | 37/1759 [00:00<00:37, 45.55it/s][A
  2%|▏         | 42/1759 [00:00<00:37, 45.40it/s][A
  3%|▎         | 47/1759 [00:01<00:37, 45.37it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.40it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.44it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.56it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.51it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.45it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 44.46it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 44.69it/s][A
  5%|▍         | 87/1759 [00:01<00:37, 44.86it/s][A
  5%|▌         | 92/1759 [00:02<00:37, 44.97it/s][A
  6%|▌         | 97/1759 [00:02<00:36, 45.16it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 45.31it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.40it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.40it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.33it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 45.23it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 45.18it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 45.14it/s][A
  8%|▊         | 137/1759 [00:03<00:35, 45.16it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.23it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.40it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.49it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.45it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 45.38it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 45.31it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 45.23it/s][A
 10%|█         | 177/1759 [00:03<00:34, 45.21it/s][A
 10%|█         | 182/1759 [00:03<00:34, 45.24it/s][A
 11%|█         | 187/1759 [00:04<00:34, 45.36it/s][A
 11%|█         | 192/1759 [00:04<00:34, 45.43it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.43it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 45.40it/s][A
 12%|█▏        | 207/1759 [00:04<00:34, 45.35it/s][A
 12%|█▏        | 212/1759 [00:04<00:34, 45.25it/s][A
 12%|█▏        | 217/1759 [00:04<00:36, 42.75it/s][A
 13%|█▎        | 222/1759 [00:04<00:35, 43.63it/s][A
 13%|█▎        | 227/1759 [00:05<00:34, 44.22it/s][A
 13%|█▎        | 232/1759 [00:05<00:34, 44.63it/s][A
 13%|█▎        | 237/1759 [00:05<00:33, 44.95it/s][A
 14%|█▍        | 242/1759 [00:05<00:33, 45.11it/s][A
 14%|█▍        | 247/1759 [00:05<00:33, 45.28it/s][A
 14%|█▍        | 252/1759 [00:05<00:33, 45.26it/s][A
 15%|█▍        | 257/1759 [00:05<00:33, 45.05it/s][A
 15%|█▍        | 262/1759 [00:05<00:33, 45.01it/s][A
 15%|█▌        | 267/1759 [00:05<00:33, 45.06it/s][A
 15%|█▌        | 272/1759 [00:06<00:32, 45.21it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 45.31it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.43it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.46it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.49it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 45.34it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 45.18it/s][A
 17%|█▋        | 307/1759 [00:06<00:32, 45.06it/s][A
 18%|█▊        | 312/1759 [00:06<00:32, 45.14it/s][A
 18%|█▊        | 317/1759 [00:06<00:31, 45.21it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 45.37it/s][A
 19%|█▊        | 327/1759 [00:07<00:31, 45.42it/s][A
 19%|█▉        | 332/1759 [00:07<00:31, 45.36it/s][A
 19%|█▉        | 337/1759 [00:07<00:31, 45.52it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 45.43it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 45.17it/s][A
 20%|██        | 352/1759 [00:07<00:31, 45.11it/s][A
 20%|██        | 357/1759 [00:07<00:33, 41.29it/s][A
 21%|██        | 362/1759 [00:08<00:32, 42.55it/s][A
 21%|██        | 367/1759 [00:08<00:31, 43.52it/s][A
 21%|██        | 372/1759 [00:08<00:31, 44.15it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 44.59it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 44.93it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 45.17it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 45.14it/s][A
 23%|██▎       | 397/1759 [00:08<00:30, 44.86it/s][A
 23%|██▎       | 402/1759 [00:08<00:30, 44.68it/s][A
 23%|██▎       | 407/1759 [00:09<00:30, 44.80it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.05it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.20it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.45it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 45.53it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 45.62it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 45.45it/s][A
 25%|██▌       | 442/1759 [00:09<00:29, 45.19it/s][A
 25%|██▌       | 447/1759 [00:09<00:29, 44.93it/s][A
 26%|██▌       | 452/1759 [00:10<00:29, 44.92it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 45.08it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.26it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.38it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 45.50it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 45.56it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 45.49it/s][A
 28%|██▊       | 487/1759 [00:10<00:28, 45.25it/s][A
 28%|██▊       | 492/1759 [00:10<00:29, 42.97it/s][A
 28%|██▊       | 497/1759 [00:11<00:28, 43.70it/s][A
 29%|██▊       | 502/1759 [00:11<00:28, 44.15it/s][A
 29%|██▉       | 507/1759 [00:11<00:28, 44.56it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 44.85it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 45.15it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 45.30it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 45.30it/s][A
 30%|███       | 532/1759 [00:11<00:27, 45.00it/s][A
 31%|███       | 537/1759 [00:11<00:27, 44.88it/s][A
 31%|███       | 542/1759 [00:12<00:27, 44.86it/s][A
 31%|███       | 547/1759 [00:12<00:26, 45.16it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.30it/s][A
 32%|███▏      | 557/1759 [00:12<00:26, 45.36it/s][A
 32%|███▏      | 562/1759 [00:12<00:26, 45.46it/s][A
 32%|███▏      | 567/1759 [00:12<00:26, 45.48it/s][A
 33%|███▎      | 572/1759 [00:12<00:26, 45.37it/s][A
 33%|███▎      | 577/1759 [00:12<00:26, 45.19it/s][A
 33%|███▎      | 582/1759 [00:12<00:26, 45.10it/s][A
 33%|███▎      | 587/1759 [00:13<00:26, 45.06it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.15it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 45.26it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 45.42it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 45.47it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 45.49it/s][A
 35%|███▌      | 617/1759 [00:13<00:25, 45.36it/s][A
 35%|███▌      | 622/1759 [00:13<00:25, 45.11it/s][A
 36%|███▌      | 627/1759 [00:13<00:31, 36.24it/s][A
 36%|███▌      | 632/1759 [00:14<00:29, 38.70it/s][A
 36%|███▌      | 637/1759 [00:14<00:27, 40.58it/s][A
 36%|███▋      | 642/1759 [00:14<00:26, 42.06it/s][A
 37%|███▋      | 647/1759 [00:14<00:25, 43.11it/s][A
 37%|███▋      | 652/1759 [00:14<00:25, 43.88it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 44.48it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 44.75it/s][A
 38%|███▊      | 667/1759 [00:14<00:24, 44.57it/s][A
 38%|███▊      | 672/1759 [00:14<00:24, 44.48it/s][A
 38%|███▊      | 677/1759 [00:15<00:24, 44.53it/s][A
 39%|███▉      | 682/1759 [00:15<00:24, 44.73it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 44.96it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 45.18it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 45.34it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 45.48it/s][A
 40%|████      | 707/1759 [00:15<00:23, 45.54it/s][A
 40%|████      | 712/1759 [00:15<00:23, 45.42it/s][A
 41%|████      | 717/1759 [00:15<00:23, 45.25it/s][A
 41%|████      | 722/1759 [00:16<00:22, 45.10it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 45.10it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 45.15it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 45.31it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 45.37it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 45.43it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 45.44it/s][A
 43%|████▎     | 757/1759 [00:16<00:22, 45.35it/s][A
 43%|████▎     | 762/1759 [00:17<00:25, 39.53it/s][A
 44%|████▎     | 767/1759 [00:17<00:24, 41.23it/s][A
 44%|████▍     | 772/1759 [00:17<00:23, 42.45it/s][A
 44%|████▍     | 777/1759 [00:17<00:22, 43.42it/s][A
 44%|████▍     | 782/1759 [00:17<00:22, 44.03it/s][A
 45%|████▍     | 787/1759 [00:17<00:21, 44.53it/s][A
 45%|████▌     | 792/1759 [00:17<00:21, 44.88it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 45.11it/s][A
 46%|████▌     | 802/1759 [00:17<00:21, 44.83it/s][A
 46%|████▌     | 807/1759 [00:18<00:21, 44.77it/s][A
 46%|████▌     | 812/1759 [00:18<00:21, 44.88it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 45.08it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 45.25it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 45.38it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 45.44it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 45.47it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 45.37it/s][A
 48%|████▊     | 847/1759 [00:18<00:20, 45.12it/s][A
 48%|████▊     | 852/1759 [00:18<00:20, 44.97it/s][A
 49%|████▊     | 857/1759 [00:19<00:20, 45.03it/s][A
 49%|████▉     | 862/1759 [00:19<00:19, 45.08it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 45.24it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 45.39it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 45.47it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 45.45it/s][A
 50%|█████     | 887/1759 [00:19<00:19, 45.42it/s][A
 51%|█████     | 892/1759 [00:19<00:19, 45.25it/s][A
 51%|█████     | 897/1759 [00:20<00:21, 39.70it/s][A
 51%|█████▏    | 902/1759 [00:20<00:20, 41.27it/s][A
 52%|█████▏    | 907/1759 [00:20<00:20, 42.55it/s][A
 52%|█████▏    | 912/1759 [00:20<00:19, 43.39it/s][A
 52%|█████▏    | 917/1759 [00:20<00:19, 44.08it/s][A
 52%|█████▏    | 922/1759 [00:20<00:18, 44.49it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 44.84it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 45.00it/s][A
 53%|█████▎    | 937/1759 [00:20<00:18, 44.71it/s][A
 54%|█████▎    | 942/1759 [00:21<00:18, 44.74it/s][A
 54%|█████▍    | 947/1759 [00:21<00:18, 44.91it/s][A
 54%|█████▍    | 952/1759 [00:21<00:17, 45.07it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 45.21it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 45.33it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 45.39it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 45.46it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 45.32it/s][A
 56%|█████▌    | 982/1759 [00:21<00:17, 45.12it/s][A
 56%|█████▌    | 987/1759 [00:22<00:17, 44.99it/s][A
 56%|█████▋    | 992/1759 [00:22<00:17, 45.02it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 45.12it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 45.28it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.44it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 45.46it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:16, 45.44it/s][A
 58%|█████▊    | 1022/1759 [00:22<00:16, 45.33it/s][A
 58%|█████▊    | 1027/1759 [00:23<00:16, 45.17it/s][A
 59%|█████▊    | 1032/1759 [00:23<00:20, 35.76it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:18, 38.33it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:19, 36.86it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:17, 39.59it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:17, 41.34it/s][A
 60%|██████    | 1057/1759 [00:23<00:16, 42.57it/s][A
 60%|██████    | 1062/1759 [00:23<00:16, 43.52it/s][A
 61%|██████    | 1067/1759 [00:23<00:15, 44.03it/s][A
 61%|██████    | 1072/1759 [00:24<00:15, 44.14it/s][A
 61%|██████    | 1077/1759 [00:24<00:15, 44.46it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:15, 44.62it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:15, 44.62it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 44.78it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 45.04it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 45.21it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 45.42it/s][A
 63%|██████▎   | 1112/1759 [00:24<00:14, 45.34it/s][A
 64%|██████▎   | 1117/1759 [00:25<00:14, 45.21it/s][A
 64%|██████▍   | 1122/1759 [00:25<00:14, 45.14it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:14, 45.08it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:13, 45.12it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 45.07it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 45.18it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 45.29it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 45.46it/s][A
 66%|██████▌   | 1157/1759 [00:25<00:13, 45.45it/s][A
 66%|██████▌   | 1162/1759 [00:26<00:13, 45.38it/s][A
 66%|██████▋   | 1167/1759 [00:26<00:14, 41.94it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:13, 42.99it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:13, 43.67it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:13, 44.06it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 44.43it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:12, 44.78it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 45.06it/s][A
 68%|██████▊   | 1202/1759 [00:26<00:12, 45.22it/s][A
 69%|██████▊   | 1207/1759 [00:27<00:12, 44.97it/s][A
 69%|██████▉   | 1212/1759 [00:27<00:12, 45.02it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:11, 45.17it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:11, 45.24it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 45.18it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 45.17it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 45.20it/s][A
 71%|███████   | 1242/1759 [00:27<00:11, 45.29it/s][A
 71%|███████   | 1247/1759 [00:27<00:11, 45.34it/s][A
 71%|███████   | 1252/1759 [00:28<00:11, 45.21it/s][A
 71%|███████▏  | 1257/1759 [00:28<00:11, 45.17it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:10, 45.19it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:10, 45.31it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:10, 45.25it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 45.19it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 45.24it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 45.37it/s][A
 73%|███████▎  | 1292/1759 [00:28<00:10, 45.30it/s][A
 74%|███████▎  | 1297/1759 [00:29<00:10, 45.23it/s][A
 74%|███████▍  | 1302/1759 [00:29<00:10, 42.80it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 43.60it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:10, 44.24it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:09, 44.55it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 44.76it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 44.92it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 45.20it/s][A
 76%|███████▌  | 1337/1759 [00:29<00:09, 45.18it/s][A
 76%|███████▋  | 1342/1759 [00:30<00:09, 44.95it/s][A
 77%|███████▋  | 1347/1759 [00:30<00:09, 44.97it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 45.04it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:08, 45.21it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 45.31it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 45.35it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:08, 45.40it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:08, 45.46it/s][A
 79%|███████▊  | 1382/1759 [00:30<00:08, 45.31it/s][A
 79%|███████▉  | 1387/1759 [00:31<00:08, 45.15it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 45.04it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 45.08it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:07, 45.16it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 45.20it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 45.23it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 45.36it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 45.43it/s][A
 81%|████████  | 1427/1759 [00:31<00:07, 45.12it/s][A
 81%|████████▏ | 1432/1759 [00:32<00:07, 45.20it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 41.50it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 42.73it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:07, 43.60it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 44.26it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 44.64it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 44.94it/s][A
 83%|████████▎ | 1467/1759 [00:32<00:06, 45.05it/s][A
 84%|████████▎ | 1472/1759 [00:32<00:06, 45.03it/s][A
 84%|████████▍ | 1477/1759 [00:33<00:06, 44.74it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 44.63it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 44.85it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:05, 44.98it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 45.27it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 45.41it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 45.55it/s][A
 86%|████████▌ | 1512/1759 [00:33<00:05, 45.44it/s][A
 86%|████████▌ | 1517/1759 [00:33<00:05, 45.26it/s][A
 87%|████████▋ | 1522/1759 [00:34<00:05, 45.00it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 44.85it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 44.97it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 45.14it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 45.35it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 45.48it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 45.52it/s][A
 89%|████████▊ | 1557/1759 [00:34<00:04, 45.41it/s][A
 89%|████████▉ | 1562/1759 [00:34<00:04, 45.26it/s][A
 89%|████████▉ | 1567/1759 [00:35<00:04, 45.07it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 43.42it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 44.08it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 44.49it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 44.82it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 45.08it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 45.25it/s][A
 91%|█████████ | 1602/1759 [00:35<00:03, 45.22it/s][A
 91%|█████████▏| 1607/1759 [00:35<00:03, 45.11it/s][A
 92%|█████████▏| 1612/1759 [00:36<00:03, 44.81it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 44.85it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 45.04it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 45.20it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 45.35it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 45.43it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 45.46it/s][A
 94%|█████████▎| 1647/1759 [00:36<00:02, 45.35it/s][A
 94%|█████████▍| 1652/1759 [00:36<00:02, 45.13it/s][A
 94%|█████████▍| 1657/1759 [00:37<00:02, 44.92it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 44.97it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 45.04it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 45.19it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 45.33it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 45.49it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 45.50it/s][A
 96%|█████████▌| 1692/1759 [00:37<00:01, 45.44it/s][A
 96%|█████████▋| 1697/1759 [00:37<00:01, 45.20it/s][A
 97%|█████████▋| 1702/1759 [00:38<00:01, 44.94it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 41.82it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 42.83it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:00, 43.78it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 44.30it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 44.69it/s][A
 98%|█████████▊| 1732/1759 [00:38<00:00, 45.01it/s][A
 99%|█████████▊| 1737/1759 [00:38<00:00, 45.12it/s][A
 99%|█████████▉| 1742/1759 [00:38<00:00, 44.97it/s][A
 99%|█████████▉| 1747/1759 [00:39<00:00, 44.67it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 44.69it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 44.87it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 44.87it/s][A 40%|████      | 156/390 [02:25<01:07,  3.46it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 14:56:55,444 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-156
[INFO|configuration_utils.py:351] 2023-08-29 14:56:55,620 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-156/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:56:59,477 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-156/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:56:59,722 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-156/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:56:59,830 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-156/special_tokens_map.json
 40%|████      | 157/390 [02:39<1:02:55, 16.20s/it] 41%|████      | 158/390 [02:39<44:13, 11.44s/it]   41%|████      | 159/390 [02:40<31:09,  8.09s/it] 41%|████      | 160/390 [02:40<22:03,  5.75s/it] 41%|████▏     | 161/390 [02:40<15:42,  4.11s/it] 42%|████▏     | 162/390 [02:41<11:16,  2.97s/it] 42%|████▏     | 163/390 [02:41<08:39,  2.29s/it] 42%|████▏     | 164/390 [02:42<06:22,  1.69s/it] 42%|████▏     | 165/390 [02:42<04:45,  1.27s/it] 43%|████▎     | 166/390 [02:42<03:38,  1.02it/s] 43%|████▎     | 167/390 [02:42<02:51,  1.30it/s] 43%|████▎     | 168/390 [02:43<02:23,  1.55it/s] 43%|████▎     | 169/390 [02:43<01:58,  1.86it/s] 44%|████▎     | 170/390 [02:43<01:41,  2.17it/s] 44%|████▍     | 171/390 [02:44<01:29,  2.45it/s] 44%|████▍     | 172/390 [02:44<01:20,  2.69it/s] 44%|████▍     | 173/390 [02:44<01:14,  2.90it/s] 45%|████▍     | 174/390 [02:45<01:10,  3.06it/s] 45%|████▍     | 175/390 [02:45<01:07,  3.18it/s] 45%|████▌     | 176/390 [02:45<01:05,  3.28it/s] 45%|████▌     | 177/390 [02:45<01:03,  3.34it/s] 46%|████▌     | 178/390 [02:46<01:02,  3.40it/s] 46%|████▌     | 179/390 [02:46<01:04,  3.28it/s] 46%|████▌     | 180/390 [02:46<01:02,  3.35it/s] 46%|████▋     | 181/390 [02:47<01:01,  3.39it/s] 47%|████▋     | 182/390 [02:47<01:00,  3.43it/s] 47%|████▋     | 183/390 [02:47<00:59,  3.45it/s] 47%|████▋     | 184/390 [02:47<00:59,  3.47it/s] 47%|████▋     | 185/390 [02:48<00:58,  3.48it/s] 48%|████▊     | 186/390 [02:48<00:58,  3.49it/s] 48%|████▊     | 187/390 [02:48<00:58,  3.50it/s] 48%|████▊     | 188/390 [02:49<00:57,  3.50it/s] 48%|████▊     | 189/390 [02:49<00:57,  3.51it/s] 49%|████▊     | 190/390 [02:49<00:59,  3.34it/s] 49%|████▉     | 191/390 [02:49<00:58,  3.39it/s] 49%|████▉     | 192/390 [02:50<00:57,  3.43it/s] 49%|████▉     | 193/390 [02:50<00:57,  3.45it/s] 50%|████▉     | 194/390 [02:50<00:56,  3.47it/s] 50%|█████     | 195/390 [02:51<00:56,  3.48it/s] 50%|█████     | 196/390 [02:51<00:55,  3.49it/s] 51%|█████     | 197/390 [02:51<00:55,  3.50it/s] 51%|█████     | 198/390 [02:51<00:54,  3.50it/s] 51%|█████     | 199/390 [02:52<00:54,  3.50it/s] 51%|█████▏    | 200/390 [02:52<00:54,  3.51it/s] 52%|█████▏    | 201/390 [02:52<00:56,  3.34it/s] 52%|█████▏    | 202/390 [02:53<00:55,  3.39it/s] 52%|█████▏    | 203/390 [02:53<00:54,  3.43it/s] 52%|█████▏    | 204/390 [02:53<00:53,  3.45it/s] 53%|█████▎    | 205/390 [02:53<00:53,  3.47it/s] 53%|█████▎    | 206/390 [02:54<00:52,  3.48it/s] 53%|█████▎    | 207/390 [02:54<00:52,  3.49it/s] 53%|█████▎    | 208/390 [02:54<00:52,  3.49it/s] 54%|█████▎    | 209/390 [02:55<00:51,  3.49it/s] 54%|█████▍    | 210/390 [02:55<00:51,  3.49it/s] 54%|█████▍    | 211/390 [02:55<00:51,  3.50it/s] 54%|█████▍    | 212/390 [02:56<00:52,  3.40it/s] 55%|█████▍    | 213/390 [02:56<00:51,  3.43it/s] 55%|█████▍    | 214/390 [02:56<00:51,  3.45it/s] 55%|█████▌    | 215/390 [02:56<00:50,  3.47it/s] 55%|█████▌    | 216/390 [02:57<00:49,  3.48it/s] 56%|█████▌    | 217/390 [02:57<00:49,  3.49it/s] 56%|█████▌    | 218/390 [02:57<00:49,  3.50it/s] 56%|█████▌    | 219/390 [02:57<00:48,  3.50it/s] 56%|█████▋    | 220/390 [02:58<00:48,  3.50it/s] 57%|█████▋    | 221/390 [02:58<00:48,  3.50it/s] 57%|█████▋    | 222/390 [02:58<00:47,  3.50it/s] 57%|█████▋    | 223/390 [02:59<00:49,  3.37it/s] 57%|█████▋    | 224/390 [02:59<00:48,  3.41it/s] 58%|█████▊    | 225/390 [02:59<00:47,  3.44it/s] 58%|█████▊    | 226/390 [03:00<00:47,  3.46it/s] 58%|█████▊    | 227/390 [03:00<00:46,  3.47it/s] 58%|█████▊    | 228/390 [03:00<00:46,  3.48it/s] 59%|█████▊    | 229/390 [03:00<00:46,  3.49it/s] 59%|█████▉    | 230/390 [03:01<00:45,  3.50it/s] 59%|█████▉    | 231/390 [03:01<00:45,  3.50it/s] 59%|█████▉    | 232/390 [03:01<00:45,  3.50it/s] 60%|█████▉    | 233/390 [03:02<00:44,  3.51it/s] 60%|██████    | 234/390 [03:02<00:48,  3.24it/s][INFO|trainer.py:2140] 2023-08-29 14:57:32,003 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:57:32,004 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 14:57:32,004 >>   Batch size = 8
{'eval_loss': 0.986401379108429, 'eval_runtime': 39.3538, 'eval_samples_per_second': 357.45, 'eval_steps_per_second': 44.697, 'epoch': 1.99}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:30, 56.64it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.75it/s][A
  1%|          | 18/1759 [00:00<00:36, 47.82it/s][A
  1%|▏         | 23/1759 [00:00<00:36, 47.11it/s][A
  2%|▏         | 28/1759 [00:00<00:37, 46.36it/s][A
  2%|▏         | 33/1759 [00:00<00:37, 45.61it/s][A
  2%|▏         | 38/1759 [00:00<00:37, 45.43it/s][A
  2%|▏         | 43/1759 [00:00<00:37, 45.18it/s][A
  3%|▎         | 48/1759 [00:01<00:37, 45.23it/s][A
  3%|▎         | 53/1759 [00:01<00:37, 45.33it/s][A
  3%|▎         | 58/1759 [00:01<00:37, 45.48it/s][A
  4%|▎         | 63/1759 [00:01<00:37, 45.59it/s][A
  4%|▍         | 68/1759 [00:01<00:37, 45.68it/s][A
  4%|▍         | 73/1759 [00:01<00:36, 45.59it/s][A
  4%|▍         | 78/1759 [00:01<00:37, 45.36it/s][A
  5%|▍         | 83/1759 [00:01<00:37, 45.14it/s][A
  5%|▌         | 88/1759 [00:01<00:37, 45.02it/s][A
  5%|▌         | 93/1759 [00:02<00:36, 45.07it/s][A
  6%|▌         | 98/1759 [00:02<00:36, 45.14it/s][A
  6%|▌         | 103/1759 [00:02<00:36, 45.27it/s][A
  6%|▌         | 108/1759 [00:02<00:36, 45.38it/s][A
  6%|▋         | 113/1759 [00:02<00:36, 45.53it/s][A
  7%|▋         | 118/1759 [00:02<00:36, 45.55it/s][A
  7%|▋         | 123/1759 [00:02<00:35, 45.47it/s][A
  7%|▋         | 128/1759 [00:02<00:40, 40.19it/s][A
  8%|▊         | 133/1759 [00:02<00:38, 41.75it/s][A
  8%|▊         | 138/1759 [00:03<00:37, 42.88it/s][A
  8%|▊         | 143/1759 [00:03<00:36, 43.71it/s][A
  8%|▊         | 148/1759 [00:03<00:36, 44.31it/s][A
  9%|▊         | 153/1759 [00:03<00:35, 44.74it/s][A
  9%|▉         | 158/1759 [00:03<00:35, 45.06it/s][A
  9%|▉         | 163/1759 [00:03<00:35, 45.20it/s][A
 10%|▉         | 168/1759 [00:03<00:35, 44.87it/s][A
 10%|▉         | 173/1759 [00:03<00:35, 44.73it/s][A
 10%|█         | 178/1759 [00:03<00:35, 44.86it/s][A
 10%|█         | 183/1759 [00:04<00:35, 44.97it/s][A
 11%|█         | 188/1759 [00:04<00:34, 45.17it/s][A
 11%|█         | 193/1759 [00:04<00:34, 45.39it/s][A
 11%|█▏        | 198/1759 [00:04<00:34, 45.46it/s][A
 12%|█▏        | 203/1759 [00:04<00:34, 45.59it/s][A
 12%|█▏        | 208/1759 [00:04<00:34, 45.52it/s][A
 12%|█▏        | 213/1759 [00:04<00:34, 45.32it/s][A
 12%|█▏        | 218/1759 [00:04<00:34, 45.15it/s][A
 13%|█▎        | 223/1759 [00:04<00:34, 45.12it/s][A
 13%|█▎        | 228/1759 [00:05<00:33, 45.18it/s][A
 13%|█▎        | 233/1759 [00:05<00:33, 45.20it/s][A
 14%|█▎        | 238/1759 [00:05<00:33, 45.40it/s][A
 14%|█▍        | 243/1759 [00:05<00:33, 45.50it/s][A
 14%|█▍        | 248/1759 [00:05<00:33, 45.54it/s][A
 14%|█▍        | 253/1759 [00:05<00:33, 45.43it/s][A
 15%|█▍        | 258/1759 [00:05<00:33, 45.26it/s][A
 15%|█▍        | 263/1759 [00:05<00:40, 37.31it/s][A
 15%|█▌        | 268/1759 [00:06<00:37, 39.53it/s][A
 16%|█▌        | 273/1759 [00:06<00:36, 41.27it/s][A
 16%|█▌        | 278/1759 [00:06<00:34, 42.51it/s][A
 16%|█▌        | 283/1759 [00:06<00:33, 43.49it/s][A
 16%|█▋        | 288/1759 [00:06<00:33, 44.15it/s][A
 17%|█▋        | 293/1759 [00:06<00:32, 44.67it/s][A
 17%|█▋        | 298/1759 [00:06<00:32, 44.94it/s][A
 17%|█▋        | 303/1759 [00:06<00:32, 44.76it/s][A
 18%|█▊        | 308/1759 [00:06<00:32, 44.56it/s][A
 18%|█▊        | 313/1759 [00:06<00:32, 44.57it/s][A
 18%|█▊        | 318/1759 [00:07<00:32, 44.76it/s][A
 18%|█▊        | 323/1759 [00:07<00:36, 39.17it/s][A
 19%|█▊        | 328/1759 [00:07<00:34, 41.86it/s][A
 19%|█▉        | 333/1759 [00:07<00:33, 43.01it/s][A
 19%|█▉        | 338/1759 [00:07<00:32, 43.74it/s][A
 19%|█▉        | 343/1759 [00:07<00:31, 44.44it/s][A
 20%|█▉        | 348/1759 [00:07<00:31, 44.87it/s][A
 20%|██        | 353/1759 [00:07<00:31, 45.04it/s][A
 20%|██        | 358/1759 [00:08<00:31, 45.12it/s][A
 21%|██        | 363/1759 [00:08<00:30, 45.18it/s][A
 21%|██        | 368/1759 [00:08<00:31, 44.83it/s][A
 21%|██        | 373/1759 [00:08<00:30, 44.73it/s][A
 21%|██▏       | 378/1759 [00:08<00:30, 44.84it/s][A
 22%|██▏       | 383/1759 [00:08<00:30, 45.05it/s][A
 22%|██▏       | 388/1759 [00:08<00:30, 45.25it/s][A
 22%|██▏       | 393/1759 [00:08<00:30, 45.41it/s][A
 23%|██▎       | 398/1759 [00:08<00:29, 45.55it/s][A
 23%|██▎       | 403/1759 [00:09<00:29, 45.56it/s][A
 23%|██▎       | 408/1759 [00:09<00:29, 45.33it/s][A
 23%|██▎       | 413/1759 [00:09<00:29, 45.07it/s][A
 24%|██▍       | 418/1759 [00:09<00:29, 44.91it/s][A
 24%|██▍       | 423/1759 [00:09<00:29, 44.97it/s][A
 24%|██▍       | 428/1759 [00:09<00:29, 45.14it/s][A
 25%|██▍       | 433/1759 [00:09<00:29, 45.37it/s][A
 25%|██▍       | 438/1759 [00:09<00:29, 45.50it/s][A
 25%|██▌       | 443/1759 [00:09<00:28, 45.62it/s][A
 25%|██▌       | 448/1759 [00:10<00:28, 45.57it/s][A
 26%|██▌       | 453/1759 [00:10<00:28, 45.37it/s][A
 26%|██▌       | 458/1759 [00:10<00:28, 45.09it/s][A
 26%|██▋       | 463/1759 [00:10<00:28, 45.03it/s][A
 27%|██▋       | 468/1759 [00:10<00:28, 44.99it/s][A
 27%|██▋       | 473/1759 [00:10<00:28, 45.01it/s][A
 27%|██▋       | 478/1759 [00:10<00:28, 45.24it/s][A
 27%|██▋       | 483/1759 [00:10<00:28, 45.33it/s][A
 28%|██▊       | 488/1759 [00:10<00:27, 45.47it/s][A
 28%|██▊       | 493/1759 [00:11<00:27, 45.49it/s][A
 28%|██▊       | 498/1759 [00:11<00:27, 45.52it/s][A
 29%|██▊       | 503/1759 [00:11<00:27, 45.34it/s][A
 29%|██▉       | 508/1759 [00:11<00:31, 39.97it/s][A
 29%|██▉       | 513/1759 [00:11<00:29, 41.56it/s][A
 29%|██▉       | 518/1759 [00:11<00:29, 42.78it/s][A
 30%|██▉       | 523/1759 [00:11<00:28, 43.66it/s][A
 30%|███       | 528/1759 [00:11<00:27, 44.27it/s][A
 30%|███       | 533/1759 [00:11<00:27, 44.74it/s][A
 31%|███       | 538/1759 [00:12<00:27, 45.04it/s][A
 31%|███       | 543/1759 [00:12<00:26, 45.14it/s][A
 31%|███       | 548/1759 [00:12<00:27, 44.83it/s][A
 31%|███▏      | 553/1759 [00:12<00:27, 44.62it/s][A
 32%|███▏      | 558/1759 [00:12<00:26, 44.68it/s][A
 32%|███▏      | 563/1759 [00:12<00:26, 44.95it/s][A
 32%|███▏      | 568/1759 [00:12<00:26, 45.15it/s][A
 33%|███▎      | 573/1759 [00:12<00:26, 45.35it/s][A
 33%|███▎      | 578/1759 [00:12<00:25, 45.49it/s][A
 33%|███▎      | 583/1759 [00:13<00:25, 45.58it/s][A
 33%|███▎      | 588/1759 [00:13<00:25, 45.50it/s][A
 34%|███▎      | 593/1759 [00:13<00:25, 45.00it/s][A
 34%|███▍      | 598/1759 [00:13<00:25, 44.80it/s][A
 34%|███▍      | 603/1759 [00:13<00:25, 44.82it/s][A
 35%|███▍      | 608/1759 [00:13<00:25, 44.97it/s][A
 35%|███▍      | 613/1759 [00:13<00:25, 45.19it/s][A
 35%|███▌      | 618/1759 [00:13<00:25, 45.33it/s][A
 35%|███▌      | 623/1759 [00:13<00:24, 45.51it/s][A
 36%|███▌      | 628/1759 [00:14<00:24, 45.59it/s][A
 36%|███▌      | 633/1759 [00:14<00:24, 45.50it/s][A
 36%|███▋      | 638/1759 [00:14<00:24, 45.24it/s][A
 37%|███▋      | 643/1759 [00:14<00:26, 41.65it/s][A
 37%|███▋      | 648/1759 [00:14<00:25, 42.76it/s][A
 37%|███▋      | 653/1759 [00:14<00:25, 43.63it/s][A
 37%|███▋      | 658/1759 [00:14<00:24, 44.19it/s][A
 38%|███▊      | 663/1759 [00:14<00:24, 44.68it/s][A
 38%|███▊      | 668/1759 [00:14<00:24, 45.00it/s][A
 38%|███▊      | 673/1759 [00:15<00:24, 45.20it/s][A
 39%|███▊      | 678/1759 [00:15<00:23, 45.14it/s][A
 39%|███▉      | 683/1759 [00:15<00:24, 44.82it/s][A
 39%|███▉      | 688/1759 [00:15<00:23, 44.75it/s][A
 39%|███▉      | 693/1759 [00:15<00:23, 44.84it/s][A
 40%|███▉      | 698/1759 [00:15<00:23, 45.03it/s][A
 40%|███▉      | 703/1759 [00:15<00:23, 45.19it/s][A
 40%|████      | 708/1759 [00:15<00:23, 45.33it/s][A
 41%|████      | 713/1759 [00:15<00:23, 45.48it/s][A
 41%|████      | 718/1759 [00:16<00:22, 45.56it/s][A
 41%|████      | 723/1759 [00:16<00:22, 45.40it/s][A
 41%|████▏     | 728/1759 [00:16<00:22, 45.05it/s][A
 42%|████▏     | 733/1759 [00:16<00:22, 44.89it/s][A
 42%|████▏     | 738/1759 [00:16<00:22, 44.97it/s][A
 42%|████▏     | 743/1759 [00:16<00:22, 45.10it/s][A
 43%|████▎     | 748/1759 [00:16<00:22, 45.26it/s][A
 43%|████▎     | 753/1759 [00:16<00:22, 45.39it/s][A
 43%|████▎     | 758/1759 [00:16<00:22, 45.48it/s][A
 43%|████▎     | 763/1759 [00:17<00:21, 45.54it/s][A
 44%|████▎     | 768/1759 [00:17<00:21, 45.41it/s][A
 44%|████▍     | 773/1759 [00:17<00:21, 45.11it/s][A
 44%|████▍     | 778/1759 [00:17<00:23, 42.47it/s][A
 45%|████▍     | 783/1759 [00:17<00:22, 43.36it/s][A
 45%|████▍     | 788/1759 [00:17<00:22, 44.02it/s][A
 45%|████▌     | 793/1759 [00:17<00:21, 44.47it/s][A
 45%|████▌     | 798/1759 [00:17<00:21, 44.82it/s][A
 46%|████▌     | 803/1759 [00:17<00:21, 45.05it/s][A
 46%|████▌     | 808/1759 [00:18<00:21, 45.20it/s][A
 46%|████▌     | 813/1759 [00:18<00:20, 45.14it/s][A
 47%|████▋     | 818/1759 [00:18<00:21, 44.75it/s][A
 47%|████▋     | 823/1759 [00:18<00:20, 44.80it/s][A
 47%|████▋     | 828/1759 [00:18<00:20, 44.87it/s][A
 47%|████▋     | 833/1759 [00:18<00:20, 45.11it/s][A
 48%|████▊     | 838/1759 [00:18<00:20, 45.21it/s][A
 48%|████▊     | 843/1759 [00:18<00:20, 45.38it/s][A
 48%|████▊     | 848/1759 [00:18<00:20, 45.42it/s][A
 48%|████▊     | 853/1759 [00:19<00:19, 45.54it/s][A
 49%|████▉     | 858/1759 [00:19<00:19, 45.39it/s][A
 49%|████▉     | 863/1759 [00:19<00:19, 44.95it/s][A
 49%|████▉     | 868/1759 [00:19<00:19, 45.16it/s][A
 50%|████▉     | 873/1759 [00:19<00:19, 45.10it/s][A
 50%|████▉     | 878/1759 [00:19<00:19, 45.15it/s][A
 50%|█████     | 883/1759 [00:19<00:19, 45.26it/s][A
 50%|█████     | 888/1759 [00:19<00:19, 45.39it/s][A
 51%|█████     | 893/1759 [00:19<00:19, 45.43it/s][A
 51%|█████     | 898/1759 [00:20<00:18, 45.50it/s][A
 51%|█████▏    | 903/1759 [00:20<00:18, 45.40it/s][A
 52%|█████▏    | 908/1759 [00:20<00:18, 45.30it/s][A
 52%|█████▏    | 913/1759 [00:20<00:19, 42.35it/s][A
 52%|█████▏    | 918/1759 [00:20<00:19, 43.34it/s][A
 52%|█████▏    | 923/1759 [00:20<00:18, 44.01it/s][A
 53%|█████▎    | 928/1759 [00:20<00:18, 44.45it/s][A
 53%|█████▎    | 933/1759 [00:20<00:18, 44.80it/s][A
 53%|█████▎    | 938/1759 [00:20<00:18, 44.98it/s][A
 54%|█████▎    | 943/1759 [00:21<00:18, 45.08it/s][A
 54%|█████▍    | 948/1759 [00:21<00:17, 45.06it/s][A
 54%|█████▍    | 953/1759 [00:21<00:17, 44.82it/s][A
 54%|█████▍    | 958/1759 [00:21<00:17, 44.83it/s][A
 55%|█████▍    | 963/1759 [00:21<00:17, 44.88it/s][A
 55%|█████▌    | 968/1759 [00:21<00:17, 45.16it/s][A
 55%|█████▌    | 973/1759 [00:21<00:17, 45.25it/s][A
 56%|█████▌    | 978/1759 [00:21<00:17, 45.37it/s][A
 56%|█████▌    | 983/1759 [00:21<00:17, 45.41it/s][A
 56%|█████▌    | 988/1759 [00:22<00:16, 45.47it/s][A
 56%|█████▋    | 993/1759 [00:22<00:16, 45.08it/s][A
 57%|█████▋    | 998/1759 [00:22<00:16, 45.17it/s][A
 57%|█████▋    | 1003/1759 [00:22<00:16, 45.19it/s][A
 57%|█████▋    | 1008/1759 [00:22<00:16, 45.02it/s][A
 58%|█████▊    | 1013/1759 [00:22<00:16, 45.23it/s][A
 58%|█████▊    | 1018/1759 [00:22<00:16, 45.31it/s][A
 58%|█████▊    | 1023/1759 [00:22<00:16, 45.47it/s][A
 58%|█████▊    | 1028/1759 [00:22<00:16, 45.47it/s][A
 59%|█████▊    | 1033/1759 [00:23<00:15, 45.54it/s][A
 59%|█████▉    | 1038/1759 [00:23<00:15, 45.35it/s][A
 59%|█████▉    | 1043/1759 [00:23<00:15, 45.30it/s][A
 60%|█████▉    | 1048/1759 [00:23<00:17, 40.74it/s][A
 60%|█████▉    | 1053/1759 [00:23<00:16, 42.14it/s][A
 60%|██████    | 1058/1759 [00:23<00:16, 43.19it/s][A
 60%|██████    | 1063/1759 [00:23<00:15, 43.96it/s][A
 61%|██████    | 1068/1759 [00:23<00:15, 44.52it/s][A
 61%|██████    | 1073/1759 [00:23<00:15, 44.88it/s][A
 61%|██████▏   | 1078/1759 [00:24<00:15, 45.15it/s][A
 62%|██████▏   | 1083/1759 [00:24<00:14, 45.11it/s][A
 62%|██████▏   | 1088/1759 [00:24<00:14, 44.82it/s][A
 62%|██████▏   | 1093/1759 [00:24<00:14, 44.64it/s][A
 62%|██████▏   | 1098/1759 [00:24<00:14, 44.70it/s][A
 63%|██████▎   | 1103/1759 [00:24<00:14, 44.91it/s][A
 63%|██████▎   | 1108/1759 [00:24<00:14, 45.07it/s][A
 63%|██████▎   | 1113/1759 [00:24<00:14, 45.25it/s][A
 64%|██████▎   | 1118/1759 [00:24<00:14, 45.37it/s][A
 64%|██████▍   | 1123/1759 [00:25<00:13, 45.53it/s][A
 64%|██████▍   | 1128/1759 [00:25<00:13, 45.53it/s][A
 64%|██████▍   | 1133/1759 [00:25<00:13, 45.29it/s][A
 65%|██████▍   | 1138/1759 [00:25<00:13, 45.00it/s][A
 65%|██████▍   | 1143/1759 [00:25<00:13, 44.91it/s][A
 65%|██████▌   | 1148/1759 [00:25<00:13, 44.97it/s][A
 66%|██████▌   | 1153/1759 [00:25<00:13, 45.00it/s][A
 66%|██████▌   | 1158/1759 [00:25<00:13, 45.21it/s][A
 66%|██████▌   | 1163/1759 [00:25<00:13, 45.31it/s][A
 66%|██████▋   | 1168/1759 [00:26<00:12, 45.49it/s][A
 67%|██████▋   | 1173/1759 [00:26<00:12, 45.48it/s][A
 67%|██████▋   | 1178/1759 [00:26<00:12, 45.39it/s][A
 67%|██████▋   | 1183/1759 [00:26<00:14, 40.67it/s][A
 68%|██████▊   | 1188/1759 [00:26<00:13, 42.06it/s][A
 68%|██████▊   | 1193/1759 [00:26<00:13, 43.12it/s][A
 68%|██████▊   | 1198/1759 [00:26<00:12, 43.85it/s][A
 68%|██████▊   | 1203/1759 [00:26<00:12, 44.38it/s][A
 69%|██████▊   | 1208/1759 [00:27<00:12, 44.74it/s][A
 69%|██████▉   | 1213/1759 [00:27<00:12, 44.98it/s][A
 69%|██████▉   | 1218/1759 [00:27<00:11, 45.12it/s][A
 70%|██████▉   | 1223/1759 [00:27<00:11, 44.84it/s][A
 70%|██████▉   | 1228/1759 [00:27<00:11, 44.77it/s][A
 70%|███████   | 1233/1759 [00:27<00:11, 44.87it/s][A
 70%|███████   | 1238/1759 [00:27<00:11, 45.04it/s][A
 71%|███████   | 1243/1759 [00:27<00:11, 45.22it/s][A
 71%|███████   | 1248/1759 [00:27<00:11, 45.41it/s][A
 71%|███████   | 1253/1759 [00:27<00:11, 45.43it/s][A
 72%|███████▏  | 1258/1759 [00:28<00:11, 45.49it/s][A
 72%|███████▏  | 1263/1759 [00:28<00:10, 45.32it/s][A
 72%|███████▏  | 1268/1759 [00:28<00:10, 45.11it/s][A
 72%|███████▏  | 1273/1759 [00:28<00:10, 44.95it/s][A
 73%|███████▎  | 1278/1759 [00:28<00:10, 44.92it/s][A
 73%|███████▎  | 1283/1759 [00:28<00:10, 45.05it/s][A
 73%|███████▎  | 1288/1759 [00:28<00:10, 45.16it/s][A
 74%|███████▎  | 1293/1759 [00:28<00:10, 45.39it/s][A
 74%|███████▍  | 1298/1759 [00:28<00:10, 45.51it/s][A
 74%|███████▍  | 1303/1759 [00:29<00:10, 45.51it/s][A
 74%|███████▍  | 1308/1759 [00:29<00:09, 45.34it/s][A
 75%|███████▍  | 1313/1759 [00:29<00:09, 45.17it/s][A
 75%|███████▍  | 1318/1759 [00:29<00:10, 40.69it/s][A
 75%|███████▌  | 1323/1759 [00:29<00:10, 42.02it/s][A
 75%|███████▌  | 1328/1759 [00:29<00:10, 43.06it/s][A
 76%|███████▌  | 1333/1759 [00:29<00:09, 43.76it/s][A
 76%|███████▌  | 1338/1759 [00:29<00:09, 44.33it/s][A
 76%|███████▋  | 1343/1759 [00:30<00:09, 44.67it/s][A
 77%|███████▋  | 1348/1759 [00:30<00:09, 44.97it/s][A
 77%|███████▋  | 1353/1759 [00:30<00:08, 45.13it/s][A
 77%|███████▋  | 1358/1759 [00:30<00:08, 44.86it/s][A
 77%|███████▋  | 1363/1759 [00:30<00:08, 44.77it/s][A
 78%|███████▊  | 1368/1759 [00:30<00:08, 44.94it/s][A
 78%|███████▊  | 1373/1759 [00:30<00:08, 45.07it/s][A
 78%|███████▊  | 1378/1759 [00:30<00:08, 45.27it/s][A
 79%|███████▊  | 1383/1759 [00:30<00:08, 45.34it/s][A
 79%|███████▉  | 1388/1759 [00:31<00:08, 45.42it/s][A
 79%|███████▉  | 1393/1759 [00:31<00:08, 45.41it/s][A
 79%|███████▉  | 1398/1759 [00:31<00:07, 45.29it/s][A
 80%|███████▉  | 1403/1759 [00:31<00:07, 45.11it/s][A
 80%|████████  | 1408/1759 [00:31<00:07, 44.99it/s][A
 80%|████████  | 1413/1759 [00:31<00:07, 44.99it/s][A
 81%|████████  | 1418/1759 [00:31<00:07, 45.06it/s][A
 81%|████████  | 1423/1759 [00:31<00:07, 45.25it/s][A
 81%|████████  | 1428/1759 [00:31<00:07, 45.39it/s][A
 81%|████████▏ | 1433/1759 [00:32<00:07, 45.52it/s][A
 82%|████████▏ | 1438/1759 [00:32<00:07, 45.46it/s][A
 82%|████████▏ | 1443/1759 [00:32<00:06, 45.34it/s][A
 82%|████████▏ | 1448/1759 [00:32<00:06, 45.19it/s][A
 83%|████████▎ | 1453/1759 [00:32<00:06, 44.60it/s][A
 83%|████████▎ | 1458/1759 [00:32<00:06, 44.78it/s][A
 83%|████████▎ | 1463/1759 [00:32<00:06, 44.92it/s][A
 83%|████████▎ | 1468/1759 [00:32<00:06, 45.11it/s][A
 84%|████████▎ | 1473/1759 [00:32<00:06, 45.30it/s][A
 84%|████████▍ | 1478/1759 [00:33<00:06, 45.43it/s][A
 84%|████████▍ | 1483/1759 [00:33<00:06, 45.39it/s][A
 85%|████████▍ | 1488/1759 [00:33<00:05, 45.31it/s][A
 85%|████████▍ | 1493/1759 [00:33<00:05, 45.16it/s][A
 85%|████████▌ | 1498/1759 [00:33<00:05, 45.04it/s][A
 85%|████████▌ | 1503/1759 [00:33<00:05, 45.06it/s][A
 86%|████████▌ | 1508/1759 [00:33<00:05, 45.06it/s][A
 86%|████████▌ | 1513/1759 [00:33<00:05, 45.16it/s][A
 86%|████████▋ | 1518/1759 [00:33<00:05, 45.25it/s][A
 87%|████████▋ | 1523/1759 [00:34<00:05, 45.38it/s][A
 87%|████████▋ | 1528/1759 [00:34<00:05, 45.44it/s][A
 87%|████████▋ | 1533/1759 [00:34<00:04, 45.39it/s][A
 87%|████████▋ | 1538/1759 [00:34<00:04, 45.21it/s][A
 88%|████████▊ | 1543/1759 [00:34<00:04, 45.08it/s][A
 88%|████████▊ | 1548/1759 [00:34<00:04, 45.17it/s][A
 88%|████████▊ | 1553/1759 [00:34<00:04, 45.16it/s][A
 89%|████████▊ | 1558/1759 [00:34<00:04, 45.23it/s][A
 89%|████████▉ | 1563/1759 [00:34<00:04, 45.24it/s][A
 89%|████████▉ | 1568/1759 [00:35<00:04, 45.39it/s][A
 89%|████████▉ | 1573/1759 [00:35<00:04, 45.42it/s][A
 90%|████████▉ | 1578/1759 [00:35<00:03, 45.39it/s][A
 90%|████████▉ | 1583/1759 [00:35<00:03, 45.22it/s][A
 90%|█████████ | 1588/1759 [00:35<00:03, 45.10it/s][A
 91%|█████████ | 1593/1759 [00:35<00:03, 41.78it/s][A
 91%|█████████ | 1598/1759 [00:35<00:03, 42.93it/s][A
 91%|█████████ | 1603/1759 [00:35<00:03, 43.67it/s][A
 91%|█████████▏| 1608/1759 [00:35<00:03, 44.25it/s][A
 92%|█████████▏| 1613/1759 [00:36<00:03, 44.68it/s][A
 92%|█████████▏| 1618/1759 [00:36<00:03, 44.95it/s][A
 92%|█████████▏| 1623/1759 [00:36<00:03, 42.79it/s][A
 93%|█████████▎| 1629/1759 [00:36<00:02, 44.88it/s][A
 93%|█████████▎| 1634/1759 [00:36<00:02, 44.72it/s][A
 93%|█████████▎| 1639/1759 [00:36<00:02, 44.85it/s][A
 93%|█████████▎| 1644/1759 [00:36<00:02, 45.00it/s][A
 94%|█████████▎| 1649/1759 [00:36<00:02, 45.18it/s][A
 94%|█████████▍| 1654/1759 [00:36<00:02, 45.31it/s][A
 94%|█████████▍| 1659/1759 [00:37<00:02, 45.41it/s][A
 95%|█████████▍| 1664/1759 [00:37<00:02, 45.36it/s][A
 95%|█████████▍| 1669/1759 [00:37<00:01, 45.40it/s][A
 95%|█████████▌| 1674/1759 [00:37<00:01, 45.21it/s][A
 95%|█████████▌| 1679/1759 [00:37<00:01, 45.04it/s][A
 96%|█████████▌| 1684/1759 [00:37<00:01, 45.05it/s][A
 96%|█████████▌| 1689/1759 [00:37<00:01, 45.12it/s][A
 96%|█████████▋| 1694/1759 [00:37<00:01, 45.28it/s][A
 97%|█████████▋| 1699/1759 [00:37<00:01, 45.38it/s][A
 97%|█████████▋| 1704/1759 [00:38<00:01, 45.48it/s][A
 97%|█████████▋| 1709/1759 [00:38<00:01, 45.44it/s][A
 97%|█████████▋| 1714/1759 [00:38<00:00, 45.37it/s][A
 98%|█████████▊| 1719/1759 [00:38<00:00, 45.24it/s][A
 98%|█████████▊| 1724/1759 [00:38<00:00, 45.19it/s][A
 98%|█████████▊| 1729/1759 [00:38<00:00, 42.83it/s][A
 99%|█████████▊| 1734/1759 [00:38<00:00, 43.62it/s][A
 99%|█████████▉| 1739/1759 [00:38<00:00, 44.24it/s][A
 99%|█████████▉| 1744/1759 [00:38<00:00, 40.44it/s][A
 99%|█████████▉| 1749/1759 [00:39<00:00, 23.44it/s][A
100%|█████████▉| 1754/1759 [00:39<00:00, 27.54it/s][A
100%|██████████| 1759/1759 [00:39<00:00, 31.29it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 31.29it/s][A 60%|██████    | 234/390 [03:42<00:48,  3.24it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 14:58:11,974 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-234
[INFO|configuration_utils.py:351] 2023-08-29 14:58:12,212 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-234/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:58:16,382 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-234/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:58:16,589 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-234/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:58:16,692 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-234/special_tokens_map.json
 60%|██████    | 235/390 [03:55<42:04, 16.29s/it] 61%|██████    | 236/390 [03:56<29:30, 11.50s/it] 61%|██████    | 237/390 [03:56<20:44,  8.14s/it] 61%|██████    | 238/390 [03:56<14:38,  5.78s/it] 61%|██████▏   | 239/390 [03:57<10:24,  4.14s/it] 62%|██████▏   | 240/390 [03:57<07:27,  2.98s/it] 62%|██████▏   | 241/390 [03:57<05:23,  2.17s/it] 62%|██████▏   | 242/390 [03:58<03:58,  1.61s/it] 62%|██████▏   | 243/390 [03:58<02:58,  1.21s/it] 63%|██████▎   | 244/390 [03:58<02:16,  1.07it/s] 63%|██████▎   | 245/390 [03:58<01:47,  1.35it/s] 63%|██████▎   | 246/390 [03:59<01:27,  1.65it/s] 63%|██████▎   | 247/390 [03:59<01:14,  1.92it/s] 64%|██████▎   | 248/390 [03:59<01:04,  2.22it/s] 64%|██████▍   | 249/390 [04:00<00:56,  2.49it/s] 64%|██████▍   | 250/390 [04:00<00:51,  2.73it/s] 64%|██████▍   | 251/390 [04:00<00:47,  2.93it/s] 65%|██████▍   | 252/390 [04:00<00:44,  3.08it/s] 65%|██████▍   | 253/390 [04:01<00:42,  3.20it/s] 65%|██████▌   | 254/390 [04:01<00:41,  3.28it/s] 65%|██████▌   | 255/390 [04:01<00:40,  3.35it/s] 66%|██████▌   | 256/390 [04:02<00:39,  3.40it/s] 66%|██████▌   | 257/390 [04:02<00:38,  3.43it/s] 66%|██████▌   | 258/390 [04:02<00:40,  3.23it/s] 66%|██████▋   | 259/390 [04:03<00:39,  3.32it/s] 67%|██████▋   | 260/390 [04:03<00:38,  3.37it/s] 67%|██████▋   | 261/390 [04:03<00:37,  3.41it/s] 67%|██████▋   | 262/390 [04:03<00:37,  3.44it/s] 67%|██████▋   | 263/390 [04:04<00:36,  3.47it/s] 68%|██████▊   | 264/390 [04:04<00:36,  3.48it/s] 68%|██████▊   | 265/390 [04:04<00:35,  3.49it/s] 68%|██████▊   | 266/390 [04:04<00:35,  3.50it/s] 68%|██████▊   | 267/390 [04:05<00:35,  3.50it/s] 69%|██████▊   | 268/390 [04:05<00:34,  3.51it/s] 69%|██████▉   | 269/390 [04:05<00:34,  3.51it/s] 69%|██████▉   | 270/390 [04:06<00:34,  3.51it/s] 69%|██████▉   | 271/390 [04:06<00:33,  3.51it/s] 70%|██████▉   | 272/390 [04:06<00:33,  3.51it/s] 70%|███████   | 273/390 [04:06<00:33,  3.51it/s] 70%|███████   | 274/390 [04:07<00:33,  3.51it/s] 71%|███████   | 275/390 [04:07<00:32,  3.51it/s] 71%|███████   | 276/390 [04:07<00:32,  3.51it/s] 71%|███████   | 277/390 [04:08<00:32,  3.51it/s] 71%|███████▏  | 278/390 [04:08<00:31,  3.51it/s] 72%|███████▏  | 279/390 [04:08<00:34,  3.18it/s] 72%|███████▏  | 280/390 [04:09<00:33,  3.28it/s] 72%|███████▏  | 281/390 [04:09<00:32,  3.34it/s] 72%|███████▏  | 282/390 [04:09<00:31,  3.39it/s] 73%|███████▎  | 283/390 [04:09<00:31,  3.42it/s] 73%|███████▎  | 284/390 [04:10<00:30,  3.45it/s] 73%|███████▎  | 285/390 [04:10<00:30,  3.47it/s] 73%|███████▎  | 286/390 [04:10<00:29,  3.48it/s] 74%|███████▎  | 287/390 [04:11<00:29,  3.48it/s] 74%|███████▍  | 288/390 [04:11<00:29,  3.49it/s] 74%|███████▍  | 289/390 [04:11<00:28,  3.50it/s] 74%|███████▍  | 290/390 [04:11<00:28,  3.50it/s] 75%|███████▍  | 291/390 [04:12<00:28,  3.51it/s] 75%|███████▍  | 292/390 [04:12<00:27,  3.51it/s] 75%|███████▌  | 293/390 [04:12<00:27,  3.51it/s] 75%|███████▌  | 294/390 [04:13<00:27,  3.51it/s] 76%|███████▌  | 295/390 [04:13<00:27,  3.51it/s] 76%|███████▌  | 296/390 [04:13<00:26,  3.51it/s] 76%|███████▌  | 297/390 [04:13<00:26,  3.51it/s] 76%|███████▋  | 298/390 [04:14<00:26,  3.51it/s] 77%|███████▋  | 299/390 [04:14<00:25,  3.51it/s] 77%|███████▋  | 300/390 [04:14<00:25,  3.51it/s] 77%|███████▋  | 301/390 [04:15<00:25,  3.51it/s] 77%|███████▋  | 302/390 [04:15<00:25,  3.51it/s] 78%|███████▊  | 303/390 [04:15<00:24,  3.51it/s] 78%|███████▊  | 304/390 [04:15<00:24,  3.51it/s] 78%|███████▊  | 305/390 [04:16<00:24,  3.51it/s] 78%|███████▊  | 306/390 [04:16<00:23,  3.51it/s] 79%|███████▊  | 307/390 [04:16<00:23,  3.51it/s] 79%|███████▉  | 308/390 [04:17<00:23,  3.51it/s] 79%|███████▉  | 309/390 [04:17<00:23,  3.51it/s] 79%|███████▉  | 310/390 [04:17<00:22,  3.51it/s] 80%|███████▉  | 311/390 [04:17<00:22,  3.51it/s] 80%|████████  | 312/390 [04:18<00:22,  3.51it/s][INFO|trainer.py:2140] 2023-08-29 14:58:47,805 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:58:47,805 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 14:58:47,805 >>   Batch size = 8
{'eval_loss': 0.9941954016685486, 'eval_runtime': 39.6423, 'eval_samples_per_second': 354.848, 'eval_steps_per_second': 44.372, 'epoch': 2.99}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:30, 56.60it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.43it/s][A
  1%|          | 18/1759 [00:00<00:36, 47.40it/s][A
  1%|▏         | 23/1759 [00:00<00:37, 46.50it/s][A
  2%|▏         | 28/1759 [00:00<00:37, 46.06it/s][A
  2%|▏         | 33/1759 [00:00<00:37, 45.74it/s][A
  2%|▏         | 38/1759 [00:00<00:37, 45.51it/s][A
  2%|▏         | 43/1759 [00:00<00:37, 45.38it/s][A
  3%|▎         | 48/1759 [00:01<00:37, 45.37it/s][A
  3%|▎         | 53/1759 [00:01<00:37, 45.54it/s][A
  3%|▎         | 58/1759 [00:01<00:37, 45.61it/s][A
  4%|▎         | 63/1759 [00:01<00:37, 45.60it/s][A
  4%|▍         | 68/1759 [00:01<00:37, 45.39it/s][A
  4%|▍         | 73/1759 [00:01<00:37, 45.33it/s][A
  4%|▍         | 78/1759 [00:01<00:37, 45.22it/s][A
  5%|▍         | 83/1759 [00:01<00:37, 45.18it/s][A
  5%|▌         | 88/1759 [00:01<00:37, 45.15it/s][A
  5%|▌         | 93/1759 [00:02<00:36, 45.18it/s][A
  6%|▌         | 98/1759 [00:02<00:36, 45.29it/s][A
  6%|▌         | 103/1759 [00:02<00:36, 45.38it/s][A
  6%|▌         | 108/1759 [00:02<00:36, 45.46it/s][A
  6%|▋         | 113/1759 [00:02<00:36, 45.48it/s][A
  7%|▋         | 118/1759 [00:02<00:36, 45.37it/s][A
  7%|▋         | 123/1759 [00:02<00:36, 45.28it/s][A
  7%|▋         | 128/1759 [00:02<00:36, 45.18it/s][A
  8%|▊         | 133/1759 [00:02<00:36, 45.15it/s][A
  8%|▊         | 138/1759 [00:03<00:35, 45.16it/s][A
  8%|▊         | 143/1759 [00:03<00:35, 45.20it/s][A
  8%|▊         | 148/1759 [00:03<00:35, 45.32it/s][A
  9%|▊         | 153/1759 [00:03<00:35, 45.41it/s][A
  9%|▉         | 158/1759 [00:03<00:35, 45.46it/s][A
  9%|▉         | 163/1759 [00:03<00:35, 45.40it/s][A
 10%|▉         | 168/1759 [00:03<00:35, 45.35it/s][A
 10%|▉         | 173/1759 [00:03<00:35, 45.23it/s][A
 10%|█         | 178/1759 [00:03<00:34, 45.25it/s][A
 10%|█         | 183/1759 [00:04<00:34, 45.22it/s][A
 11%|█         | 188/1759 [00:04<00:34, 45.22it/s][A
 11%|█         | 193/1759 [00:04<00:34, 45.28it/s][A
 11%|█▏        | 198/1759 [00:04<00:34, 45.37it/s][A
 12%|█▏        | 203/1759 [00:04<00:34, 45.46it/s][A
 12%|█▏        | 208/1759 [00:04<00:34, 45.44it/s][A
 12%|█▏        | 213/1759 [00:04<00:34, 45.37it/s][A
 12%|█▏        | 218/1759 [00:04<00:34, 45.28it/s][A
 13%|█▎        | 223/1759 [00:04<00:33, 45.21it/s][A
 13%|█▎        | 228/1759 [00:05<00:33, 45.20it/s][A
 13%|█▎        | 233/1759 [00:05<00:33, 45.22it/s][A
 14%|█▎        | 238/1759 [00:05<00:33, 45.35it/s][A
 14%|█▍        | 243/1759 [00:05<00:33, 45.40it/s][A
 14%|█▍        | 248/1759 [00:05<00:33, 45.42it/s][A
 14%|█▍        | 253/1759 [00:05<00:33, 45.42it/s][A
 15%|█▍        | 258/1759 [00:05<00:33, 45.34it/s][A
 15%|█▍        | 263/1759 [00:05<00:33, 45.22it/s][A
 15%|█▌        | 268/1759 [00:05<00:33, 45.16it/s][A
 16%|█▌        | 273/1759 [00:06<00:37, 39.92it/s][A
 16%|█▌        | 278/1759 [00:06<00:35, 41.52it/s][A
 16%|█▌        | 283/1759 [00:06<00:34, 42.74it/s][A
 16%|█▋        | 288/1759 [00:06<00:33, 43.45it/s][A
 17%|█▋        | 293/1759 [00:06<00:33, 44.26it/s][A
 17%|█▋        | 298/1759 [00:06<00:32, 44.68it/s][A
 17%|█▋        | 303/1759 [00:06<00:32, 45.03it/s][A
 18%|█▊        | 308/1759 [00:06<00:32, 45.14it/s][A
 18%|█▊        | 313/1759 [00:06<00:32, 44.82it/s][A
 18%|█▊        | 318/1759 [00:07<00:32, 44.63it/s][A
 18%|█▊        | 323/1759 [00:07<00:32, 44.72it/s][A
 19%|█▊        | 328/1759 [00:07<00:31, 44.97it/s][A
 19%|█▉        | 333/1759 [00:07<00:31, 45.17it/s][A
 19%|█▉        | 338/1759 [00:07<00:31, 45.39it/s][A
 19%|█▉        | 343/1759 [00:07<00:31, 45.52it/s][A
 20%|█▉        | 348/1759 [00:07<00:30, 45.58it/s][A
 20%|██        | 353/1759 [00:07<00:30, 45.46it/s][A
 20%|██        | 358/1759 [00:07<00:31, 45.18it/s][A
 21%|██        | 363/1759 [00:08<00:31, 44.95it/s][A
 21%|██        | 368/1759 [00:08<00:30, 44.98it/s][A
 21%|██        | 373/1759 [00:08<00:30, 45.07it/s][A
 21%|██▏       | 378/1759 [00:08<00:30, 45.24it/s][A
 22%|██▏       | 383/1759 [00:08<00:30, 45.39it/s][A
 22%|██▏       | 388/1759 [00:08<00:30, 45.52it/s][A
 22%|██▏       | 393/1759 [00:08<00:29, 45.59it/s][A
 23%|██▎       | 398/1759 [00:08<00:29, 45.48it/s][A
 23%|██▎       | 403/1759 [00:08<00:30, 45.20it/s][A
 23%|██▎       | 408/1759 [00:09<00:32, 41.68it/s][A
 23%|██▎       | 413/1759 [00:09<00:31, 42.85it/s][A
 24%|██▍       | 418/1759 [00:09<00:30, 43.65it/s][A
 24%|██▍       | 423/1759 [00:09<00:30, 44.25it/s][A
 24%|██▍       | 428/1759 [00:09<00:29, 44.69it/s][A
 25%|██▍       | 433/1759 [00:09<00:29, 45.02it/s][A
 25%|██▍       | 438/1759 [00:09<00:29, 45.15it/s][A
 25%|██▌       | 443/1759 [00:09<00:29, 45.15it/s][A
 25%|██▌       | 448/1759 [00:09<00:29, 44.85it/s][A
 26%|██▌       | 453/1759 [00:10<00:29, 44.72it/s][A
 26%|██▌       | 458/1759 [00:10<00:28, 44.95it/s][A
 26%|██▋       | 463/1759 [00:10<00:28, 45.12it/s][A
 27%|██▋       | 468/1759 [00:10<00:28, 45.31it/s][A
 27%|██▋       | 473/1759 [00:10<00:28, 45.43it/s][A
 27%|██▋       | 478/1759 [00:10<00:28, 45.52it/s][A
 27%|██▋       | 483/1759 [00:10<00:27, 45.63it/s][A
 28%|██▊       | 488/1759 [00:10<00:27, 45.51it/s][A
 28%|██▊       | 493/1759 [00:10<00:27, 45.24it/s][A
 28%|██▊       | 498/1759 [00:11<00:27, 45.09it/s][A
 29%|██▊       | 503/1759 [00:11<00:27, 45.05it/s][A
 29%|██▉       | 508/1759 [00:11<00:27, 45.14it/s][A
 29%|██▉       | 513/1759 [00:11<00:27, 45.25it/s][A
 29%|██▉       | 518/1759 [00:11<00:27, 45.45it/s][A
 30%|██▉       | 523/1759 [00:11<00:27, 45.55it/s][A
 30%|███       | 528/1759 [00:11<00:27, 45.59it/s][A
 30%|███       | 533/1759 [00:11<00:26, 45.43it/s][A
 31%|███       | 538/1759 [00:11<00:26, 45.25it/s][A
 31%|███       | 543/1759 [00:12<00:27, 44.23it/s][A
 31%|███       | 548/1759 [00:12<00:27, 44.48it/s][A
 31%|███▏      | 553/1759 [00:12<00:26, 44.74it/s][A
 32%|███▏      | 558/1759 [00:12<00:26, 44.98it/s][A
 32%|███▏      | 563/1759 [00:12<00:26, 45.24it/s][A
 32%|███▏      | 568/1759 [00:12<00:26, 45.37it/s][A
 33%|███▎      | 573/1759 [00:12<00:26, 45.45it/s][A
 33%|███▎      | 578/1759 [00:12<00:26, 45.28it/s][A
 33%|███▎      | 583/1759 [00:12<00:26, 45.08it/s][A
 33%|███▎      | 588/1759 [00:13<00:26, 45.02it/s][A
 34%|███▎      | 593/1759 [00:13<00:25, 45.02it/s][A
 34%|███▍      | 598/1759 [00:13<00:25, 45.15it/s][A
 34%|███▍      | 603/1759 [00:13<00:25, 45.29it/s][A
 35%|███▍      | 608/1759 [00:13<00:25, 45.41it/s][A
 35%|███▍      | 613/1759 [00:13<00:25, 45.51it/s][A
 35%|███▌      | 618/1759 [00:13<00:25, 45.49it/s][A
 35%|███▌      | 623/1759 [00:13<00:25, 45.34it/s][A
 36%|███▌      | 628/1759 [00:13<00:25, 45.17it/s][A
 36%|███▌      | 633/1759 [00:14<00:25, 45.01it/s][A
 36%|███▋      | 638/1759 [00:14<00:24, 45.02it/s][A
 37%|███▋      | 643/1759 [00:14<00:24, 45.04it/s][A
 37%|███▋      | 648/1759 [00:14<00:24, 45.21it/s][A
 37%|███▋      | 653/1759 [00:14<00:24, 45.33it/s][A
 37%|███▋      | 658/1759 [00:14<00:24, 45.50it/s][A
 38%|███▊      | 663/1759 [00:14<00:24, 45.52it/s][A
 38%|███▊      | 668/1759 [00:14<00:24, 45.41it/s][A
 38%|███▊      | 673/1759 [00:14<00:24, 45.23it/s][A
 39%|███▊      | 678/1759 [00:15<00:23, 45.07it/s][A
 39%|███▉      | 683/1759 [00:15<00:25, 42.62it/s][A
 39%|███▉      | 688/1759 [00:15<00:24, 43.48it/s][A
 39%|███▉      | 693/1759 [00:15<00:24, 44.13it/s][A
 40%|███▉      | 698/1759 [00:15<00:23, 44.58it/s][A
 40%|███▉      | 703/1759 [00:15<00:23, 44.89it/s][A
 40%|████      | 708/1759 [00:15<00:23, 45.10it/s][A
 41%|████      | 713/1759 [00:15<00:23, 45.24it/s][A
 41%|████      | 718/1759 [00:15<00:22, 45.26it/s][A
 41%|████      | 723/1759 [00:16<00:23, 44.96it/s][A
 41%|████▏     | 728/1759 [00:16<00:22, 44.88it/s][A
 42%|████▏     | 733/1759 [00:16<00:22, 45.07it/s][A
 42%|████▏     | 738/1759 [00:16<00:22, 45.20it/s][A
 42%|████▏     | 743/1759 [00:16<00:22, 45.36it/s][A
 43%|████▎     | 748/1759 [00:16<00:22, 45.38it/s][A
 43%|████▎     | 753/1759 [00:16<00:22, 45.51it/s][A
 43%|████▎     | 758/1759 [00:16<00:21, 45.55it/s][A
 43%|████▎     | 763/1759 [00:16<00:21, 45.41it/s][A
 44%|████▎     | 768/1759 [00:17<00:21, 45.20it/s][A
 44%|████▍     | 773/1759 [00:17<00:21, 45.07it/s][A
 44%|████▍     | 778/1759 [00:17<00:21, 45.11it/s][A
 45%|████▍     | 783/1759 [00:17<00:21, 45.26it/s][A
 45%|████▍     | 788/1759 [00:17<00:21, 45.32it/s][A
 45%|████▌     | 793/1759 [00:17<00:21, 45.43it/s][A
 45%|████▌     | 798/1759 [00:17<00:21, 45.47it/s][A
 46%|████▌     | 803/1759 [00:17<00:21, 45.45it/s][A
 46%|████▌     | 808/1759 [00:17<00:20, 45.30it/s][A
 46%|████▌     | 813/1759 [00:18<00:20, 45.16it/s][A
 47%|████▋     | 818/1759 [00:18<00:22, 42.27it/s][A
 47%|████▋     | 823/1759 [00:18<00:21, 43.26it/s][A
 47%|████▋     | 828/1759 [00:18<00:21, 43.97it/s][A
 47%|████▋     | 833/1759 [00:18<00:20, 44.43it/s][A
 48%|████▊     | 838/1759 [00:18<00:20, 44.82it/s][A
 48%|████▊     | 843/1759 [00:18<00:20, 45.07it/s][A
 48%|████▊     | 848/1759 [00:18<00:20, 45.25it/s][A
 48%|████▊     | 853/1759 [00:18<00:20, 45.19it/s][A
 49%|████▉     | 858/1759 [00:19<00:20, 44.94it/s][A
 49%|████▉     | 863/1759 [00:19<00:19, 44.90it/s][A
 49%|████▉     | 868/1759 [00:19<00:19, 45.03it/s][A
 50%|████▉     | 873/1759 [00:19<00:19, 45.17it/s][A
 50%|████▉     | 878/1759 [00:19<00:19, 45.33it/s][A
 50%|█████     | 883/1759 [00:19<00:19, 45.38it/s][A
 50%|█████     | 888/1759 [00:19<00:19, 45.46it/s][A
 51%|█████     | 893/1759 [00:19<00:19, 45.43it/s][A
 51%|█████     | 898/1759 [00:19<00:19, 45.29it/s][A
 51%|█████▏    | 903/1759 [00:20<00:18, 45.07it/s][A
 52%|█████▏    | 908/1759 [00:20<00:18, 44.97it/s][A
 52%|█████▏    | 913/1759 [00:20<00:18, 45.11it/s][A
 52%|█████▏    | 918/1759 [00:20<00:18, 45.26it/s][A
 52%|█████▏    | 923/1759 [00:20<00:19, 42.29it/s][A
 53%|█████▎    | 928/1759 [00:20<00:18, 43.77it/s][A
 53%|█████▎    | 933/1759 [00:20<00:18, 44.37it/s][A
 53%|█████▎    | 938/1759 [00:20<00:18, 44.79it/s][A
 54%|█████▎    | 943/1759 [00:20<00:18, 44.90it/s][A
 54%|█████▍    | 948/1759 [00:21<00:18, 44.85it/s][A
 54%|█████▍    | 953/1759 [00:21<00:19, 40.98it/s][A
 54%|█████▍    | 958/1759 [00:21<00:18, 42.33it/s][A
 55%|█████▍    | 963/1759 [00:21<00:18, 43.21it/s][A
 55%|█████▌    | 968/1759 [00:21<00:18, 43.90it/s][A
 55%|█████▌    | 973/1759 [00:21<00:17, 44.51it/s][A
 56%|█████▌    | 978/1759 [00:21<00:17, 44.83it/s][A
 56%|█████▌    | 983/1759 [00:21<00:17, 45.09it/s][A
 56%|█████▌    | 988/1759 [00:21<00:17, 45.13it/s][A
 56%|█████▋    | 993/1759 [00:22<00:17, 44.84it/s][A
 57%|█████▋    | 998/1759 [00:22<00:17, 44.68it/s][A
 57%|█████▋    | 1003/1759 [00:22<00:16, 44.84it/s][A
 57%|█████▋    | 1008/1759 [00:22<00:16, 44.98it/s][A
 58%|█████▊    | 1013/1759 [00:22<00:16, 45.18it/s][A
 58%|█████▊    | 1018/1759 [00:22<00:16, 45.32it/s][A
 58%|█████▊    | 1023/1759 [00:22<00:16, 45.49it/s][A
 58%|█████▊    | 1028/1759 [00:22<00:16, 45.60it/s][A
 59%|█████▊    | 1033/1759 [00:22<00:15, 45.50it/s][A
 59%|█████▉    | 1038/1759 [00:23<00:15, 45.20it/s][A
 59%|█████▉    | 1043/1759 [00:23<00:17, 41.79it/s][A
 60%|█████▉    | 1048/1759 [00:23<00:29, 24.10it/s][A
 60%|█████▉    | 1053/1759 [00:23<00:25, 28.12it/s][A
 60%|██████    | 1058/1759 [00:23<00:22, 31.82it/s][A
 60%|██████    | 1063/1759 [00:23<00:19, 35.03it/s][A
 61%|██████    | 1068/1759 [00:24<00:18, 37.70it/s][A
 61%|██████    | 1073/1759 [00:24<00:18, 37.62it/s][A
 61%|██████▏   | 1078/1759 [00:24<00:17, 39.78it/s][A
 62%|██████▏   | 1083/1759 [00:24<00:16, 41.38it/s][A
 62%|██████▏   | 1088/1759 [00:24<00:15, 42.22it/s][A
 62%|██████▏   | 1093/1759 [00:24<00:15, 42.91it/s][A
 62%|██████▏   | 1098/1759 [00:24<00:16, 41.22it/s][A
 63%|██████▎   | 1103/1759 [00:24<00:15, 42.53it/s][A
 63%|██████▎   | 1108/1759 [00:24<00:14, 43.46it/s][A
 63%|██████▎   | 1113/1759 [00:25<00:14, 44.04it/s][A
 64%|██████▎   | 1118/1759 [00:25<00:14, 44.50it/s][A
 64%|██████▍   | 1123/1759 [00:25<00:14, 44.87it/s][A
 64%|██████▍   | 1128/1759 [00:25<00:14, 45.02it/s][A
 64%|██████▍   | 1133/1759 [00:25<00:13, 44.91it/s][A
 65%|██████▍   | 1138/1759 [00:25<00:13, 44.68it/s][A
 65%|██████▍   | 1143/1759 [00:25<00:13, 44.75it/s][A
 65%|██████▌   | 1148/1759 [00:25<00:13, 44.89it/s][A
 66%|██████▌   | 1153/1759 [00:25<00:13, 45.11it/s][A
 66%|██████▌   | 1158/1759 [00:26<00:13, 45.26it/s][A
 66%|██████▌   | 1163/1759 [00:26<00:13, 45.43it/s][A
 66%|██████▋   | 1168/1759 [00:26<00:12, 45.47it/s][A
 67%|██████▋   | 1173/1759 [00:26<00:12, 45.42it/s][A
 67%|██████▋   | 1178/1759 [00:26<00:12, 45.19it/s][A
 67%|██████▋   | 1183/1759 [00:26<00:12, 45.06it/s][A
 68%|██████▊   | 1188/1759 [00:26<00:12, 45.01it/s][A
 68%|██████▊   | 1193/1759 [00:26<00:12, 45.00it/s][A
 68%|██████▊   | 1198/1759 [00:26<00:12, 45.15it/s][A
 68%|██████▊   | 1203/1759 [00:27<00:12, 45.28it/s][A
 69%|██████▊   | 1208/1759 [00:27<00:12, 45.42it/s][A
 69%|██████▉   | 1213/1759 [00:27<00:12, 45.47it/s][A
 69%|██████▉   | 1218/1759 [00:27<00:11, 45.51it/s][A
 70%|██████▉   | 1223/1759 [00:27<00:11, 45.41it/s][A
 70%|██████▉   | 1228/1759 [00:27<00:11, 45.27it/s][A
 70%|███████   | 1233/1759 [00:27<00:11, 44.45it/s][A
 70%|███████   | 1238/1759 [00:27<00:11, 44.66it/s][A
 71%|███████   | 1243/1759 [00:27<00:11, 44.80it/s][A
 71%|███████   | 1248/1759 [00:28<00:11, 44.97it/s][A
 71%|███████   | 1253/1759 [00:28<00:11, 45.14it/s][A
 72%|███████▏  | 1258/1759 [00:28<00:11, 45.25it/s][A
 72%|███████▏  | 1263/1759 [00:28<00:10, 45.26it/s][A
 72%|███████▏  | 1268/1759 [00:28<00:10, 45.20it/s][A
 72%|███████▏  | 1273/1759 [00:28<00:10, 45.10it/s][A
 73%|███████▎  | 1278/1759 [00:28<00:10, 45.08it/s][A
 73%|███████▎  | 1283/1759 [00:28<00:10, 45.17it/s][A
 73%|███████▎  | 1288/1759 [00:28<00:10, 45.19it/s][A
 74%|███████▎  | 1293/1759 [00:29<00:10, 45.22it/s][A
 74%|███████▍  | 1298/1759 [00:29<00:10, 45.30it/s][A
 74%|███████▍  | 1303/1759 [00:29<00:10, 45.40it/s][A
 74%|███████▍  | 1308/1759 [00:29<00:09, 45.37it/s][A
 75%|███████▍  | 1313/1759 [00:29<00:09, 45.29it/s][A
 75%|███████▍  | 1318/1759 [00:29<00:09, 45.16it/s][A
 75%|███████▌  | 1323/1759 [00:29<00:09, 45.13it/s][A
 75%|███████▌  | 1328/1759 [00:29<00:09, 45.13it/s][A
 76%|███████▌  | 1333/1759 [00:29<00:09, 45.19it/s][A
 76%|███████▌  | 1338/1759 [00:30<00:09, 45.28it/s][A
 76%|███████▋  | 1343/1759 [00:30<00:09, 45.38it/s][A
 77%|███████▋  | 1348/1759 [00:30<00:09, 45.43it/s][A
 77%|███████▋  | 1353/1759 [00:30<00:08, 45.37it/s][A
 77%|███████▋  | 1358/1759 [00:30<00:08, 45.25it/s][A
 77%|███████▋  | 1363/1759 [00:30<00:08, 45.18it/s][A
 78%|███████▊  | 1368/1759 [00:30<00:08, 45.14it/s][A
 78%|███████▊  | 1373/1759 [00:30<00:09, 41.98it/s][A
 78%|███████▊  | 1378/1759 [00:30<00:08, 43.08it/s][A
 79%|███████▊  | 1383/1759 [00:31<00:08, 43.86it/s][A
 79%|███████▉  | 1388/1759 [00:31<00:08, 44.43it/s][A
 79%|███████▉  | 1393/1759 [00:31<00:08, 44.78it/s][A
 79%|███████▉  | 1398/1759 [00:31<00:08, 44.77it/s][A
 80%|███████▉  | 1403/1759 [00:31<00:07, 44.89it/s][A
 80%|████████  | 1408/1759 [00:31<00:07, 44.91it/s][A
 80%|████████  | 1413/1759 [00:31<00:07, 44.74it/s][A
 81%|████████  | 1418/1759 [00:31<00:07, 44.81it/s][A
 81%|████████  | 1423/1759 [00:31<00:07, 45.05it/s][A
 81%|████████  | 1428/1759 [00:32<00:07, 45.25it/s][A
 81%|████████▏ | 1433/1759 [00:32<00:07, 45.39it/s][A
 82%|████████▏ | 1438/1759 [00:32<00:07, 45.43it/s][A
 82%|████████▏ | 1443/1759 [00:32<00:06, 45.42it/s][A
 82%|████████▏ | 1448/1759 [00:32<00:06, 45.31it/s][A
 83%|████████▎ | 1453/1759 [00:32<00:06, 45.14it/s][A
 83%|████████▎ | 1458/1759 [00:32<00:06, 44.96it/s][A
 83%|████████▎ | 1463/1759 [00:32<00:06, 44.97it/s][A
 83%|████████▎ | 1468/1759 [00:32<00:06, 45.13it/s][A
 84%|████████▎ | 1473/1759 [00:33<00:06, 45.30it/s][A
 84%|████████▍ | 1478/1759 [00:33<00:06, 45.44it/s][A
 84%|████████▍ | 1483/1759 [00:33<00:06, 45.48it/s][A
 85%|████████▍ | 1488/1759 [00:33<00:05, 45.46it/s][A
 85%|████████▍ | 1493/1759 [00:33<00:05, 45.33it/s][A
 85%|████████▌ | 1498/1759 [00:33<00:05, 45.17it/s][A
 85%|████████▌ | 1503/1759 [00:33<00:05, 45.01it/s][A
 86%|████████▌ | 1508/1759 [00:33<00:05, 42.59it/s][A
 86%|████████▌ | 1513/1759 [00:33<00:05, 43.48it/s][A
 86%|████████▋ | 1518/1759 [00:34<00:05, 44.10it/s][A
 87%|████████▋ | 1523/1759 [00:34<00:05, 44.53it/s][A
 87%|████████▋ | 1528/1759 [00:34<00:05, 44.86it/s][A
 87%|████████▋ | 1533/1759 [00:34<00:05, 45.07it/s][A
 87%|████████▋ | 1538/1759 [00:34<00:04, 45.21it/s][A
 88%|████████▊ | 1543/1759 [00:34<00:04, 45.21it/s][A
 88%|████████▊ | 1548/1759 [00:34<00:04, 44.91it/s][A
 88%|████████▊ | 1553/1759 [00:34<00:04, 44.90it/s][A
 89%|████████▊ | 1558/1759 [00:34<00:04, 44.98it/s][A
 89%|████████▉ | 1563/1759 [00:35<00:04, 45.14it/s][A
 89%|████████▉ | 1568/1759 [00:35<00:04, 45.29it/s][A
 89%|████████▉ | 1573/1759 [00:35<00:04, 45.42it/s][A
 90%|████████▉ | 1578/1759 [00:35<00:03, 45.50it/s][A
 90%|████████▉ | 1583/1759 [00:35<00:03, 45.49it/s][A
 90%|█████████ | 1588/1759 [00:35<00:03, 45.31it/s][A
 91%|█████████ | 1593/1759 [00:35<00:03, 45.10it/s][A
 91%|█████████ | 1598/1759 [00:35<00:03, 44.93it/s][A
 91%|█████████ | 1603/1759 [00:35<00:03, 44.96it/s][A
 91%|█████████▏| 1608/1759 [00:36<00:03, 45.03it/s][A
 92%|█████████▏| 1613/1759 [00:36<00:03, 45.20it/s][A
 92%|█████████▏| 1618/1759 [00:36<00:03, 45.32it/s][A
 92%|█████████▏| 1623/1759 [00:36<00:02, 45.44it/s][A
 93%|█████████▎| 1628/1759 [00:36<00:02, 45.48it/s][A
 93%|█████████▎| 1633/1759 [00:36<00:02, 45.38it/s][A
 93%|█████████▎| 1638/1759 [00:36<00:02, 45.14it/s][A
 93%|█████████▎| 1643/1759 [00:36<00:02, 42.63it/s][A
 94%|█████████▎| 1648/1759 [00:36<00:02, 43.50it/s][A
 94%|█████████▍| 1653/1759 [00:37<00:02, 44.02it/s][A
 94%|█████████▍| 1658/1759 [00:37<00:02, 44.48it/s][A
 95%|█████████▍| 1663/1759 [00:37<00:02, 44.81it/s][A
 95%|█████████▍| 1668/1759 [00:37<00:02, 45.09it/s][A
 95%|█████████▌| 1673/1759 [00:37<00:01, 45.22it/s][A
 95%|█████████▌| 1678/1759 [00:37<00:01, 45.19it/s][A
 96%|█████████▌| 1683/1759 [00:37<00:01, 44.85it/s][A
 96%|█████████▌| 1688/1759 [00:37<00:01, 44.81it/s][A
 96%|█████████▌| 1693/1759 [00:37<00:01, 44.87it/s][A
 97%|█████████▋| 1698/1759 [00:38<00:01, 45.09it/s][A
 97%|█████████▋| 1703/1759 [00:38<00:01, 45.26it/s][A
 97%|█████████▋| 1708/1759 [00:38<00:01, 45.38it/s][A
 97%|█████████▋| 1713/1759 [00:38<00:01, 45.42it/s][A
 98%|█████████▊| 1718/1759 [00:38<00:00, 45.44it/s][A
 98%|█████████▊| 1723/1759 [00:38<00:00, 45.27it/s][A
 98%|█████████▊| 1728/1759 [00:38<00:00, 45.06it/s][A
 99%|█████████▊| 1733/1759 [00:38<00:00, 44.93it/s][A
 99%|█████████▉| 1738/1759 [00:38<00:00, 44.93it/s][A
 99%|█████████▉| 1743/1759 [00:39<00:00, 45.10it/s][A
 99%|█████████▉| 1748/1759 [00:39<00:00, 45.23it/s][A
100%|█████████▉| 1753/1759 [00:39<00:00, 45.37it/s][A
100%|█████████▉| 1758/1759 [00:39<00:00, 45.39it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 45.39it/s][A 80%|████████  | 312/390 [04:57<00:22,  3.51it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 14:59:27,579 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-312
[INFO|configuration_utils.py:351] 2023-08-29 14:59:27,847 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-312/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:59:31,523 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-312/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:59:31,706 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-312/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:59:31,798 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-312/special_tokens_map.json
 80%|████████  | 313/390 [05:14<21:53, 17.06s/it] 81%|████████  | 314/390 [05:14<15:14, 12.03s/it] 81%|████████  | 315/390 [05:14<10:37,  8.51s/it] 81%|████████  | 316/390 [05:15<07:27,  6.04s/it] 81%|████████▏ | 317/390 [05:15<05:15,  4.32s/it] 82%|████████▏ | 318/390 [05:15<03:43,  3.11s/it] 82%|████████▏ | 319/390 [05:16<02:40,  2.26s/it] 82%|████████▏ | 320/390 [05:16<01:56,  1.67s/it] 82%|████████▏ | 321/390 [05:16<01:26,  1.26s/it] 83%|████████▎ | 322/390 [05:17<01:07,  1.01it/s] 83%|████████▎ | 323/390 [05:17<00:52,  1.28it/s] 83%|████████▎ | 324/390 [05:17<00:41,  1.58it/s] 83%|████████▎ | 325/390 [05:17<00:34,  1.88it/s] 84%|████████▎ | 326/390 [05:18<00:29,  2.18it/s] 84%|████████▍ | 327/390 [05:18<00:25,  2.45it/s] 84%|████████▍ | 328/390 [05:18<00:23,  2.68it/s] 84%|████████▍ | 329/390 [05:19<00:21,  2.87it/s] 85%|████████▍ | 330/390 [05:19<00:19,  3.02it/s] 85%|████████▍ | 331/390 [05:19<00:18,  3.13it/s] 85%|████████▌ | 332/390 [05:19<00:18,  3.22it/s] 85%|████████▌ | 333/390 [05:20<00:18,  3.15it/s] 86%|████████▌ | 334/390 [05:20<00:17,  3.23it/s] 86%|████████▌ | 335/390 [05:20<00:16,  3.29it/s] 86%|████████▌ | 336/390 [05:21<00:16,  3.34it/s] 86%|████████▋ | 337/390 [05:21<00:15,  3.37it/s] 87%|████████▋ | 338/390 [05:21<00:15,  3.39it/s] 87%|████████▋ | 339/390 [05:22<00:14,  3.41it/s] 87%|████████▋ | 340/390 [05:22<00:14,  3.42it/s] 87%|████████▋ | 341/390 [05:22<00:14,  3.42it/s] 88%|████████▊ | 342/390 [05:22<00:13,  3.43it/s] 88%|████████▊ | 343/390 [05:23<00:13,  3.43it/s] 88%|████████▊ | 344/390 [05:23<00:14,  3.28it/s] 88%|████████▊ | 345/390 [05:23<00:13,  3.33it/s] 89%|████████▊ | 346/390 [05:24<00:13,  3.36it/s] 89%|████████▉ | 347/390 [05:24<00:12,  3.39it/s] 89%|████████▉ | 348/390 [05:24<00:12,  3.40it/s] 89%|████████▉ | 349/390 [05:25<00:12,  3.41it/s] 90%|████████▉ | 350/390 [05:25<00:11,  3.42it/s] 90%|█████████ | 351/390 [05:25<00:11,  3.42it/s] 90%|█████████ | 352/390 [05:25<00:11,  3.43it/s] 91%|█████████ | 353/390 [05:26<00:10,  3.43it/s] 91%|█████████ | 354/390 [05:26<00:10,  3.43it/s] 91%|█████████ | 355/390 [05:26<00:10,  3.31it/s] 91%|█████████▏| 356/390 [05:27<00:10,  3.35it/s] 92%|█████████▏| 357/390 [05:27<00:09,  3.37it/s] 92%|█████████▏| 358/390 [05:27<00:09,  3.39it/s] 92%|█████████▏| 359/390 [05:27<00:09,  3.41it/s] 92%|█████████▏| 360/390 [05:28<00:08,  3.42it/s] 93%|█████████▎| 361/390 [05:28<00:08,  3.42it/s] 93%|█████████▎| 362/390 [05:28<00:08,  3.43it/s] 93%|█████████▎| 363/390 [05:29<00:07,  3.43it/s] 93%|█████████▎| 364/390 [05:29<00:07,  3.45it/s] 94%|█████████▎| 365/390 [05:29<00:07,  3.47it/s] 94%|█████████▍| 366/390 [05:29<00:06,  3.48it/s] 94%|█████████▍| 367/390 [05:30<00:06,  3.49it/s] 94%|█████████▍| 368/390 [05:30<00:06,  3.50it/s] 95%|█████████▍| 369/390 [05:30<00:05,  3.51it/s] 95%|█████████▍| 370/390 [05:31<00:05,  3.51it/s] 95%|█████████▌| 371/390 [05:31<00:05,  3.51it/s] 95%|█████████▌| 372/390 [05:31<00:05,  3.51it/s] 96%|█████████▌| 373/390 [05:31<00:04,  3.52it/s] 96%|█████████▌| 374/390 [05:32<00:04,  3.51it/s] 96%|█████████▌| 375/390 [05:32<00:04,  3.51it/s] 96%|█████████▋| 376/390 [05:32<00:04,  3.38it/s] 97%|█████████▋| 377/390 [05:33<00:03,  3.42it/s] 97%|█████████▋| 378/390 [05:33<00:03,  3.45it/s] 97%|█████████▋| 379/390 [05:33<00:03,  3.47it/s] 97%|█████████▋| 380/390 [05:34<00:02,  3.48it/s] 98%|█████████▊| 381/390 [05:34<00:02,  3.49it/s] 98%|█████████▊| 382/390 [05:34<00:02,  3.50it/s] 98%|█████████▊| 383/390 [05:34<00:01,  3.51it/s] 98%|█████████▊| 384/390 [05:35<00:01,  3.51it/s] 99%|█████████▊| 385/390 [05:35<00:01,  3.51it/s] 99%|█████████▉| 386/390 [05:35<00:01,  3.51it/s] 99%|█████████▉| 387/390 [05:35<00:00,  3.52it/s] 99%|█████████▉| 388/390 [05:36<00:00,  3.52it/s]100%|█████████▉| 389/390 [05:36<00:00,  3.52it/s]100%|██████████| 390/390 [05:36<00:00,  3.52it/s][INFO|trainer.py:2140] 2023-08-29 15:00:06,427 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 15:00:06,428 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 15:00:06,428 >>   Batch size = 8
{'eval_loss': 1.0091254711151123, 'eval_runtime': 39.4655, 'eval_samples_per_second': 356.438, 'eval_steps_per_second': 44.571, 'epoch': 3.99}

  0%|          | 0/1759 [00:00<?, ?it/s][A
  0%|          | 6/1759 [00:00<00:30, 56.73it/s][A
  1%|          | 12/1759 [00:00<00:35, 49.35it/s][A
  1%|          | 17/1759 [00:00<00:36, 47.45it/s][A
  1%|▏         | 22/1759 [00:00<00:37, 46.48it/s][A
  2%|▏         | 27/1759 [00:00<00:37, 46.03it/s][A
  2%|▏         | 32/1759 [00:00<00:37, 45.78it/s][A
  2%|▏         | 37/1759 [00:00<00:37, 45.58it/s][A
  2%|▏         | 42/1759 [00:00<00:37, 45.44it/s][A
  3%|▎         | 47/1759 [00:01<00:37, 45.42it/s][A
  3%|▎         | 52/1759 [00:01<00:37, 45.49it/s][A
  3%|▎         | 57/1759 [00:01<00:37, 45.62it/s][A
  4%|▎         | 62/1759 [00:01<00:37, 45.53it/s][A
  4%|▍         | 67/1759 [00:01<00:37, 45.38it/s][A
  4%|▍         | 72/1759 [00:01<00:37, 45.35it/s][A
  4%|▍         | 77/1759 [00:01<00:37, 45.29it/s][A
  5%|▍         | 82/1759 [00:01<00:37, 45.25it/s][A
  5%|▍         | 87/1759 [00:01<00:39, 42.76it/s][A
  5%|▌         | 92/1759 [00:02<00:38, 43.82it/s][A
  6%|▌         | 97/1759 [00:02<00:37, 44.42it/s][A
  6%|▌         | 102/1759 [00:02<00:36, 44.84it/s][A
  6%|▌         | 107/1759 [00:02<00:36, 45.11it/s][A
  6%|▋         | 112/1759 [00:02<00:36, 45.17it/s][A
  7%|▋         | 117/1759 [00:02<00:36, 45.21it/s][A
  7%|▋         | 122/1759 [00:02<00:36, 45.15it/s][A
  7%|▋         | 127/1759 [00:02<00:36, 44.98it/s][A
  8%|▊         | 132/1759 [00:02<00:36, 44.86it/s][A
  8%|▊         | 137/1759 [00:03<00:36, 45.01it/s][A
  8%|▊         | 142/1759 [00:03<00:35, 45.24it/s][A
  8%|▊         | 147/1759 [00:03<00:35, 45.40it/s][A
  9%|▊         | 152/1759 [00:03<00:35, 45.54it/s][A
  9%|▉         | 157/1759 [00:03<00:35, 45.60it/s][A
  9%|▉         | 162/1759 [00:03<00:35, 45.61it/s][A
  9%|▉         | 167/1759 [00:03<00:35, 45.47it/s][A
 10%|▉         | 172/1759 [00:03<00:35, 45.33it/s][A
 10%|█         | 177/1759 [00:03<00:35, 45.15it/s][A
 10%|█         | 182/1759 [00:04<00:34, 45.11it/s][A
 11%|█         | 187/1759 [00:04<00:34, 45.21it/s][A
 11%|█         | 192/1759 [00:04<00:34, 45.40it/s][A
 11%|█         | 197/1759 [00:04<00:34, 45.53it/s][A
 11%|█▏        | 202/1759 [00:04<00:34, 45.56it/s][A
 12%|█▏        | 207/1759 [00:04<00:35, 43.66it/s][A
 12%|█▏        | 212/1759 [00:05<01:05, 23.72it/s][A
 12%|█▏        | 217/1759 [00:05<00:55, 28.04it/s][A
 13%|█▎        | 222/1759 [00:05<00:48, 31.73it/s][A
 13%|█▎        | 227/1759 [00:05<00:43, 34.97it/s][A
 13%|█▎        | 232/1759 [00:05<00:40, 37.65it/s][A
 13%|█▎        | 237/1759 [00:05<00:38, 39.79it/s][A
 14%|█▍        | 242/1759 [00:05<00:36, 41.42it/s][A
 14%|█▍        | 247/1759 [00:05<00:35, 42.67it/s][A
 14%|█▍        | 252/1759 [00:05<00:34, 43.38it/s][A
 15%|█▍        | 257/1759 [00:05<00:34, 43.62it/s][A
 15%|█▍        | 262/1759 [00:06<00:34, 43.84it/s][A
 15%|█▌        | 267/1759 [00:06<00:33, 44.15it/s][A
 15%|█▌        | 272/1759 [00:06<00:33, 44.54it/s][A
 16%|█▌        | 277/1759 [00:06<00:32, 44.91it/s][A
 16%|█▌        | 282/1759 [00:06<00:32, 45.16it/s][A
 16%|█▋        | 287/1759 [00:06<00:32, 45.35it/s][A
 17%|█▋        | 292/1759 [00:06<00:32, 45.49it/s][A
 17%|█▋        | 297/1759 [00:06<00:32, 45.46it/s][A
 17%|█▋        | 302/1759 [00:06<00:32, 45.27it/s][A
 17%|█▋        | 307/1759 [00:07<00:32, 45.13it/s][A
 18%|█▊        | 312/1759 [00:07<00:32, 45.06it/s][A
 18%|█▊        | 317/1759 [00:07<00:32, 45.05it/s][A
 18%|█▊        | 322/1759 [00:07<00:31, 45.20it/s][A
 19%|█▊        | 327/1759 [00:07<00:33, 42.44it/s][A
 19%|█▉        | 332/1759 [00:07<00:32, 43.41it/s][A
 19%|█▉        | 337/1759 [00:07<00:32, 44.13it/s][A
 19%|█▉        | 342/1759 [00:07<00:31, 44.64it/s][A
 20%|█▉        | 347/1759 [00:07<00:31, 44.90it/s][A
 20%|██        | 352/1759 [00:08<00:31, 44.97it/s][A
 20%|██        | 357/1759 [00:08<00:31, 44.96it/s][A
 21%|██        | 362/1759 [00:08<00:31, 44.99it/s][A
 21%|██        | 367/1759 [00:08<00:31, 44.80it/s][A
 21%|██        | 372/1759 [00:08<00:30, 44.87it/s][A
 21%|██▏       | 377/1759 [00:08<00:30, 45.06it/s][A
 22%|██▏       | 382/1759 [00:08<00:30, 45.21it/s][A
 22%|██▏       | 387/1759 [00:08<00:30, 45.38it/s][A
 22%|██▏       | 392/1759 [00:08<00:30, 45.52it/s][A
 23%|██▎       | 397/1759 [00:09<00:29, 45.55it/s][A
 23%|██▎       | 402/1759 [00:09<00:29, 45.44it/s][A
 23%|██▎       | 407/1759 [00:09<00:29, 45.29it/s][A
 23%|██▎       | 412/1759 [00:09<00:29, 45.12it/s][A
 24%|██▎       | 417/1759 [00:09<00:29, 45.15it/s][A
 24%|██▍       | 422/1759 [00:09<00:29, 45.11it/s][A
 24%|██▍       | 427/1759 [00:09<00:29, 45.26it/s][A
 25%|██▍       | 432/1759 [00:09<00:29, 45.38it/s][A
 25%|██▍       | 437/1759 [00:09<00:29, 45.50it/s][A
 25%|██▌       | 442/1759 [00:10<00:28, 45.52it/s][A
 25%|██▌       | 447/1759 [00:10<00:28, 45.41it/s][A
 26%|██▌       | 452/1759 [00:10<00:28, 45.26it/s][A
 26%|██▌       | 457/1759 [00:10<00:28, 45.21it/s][A
 26%|██▋       | 462/1759 [00:10<00:28, 45.15it/s][A
 27%|██▋       | 467/1759 [00:10<00:28, 45.13it/s][A
 27%|██▋       | 472/1759 [00:10<00:28, 45.18it/s][A
 27%|██▋       | 477/1759 [00:10<00:28, 45.32it/s][A
 27%|██▋       | 482/1759 [00:10<00:28, 45.43it/s][A
 28%|██▊       | 487/1759 [00:11<00:27, 45.48it/s][A
 28%|██▊       | 492/1759 [00:11<00:27, 45.41it/s][A
 28%|██▊       | 497/1759 [00:11<00:27, 45.30it/s][A
 29%|██▊       | 502/1759 [00:11<00:27, 45.24it/s][A
 29%|██▉       | 507/1759 [00:11<00:27, 45.16it/s][A
 29%|██▉       | 512/1759 [00:11<00:27, 45.18it/s][A
 29%|██▉       | 517/1759 [00:11<00:27, 45.22it/s][A
 30%|██▉       | 522/1759 [00:11<00:27, 45.41it/s][A
 30%|██▉       | 527/1759 [00:11<00:27, 45.50it/s][A
 30%|███       | 532/1759 [00:12<00:26, 45.48it/s][A
 31%|███       | 537/1759 [00:12<00:26, 45.42it/s][A
 31%|███       | 542/1759 [00:12<00:27, 45.04it/s][A
 31%|███       | 547/1759 [00:12<00:26, 45.12it/s][A
 31%|███▏      | 552/1759 [00:12<00:26, 45.10it/s][A
 32%|███▏      | 557/1759 [00:12<00:29, 40.63it/s][A
 32%|███▏      | 562/1759 [00:12<00:28, 42.06it/s][A
 32%|███▏      | 567/1759 [00:12<00:27, 43.10it/s][A
 33%|███▎      | 572/1759 [00:13<00:27, 43.89it/s][A
 33%|███▎      | 577/1759 [00:13<00:26, 44.37it/s][A
 33%|███▎      | 582/1759 [00:13<00:26, 44.77it/s][A
 33%|███▎      | 587/1759 [00:13<00:26, 45.01it/s][A
 34%|███▎      | 592/1759 [00:13<00:25, 45.23it/s][A
 34%|███▍      | 597/1759 [00:13<00:25, 44.92it/s][A
 34%|███▍      | 602/1759 [00:13<00:25, 44.86it/s][A
 35%|███▍      | 607/1759 [00:13<00:25, 44.98it/s][A
 35%|███▍      | 612/1759 [00:13<00:25, 45.16it/s][A
 35%|███▌      | 617/1759 [00:13<00:25, 45.29it/s][A
 35%|███▌      | 622/1759 [00:14<00:25, 45.46it/s][A
 36%|███▌      | 627/1759 [00:14<00:24, 45.54it/s][A
 36%|███▌      | 632/1759 [00:14<00:24, 45.55it/s][A
 36%|███▌      | 637/1759 [00:14<00:24, 45.46it/s][A
 36%|███▋      | 642/1759 [00:14<00:24, 45.27it/s][A
 37%|███▋      | 647/1759 [00:14<00:24, 45.16it/s][A
 37%|███▋      | 652/1759 [00:14<00:24, 45.13it/s][A
 37%|███▋      | 657/1759 [00:14<00:24, 45.21it/s][A
 38%|███▊      | 662/1759 [00:14<00:24, 45.35it/s][A
 38%|███▊      | 667/1759 [00:15<00:24, 45.43it/s][A
 38%|███▊      | 672/1759 [00:15<00:23, 45.51it/s][A
 38%|███▊      | 677/1759 [00:15<00:23, 45.50it/s][A
 39%|███▉      | 682/1759 [00:15<00:23, 45.34it/s][A
 39%|███▉      | 687/1759 [00:15<00:23, 45.16it/s][A
 39%|███▉      | 692/1759 [00:15<00:23, 45.04it/s][A
 40%|███▉      | 697/1759 [00:15<00:23, 45.11it/s][A
 40%|███▉      | 702/1759 [00:15<00:23, 45.19it/s][A
 40%|████      | 707/1759 [00:15<00:23, 45.32it/s][A
 40%|████      | 712/1759 [00:16<00:23, 45.42it/s][A
 41%|████      | 717/1759 [00:16<00:22, 45.50it/s][A
 41%|████      | 722/1759 [00:16<00:22, 45.41it/s][A
 41%|████▏     | 727/1759 [00:16<00:22, 45.32it/s][A
 42%|████▏     | 732/1759 [00:16<00:22, 45.16it/s][A
 42%|████▏     | 737/1759 [00:16<00:22, 45.10it/s][A
 42%|████▏     | 742/1759 [00:16<00:22, 45.11it/s][A
 42%|████▏     | 747/1759 [00:16<00:22, 45.17it/s][A
 43%|████▎     | 752/1759 [00:16<00:22, 45.32it/s][A
 43%|████▎     | 757/1759 [00:17<00:22, 45.42it/s][A
 43%|████▎     | 762/1759 [00:17<00:21, 45.46it/s][A
 44%|████▎     | 767/1759 [00:17<00:21, 45.40it/s][A
 44%|████▍     | 772/1759 [00:17<00:21, 45.29it/s][A
 44%|████▍     | 777/1759 [00:17<00:21, 45.14it/s][A
 44%|████▍     | 782/1759 [00:17<00:21, 45.09it/s][A
 45%|████▍     | 787/1759 [00:17<00:23, 41.96it/s][A
 45%|████▌     | 792/1759 [00:17<00:22, 43.12it/s][A
 45%|████▌     | 797/1759 [00:17<00:21, 43.85it/s][A
 46%|████▌     | 802/1759 [00:18<00:21, 44.51it/s][A
 46%|████▌     | 807/1759 [00:18<00:21, 44.82it/s][A
 46%|████▌     | 812/1759 [00:18<00:21, 45.02it/s][A
 46%|████▋     | 817/1759 [00:18<00:20, 45.00it/s][A
 47%|████▋     | 822/1759 [00:18<00:20, 45.00it/s][A
 47%|████▋     | 827/1759 [00:18<00:20, 44.75it/s][A
 47%|████▋     | 832/1759 [00:18<00:20, 44.78it/s][A
 48%|████▊     | 837/1759 [00:18<00:20, 45.01it/s][A
 48%|████▊     | 842/1759 [00:18<00:20, 45.16it/s][A
 48%|████▊     | 847/1759 [00:19<00:20, 45.35it/s][A
 48%|████▊     | 852/1759 [00:19<00:19, 45.49it/s][A
 49%|████▊     | 857/1759 [00:19<00:19, 45.57it/s][A
 49%|████▉     | 862/1759 [00:19<00:19, 45.50it/s][A
 49%|████▉     | 867/1759 [00:19<00:19, 45.37it/s][A
 50%|████▉     | 872/1759 [00:19<00:19, 45.12it/s][A
 50%|████▉     | 877/1759 [00:19<00:19, 45.09it/s][A
 50%|█████     | 882/1759 [00:19<00:19, 45.10it/s][A
 50%|█████     | 887/1759 [00:19<00:19, 45.23it/s][A
 51%|█████     | 892/1759 [00:20<00:19, 45.34it/s][A
 51%|█████     | 897/1759 [00:20<00:18, 45.42it/s][A
 51%|█████▏    | 902/1759 [00:20<00:18, 45.45it/s][A
 52%|█████▏    | 907/1759 [00:20<00:18, 45.51it/s][A
 52%|█████▏    | 912/1759 [00:20<00:18, 45.42it/s][A
 52%|█████▏    | 917/1759 [00:20<00:18, 45.32it/s][A
 52%|█████▏    | 922/1759 [00:20<00:18, 45.21it/s][A
 53%|█████▎    | 927/1759 [00:20<00:18, 45.15it/s][A
 53%|█████▎    | 932/1759 [00:20<00:18, 45.24it/s][A
 53%|█████▎    | 937/1759 [00:21<00:18, 45.36it/s][A
 54%|█████▎    | 942/1759 [00:21<00:18, 45.39it/s][A
 54%|█████▍    | 947/1759 [00:21<00:17, 45.37it/s][A
 54%|█████▍    | 952/1759 [00:21<00:17, 45.37it/s][A
 54%|█████▍    | 957/1759 [00:21<00:17, 45.29it/s][A
 55%|█████▍    | 962/1759 [00:21<00:17, 45.20it/s][A
 55%|█████▍    | 967/1759 [00:21<00:17, 45.14it/s][A
 55%|█████▌    | 972/1759 [00:21<00:17, 45.12it/s][A
 56%|█████▌    | 977/1759 [00:21<00:17, 45.12it/s][A
 56%|█████▌    | 982/1759 [00:22<00:17, 45.25it/s][A
 56%|█████▌    | 987/1759 [00:22<00:17, 45.33it/s][A
 56%|█████▋    | 992/1759 [00:22<00:16, 45.42it/s][A
 57%|█████▋    | 997/1759 [00:22<00:16, 45.38it/s][A
 57%|█████▋    | 1002/1759 [00:22<00:16, 45.37it/s][A
 57%|█████▋    | 1007/1759 [00:22<00:16, 45.32it/s][A
 58%|█████▊    | 1012/1759 [00:22<00:16, 45.29it/s][A
 58%|█████▊    | 1017/1759 [00:22<00:19, 38.20it/s][A
 58%|█████▊    | 1022/1759 [00:23<00:18, 40.15it/s][A
 58%|█████▊    | 1027/1759 [00:23<00:17, 41.70it/s][A
 59%|█████▊    | 1032/1759 [00:23<00:16, 42.78it/s][A
 59%|█████▉    | 1037/1759 [00:23<00:16, 43.65it/s][A
 59%|█████▉    | 1042/1759 [00:23<00:16, 44.22it/s][A
 60%|█████▉    | 1047/1759 [00:23<00:15, 44.67it/s][A
 60%|█████▉    | 1052/1759 [00:23<00:15, 44.92it/s][A
 60%|██████    | 1057/1759 [00:23<00:15, 44.70it/s][A
 60%|██████    | 1062/1759 [00:23<00:15, 44.65it/s][A
 61%|██████    | 1067/1759 [00:24<00:15, 44.78it/s][A
 61%|██████    | 1072/1759 [00:24<00:15, 45.01it/s][A
 61%|██████    | 1077/1759 [00:24<00:15, 45.27it/s][A
 62%|██████▏   | 1082/1759 [00:24<00:14, 45.43it/s][A
 62%|██████▏   | 1087/1759 [00:24<00:14, 45.52it/s][A
 62%|██████▏   | 1092/1759 [00:24<00:14, 45.52it/s][A
 62%|██████▏   | 1097/1759 [00:24<00:14, 45.39it/s][A
 63%|██████▎   | 1102/1759 [00:24<00:14, 45.09it/s][A
 63%|██████▎   | 1107/1759 [00:24<00:14, 44.91it/s][A
 63%|██████▎   | 1112/1759 [00:25<00:14, 44.90it/s][A
 64%|██████▎   | 1117/1759 [00:25<00:14, 44.99it/s][A
 64%|██████▍   | 1122/1759 [00:25<00:14, 45.18it/s][A
 64%|██████▍   | 1127/1759 [00:25<00:13, 45.30it/s][A
 64%|██████▍   | 1132/1759 [00:25<00:13, 45.46it/s][A
 65%|██████▍   | 1137/1759 [00:25<00:13, 45.55it/s][A
 65%|██████▍   | 1142/1759 [00:25<00:13, 45.48it/s][A
 65%|██████▌   | 1147/1759 [00:25<00:13, 45.20it/s][A
 65%|██████▌   | 1152/1759 [00:25<00:13, 45.06it/s][A
 66%|██████▌   | 1157/1759 [00:26<00:13, 45.00it/s][A
 66%|██████▌   | 1162/1759 [00:26<00:13, 45.09it/s][A
 66%|██████▋   | 1167/1759 [00:26<00:13, 45.17it/s][A
 67%|██████▋   | 1172/1759 [00:26<00:12, 45.30it/s][A
 67%|██████▋   | 1177/1759 [00:26<00:12, 45.35it/s][A
 67%|██████▋   | 1182/1759 [00:26<00:12, 45.41it/s][A
 67%|██████▋   | 1187/1759 [00:26<00:12, 45.41it/s][A
 68%|██████▊   | 1192/1759 [00:26<00:12, 45.32it/s][A
 68%|██████▊   | 1197/1759 [00:26<00:12, 45.21it/s][A
 68%|██████▊   | 1202/1759 [00:27<00:12, 45.17it/s][A
 69%|██████▊   | 1207/1759 [00:27<00:12, 45.20it/s][A
 69%|██████▉   | 1212/1759 [00:27<00:12, 45.12it/s][A
 69%|██████▉   | 1217/1759 [00:27<00:11, 45.32it/s][A
 69%|██████▉   | 1222/1759 [00:27<00:11, 45.31it/s][A
 70%|██████▉   | 1227/1759 [00:27<00:11, 45.33it/s][A
 70%|███████   | 1232/1759 [00:27<00:11, 45.28it/s][A
 70%|███████   | 1237/1759 [00:27<00:11, 45.30it/s][A
 71%|███████   | 1242/1759 [00:28<00:11, 45.19it/s][A
 71%|███████   | 1247/1759 [00:28<00:14, 34.66it/s][A
 71%|███████   | 1252/1759 [00:28<00:13, 37.43it/s][A
 71%|███████▏  | 1257/1759 [00:28<00:12, 39.60it/s][A
 72%|███████▏  | 1262/1759 [00:28<00:12, 41.29it/s][A
 72%|███████▏  | 1267/1759 [00:28<00:11, 42.56it/s][A
 72%|███████▏  | 1272/1759 [00:28<00:11, 43.50it/s][A
 73%|███████▎  | 1277/1759 [00:28<00:10, 44.18it/s][A
 73%|███████▎  | 1282/1759 [00:28<00:10, 44.53it/s][A
 73%|███████▎  | 1287/1759 [00:28<00:10, 44.41it/s][A
 73%|███████▎  | 1292/1759 [00:29<00:10, 44.29it/s][A
 74%|███████▎  | 1297/1759 [00:29<00:10, 44.48it/s][A
 74%|███████▍  | 1302/1759 [00:29<00:10, 44.73it/s][A
 74%|███████▍  | 1307/1759 [00:29<00:10, 45.03it/s][A
 75%|███████▍  | 1312/1759 [00:29<00:09, 45.28it/s][A
 75%|███████▍  | 1317/1759 [00:29<00:09, 45.45it/s][A
 75%|███████▌  | 1322/1759 [00:29<00:09, 45.56it/s][A
 75%|███████▌  | 1327/1759 [00:29<00:09, 45.51it/s][A
 76%|███████▌  | 1332/1759 [00:29<00:09, 45.13it/s][A
 76%|███████▌  | 1337/1759 [00:30<00:09, 44.90it/s][A
 76%|███████▋  | 1342/1759 [00:30<00:09, 44.83it/s][A
 77%|███████▋  | 1347/1759 [00:30<00:09, 44.95it/s][A
 77%|███████▋  | 1352/1759 [00:30<00:09, 45.08it/s][A
 77%|███████▋  | 1357/1759 [00:30<00:08, 45.24it/s][A
 77%|███████▋  | 1362/1759 [00:30<00:08, 45.37it/s][A
 78%|███████▊  | 1367/1759 [00:30<00:08, 45.53it/s][A
 78%|███████▊  | 1372/1759 [00:30<00:08, 45.56it/s][A
 78%|███████▊  | 1377/1759 [00:30<00:08, 45.41it/s][A
 79%|███████▊  | 1382/1759 [00:31<00:08, 45.15it/s][A
 79%|███████▉  | 1387/1759 [00:31<00:08, 44.94it/s][A
 79%|███████▉  | 1392/1759 [00:31<00:08, 44.97it/s][A
 79%|███████▉  | 1397/1759 [00:31<00:08, 45.06it/s][A
 80%|███████▉  | 1402/1759 [00:31<00:07, 45.25it/s][A
 80%|███████▉  | 1407/1759 [00:31<00:07, 45.44it/s][A
 80%|████████  | 1412/1759 [00:31<00:07, 45.58it/s][A
 81%|████████  | 1417/1759 [00:31<00:07, 45.54it/s][A
 81%|████████  | 1422/1759 [00:31<00:07, 45.41it/s][A
 81%|████████  | 1427/1759 [00:32<00:07, 45.18it/s][A
 81%|████████▏ | 1432/1759 [00:32<00:07, 45.01it/s][A
 82%|████████▏ | 1437/1759 [00:32<00:07, 44.96it/s][A
 82%|████████▏ | 1442/1759 [00:32<00:07, 45.06it/s][A
 82%|████████▏ | 1447/1759 [00:32<00:06, 45.16it/s][A
 83%|████████▎ | 1452/1759 [00:32<00:06, 45.30it/s][A
 83%|████████▎ | 1457/1759 [00:32<00:06, 45.33it/s][A
 83%|████████▎ | 1462/1759 [00:32<00:06, 45.54it/s][A
 83%|████████▎ | 1467/1759 [00:33<00:07, 41.12it/s][A
 84%|████████▎ | 1472/1759 [00:33<00:07, 37.20it/s][A
 84%|████████▍ | 1477/1759 [00:33<00:07, 39.52it/s][A
 84%|████████▍ | 1482/1759 [00:33<00:06, 41.23it/s][A
 85%|████████▍ | 1487/1759 [00:33<00:06, 42.51it/s][A
 85%|████████▍ | 1492/1759 [00:33<00:06, 43.46it/s][A
 85%|████████▌ | 1497/1759 [00:33<00:05, 44.15it/s][A
 85%|████████▌ | 1502/1759 [00:33<00:05, 44.65it/s][A
 86%|████████▌ | 1507/1759 [00:33<00:05, 44.74it/s][A
 86%|████████▌ | 1512/1759 [00:34<00:05, 44.46it/s][A
 86%|████████▌ | 1517/1759 [00:34<00:05, 44.37it/s][A
 87%|████████▋ | 1522/1759 [00:34<00:05, 44.56it/s][A
 87%|████████▋ | 1527/1759 [00:34<00:05, 44.78it/s][A
 87%|████████▋ | 1532/1759 [00:34<00:05, 45.05it/s][A
 87%|████████▋ | 1537/1759 [00:34<00:04, 45.29it/s][A
 88%|████████▊ | 1542/1759 [00:34<00:04, 45.43it/s][A
 88%|████████▊ | 1547/1759 [00:34<00:04, 45.57it/s][A
 88%|████████▊ | 1552/1759 [00:34<00:04, 45.44it/s][A
 89%|████████▊ | 1557/1759 [00:35<00:04, 45.16it/s][A
 89%|████████▉ | 1562/1759 [00:35<00:04, 44.90it/s][A
 89%|████████▉ | 1567/1759 [00:35<00:04, 44.86it/s][A
 89%|████████▉ | 1572/1759 [00:35<00:04, 44.98it/s][A
 90%|████████▉ | 1577/1759 [00:35<00:04, 45.15it/s][A
 90%|████████▉ | 1582/1759 [00:35<00:03, 45.37it/s][A
 90%|█████████ | 1587/1759 [00:35<00:03, 45.51it/s][A
 91%|█████████ | 1592/1759 [00:35<00:03, 45.58it/s][A
 91%|█████████ | 1597/1759 [00:35<00:03, 45.43it/s][A
 91%|█████████ | 1602/1759 [00:36<00:03, 45.20it/s][A
 91%|█████████▏| 1607/1759 [00:36<00:03, 45.00it/s][A
 92%|█████████▏| 1612/1759 [00:36<00:03, 44.93it/s][A
 92%|█████████▏| 1617/1759 [00:36<00:03, 45.00it/s][A
 92%|█████████▏| 1622/1759 [00:36<00:03, 45.09it/s][A
 92%|█████████▏| 1627/1759 [00:36<00:02, 45.22it/s][A
 93%|█████████▎| 1632/1759 [00:36<00:02, 45.34it/s][A
 93%|█████████▎| 1637/1759 [00:36<00:02, 45.45it/s][A
 93%|█████████▎| 1642/1759 [00:36<00:02, 45.49it/s][A
 94%|█████████▎| 1647/1759 [00:37<00:02, 45.30it/s][A
 94%|█████████▍| 1652/1759 [00:37<00:02, 45.10it/s][A
 94%|█████████▍| 1657/1759 [00:37<00:02, 45.00it/s][A
 94%|█████████▍| 1662/1759 [00:37<00:02, 44.98it/s][A
 95%|█████████▍| 1667/1759 [00:37<00:02, 45.09it/s][A
 95%|█████████▌| 1672/1759 [00:37<00:01, 45.21it/s][A
 95%|█████████▌| 1677/1759 [00:37<00:01, 45.35it/s][A
 96%|█████████▌| 1682/1759 [00:37<00:01, 45.43it/s][A
 96%|█████████▌| 1687/1759 [00:37<00:01, 45.44it/s][A
 96%|█████████▌| 1692/1759 [00:38<00:01, 45.30it/s][A
 96%|█████████▋| 1697/1759 [00:38<00:01, 45.14it/s][A
 97%|█████████▋| 1702/1759 [00:38<00:01, 31.68it/s][A
 97%|█████████▋| 1707/1759 [00:38<00:01, 34.89it/s][A
 97%|█████████▋| 1712/1759 [00:38<00:01, 37.52it/s][A
 98%|█████████▊| 1717/1759 [00:38<00:01, 39.65it/s][A
 98%|█████████▊| 1722/1759 [00:38<00:00, 41.26it/s][A
 98%|█████████▊| 1727/1759 [00:38<00:00, 42.53it/s][A
 98%|█████████▊| 1732/1759 [00:39<00:00, 43.40it/s][A
 99%|█████████▊| 1737/1759 [00:39<00:00, 44.01it/s][A
 99%|█████████▉| 1742/1759 [00:39<00:00, 44.03it/s][A
 99%|█████████▉| 1747/1759 [00:39<00:00, 44.25it/s][A
100%|█████████▉| 1752/1759 [00:39<00:00, 44.57it/s][A
100%|█████████▉| 1757/1759 [00:39<00:00, 44.86it/s][A
                                                   [A                                                 
100%|██████████| 1759/1759 [00:39<00:00, 44.86it/s][A100%|██████████| 390/390 [06:16<00:00,  3.52it/s]
                                                   [A[INFO|trainer.py:1894] 2023-08-29 15:00:46,534 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-390
[INFO|configuration_utils.py:351] 2023-08-29 15:00:46,910 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-390/config.json
[INFO|modeling_utils.py:886] 2023-08-29 15:00:52,112 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-390/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 15:00:52,334 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-390/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 15:00:52,451 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-390/special_tokens_map.json
[INFO|trainer.py:1343] 2023-08-29 15:01:02,056 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:1352] 2023-08-29 15:01:02,096 >> Loading best model from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-78 (score: 0.9683729410171509).
                                                 100%|██████████| 390/390 [06:48<00:00,  3.52it/s]100%|██████████| 390/390 [06:48<00:00,  1.05s/it]
[INFO|trainer.py:1894] 2023-08-29 15:01:18,477 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model
[INFO|configuration_utils.py:351] 2023-08-29 15:01:18,702 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/config.json
[INFO|modeling_utils.py:886] 2023-08-29 15:01:23,053 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 15:01:23,219 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 15:01:23,299 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/special_tokens_map.json
[INFO|trainer_pt_utils.py:908] 2023-08-29 15:01:23,939 >> ***** train metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:01:23,939 >>   epoch                    =       4.99
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:01:23,939 >>   train_loss               =     0.3545
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:01:23,939 >>   train_runtime            = 0:06:48.44
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:01:23,939 >>   train_samples            =       5000
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:01:23,939 >>   train_samples_per_second =     61.207
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:01:23,939 >>   train_steps_per_second   =      0.955
{'eval_loss': 1.013979196548462, 'eval_runtime': 39.6778, 'eval_samples_per_second': 354.531, 'eval_steps_per_second': 44.332, 'epoch': 4.99}
{'train_runtime': 408.45, 'train_samples_per_second': 61.207, 'train_steps_per_second': 0.955, 'train_loss': 0.3545470017653245, 'epoch': 4.99}
08/29/2023 15:01:24 - INFO - transformer_base.run_clm_rl -   *** Evaluate ***
[INFO|trainer.py:2140] 2023-08-29 15:01:24,311 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 15:01:24,311 >>   Num examples = 14067
[INFO|trainer.py:2145] 2023-08-29 15:01:24,311 >>   Batch size = 8
  0%|          | 0/1759 [00:00<?, ?it/s]  0%|          | 6/1759 [00:00<00:31, 56.34it/s]  1%|          | 12/1759 [00:00<00:34, 50.28it/s]  1%|          | 18/1759 [00:00<00:36, 48.32it/s]  1%|▏         | 23/1759 [00:00<00:36, 47.38it/s]  2%|▏         | 28/1759 [00:00<00:36, 47.08it/s]  2%|▏         | 33/1759 [00:00<00:36, 46.77it/s]  2%|▏         | 38/1759 [00:00<00:36, 46.54it/s]  2%|▏         | 43/1759 [00:00<00:37, 46.16it/s]  3%|▎         | 48/1759 [00:01<00:37, 45.53it/s]  3%|▎         | 53/1759 [00:01<00:37, 45.24it/s]  3%|▎         | 58/1759 [00:01<00:37, 45.28it/s]  4%|▎         | 63/1759 [00:01<00:37, 45.43it/s]  4%|▍         | 68/1759 [00:01<00:37, 45.54it/s]  4%|▍         | 73/1759 [00:01<00:36, 45.63it/s]  4%|▍         | 78/1759 [00:01<00:36, 45.68it/s]  5%|▍         | 83/1759 [00:01<00:36, 45.73it/s]  5%|▌         | 88/1759 [00:01<00:40, 41.25it/s]  5%|▌         | 93/1759 [00:02<00:39, 42.53it/s]  6%|▌         | 98/1759 [00:02<00:38, 43.48it/s]  6%|▌         | 103/1759 [00:02<00:37, 44.14it/s]  6%|▌         | 108/1759 [00:02<00:36, 44.64it/s]  6%|▋         | 113/1759 [00:02<00:36, 44.91it/s]  7%|▋         | 118/1759 [00:02<00:36, 45.21it/s]  7%|▋         | 123/1759 [00:02<00:36, 45.38it/s]  7%|▋         | 128/1759 [00:02<00:36, 45.09it/s]  8%|▊         | 133/1759 [00:02<00:36, 45.07it/s]  8%|▊         | 138/1759 [00:03<00:35, 45.22it/s]  8%|▊         | 143/1759 [00:03<00:35, 45.38it/s]  8%|▊         | 148/1759 [00:03<00:35, 45.53it/s]  9%|▊         | 153/1759 [00:03<00:35, 45.55it/s]  9%|▉         | 158/1759 [00:03<00:35, 45.61it/s]  9%|▉         | 163/1759 [00:03<00:35, 45.60it/s] 10%|▉         | 168/1759 [00:03<00:34, 45.52it/s] 10%|▉         | 173/1759 [00:03<00:35, 45.25it/s] 10%|█         | 178/1759 [00:03<00:35, 45.15it/s] 10%|█         | 183/1759 [00:04<00:34, 45.27it/s] 11%|█         | 188/1759 [00:04<00:34, 45.43it/s] 11%|█         | 193/1759 [00:04<00:34, 45.51it/s] 11%|█▏        | 198/1759 [00:04<00:34, 45.62it/s] 12%|█▏        | 203/1759 [00:04<00:34, 45.65it/s] 12%|█▏        | 208/1759 [00:04<00:33, 45.69it/s] 12%|█▏        | 213/1759 [00:04<00:33, 45.54it/s] 12%|█▏        | 218/1759 [00:04<00:33, 45.39it/s] 13%|█▎        | 223/1759 [00:04<00:37, 41.41it/s] 13%|█▎        | 228/1759 [00:05<00:35, 42.73it/s] 13%|█▎        | 233/1759 [00:05<00:34, 43.70it/s] 14%|█▎        | 238/1759 [00:05<00:34, 44.32it/s] 14%|█▍        | 243/1759 [00:05<00:33, 44.79it/s] 14%|█▍        | 248/1759 [00:05<00:33, 45.11it/s] 14%|█▍        | 253/1759 [00:05<00:33, 45.25it/s] 15%|█▍        | 258/1759 [00:05<00:33, 45.21it/s] 15%|█▍        | 263/1759 [00:05<00:33, 44.89it/s] 15%|█▌        | 268/1759 [00:05<00:33, 44.85it/s] 16%|█▌        | 273/1759 [00:06<00:33, 44.96it/s] 16%|█▌        | 278/1759 [00:06<00:32, 45.19it/s] 16%|█▌        | 283/1759 [00:06<00:32, 45.39it/s] 16%|█▋        | 288/1759 [00:06<00:32, 45.50it/s] 17%|█▋        | 293/1759 [00:06<00:32, 45.59it/s] 17%|█▋        | 298/1759 [00:06<00:32, 45.64it/s] 17%|█▋        | 303/1759 [00:06<00:31, 45.62it/s] 18%|█▊        | 308/1759 [00:06<00:31, 45.39it/s] 18%|█▊        | 313/1759 [00:06<00:31, 45.30it/s] 18%|█▊        | 318/1759 [00:07<00:31, 45.17it/s] 18%|█▊        | 323/1759 [00:07<00:31, 45.19it/s] 19%|█▊        | 328/1759 [00:07<00:31, 45.38it/s] 19%|█▉        | 333/1759 [00:07<00:31, 45.54it/s] 19%|█▉        | 338/1759 [00:07<00:31, 45.61it/s] 19%|█▉        | 343/1759 [00:07<00:31, 45.61it/s] 20%|█▉        | 348/1759 [00:07<00:31, 45.50it/s] 20%|██        | 353/1759 [00:07<00:30, 45.38it/s] 20%|██        | 358/1759 [00:07<00:30, 45.24it/s] 21%|██        | 363/1759 [00:08<00:30, 45.09it/s] 21%|██        | 368/1759 [00:08<00:30, 45.17it/s] 21%|██        | 373/1759 [00:08<00:30, 45.23it/s] 21%|██▏       | 378/1759 [00:08<00:30, 45.43it/s] 22%|██▏       | 383/1759 [00:08<00:30, 45.55it/s] 22%|██▏       | 388/1759 [00:08<00:30, 45.62it/s] 22%|██▏       | 393/1759 [00:08<00:29, 45.56it/s] 23%|██▎       | 398/1759 [00:08<00:29, 45.43it/s] 23%|██▎       | 403/1759 [00:08<00:29, 45.24it/s] 23%|██▎       | 408/1759 [00:09<00:29, 45.19it/s] 23%|██▎       | 413/1759 [00:09<00:29, 45.19it/s] 24%|██▍       | 418/1759 [00:09<00:29, 45.32it/s] 24%|██▍       | 423/1759 [00:09<00:29, 45.42it/s] 24%|██▍       | 428/1759 [00:09<00:29, 45.57it/s] 25%|██▍       | 433/1759 [00:09<00:29, 45.64it/s] 25%|██▍       | 438/1759 [00:09<00:28, 45.57it/s] 25%|██▌       | 443/1759 [00:09<00:29, 45.38it/s] 25%|██▌       | 448/1759 [00:09<00:28, 45.28it/s] 26%|██▌       | 453/1759 [00:10<00:28, 45.13it/s] 26%|██▌       | 458/1759 [00:10<00:28, 45.12it/s] 26%|██▋       | 463/1759 [00:10<00:28, 45.18it/s] 27%|██▋       | 468/1759 [00:10<00:28, 45.33it/s] 27%|██▋       | 473/1759 [00:10<00:28, 45.45it/s] 27%|██▋       | 478/1759 [00:10<00:28, 45.56it/s] 27%|██▋       | 483/1759 [00:10<00:28, 45.53it/s] 28%|██▊       | 488/1759 [00:10<00:28, 45.33it/s] 28%|██▊       | 493/1759 [00:10<00:27, 45.30it/s] 28%|██▊       | 498/1759 [00:11<00:34, 36.85it/s] 29%|██▊       | 503/1759 [00:11<00:32, 39.18it/s] 29%|██▉       | 508/1759 [00:11<00:30, 40.95it/s] 29%|██▉       | 513/1759 [00:11<00:29, 42.28it/s] 29%|██▉       | 518/1759 [00:11<00:28, 43.29it/s] 30%|██▉       | 523/1759 [00:11<00:28, 44.01it/s] 30%|███       | 528/1759 [00:11<00:27, 44.52it/s] 30%|███       | 533/1759 [00:11<00:27, 44.86it/s] 31%|███       | 538/1759 [00:11<00:27, 44.61it/s] 31%|███       | 543/1759 [00:12<00:27, 44.60it/s] 31%|███       | 548/1759 [00:12<00:27, 44.78it/s] 31%|███▏      | 553/1759 [00:12<00:26, 45.09it/s] 32%|███▏      | 558/1759 [00:12<00:26, 45.29it/s] 32%|███▏      | 563/1759 [00:12<00:26, 45.45it/s] 32%|███▏      | 568/1759 [00:12<00:26, 45.53it/s] 33%|███▎      | 573/1759 [00:12<00:26, 45.61it/s] 33%|███▎      | 578/1759 [00:12<00:25, 45.55it/s] 33%|███▎      | 583/1759 [00:12<00:25, 45.27it/s] 33%|███▎      | 588/1759 [00:13<00:25, 45.12it/s] 34%|███▎      | 593/1759 [00:13<00:25, 45.09it/s] 34%|███▍      | 598/1759 [00:13<00:25, 45.21it/s] 34%|███▍      | 603/1759 [00:13<00:25, 45.39it/s] 35%|███▍      | 608/1759 [00:13<00:25, 45.44it/s] 35%|███▍      | 613/1759 [00:13<00:25, 45.51it/s] 35%|███▌      | 618/1759 [00:13<00:25, 45.53it/s] 35%|███▌      | 623/1759 [00:13<00:25, 45.43it/s] 36%|███▌      | 628/1759 [00:13<00:25, 45.22it/s] 36%|███▌      | 633/1759 [00:14<00:24, 45.08it/s] 36%|███▋      | 638/1759 [00:14<00:24, 45.08it/s] 37%|███▋      | 643/1759 [00:14<00:24, 45.16it/s] 37%|███▋      | 648/1759 [00:14<00:24, 45.26it/s] 37%|███▋      | 653/1759 [00:14<00:24, 45.38it/s] 37%|███▋      | 658/1759 [00:14<00:24, 45.47it/s] 38%|███▊      | 663/1759 [00:14<00:24, 45.52it/s] 38%|███▊      | 668/1759 [00:14<00:24, 45.41it/s] 38%|███▊      | 673/1759 [00:14<00:24, 45.17it/s] 39%|███▊      | 678/1759 [00:15<00:23, 45.09it/s] 39%|███▉      | 683/1759 [00:15<00:28, 38.04it/s] 39%|███▉      | 688/1759 [00:15<00:26, 40.17it/s] 39%|███▉      | 693/1759 [00:15<00:25, 41.75it/s] 40%|███▉      | 698/1759 [00:15<00:24, 42.91it/s] 40%|███▉      | 703/1759 [00:15<00:24, 43.74it/s] 40%|████      | 708/1759 [00:15<00:23, 44.36it/s] 41%|████      | 713/1759 [00:15<00:23, 44.78it/s] 41%|████      | 718/1759 [00:15<00:23, 45.10it/s] 41%|████      | 723/1759 [00:16<00:23, 44.91it/s] 41%|████▏     | 728/1759 [00:16<00:23, 44.70it/s] 42%|████▏     | 733/1759 [00:16<00:22, 44.67it/s] 42%|████▏     | 738/1759 [00:16<00:22, 44.80it/s] 42%|████▏     | 743/1759 [00:16<00:22, 45.10it/s] 43%|████▎     | 748/1759 [00:16<00:22, 45.33it/s] 43%|████▎     | 753/1759 [00:16<00:22, 45.49it/s] 43%|████▎     | 758/1759 [00:16<00:21, 45.60it/s] 43%|████▎     | 763/1759 [00:16<00:21, 45.64it/s] 44%|████▎     | 768/1759 [00:17<00:21, 45.34it/s] 44%|████▍     | 773/1759 [00:17<00:21, 45.04it/s] 44%|████▍     | 778/1759 [00:17<00:21, 44.90it/s] 45%|████▍     | 783/1759 [00:17<00:21, 44.95it/s] 45%|████▍     | 788/1759 [00:17<00:21, 45.11it/s] 45%|████▌     | 793/1759 [00:17<00:21, 45.31it/s] 45%|████▌     | 798/1759 [00:17<00:21, 45.42it/s] 46%|████▌     | 803/1759 [00:17<00:20, 45.54it/s] 46%|████▌     | 808/1759 [00:17<00:20, 45.59it/s] 46%|████▌     | 813/1759 [00:18<00:20, 45.50it/s] 47%|████▋     | 818/1759 [00:18<00:20, 45.25it/s] 47%|████▋     | 823/1759 [00:18<00:20, 45.12it/s] 47%|████▋     | 828/1759 [00:18<00:20, 45.10it/s] 47%|████▋     | 833/1759 [00:18<00:20, 45.18it/s] 48%|████▊     | 838/1759 [00:18<00:20, 45.28it/s] 48%|████▊     | 843/1759 [00:18<00:20, 45.38it/s] 48%|████▊     | 848/1759 [00:18<00:20, 45.46it/s] 48%|████▊     | 853/1759 [00:18<00:19, 45.51it/s] 49%|████▉     | 858/1759 [00:19<00:19, 45.39it/s] 49%|████▉     | 863/1759 [00:19<00:19, 45.19it/s] 49%|████▉     | 868/1759 [00:19<00:19, 45.11it/s] 50%|████▉     | 873/1759 [00:19<00:19, 45.08it/s] 50%|████▉     | 878/1759 [00:19<00:19, 45.18it/s] 50%|█████     | 883/1759 [00:19<00:19, 45.20it/s] 50%|█████     | 888/1759 [00:19<00:19, 45.30it/s] 51%|█████     | 893/1759 [00:19<00:19, 45.39it/s] 51%|█████     | 898/1759 [00:19<00:18, 45.43it/s] 51%|█████▏    | 903/1759 [00:20<00:18, 45.29it/s] 52%|█████▏    | 908/1759 [00:20<00:18, 45.16it/s] 52%|█████▏    | 913/1759 [00:20<00:18, 45.10it/s] 52%|█████▏    | 918/1759 [00:20<00:18, 45.17it/s] 52%|█████▏    | 923/1759 [00:20<00:18, 45.19it/s] 53%|█████▎    | 928/1759 [00:20<00:18, 45.24it/s] 53%|█████▎    | 933/1759 [00:20<00:18, 45.21it/s] 53%|█████▎    | 938/1759 [00:20<00:18, 45.36it/s] 54%|█████▎    | 943/1759 [00:20<00:18, 45.30it/s] 54%|█████▍    | 948/1759 [00:21<00:17, 45.23it/s] 54%|█████▍    | 953/1759 [00:21<00:17, 45.13it/s] 54%|█████▍    | 958/1759 [00:21<00:17, 45.01it/s] 55%|█████▍    | 963/1759 [00:21<00:17, 45.16it/s] 55%|█████▌    | 968/1759 [00:21<00:17, 45.23it/s] 55%|█████▌    | 973/1759 [00:21<00:17, 45.33it/s] 56%|█████▌    | 978/1759 [00:21<00:17, 45.39it/s] 56%|█████▌    | 983/1759 [00:21<00:17, 45.43it/s] 56%|█████▌    | 988/1759 [00:21<00:16, 45.39it/s] 56%|█████▋    | 993/1759 [00:22<00:18, 40.51it/s] 57%|█████▋    | 998/1759 [00:22<00:18, 41.97it/s] 57%|█████▋    | 1003/1759 [00:22<00:17, 43.07it/s] 57%|█████▋    | 1008/1759 [00:22<00:17, 43.85it/s] 58%|█████▊    | 1013/1759 [00:22<00:16, 44.40it/s] 58%|█████▊    | 1018/1759 [00:22<00:16, 44.70it/s] 58%|█████▊    | 1023/1759 [00:22<00:16, 44.92it/s] 58%|█████▊    | 1028/1759 [00:22<00:16, 44.97it/s] 59%|█████▊    | 1033/1759 [00:22<00:16, 44.76it/s] 59%|█████▉    | 1038/1759 [00:23<00:16, 44.62it/s] 59%|█████▉    | 1043/1759 [00:23<00:16, 44.70it/s] 60%|█████▉    | 1048/1759 [00:23<00:15, 44.94it/s] 60%|█████▉    | 1053/1759 [00:23<00:15, 45.10it/s] 60%|██████    | 1058/1759 [00:23<00:15, 45.30it/s] 60%|██████    | 1063/1759 [00:23<00:15, 45.36it/s] 61%|██████    | 1068/1759 [00:23<00:15, 45.46it/s] 61%|██████    | 1073/1759 [00:23<00:15, 45.42it/s] 61%|██████▏   | 1078/1759 [00:23<00:15, 45.30it/s] 62%|██████▏   | 1083/1759 [00:24<00:14, 45.12it/s] 62%|██████▏   | 1088/1759 [00:24<00:14, 45.04it/s] 62%|██████▏   | 1093/1759 [00:24<00:14, 45.05it/s] 62%|██████▏   | 1098/1759 [00:24<00:14, 45.21it/s] 63%|██████▎   | 1103/1759 [00:24<00:14, 45.26it/s] 63%|██████▎   | 1108/1759 [00:24<00:14, 45.36it/s] 63%|██████▎   | 1113/1759 [00:24<00:14, 45.39it/s] 64%|██████▎   | 1118/1759 [00:24<00:14, 45.31it/s] 64%|██████▍   | 1123/1759 [00:24<00:14, 45.24it/s] 64%|██████▍   | 1128/1759 [00:25<00:13, 45.12it/s] 64%|██████▍   | 1133/1759 [00:25<00:13, 45.01it/s] 65%|██████▍   | 1138/1759 [00:25<00:13, 44.99it/s] 65%|██████▍   | 1143/1759 [00:25<00:13, 45.16it/s] 65%|██████▌   | 1148/1759 [00:25<00:13, 45.31it/s] 66%|██████▌   | 1153/1759 [00:25<00:13, 45.43it/s] 66%|██████▌   | 1158/1759 [00:25<00:13, 45.46it/s] 66%|██████▌   | 1163/1759 [00:25<00:13, 45.45it/s] 66%|██████▋   | 1168/1759 [00:25<00:13, 45.37it/s] 67%|██████▋   | 1173/1759 [00:26<00:12, 45.29it/s] 67%|██████▋   | 1178/1759 [00:26<00:12, 45.20it/s] 67%|██████▋   | 1183/1759 [00:26<00:12, 45.23it/s] 68%|██████▊   | 1188/1759 [00:26<00:12, 45.28it/s] 68%|██████▊   | 1193/1759 [00:26<00:12, 45.46it/s] 68%|██████▊   | 1198/1759 [00:26<00:12, 45.57it/s] 68%|██████▊   | 1203/1759 [00:26<00:12, 45.61it/s] 69%|██████▊   | 1208/1759 [00:26<00:12, 45.52it/s] 69%|██████▉   | 1213/1759 [00:26<00:12, 45.41it/s] 69%|██████▉   | 1218/1759 [00:27<00:11, 45.28it/s] 70%|██████▉   | 1223/1759 [00:27<00:13, 40.98it/s] 70%|██████▉   | 1228/1759 [00:27<00:12, 42.33it/s] 70%|███████   | 1233/1759 [00:27<00:12, 43.34it/s] 70%|███████   | 1238/1759 [00:27<00:11, 44.07it/s] 71%|███████   | 1243/1759 [00:27<00:11, 44.58it/s] 71%|███████   | 1248/1759 [00:27<00:11, 44.97it/s] 71%|███████   | 1253/1759 [00:27<00:11, 45.21it/s] 72%|███████▏  | 1258/1759 [00:27<00:11, 45.15it/s] 72%|███████▏  | 1263/1759 [00:28<00:11, 44.84it/s] 72%|███████▏  | 1268/1759 [00:28<00:10, 44.74it/s] 72%|███████▏  | 1273/1759 [00:28<00:10, 44.93it/s] 73%|███████▎  | 1278/1759 [00:28<00:10, 45.10it/s] 73%|███████▎  | 1283/1759 [00:28<00:10, 45.34it/s] 73%|███████▎  | 1288/1759 [00:28<00:10, 45.50it/s] 74%|███████▎  | 1293/1759 [00:28<00:10, 45.62it/s] 74%|███████▍  | 1298/1759 [00:28<00:10, 45.68it/s] 74%|███████▍  | 1303/1759 [00:28<00:10, 45.52it/s] 74%|███████▍  | 1308/1759 [00:29<00:09, 45.25it/s] 75%|███████▍  | 1313/1759 [00:29<00:09, 45.06it/s] 75%|███████▍  | 1318/1759 [00:29<00:09, 45.06it/s] 75%|███████▌  | 1323/1759 [00:29<00:09, 45.13it/s] 75%|███████▌  | 1328/1759 [00:29<00:09, 45.27it/s] 76%|███████▌  | 1333/1759 [00:29<00:09, 45.47it/s] 76%|███████▌  | 1338/1759 [00:29<00:09, 45.59it/s] 76%|███████▋  | 1343/1759 [00:29<00:09, 45.42it/s] 77%|███████▋  | 1348/1759 [00:29<00:09, 45.36it/s] 77%|███████▋  | 1353/1759 [00:30<00:08, 45.45it/s] 77%|███████▋  | 1358/1759 [00:30<00:08, 45.23it/s] 77%|███████▋  | 1363/1759 [00:30<00:08, 45.23it/s] 78%|███████▊  | 1368/1759 [00:30<00:08, 45.23it/s] 78%|███████▊  | 1373/1759 [00:30<00:08, 45.25it/s] 78%|███████▊  | 1378/1759 [00:30<00:08, 45.40it/s] 79%|███████▊  | 1383/1759 [00:30<00:08, 45.56it/s] 79%|███████▉  | 1388/1759 [00:30<00:08, 45.64it/s] 79%|███████▉  | 1393/1759 [00:30<00:08, 45.56it/s] 79%|███████▉  | 1398/1759 [00:31<00:07, 45.40it/s] 80%|███████▉  | 1403/1759 [00:31<00:07, 45.21it/s] 80%|████████  | 1408/1759 [00:31<00:07, 45.19it/s] 80%|████████  | 1413/1759 [00:31<00:07, 45.21it/s] 81%|████████  | 1418/1759 [00:31<00:07, 45.32it/s] 81%|████████  | 1423/1759 [00:31<00:07, 45.41it/s] 81%|████████  | 1428/1759 [00:31<00:07, 45.54it/s] 81%|████████▏ | 1433/1759 [00:31<00:07, 45.60it/s] 82%|████████▏ | 1438/1759 [00:31<00:07, 45.51it/s] 82%|████████▏ | 1443/1759 [00:32<00:06, 45.37it/s] 82%|████████▏ | 1448/1759 [00:32<00:06, 45.23it/s] 83%|████████▎ | 1453/1759 [00:32<00:10, 29.66it/s] 83%|████████▎ | 1458/1759 [00:32<00:09, 33.18it/s] 83%|████████▎ | 1463/1759 [00:32<00:08, 36.19it/s] 83%|████████▎ | 1468/1759 [00:32<00:07, 38.62it/s] 84%|████████▎ | 1473/1759 [00:32<00:07, 40.56it/s] 84%|████████▍ | 1478/1759 [00:33<00:06, 42.02it/s] 84%|████████▍ | 1483/1759 [00:33<00:06, 43.10it/s] 85%|████████▍ | 1488/1759 [00:33<00:06, 43.81it/s] 85%|████████▍ | 1493/1759 [00:33<00:06, 43.91it/s] 85%|████████▌ | 1498/1759 [00:33<00:05, 44.03it/s] 85%|████████▌ | 1503/1759 [00:33<00:05, 44.27it/s] 86%|████████▌ | 1508/1759 [00:33<00:05, 44.58it/s] 86%|████████▌ | 1513/1759 [00:33<00:05, 44.87it/s] 86%|████████▋ | 1518/1759 [00:33<00:05, 45.11it/s] 87%|████████▋ | 1523/1759 [00:34<00:05, 45.33it/s] 87%|████████▋ | 1528/1759 [00:34<00:05, 45.50it/s] 87%|████████▋ | 1533/1759 [00:34<00:04, 45.55it/s] 87%|████████▋ | 1538/1759 [00:34<00:04, 45.35it/s] 88%|████████▊ | 1543/1759 [00:34<00:04, 45.16it/s] 88%|████████▊ | 1548/1759 [00:34<00:04, 45.09it/s] 88%|████████▊ | 1553/1759 [00:34<00:04, 45.07it/s] 89%|████████▊ | 1558/1759 [00:34<00:04, 45.19it/s] 89%|████████▉ | 1563/1759 [00:34<00:04, 45.30it/s] 89%|████████▉ | 1568/1759 [00:35<00:04, 45.44it/s] 89%|████████▉ | 1573/1759 [00:35<00:04, 45.56it/s] 90%|████████▉ | 1578/1759 [00:35<00:03, 45.60it/s] 90%|████████▉ | 1583/1759 [00:35<00:03, 45.51it/s] 90%|█████████ | 1588/1759 [00:35<00:03, 45.33it/s] 91%|█████████ | 1593/1759 [00:35<00:03, 45.25it/s] 91%|█████████ | 1598/1759 [00:35<00:03, 45.26it/s] 91%|█████████ | 1603/1759 [00:35<00:03, 45.25it/s] 91%|█████████▏| 1608/1759 [00:35<00:03, 45.35it/s] 92%|█████████▏| 1613/1759 [00:36<00:03, 45.42it/s] 92%|█████████▏| 1618/1759 [00:36<00:03, 45.48it/s] 92%|█████████▏| 1623/1759 [00:36<00:02, 45.48it/s] 93%|█████████▎| 1628/1759 [00:36<00:02, 45.38it/s] 93%|█████████▎| 1633/1759 [00:36<00:02, 45.29it/s] 93%|█████████▎| 1638/1759 [00:36<00:02, 45.24it/s] 93%|█████████▎| 1643/1759 [00:36<00:02, 45.18it/s] 94%|█████████▎| 1648/1759 [00:36<00:02, 45.21it/s] 94%|█████████▍| 1653/1759 [00:36<00:02, 45.31it/s] 94%|█████████▍| 1658/1759 [00:37<00:02, 45.42it/s] 95%|█████████▍| 1663/1759 [00:37<00:02, 45.46it/s] 95%|█████████▍| 1668/1759 [00:37<00:02, 45.46it/s] 95%|█████████▌| 1673/1759 [00:37<00:01, 45.39it/s] 95%|█████████▌| 1678/1759 [00:37<00:01, 45.32it/s] 96%|█████████▌| 1683/1759 [00:37<00:01, 45.21it/s] 96%|█████████▌| 1688/1759 [00:37<00:02, 33.13it/s] 96%|█████████▌| 1693/1759 [00:37<00:01, 36.16it/s] 97%|█████████▋| 1698/1759 [00:38<00:01, 38.59it/s] 97%|█████████▋| 1703/1759 [00:38<00:01, 40.51it/s] 97%|█████████▋| 1708/1759 [00:38<00:01, 41.95it/s] 97%|█████████▋| 1713/1759 [00:38<00:01, 43.05it/s] 98%|█████████▊| 1718/1759 [00:38<00:00, 43.83it/s] 98%|█████████▊| 1723/1759 [00:38<00:00, 44.32it/s] 98%|█████████▊| 1728/1759 [00:38<00:00, 44.24it/s] 99%|█████████▊| 1733/1759 [00:38<00:00, 44.38it/s] 99%|█████████▉| 1738/1759 [00:38<00:00, 44.73it/s] 99%|█████████▉| 1743/1759 [00:39<00:00, 44.99it/s] 99%|█████████▉| 1748/1759 [00:39<00:00, 45.19it/s]100%|█████████▉| 1753/1759 [00:39<00:00, 45.31it/s]100%|█████████▉| 1758/1759 [00:39<00:00, 45.43it/s]100%|██████████| 1759/1759 [00:39<00:00, 44.69it/s]
[INFO|trainer_pt_utils.py:908] 2023-08-29 15:02:03,691 >> ***** eval metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:02:03,691 >>   epoch                   =       4.99
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:02:03,691 >>   eval_loss               =     0.9684
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:02:03,691 >>   eval_runtime            = 0:00:39.38
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:02:03,691 >>   eval_samples            =      14067
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:02:03,691 >>   eval_samples_per_second =    357.211
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:02:03,691 >>   eval_steps_per_second   =     44.667
[INFO|trainer_pt_utils.py:913] 2023-08-29 15:02:03,691 >>   perplexity              =     2.6337
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:22,148 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:22,205 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:22,205 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:22,205 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:22,205 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 15:02:23,197 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 15:02:23,198 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 15:02:23,864 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 15:02:25,009 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 15:02:25,009 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:28,395 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:28,450 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:28,450 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:28,450 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:02:28,450 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 15:02:29,380 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 15:02:29,381 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 15:02:30,055 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 15:02:30,323 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 15:02:30,323 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-312
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-156
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-390
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-78
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/generator/iter5/model/checkpoint-234
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/dev.jsonl', 'labels': ['country', 'part of', 'platform', 'publisher', 'sport'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_in_all_single_is_eval_True.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_out_filter_all_single_is_eval_True.jsonl'}}
predict vocab size: 22024
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 22124, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.36it/s]Extractor Predicting: 2it [00:01,  1.53it/s]Extractor Predicting: 3it [00:01,  1.58it/s]Extractor Predicting: 4it [00:02,  1.68it/s]Extractor Predicting: 5it [00:03,  1.71it/s]Extractor Predicting: 6it [00:03,  1.69it/s]Extractor Predicting: 7it [00:04,  1.72it/s]Extractor Predicting: 8it [00:04,  1.72it/s]Extractor Predicting: 9it [00:05,  1.71it/s]Extractor Predicting: 10it [00:06,  1.66it/s]Extractor Predicting: 11it [00:06,  1.64it/s]Extractor Predicting: 12it [00:07,  1.62it/s]Extractor Predicting: 13it [00:07,  1.60it/s]Extractor Predicting: 14it [00:08,  1.58it/s]Extractor Predicting: 15it [00:09,  1.50it/s]Extractor Predicting: 16it [00:09,  1.51it/s]Extractor Predicting: 17it [00:10,  1.52it/s]Extractor Predicting: 18it [00:11,  1.53it/s]Extractor Predicting: 19it [00:11,  1.56it/s]Extractor Predicting: 20it [00:12,  1.55it/s]Extractor Predicting: 21it [00:13,  1.54it/s]Extractor Predicting: 22it [00:13,  1.55it/s]Extractor Predicting: 23it [00:14,  1.50it/s]Extractor Predicting: 24it [00:15,  1.54it/s]Extractor Predicting: 25it [00:15,  1.59it/s]Extractor Predicting: 26it [00:16,  1.57it/s]Extractor Predicting: 27it [00:17,  1.58it/s]Extractor Predicting: 28it [00:17,  1.65it/s]Extractor Predicting: 29it [00:18,  1.69it/s]Extractor Predicting: 30it [00:18,  1.70it/s]Extractor Predicting: 31it [00:19,  1.69it/s]Extractor Predicting: 32it [00:19,  1.65it/s]Extractor Predicting: 33it [00:20,  1.69it/s]Extractor Predicting: 34it [00:21,  1.69it/s]Extractor Predicting: 35it [00:21,  1.71it/s]Extractor Predicting: 36it [00:22,  1.69it/s]Extractor Predicting: 37it [00:22,  1.70it/s]Extractor Predicting: 38it [00:23,  1.73it/s]Extractor Predicting: 39it [00:24,  1.71it/s]Extractor Predicting: 40it [00:24,  1.71it/s]Extractor Predicting: 41it [00:25,  1.66it/s]Extractor Predicting: 42it [00:25,  1.69it/s]Extractor Predicting: 43it [00:26,  1.69it/s]Extractor Predicting: 44it [00:26,  1.71it/s]Extractor Predicting: 45it [00:27,  1.73it/s]Extractor Predicting: 46it [00:28,  1.74it/s]Extractor Predicting: 47it [00:28,  1.75it/s]Extractor Predicting: 48it [00:29,  1.72it/s]Extractor Predicting: 49it [00:29,  1.73it/s]Extractor Predicting: 50it [00:30,  1.72it/s]Extractor Predicting: 51it [00:30,  1.74it/s]Extractor Predicting: 52it [00:31,  1.71it/s]Extractor Predicting: 53it [00:32,  1.73it/s]Extractor Predicting: 54it [00:32,  1.76it/s]Extractor Predicting: 55it [00:33,  1.77it/s]Extractor Predicting: 56it [00:33,  1.77it/s]Extractor Predicting: 57it [00:34,  1.74it/s]Extractor Predicting: 58it [00:35,  1.69it/s]Extractor Predicting: 59it [00:35,  1.69it/s]Extractor Predicting: 60it [00:36,  1.73it/s]Extractor Predicting: 61it [00:36,  1.73it/s]Extractor Predicting: 62it [00:37,  1.71it/s]Extractor Predicting: 63it [00:37,  1.72it/s]Extractor Predicting: 64it [00:38,  1.71it/s]Extractor Predicting: 65it [00:39,  1.70it/s]Extractor Predicting: 66it [00:39,  1.65it/s]Extractor Predicting: 67it [00:40,  1.67it/s]Extractor Predicting: 68it [00:41,  1.62it/s]Extractor Predicting: 69it [00:41,  1.68it/s]Extractor Predicting: 70it [00:42,  1.72it/s]Extractor Predicting: 71it [00:42,  1.73it/s]Extractor Predicting: 72it [00:43,  1.69it/s]Extractor Predicting: 73it [00:43,  1.67it/s]Extractor Predicting: 74it [00:44,  1.67it/s]Extractor Predicting: 75it [00:45,  1.61it/s]Extractor Predicting: 76it [00:45,  1.60it/s]Extractor Predicting: 77it [00:46,  1.61it/s]Extractor Predicting: 78it [00:46,  1.70it/s]Extractor Predicting: 79it [00:47,  1.68it/s]Extractor Predicting: 80it [00:48,  1.70it/s]Extractor Predicting: 81it [00:48,  1.69it/s]Extractor Predicting: 82it [00:49,  1.71it/s]Extractor Predicting: 83it [00:49,  1.70it/s]Extractor Predicting: 84it [00:50,  1.75it/s]Extractor Predicting: 85it [00:50,  1.75it/s]Extractor Predicting: 86it [00:51,  1.71it/s]Extractor Predicting: 87it [00:52,  1.70it/s]Extractor Predicting: 88it [00:52,  1.61it/s]Extractor Predicting: 89it [00:53,  1.67it/s]Extractor Predicting: 90it [00:54,  1.51it/s]Extractor Predicting: 91it [00:54,  1.58it/s]Extractor Predicting: 92it [00:55,  1.54it/s]Extractor Predicting: 93it [00:56,  1.54it/s]Extractor Predicting: 94it [00:56,  1.58it/s]Extractor Predicting: 95it [00:57,  1.66it/s]Extractor Predicting: 96it [00:57,  1.68it/s]Extractor Predicting: 97it [00:58,  1.75it/s]Extractor Predicting: 98it [00:58,  1.79it/s]Extractor Predicting: 99it [00:59,  1.76it/s]Extractor Predicting: 100it [00:59,  1.85it/s]Extractor Predicting: 101it [01:00,  1.74it/s]Extractor Predicting: 102it [01:01,  1.74it/s]Extractor Predicting: 103it [01:01,  1.77it/s]Extractor Predicting: 104it [01:02,  1.78it/s]Extractor Predicting: 105it [01:02,  1.82it/s]Extractor Predicting: 106it [01:03,  1.80it/s]Extractor Predicting: 107it [01:03,  1.77it/s]Extractor Predicting: 108it [01:04,  1.76it/s]Extractor Predicting: 109it [01:05,  1.76it/s]Extractor Predicting: 110it [01:05,  1.72it/s]Extractor Predicting: 111it [01:06,  1.76it/s]Extractor Predicting: 112it [01:06,  1.78it/s]Extractor Predicting: 113it [01:07,  1.79it/s]Extractor Predicting: 114it [01:07,  1.83it/s]Extractor Predicting: 115it [01:08,  1.82it/s]Extractor Predicting: 116it [01:08,  1.85it/s]Extractor Predicting: 117it [01:09,  1.83it/s]Extractor Predicting: 118it [01:10,  1.83it/s]Extractor Predicting: 119it [01:10,  1.81it/s]Extractor Predicting: 120it [01:11,  1.85it/s]Extractor Predicting: 121it [01:11,  1.83it/s]Extractor Predicting: 122it [01:12,  1.78it/s]Extractor Predicting: 123it [01:12,  1.78it/s]Extractor Predicting: 124it [01:13,  1.77it/s]Extractor Predicting: 125it [01:13,  1.78it/s]Extractor Predicting: 126it [01:14,  1.79it/s]Extractor Predicting: 127it [01:15,  1.85it/s]Extractor Predicting: 128it [01:15,  1.82it/s]Extractor Predicting: 129it [01:16,  1.83it/s]Extractor Predicting: 130it [01:16,  1.82it/s]Extractor Predicting: 131it [01:17,  1.81it/s]Extractor Predicting: 132it [01:17,  1.84it/s]Extractor Predicting: 133it [01:18,  1.79it/s]Extractor Predicting: 134it [01:18,  1.83it/s]Extractor Predicting: 135it [01:19,  1.83it/s]Extractor Predicting: 136it [01:20,  1.82it/s]Extractor Predicting: 137it [01:20,  1.80it/s]Extractor Predicting: 138it [01:21,  1.78it/s]Extractor Predicting: 139it [01:21,  1.78it/s]Extractor Predicting: 140it [01:22,  1.76it/s]Extractor Predicting: 141it [01:22,  1.79it/s]Extractor Predicting: 142it [01:23,  1.83it/s]Extractor Predicting: 143it [01:23,  1.86it/s]Extractor Predicting: 144it [01:24,  1.86it/s]Extractor Predicting: 145it [01:25,  1.79it/s]Extractor Predicting: 146it [01:25,  1.77it/s]Extractor Predicting: 147it [01:26,  1.75it/s]Extractor Predicting: 148it [01:26,  1.74it/s]Extractor Predicting: 149it [01:27,  1.73it/s]Extractor Predicting: 150it [01:27,  1.74it/s]Extractor Predicting: 151it [01:28,  1.68it/s]Extractor Predicting: 152it [01:29,  1.63it/s]Extractor Predicting: 153it [01:29,  1.59it/s]Extractor Predicting: 154it [01:30,  1.59it/s]Extractor Predicting: 155it [01:31,  1.57it/s]Extractor Predicting: 156it [01:31,  1.58it/s]Extractor Predicting: 157it [01:32,  1.62it/s]Extractor Predicting: 158it [01:33,  1.58it/s]Extractor Predicting: 159it [01:33,  1.63it/s]Extractor Predicting: 160it [01:34,  1.67it/s]Extractor Predicting: 161it [01:34,  1.70it/s]Extractor Predicting: 162it [01:35,  1.71it/s]Extractor Predicting: 163it [01:35,  1.69it/s]Extractor Predicting: 164it [01:36,  1.70it/s]Extractor Predicting: 165it [01:37,  1.69it/s]Extractor Predicting: 166it [01:37,  1.66it/s]Extractor Predicting: 167it [01:38,  1.70it/s]Extractor Predicting: 168it [01:38,  1.68it/s]Extractor Predicting: 169it [01:39,  1.71it/s]Extractor Predicting: 170it [01:39,  1.74it/s]Extractor Predicting: 171it [01:40,  1.77it/s]Extractor Predicting: 172it [01:41,  1.71it/s]Extractor Predicting: 173it [01:41,  1.75it/s]Extractor Predicting: 174it [01:42,  1.75it/s]Extractor Predicting: 175it [01:42,  1.72it/s]Extractor Predicting: 176it [01:43,  1.71it/s]Extractor Predicting: 177it [01:44,  1.69it/s]Extractor Predicting: 178it [01:44,  1.77it/s]Extractor Predicting: 179it [01:45,  1.88it/s]Extractor Predicting: 180it [01:45,  1.98it/s]Extractor Predicting: 181it [01:46,  1.97it/s]Extractor Predicting: 182it [01:46,  1.92it/s]Extractor Predicting: 183it [01:47,  1.80it/s]Extractor Predicting: 184it [01:47,  1.72it/s]Extractor Predicting: 185it [01:48,  1.74it/s]Extractor Predicting: 186it [01:48,  1.73it/s]Extractor Predicting: 187it [01:49,  1.71it/s]Extractor Predicting: 188it [01:50,  1.69it/s]Extractor Predicting: 189it [01:50,  1.70it/s]Extractor Predicting: 190it [01:51,  1.65it/s]Extractor Predicting: 191it [01:52,  1.64it/s]Extractor Predicting: 192it [01:52,  1.67it/s]Extractor Predicting: 193it [01:53,  1.75it/s]Extractor Predicting: 194it [01:53,  1.77it/s]Extractor Predicting: 195it [01:54,  1.79it/s]Extractor Predicting: 196it [01:54,  1.75it/s]Extractor Predicting: 197it [01:55,  1.74it/s]Extractor Predicting: 198it [01:56,  1.69it/s]Extractor Predicting: 199it [01:56,  1.67it/s]Extractor Predicting: 200it [01:57,  1.70it/s]Extractor Predicting: 201it [01:57,  1.71it/s]Extractor Predicting: 202it [01:58,  1.70it/s]Extractor Predicting: 203it [01:58,  1.71it/s]Extractor Predicting: 204it [01:59,  1.72it/s]Extractor Predicting: 205it [02:00,  1.75it/s]Extractor Predicting: 206it [02:00,  1.74it/s]Extractor Predicting: 207it [02:01,  1.73it/s]Extractor Predicting: 208it [02:01,  1.70it/s]Extractor Predicting: 209it [02:02,  1.71it/s]Extractor Predicting: 210it [02:02,  1.74it/s]Extractor Predicting: 211it [02:03,  1.71it/s]Extractor Predicting: 212it [02:04,  1.68it/s]Extractor Predicting: 213it [02:04,  1.67it/s]Extractor Predicting: 214it [02:05,  1.67it/s]Extractor Predicting: 215it [02:05,  1.71it/s]Extractor Predicting: 216it [02:06,  1.70it/s]Extractor Predicting: 217it [02:07,  1.72it/s]Extractor Predicting: 218it [02:07,  1.75it/s]Extractor Predicting: 219it [02:08,  1.74it/s]Extractor Predicting: 220it [02:08,  1.73it/s]Extractor Predicting: 221it [02:09,  1.74it/s]Extractor Predicting: 222it [02:09,  1.75it/s]Extractor Predicting: 223it [02:10,  1.72it/s]Extractor Predicting: 224it [02:11,  1.68it/s]Extractor Predicting: 225it [02:12,  1.46it/s]Extractor Predicting: 226it [02:12,  1.54it/s]Extractor Predicting: 227it [02:13,  1.59it/s]Extractor Predicting: 228it [02:13,  1.60it/s]Extractor Predicting: 229it [02:14,  1.62it/s]Extractor Predicting: 230it [02:15,  1.63it/s]Extractor Predicting: 231it [02:15,  1.61it/s]Extractor Predicting: 232it [02:16,  1.67it/s]Extractor Predicting: 233it [02:16,  1.63it/s]Extractor Predicting: 234it [02:17,  1.60it/s]Extractor Predicting: 235it [02:18,  1.63it/s]Extractor Predicting: 236it [02:18,  1.64it/s]Extractor Predicting: 237it [02:19,  1.66it/s]Extractor Predicting: 238it [02:19,  1.63it/s]Extractor Predicting: 239it [02:20,  1.66it/s]Extractor Predicting: 240it [02:21,  1.67it/s]Extractor Predicting: 241it [02:21,  1.69it/s]Extractor Predicting: 242it [02:22,  1.66it/s]Extractor Predicting: 243it [02:22,  1.67it/s]Extractor Predicting: 244it [02:23,  1.68it/s]Extractor Predicting: 245it [02:24,  1.64it/s]Extractor Predicting: 246it [02:24,  1.68it/s]Extractor Predicting: 247it [02:25,  1.71it/s]Extractor Predicting: 248it [02:25,  1.65it/s]Extractor Predicting: 249it [02:26,  1.65it/s]Extractor Predicting: 250it [02:27,  1.69it/s]Extractor Predicting: 251it [02:27,  1.72it/s]Extractor Predicting: 252it [02:28,  1.76it/s]Extractor Predicting: 253it [02:28,  1.76it/s]Extractor Predicting: 254it [02:29,  1.76it/s]Extractor Predicting: 255it [02:29,  1.74it/s]Extractor Predicting: 256it [02:30,  1.72it/s]Extractor Predicting: 257it [02:31,  1.72it/s]Extractor Predicting: 258it [02:31,  1.74it/s]Extractor Predicting: 259it [02:32,  1.71it/s]Extractor Predicting: 260it [02:32,  1.72it/s]Extractor Predicting: 261it [02:33,  1.76it/s]Extractor Predicting: 262it [02:33,  1.80it/s]Extractor Predicting: 263it [02:34,  1.79it/s]Extractor Predicting: 264it [02:35,  1.81it/s]Extractor Predicting: 265it [02:35,  1.79it/s]Extractor Predicting: 266it [02:36,  1.78it/s]Extractor Predicting: 267it [02:36,  1.77it/s]Extractor Predicting: 268it [02:37,  1.73it/s]Extractor Predicting: 269it [02:37,  1.75it/s]Extractor Predicting: 270it [02:38,  1.73it/s]Extractor Predicting: 271it [02:39,  1.75it/s]Extractor Predicting: 272it [02:39,  1.77it/s]Extractor Predicting: 273it [02:40,  1.77it/s]Extractor Predicting: 274it [02:40,  1.77it/s]Extractor Predicting: 275it [02:41,  1.75it/s]Extractor Predicting: 276it [02:41,  1.77it/s]Extractor Predicting: 277it [02:42,  1.77it/s]Extractor Predicting: 278it [02:43,  1.73it/s]Extractor Predicting: 279it [02:43,  1.72it/s]Extractor Predicting: 280it [02:44,  1.70it/s]Extractor Predicting: 281it [02:44,  1.70it/s]Extractor Predicting: 282it [02:45,  1.67it/s]Extractor Predicting: 283it [02:46,  1.67it/s]Extractor Predicting: 284it [02:46,  1.72it/s]Extractor Predicting: 285it [02:47,  1.71it/s]Extractor Predicting: 286it [02:47,  1.67it/s]Extractor Predicting: 287it [02:48,  1.65it/s]Extractor Predicting: 288it [02:48,  1.68it/s]Extractor Predicting: 289it [02:49,  1.64it/s]Extractor Predicting: 290it [02:50,  1.65it/s]Extractor Predicting: 291it [02:50,  1.67it/s]Extractor Predicting: 292it [02:51,  1.65it/s]Extractor Predicting: 293it [02:52,  1.66it/s]Extractor Predicting: 294it [02:52,  1.67it/s]Extractor Predicting: 295it [02:53,  1.67it/s]Extractor Predicting: 296it [02:53,  1.68it/s]Extractor Predicting: 297it [02:54,  1.67it/s]Extractor Predicting: 298it [02:54,  1.71it/s]Extractor Predicting: 299it [02:55,  1.67it/s]Extractor Predicting: 300it [02:56,  1.65it/s]Extractor Predicting: 301it [02:56,  1.65it/s]Extractor Predicting: 302it [02:57,  1.67it/s]Extractor Predicting: 303it [02:58,  1.67it/s]Extractor Predicting: 304it [02:58,  1.69it/s]Extractor Predicting: 305it [02:59,  1.72it/s]Extractor Predicting: 306it [02:59,  1.68it/s]Extractor Predicting: 307it [03:00,  1.71it/s]Extractor Predicting: 308it [03:00,  1.72it/s]Extractor Predicting: 309it [03:01,  1.70it/s]Extractor Predicting: 310it [03:02,  1.64it/s]Extractor Predicting: 311it [03:02,  1.59it/s]Extractor Predicting: 312it [03:03,  1.53it/s]Extractor Predicting: 313it [03:04,  1.53it/s]Extractor Predicting: 314it [03:04,  1.51it/s]Extractor Predicting: 315it [03:05,  1.51it/s]Extractor Predicting: 316it [03:06,  1.50it/s]Extractor Predicting: 317it [03:06,  1.51it/s]Extractor Predicting: 318it [03:07,  1.52it/s]Extractor Predicting: 319it [03:08,  1.47it/s]Extractor Predicting: 320it [03:08,  1.49it/s]Extractor Predicting: 321it [03:09,  1.48it/s]Extractor Predicting: 322it [03:10,  1.49it/s]Extractor Predicting: 323it [03:10,  1.50it/s]Extractor Predicting: 324it [03:11,  1.51it/s]Extractor Predicting: 325it [03:12,  1.51it/s]Extractor Predicting: 326it [03:12,  1.52it/s]Extractor Predicting: 327it [03:13,  1.57it/s]Extractor Predicting: 328it [03:14,  1.59it/s]Extractor Predicting: 329it [03:14,  1.62it/s]Extractor Predicting: 330it [03:15,  1.66it/s]Extractor Predicting: 331it [03:15,  1.68it/s]Extractor Predicting: 332it [03:16,  1.72it/s]Extractor Predicting: 333it [03:16,  1.72it/s]Extractor Predicting: 334it [03:17,  1.69it/s]Extractor Predicting: 335it [03:18,  1.70it/s]Extractor Predicting: 336it [03:19,  1.42it/s]Extractor Predicting: 337it [03:19,  1.53it/s]Extractor Predicting: 338it [03:20,  1.59it/s]Extractor Predicting: 339it [03:20,  1.62it/s]Extractor Predicting: 340it [03:21,  1.61it/s]Extractor Predicting: 341it [03:22,  1.58it/s]Extractor Predicting: 342it [03:22,  1.60it/s]Extractor Predicting: 343it [03:23,  1.61it/s]Extractor Predicting: 344it [03:23,  1.57it/s]Extractor Predicting: 345it [03:24,  1.57it/s]Extractor Predicting: 346it [03:25,  1.55it/s]Extractor Predicting: 347it [03:25,  1.56it/s]Extractor Predicting: 348it [03:26,  1.57it/s]Extractor Predicting: 349it [03:27,  1.58it/s]Extractor Predicting: 350it [03:27,  1.57it/s]Extractor Predicting: 351it [03:28,  1.59it/s]Extractor Predicting: 352it [03:29,  1.58it/s]Extractor Predicting: 353it [03:29,  1.57it/s]Extractor Predicting: 354it [03:30,  1.57it/s]Extractor Predicting: 355it [03:30,  1.59it/s]Extractor Predicting: 356it [03:31,  1.61it/s]Extractor Predicting: 357it [03:32,  1.62it/s]Extractor Predicting: 358it [03:32,  1.62it/s]Extractor Predicting: 359it [03:33,  1.60it/s]Extractor Predicting: 360it [03:34,  1.61it/s]Extractor Predicting: 361it [03:34,  1.66it/s]Extractor Predicting: 362it [03:35,  1.66it/s]Extractor Predicting: 363it [03:35,  1.63it/s]Extractor Predicting: 364it [03:36,  1.63it/s]Extractor Predicting: 365it [03:37,  1.69it/s]Extractor Predicting: 366it [03:37,  1.66it/s]Extractor Predicting: 367it [03:38,  1.66it/s]Extractor Predicting: 368it [03:38,  1.63it/s]Extractor Predicting: 369it [03:39,  1.64it/s]Extractor Predicting: 370it [03:40,  1.67it/s]Extractor Predicting: 371it [03:40,  1.65it/s]Extractor Predicting: 372it [03:41,  1.65it/s]Extractor Predicting: 373it [03:41,  1.63it/s]Extractor Predicting: 374it [03:42,  1.66it/s]Extractor Predicting: 375it [03:43,  1.68it/s]Extractor Predicting: 376it [03:43,  1.71it/s]Extractor Predicting: 377it [03:44,  1.69it/s]Extractor Predicting: 378it [03:44,  1.69it/s]Extractor Predicting: 379it [03:45,  1.64it/s]Extractor Predicting: 380it [03:46,  1.62it/s]Extractor Predicting: 381it [03:46,  1.64it/s]Extractor Predicting: 382it [03:47,  1.64it/s]Extractor Predicting: 383it [03:47,  1.66it/s]Extractor Predicting: 384it [03:48,  1.67it/s]Extractor Predicting: 385it [03:49,  1.66it/s]Extractor Predicting: 386it [03:49,  1.67it/s]Extractor Predicting: 387it [03:50,  1.66it/s]Extractor Predicting: 388it [03:50,  1.65it/s]Extractor Predicting: 389it [03:51,  1.70it/s]Extractor Predicting: 390it [03:52,  1.71it/s]Extractor Predicting: 391it [03:52,  1.71it/s]Extractor Predicting: 392it [03:53,  1.74it/s]Extractor Predicting: 393it [03:53,  1.73it/s]Extractor Predicting: 394it [03:54,  1.70it/s]Extractor Predicting: 395it [03:54,  1.72it/s]Extractor Predicting: 396it [03:55,  1.70it/s]Extractor Predicting: 397it [03:56,  1.71it/s]Extractor Predicting: 398it [03:56,  1.74it/s]Extractor Predicting: 399it [03:57,  1.74it/s]Extractor Predicting: 400it [03:57,  1.70it/s]Extractor Predicting: 401it [03:58,  1.65it/s]Extractor Predicting: 402it [03:59,  1.63it/s]Extractor Predicting: 403it [03:59,  1.62it/s]Extractor Predicting: 404it [04:00,  1.65it/s]Extractor Predicting: 405it [04:00,  1.67it/s]Extractor Predicting: 406it [04:01,  1.68it/s]Extractor Predicting: 407it [04:02,  1.72it/s]Extractor Predicting: 408it [04:02,  1.77it/s]Extractor Predicting: 409it [04:03,  1.80it/s]Extractor Predicting: 410it [04:03,  1.82it/s]Extractor Predicting: 411it [04:04,  1.82it/s]Extractor Predicting: 412it [04:04,  1.80it/s]Extractor Predicting: 413it [04:05,  1.85it/s]Extractor Predicting: 414it [04:05,  1.88it/s]Extractor Predicting: 415it [04:06,  1.79it/s]Extractor Predicting: 416it [04:07,  1.71it/s]Extractor Predicting: 417it [04:07,  1.63it/s]Extractor Predicting: 418it [04:08,  1.59it/s]Extractor Predicting: 419it [04:09,  1.57it/s]Extractor Predicting: 420it [04:09,  1.52it/s]Extractor Predicting: 421it [04:10,  1.52it/s]Extractor Predicting: 422it [04:10,  1.74it/s]Extractor Predicting: 422it [04:10,  1.68it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:00,919 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:00,972 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:00,972 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:00,972 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:00,972 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 15:07:01,934 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 15:07:01,935 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 15:07:02,588 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 15:07:03,762 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 15:07:03,762 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:06,959 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:06,961 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:06,961 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:06,961 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:07:06,961 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 15:07:07,850 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 15:07:07,851 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 15:07:08,450 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 15:07:08,699 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 15:07:08,740 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_out_filter_all_single_is_eval_True.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_in_all_single_is_eval_True.jsonl",
  "precision": 0.20216664011470448,
  "recall": 0.09021113243761997,
  "score": 0.12475422729060165,
  "mode": "all_single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/results_all_single_is_eval_True.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_in_single_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_out_filter_single_is_eval_False.jsonl'}}
predict vocab size: 13679
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 13779, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.62it/s]Extractor Predicting: 2it [00:01,  1.62it/s]Extractor Predicting: 3it [00:01,  1.62it/s]Extractor Predicting: 4it [00:02,  1.66it/s]Extractor Predicting: 5it [00:03,  1.67it/s]Extractor Predicting: 6it [00:03,  1.70it/s]Extractor Predicting: 7it [00:04,  1.72it/s]Extractor Predicting: 8it [00:04,  1.71it/s]Extractor Predicting: 9it [00:05,  1.69it/s]Extractor Predicting: 10it [00:05,  1.69it/s]Extractor Predicting: 11it [00:06,  1.68it/s]Extractor Predicting: 12it [00:07,  1.69it/s]Extractor Predicting: 13it [00:07,  1.70it/s]Extractor Predicting: 14it [00:08,  1.69it/s]Extractor Predicting: 15it [00:08,  1.70it/s]Extractor Predicting: 16it [00:09,  1.74it/s]Extractor Predicting: 17it [00:10,  1.73it/s]Extractor Predicting: 18it [00:10,  1.72it/s]Extractor Predicting: 19it [00:11,  1.70it/s]Extractor Predicting: 20it [00:11,  1.66it/s]Extractor Predicting: 21it [00:12,  1.66it/s]Extractor Predicting: 22it [00:13,  1.66it/s]Extractor Predicting: 23it [00:13,  1.65it/s]Extractor Predicting: 24it [00:14,  1.68it/s]Extractor Predicting: 25it [00:14,  1.70it/s]Extractor Predicting: 26it [00:15,  1.68it/s]Extractor Predicting: 27it [00:15,  1.71it/s]Extractor Predicting: 28it [00:16,  1.68it/s]Extractor Predicting: 29it [00:17,  1.67it/s]Extractor Predicting: 30it [00:17,  1.68it/s]Extractor Predicting: 31it [00:18,  1.65it/s]Extractor Predicting: 32it [00:19,  1.67it/s]Extractor Predicting: 33it [00:19,  1.68it/s]Extractor Predicting: 34it [00:20,  1.67it/s]Extractor Predicting: 35it [00:20,  1.56it/s]Extractor Predicting: 36it [00:21,  1.59it/s]Extractor Predicting: 37it [00:22,  1.59it/s]Extractor Predicting: 38it [00:22,  1.62it/s]Extractor Predicting: 39it [00:23,  1.63it/s]Extractor Predicting: 40it [00:23,  1.63it/s]Extractor Predicting: 41it [00:24,  1.63it/s]Extractor Predicting: 42it [00:25,  1.66it/s]Extractor Predicting: 43it [00:25,  1.71it/s]Extractor Predicting: 44it [00:26,  1.69it/s]Extractor Predicting: 45it [00:26,  1.63it/s]Extractor Predicting: 46it [00:27,  1.59it/s]Extractor Predicting: 47it [00:28,  1.60it/s]Extractor Predicting: 48it [00:28,  1.62it/s]Extractor Predicting: 49it [00:29,  1.62it/s]Extractor Predicting: 50it [00:30,  1.63it/s]Extractor Predicting: 51it [00:30,  1.61it/s]Extractor Predicting: 52it [00:31,  1.61it/s]Extractor Predicting: 53it [00:31,  1.62it/s]Extractor Predicting: 54it [00:32,  1.57it/s]Extractor Predicting: 55it [00:33,  1.57it/s]Extractor Predicting: 56it [00:33,  1.59it/s]Extractor Predicting: 57it [00:34,  1.59it/s]Extractor Predicting: 58it [00:35,  1.59it/s]Extractor Predicting: 59it [00:35,  1.59it/s]Extractor Predicting: 60it [00:36,  1.62it/s]Extractor Predicting: 61it [00:36,  1.62it/s]Extractor Predicting: 62it [00:37,  1.59it/s]Extractor Predicting: 63it [00:38,  1.61it/s]Extractor Predicting: 64it [00:38,  1.66it/s]Extractor Predicting: 65it [00:39,  1.69it/s]Extractor Predicting: 66it [00:39,  1.69it/s]Extractor Predicting: 67it [00:40,  1.68it/s]Extractor Predicting: 68it [00:41,  1.68it/s]Extractor Predicting: 69it [00:41,  1.69it/s]Extractor Predicting: 70it [00:42,  1.62it/s]Extractor Predicting: 71it [00:43,  1.63it/s]Extractor Predicting: 72it [00:43,  1.65it/s]Extractor Predicting: 73it [00:44,  1.66it/s]Extractor Predicting: 74it [00:44,  1.66it/s]Extractor Predicting: 75it [00:45,  1.67it/s]Extractor Predicting: 76it [00:46,  1.66it/s]Extractor Predicting: 77it [00:46,  1.72it/s]Extractor Predicting: 78it [00:47,  1.73it/s]Extractor Predicting: 79it [00:47,  1.69it/s]Extractor Predicting: 80it [00:48,  1.69it/s]Extractor Predicting: 81it [00:48,  1.72it/s]Extractor Predicting: 82it [00:49,  1.70it/s]Extractor Predicting: 83it [00:50,  1.66it/s]Extractor Predicting: 84it [00:50,  1.67it/s]Extractor Predicting: 85it [00:51,  1.66it/s]Extractor Predicting: 86it [00:51,  1.68it/s]Extractor Predicting: 87it [00:52,  1.71it/s]Extractor Predicting: 88it [00:53,  1.64it/s]Extractor Predicting: 89it [00:53,  1.64it/s]Extractor Predicting: 90it [00:54,  1.65it/s]Extractor Predicting: 91it [00:54,  1.68it/s]Extractor Predicting: 92it [00:55,  1.72it/s]Extractor Predicting: 93it [00:56,  1.72it/s]Extractor Predicting: 94it [00:56,  1.72it/s]Extractor Predicting: 95it [00:57,  1.72it/s]Extractor Predicting: 96it [00:57,  1.68it/s]Extractor Predicting: 97it [00:58,  1.73it/s]Extractor Predicting: 98it [00:58,  1.73it/s]Extractor Predicting: 99it [00:59,  1.74it/s]Extractor Predicting: 100it [01:00,  1.72it/s]Extractor Predicting: 101it [01:00,  1.67it/s]Extractor Predicting: 102it [01:01,  1.67it/s]Extractor Predicting: 103it [01:01,  1.68it/s]Extractor Predicting: 104it [01:02,  1.71it/s]Extractor Predicting: 105it [01:03,  1.68it/s]Extractor Predicting: 106it [01:03,  1.67it/s]Extractor Predicting: 107it [01:04,  1.70it/s]Extractor Predicting: 108it [01:04,  1.70it/s]Extractor Predicting: 109it [01:05,  1.70it/s]Extractor Predicting: 110it [01:06,  1.73it/s]Extractor Predicting: 111it [01:06,  1.73it/s]Extractor Predicting: 112it [01:07,  1.71it/s]Extractor Predicting: 113it [01:07,  1.70it/s]Extractor Predicting: 114it [01:08,  1.70it/s]Extractor Predicting: 115it [01:08,  1.70it/s]Extractor Predicting: 116it [01:09,  1.55it/s]Extractor Predicting: 117it [01:10,  1.64it/s]Extractor Predicting: 118it [01:10,  1.65it/s]Extractor Predicting: 119it [01:11,  1.68it/s]Extractor Predicting: 120it [01:11,  1.73it/s]Extractor Predicting: 121it [01:12,  1.74it/s]Extractor Predicting: 122it [01:13,  1.69it/s]Extractor Predicting: 123it [01:13,  1.70it/s]Extractor Predicting: 124it [01:14,  1.69it/s]Extractor Predicting: 125it [01:15,  1.65it/s]Extractor Predicting: 126it [01:15,  1.66it/s]Extractor Predicting: 127it [01:16,  1.70it/s]Extractor Predicting: 128it [01:16,  1.72it/s]Extractor Predicting: 129it [01:17,  1.73it/s]Extractor Predicting: 130it [01:17,  1.70it/s]Extractor Predicting: 131it [01:18,  1.66it/s]Extractor Predicting: 132it [01:19,  1.67it/s]Extractor Predicting: 133it [01:19,  1.69it/s]Extractor Predicting: 134it [01:20,  1.68it/s]Extractor Predicting: 135it [01:20,  1.70it/s]Extractor Predicting: 136it [01:21,  1.75it/s]Extractor Predicting: 137it [01:22,  1.75it/s]Extractor Predicting: 138it [01:22,  1.72it/s]Extractor Predicting: 139it [01:23,  1.70it/s]Extractor Predicting: 140it [01:23,  1.73it/s]Extractor Predicting: 141it [01:24,  1.75it/s]Extractor Predicting: 142it [01:24,  1.77it/s]Extractor Predicting: 143it [01:25,  1.81it/s]Extractor Predicting: 144it [01:25,  1.77it/s]Extractor Predicting: 145it [01:26,  1.77it/s]Extractor Predicting: 146it [01:27,  1.77it/s]Extractor Predicting: 147it [01:27,  1.76it/s]Extractor Predicting: 148it [01:28,  1.76it/s]Extractor Predicting: 149it [01:28,  1.75it/s]Extractor Predicting: 150it [01:29,  1.76it/s]Extractor Predicting: 151it [01:29,  1.76it/s]Extractor Predicting: 152it [01:30,  1.78it/s]Extractor Predicting: 153it [01:31,  1.76it/s]Extractor Predicting: 154it [01:31,  1.75it/s]Extractor Predicting: 155it [01:32,  1.75it/s]Extractor Predicting: 156it [01:32,  1.75it/s]Extractor Predicting: 157it [01:33,  1.74it/s]Extractor Predicting: 158it [01:34,  1.71it/s]Extractor Predicting: 159it [01:34,  1.75it/s]Extractor Predicting: 160it [01:35,  1.79it/s]Extractor Predicting: 161it [01:35,  1.65it/s]Extractor Predicting: 162it [01:36,  1.65it/s]Extractor Predicting: 163it [01:36,  1.66it/s]Extractor Predicting: 164it [01:37,  1.72it/s]Extractor Predicting: 165it [01:38,  1.72it/s]Extractor Predicting: 166it [01:38,  1.61it/s]Extractor Predicting: 167it [01:39,  1.60it/s]Extractor Predicting: 168it [01:40,  1.62it/s]Extractor Predicting: 169it [01:40,  1.63it/s]Extractor Predicting: 170it [01:41,  1.58it/s]Extractor Predicting: 170it [01:41,  1.68it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:02,995 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:03,023 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:03,023 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:03,023 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:03,023 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 15:09:03,574 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 15:09:03,575 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 15:09:03,872 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 15:09:05,010 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 15:09:05,010 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:07,494 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:07,523 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:07,523 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:07,523 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 15:09:07,523 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 15:09:08,080 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 15:09:08,081 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 15:09:08,416 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 15:09:08,652 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 15:09:08,652 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_out_filter_single_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_in_single_is_eval_False.jsonl",
  "precision": 0.38558909444985395,
  "recall": 0.09717791411042945,
  "score": 0.15523324186593493,
  "mode": "single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/results_single_is_eval_False.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5', 'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_in_multi_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_out_filter_multi_is_eval_False.jsonl'}}
predict vocab size: 3869
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 3969, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.62it/s]Extractor Predicting: 2it [00:01,  1.60it/s]Extractor Predicting: 3it [00:01,  1.57it/s]Extractor Predicting: 4it [00:02,  1.57it/s]Extractor Predicting: 5it [00:03,  1.60it/s]Extractor Predicting: 6it [00:03,  1.58it/s]Extractor Predicting: 7it [00:04,  1.56it/s]Extractor Predicting: 8it [00:05,  1.58it/s]Extractor Predicting: 9it [00:05,  1.62it/s]Extractor Predicting: 10it [00:06,  1.61it/s]Extractor Predicting: 11it [00:06,  1.55it/s]Extractor Predicting: 12it [00:07,  1.62it/s]Extractor Predicting: 13it [00:08,  1.65it/s]Extractor Predicting: 14it [00:08,  1.57it/s]Extractor Predicting: 15it [00:09,  1.59it/s]Extractor Predicting: 16it [00:10,  1.61it/s]Extractor Predicting: 17it [00:10,  1.61it/s]Extractor Predicting: 18it [00:11,  1.61it/s]Extractor Predicting: 19it [00:11,  1.59it/s]Extractor Predicting: 20it [00:12,  1.55it/s]Extractor Predicting: 21it [00:13,  1.59it/s]Extractor Predicting: 22it [00:13,  1.56it/s]Extractor Predicting: 23it [00:14,  1.57it/s]Extractor Predicting: 24it [00:15,  1.59it/s]Extractor Predicting: 25it [00:15,  1.63it/s]Extractor Predicting: 26it [00:16,  1.65it/s]Extractor Predicting: 27it [00:16,  1.61it/s]Extractor Predicting: 28it [00:17,  1.63it/s]Extractor Predicting: 29it [00:18,  1.63it/s]Extractor Predicting: 30it [00:18,  1.63it/s]Extractor Predicting: 31it [00:19,  1.64it/s]Extractor Predicting: 32it [00:19,  1.64it/s]Extractor Predicting: 33it [00:20,  1.56it/s]Extractor Predicting: 33it [00:20,  1.60it/s]
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_out_filter_multi_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/pred_in_multi_is_eval_False.jsonl",
  "precision": 0.5765765765765766,
  "recall": 0.03402445507708666,
  "score": 0.06425702811244981,
  "mode": "multi",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter5/results_multi_is_eval_False.json"
}
{'eval_best': {'path_test': 'zero_rte/wiki/unseen_5_seed_3/test.jsonl', 'save_dir': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/', 'labels': ['continent', 'owned by', 'performer', 'producer', 'replaces'], 'num_iter': 5, 'limit': 5000}}
Traceback (most recent call last):
  File "wrapper.py", line 811, in <module>
    Fire()
  File "/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/fire/core.py", line 471, in _Fire
    target=component.__name__)
  File "/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/fire/core.py", line 681, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "wrapper.py", line 654, in main_dual
    eval_best(path_test=path_test, save_dir=save_dir, labels=labels_test, num_iter=num_iter, limit=limit)
  File "wrapper.py", line 711, in eval_best
    with open(path_results) as f:
FileNotFoundError: [Errno 2] No such file or directory: 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_withTrainFalse_synthetic_large/unseen_5_seed_3/extractor/iter1/results_single_is_eval_True_limit5000.json'
