Warn: we adopt CRF implemented by allennlp, please install it first before using CRF.
{'main_dual': {'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'save_dir': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/', 'num_iter': 5, 'data_name': 'wiki', 'split': 'unseen_10_seed_3', 'type': 'filtered', 'model_size': 'large', 'with_train': True, 'by_rel': False, 'rl_version': 'all', 'rescale_train': False, 'score_only_ext': True, 'limit': 5000, 'g_encoder_name': 'generate', 'num_gen_per_label': 500, 'diverse': False}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/0.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/0_ext.jsonl'}}
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/0_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/0.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.2, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/0.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter1/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter1/data', model_name='outputs/wrapper/wiki/unseen_10_seed_3/generator/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter1', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter1', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter1', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/1.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/1_ext.jsonl'}}
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/1_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/1.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.4, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/1.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter2/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter2/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter1/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter2', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter2', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter2', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/2.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/2_ext.jsonl'}}
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/2_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/2.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.6, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/2.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter3/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter3/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter2/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter3', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter3', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter3', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/3.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/3_ext.jsonl'}}
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/3_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/3.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.8, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/3.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter4/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter4/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter3/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter4', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter4', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter4', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/4.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/4_ext.jsonl'}}
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/synthetic/4_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/4.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 1.0, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/filtered/4.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter5/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter5/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/generator/iter4/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter5', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter5', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter5', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'eval_best': {'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'save_dir': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'num_iter': 5, 'limit': 5000}}
Traceback (most recent call last):
  File "wrapper.py", line 811, in <module>
    Fire()
  File "/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/fire/core.py", line 471, in _Fire
    target=component.__name__)
  File "/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/fire/core.py", line 681, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "wrapper.py", line 654, in main_dual
    eval_best(path_test=path_test, save_dir=save_dir, labels=labels_test, num_iter=num_iter, limit=limit)
  File "wrapper.py", line 711, in eval_best
    with open(path_results) as f:
FileNotFoundError: [Errno 2] No such file or directory: 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_filtered_large/unseen_10_seed_3/extractor/iter1/results_single_is_eval_True_limit5000.json'
Warn: we adopt CRF implemented by allennlp, please install it first before using CRF.
{'main_dual': {'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'save_dir': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/', 'num_iter': 5, 'data_name': 'wiki', 'split': 'unseen_10_seed_3', 'type': 'train', 'model_size': 'large', 'with_train': True, 'by_rel': False, 'rl_version': 'all', 'rescale_train': False, 'score_only_ext': True, 'limit': 5000, 'g_encoder_name': 'generate', 'num_gen_per_label': 500, 'diverse': False}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/0.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/0_ext.jsonl'}}
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/0_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/0.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.2, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/0.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter1/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter1/data', model_name='outputs/wrapper/wiki/unseen_10_seed_3/generator/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter1', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter1', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter1', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/1.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/1_ext.jsonl'}}
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/1_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/1.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.4, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/1.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter2/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter2/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter1/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter2', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter2', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter2', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/2.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/2_ext.jsonl'}}
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/2_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/2.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.6, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/2.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter2/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter3', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter3', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter3', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/3.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/3_ext.jsonl'}}
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/3_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/3.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 0.8, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/3.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
08/29/2023 14:08:48 - WARNING - transformer_base.run_clm_rl -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True
08/29/2023 14:08:48 - INFO - transformer_base.run_clm_rl -   Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=2,
greater_is_better=False,
group_by_length=False,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_on_each_node=True,
logging_dir=runs/Aug29_14-08-48_ctolab01.scc.idea,
logging_first_step=False,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
output_dir=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
08/29/2023 14:08:49 - WARNING - datasets.builder -   Using custom data configuration default-0e3538365263e6a0
Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/xuting/.cache/huggingface/datasets/json/default-0e3538365263e6a0/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...
0 tables [00:00, ? tables/s]                            0 tables [00:00, ? tables/s]                            [INFO|configuration_utils.py:515] 2023-08-29 14:08:49,471 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 14:08:49,472 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter2/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 14:08:49,477 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 14:08:49,478 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter2/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 14:08:49,492 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:08:49,498 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:08:49,498 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:08:49,498 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:08:49,498 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:08:49,498 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:08:49,498 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/tokenizer_config.json
[INFO|modeling_utils.py:1150] 2023-08-29 14:08:49,605 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 14:08:58,348 >> All model checkpoint weights were used when initializing Model.

[INFO|modeling_utils.py:1345] 2023-08-29 14:08:58,352 >> All the weights of Model were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Model for predictions without further training.
Dataset json downloaded and prepared to /home/xuting/.cache/huggingface/datasets/json/default-0e3538365263e6a0/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.
PreTrainedTokenizerFast(name_or_path='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'})
08/29/2023 14:08:58 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.tokenize_function at 0x14a81ebc20e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
  0%|          | 0/8 [00:00<?, ?ba/s] 12%|█▎        | 1/8 [00:00<00:02,  3.21ba/s] 25%|██▌       | 2/8 [00:00<00:01,  3.96ba/s] 38%|███▊      | 3/8 [00:00<00:01,  4.29ba/s] 50%|█████     | 4/8 [00:00<00:00,  4.41ba/s] 62%|██████▎   | 5/8 [00:01<00:00,  4.49ba/s] 75%|███████▌  | 6/8 [00:01<00:00,  4.54ba/s] 88%|████████▊ | 7/8 [00:01<00:00,  4.56ba/s]100%|██████████| 8/8 [00:01<00:00,  4.74ba/s]100%|██████████| 8/8 [00:01<00:00,  4.46ba/s]
  0%|          | 0/9 [00:00<?, ?ba/s] 11%|█         | 1/9 [00:00<00:01,  4.20ba/s] 22%|██▏       | 2/9 [00:00<00:01,  4.48ba/s] 33%|███▎      | 3/9 [00:00<00:01,  4.57ba/s] 44%|████▍     | 4/9 [00:00<00:01,  4.62ba/s] 56%|█████▌    | 5/9 [00:01<00:00,  4.65ba/s] 67%|██████▋   | 6/9 [00:01<00:00,  4.64ba/s] 78%|███████▊  | 7/9 [00:01<00:00,  4.64ba/s] 89%|████████▉ | 8/9 [00:01<00:00,  4.65ba/s]100%|██████████| 9/9 [00:01<00:00,  5.36ba/s]100%|██████████| 9/9 [00:01<00:00,  4.84ba/s]
  0%|          | 0/8 [00:00<?, ?ba/s] 12%|█▎        | 1/8 [00:00<00:00,  8.25ba/s] 25%|██▌       | 2/8 [00:00<00:00,  9.15ba/s] 50%|█████     | 4/8 [00:00<00:00,  9.79ba/s] 75%|███████▌  | 6/8 [00:00<00:00, 10.01ba/s]100%|██████████| 8/8 [00:00<00:00, 10.25ba/s]100%|██████████| 8/8 [00:00<00:00,  9.99ba/s]
  0%|          | 0/9 [00:00<?, ?ba/s] 11%|█         | 1/9 [00:00<00:02,  3.90ba/s] 33%|███▎      | 3/9 [00:00<00:00,  7.17ba/s] 56%|█████▌    | 5/9 [00:00<00:00,  8.49ba/s] 78%|███████▊  | 7/9 [00:00<00:00,  9.20ba/s]100%|██████████| 9/9 [00:00<00:00, 10.40ba/s]100%|██████████| 9/9 [00:00<00:00,  9.07ba/s]
[INFO|trainer.py:414] 2023-08-29 14:09:09,062 >> Using amp fp16 backend
[INFO|trainer.py:1147] 2023-08-29 14:09:09,075 >> ***** Running training *****
[INFO|trainer.py:1148] 2023-08-29 14:09:09,075 >>   Num examples = 7899
[INFO|trainer.py:1149] 2023-08-29 14:09:09,075 >>   Num Epochs = 5
[INFO|trainer.py:1150] 2023-08-29 14:09:09,075 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1151] 2023-08-29 14:09:09,075 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1152] 2023-08-29 14:09:09,075 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1153] 2023-08-29 14:09:09,075 >>   Total optimization steps = 615
  0%|          | 0/615 [00:00<?, ?it/s]  0%|          | 1/615 [00:04<46:43,  4.57s/it]  0%|          | 2/615 [00:04<20:59,  2.05s/it]  0%|          | 3/615 [00:05<12:45,  1.25s/it]  1%|          | 4/615 [00:05<08:52,  1.15it/s]  1%|          | 5/615 [00:05<06:40,  1.52it/s]  1%|          | 6/615 [00:05<05:19,  1.91it/s]  1%|          | 7/615 [00:06<04:27,  2.27it/s]  1%|▏         | 8/615 [00:06<03:58,  2.55it/s]  1%|▏         | 9/615 [00:06<03:34,  2.83it/s]  2%|▏         | 10/615 [00:07<03:18,  3.05it/s]  2%|▏         | 11/615 [00:07<03:07,  3.23it/s]  2%|▏         | 12/615 [00:07<02:59,  3.36it/s]  2%|▏         | 13/615 [00:07<02:54,  3.45it/s]  2%|▏         | 14/615 [00:08<02:51,  3.51it/s]  2%|▏         | 15/615 [00:08<02:48,  3.57it/s]  3%|▎         | 16/615 [00:08<02:45,  3.61it/s]  3%|▎         | 17/615 [00:08<02:44,  3.64it/s]  3%|▎         | 18/615 [00:09<02:42,  3.67it/s]  3%|▎         | 19/615 [00:09<02:41,  3.68it/s]  3%|▎         | 20/615 [00:09<02:41,  3.69it/s]  3%|▎         | 21/615 [00:10<02:40,  3.70it/s]  4%|▎         | 22/615 [00:10<02:40,  3.70it/s]  4%|▎         | 23/615 [00:10<02:39,  3.70it/s]  4%|▍         | 24/615 [00:10<02:39,  3.70it/s]  4%|▍         | 25/615 [00:11<02:39,  3.69it/s]  4%|▍         | 26/615 [00:11<02:39,  3.70it/s]  4%|▍         | 27/615 [00:11<02:39,  3.70it/s]  5%|▍         | 28/615 [00:11<02:38,  3.70it/s]  5%|▍         | 29/615 [00:12<02:38,  3.70it/s]  5%|▍         | 30/615 [00:12<02:38,  3.70it/s]  5%|▌         | 31/615 [00:12<02:37,  3.70it/s]  5%|▌         | 32/615 [00:13<02:37,  3.70it/s]  5%|▌         | 33/615 [00:13<02:37,  3.70it/s]  6%|▌         | 34/615 [00:13<02:36,  3.70it/s]  6%|▌         | 35/615 [00:13<02:36,  3.70it/s]  6%|▌         | 36/615 [00:14<02:36,  3.70it/s]  6%|▌         | 37/615 [00:14<02:36,  3.70it/s]  6%|▌         | 38/615 [00:14<02:35,  3.71it/s]  6%|▋         | 39/615 [00:14<02:36,  3.67it/s]  7%|▋         | 40/615 [00:15<02:36,  3.68it/s]  7%|▋         | 41/615 [00:15<02:35,  3.68it/s]  7%|▋         | 42/615 [00:15<02:35,  3.69it/s]  7%|▋         | 43/615 [00:16<02:34,  3.69it/s]  7%|▋         | 44/615 [00:16<02:34,  3.68it/s]  7%|▋         | 45/615 [00:16<02:34,  3.69it/s]  7%|▋         | 46/615 [00:16<02:34,  3.69it/s]  8%|▊         | 47/615 [00:17<02:34,  3.69it/s]  8%|▊         | 48/615 [00:17<02:33,  3.69it/s]  8%|▊         | 49/615 [00:17<02:33,  3.69it/s]  8%|▊         | 50/615 [00:17<02:32,  3.70it/s]  8%|▊         | 51/615 [00:18<02:32,  3.71it/s]  8%|▊         | 52/615 [00:18<02:31,  3.71it/s]  9%|▊         | 53/615 [00:18<02:31,  3.71it/s]  9%|▉         | 54/615 [00:18<02:31,  3.71it/s]  9%|▉         | 55/615 [00:19<02:30,  3.71it/s]  9%|▉         | 56/615 [00:19<02:30,  3.71it/s]  9%|▉         | 57/615 [00:19<02:30,  3.71it/s]  9%|▉         | 58/615 [00:20<02:30,  3.71it/s] 10%|▉         | 59/615 [00:20<02:29,  3.71it/s] 10%|▉         | 60/615 [00:20<02:29,  3.71it/s] 10%|▉         | 61/615 [00:20<02:29,  3.71it/s] 10%|█         | 62/615 [00:21<02:28,  3.72it/s] 10%|█         | 63/615 [00:21<02:28,  3.72it/s] 10%|█         | 64/615 [00:21<02:28,  3.72it/s] 11%|█         | 65/615 [00:21<02:27,  3.72it/s] 11%|█         | 66/615 [00:22<02:27,  3.72it/s] 11%|█         | 67/615 [00:22<02:27,  3.72it/s] 11%|█         | 68/615 [00:22<02:27,  3.71it/s] 11%|█         | 69/615 [00:23<02:27,  3.71it/s] 11%|█▏        | 70/615 [00:23<02:26,  3.71it/s] 12%|█▏        | 71/615 [00:23<02:26,  3.71it/s] 12%|█▏        | 72/615 [00:23<02:26,  3.71it/s] 12%|█▏        | 73/615 [00:24<02:26,  3.71it/s] 12%|█▏        | 74/615 [00:24<02:25,  3.71it/s] 12%|█▏        | 75/615 [00:24<02:25,  3.71it/s] 12%|█▏        | 76/615 [00:24<02:25,  3.71it/s] 13%|█▎        | 77/615 [00:25<02:24,  3.71it/s] 13%|█▎        | 78/615 [00:25<02:24,  3.71it/s] 13%|█▎        | 79/615 [00:25<02:24,  3.71it/s] 13%|█▎        | 80/615 [00:25<02:25,  3.69it/s] 13%|█▎        | 81/615 [00:26<02:24,  3.70it/s] 13%|█▎        | 82/615 [00:26<02:23,  3.70it/s] 13%|█▎        | 83/615 [00:26<02:23,  3.71it/s] 14%|█▎        | 84/615 [00:27<02:23,  3.71it/s] 14%|█▍        | 85/615 [00:27<02:22,  3.71it/s] 14%|█▍        | 86/615 [00:27<02:22,  3.71it/s] 14%|█▍        | 87/615 [00:27<02:22,  3.71it/s] 14%|█▍        | 88/615 [00:28<02:22,  3.71it/s] 14%|█▍        | 89/615 [00:28<02:21,  3.71it/s] 15%|█▍        | 90/615 [00:28<02:21,  3.71it/s] 15%|█▍        | 91/615 [00:28<02:21,  3.71it/s] 15%|█▍        | 92/615 [00:29<02:21,  3.69it/s] 15%|█▌        | 93/615 [00:29<02:21,  3.69it/s] 15%|█▌        | 94/615 [00:29<02:20,  3.70it/s] 15%|█▌        | 95/615 [00:30<02:20,  3.70it/s] 16%|█▌        | 96/615 [00:30<02:20,  3.70it/s] 16%|█▌        | 97/615 [00:30<02:19,  3.70it/s] 16%|█▌        | 98/615 [00:30<02:19,  3.70it/s] 16%|█▌        | 99/615 [00:31<02:19,  3.70it/s] 16%|█▋        | 100/615 [00:31<02:19,  3.70it/s] 16%|█▋        | 101/615 [00:31<02:18,  3.70it/s] 17%|█▋        | 102/615 [00:31<02:18,  3.70it/s] 17%|█▋        | 103/615 [00:32<02:18,  3.70it/s] 17%|█▋        | 104/615 [00:32<02:18,  3.68it/s] 17%|█▋        | 105/615 [00:32<02:18,  3.68it/s] 17%|█▋        | 106/615 [00:33<02:18,  3.69it/s] 17%|█▋        | 107/615 [00:33<02:17,  3.69it/s] 18%|█▊        | 108/615 [00:33<02:17,  3.70it/s] 18%|█▊        | 109/615 [00:33<02:16,  3.70it/s] 18%|█▊        | 110/615 [00:34<02:16,  3.70it/s] 18%|█▊        | 111/615 [00:34<02:16,  3.70it/s] 18%|█▊        | 112/615 [00:34<02:15,  3.70it/s] 18%|█▊        | 113/615 [00:34<02:15,  3.70it/s] 19%|█▊        | 114/615 [00:35<02:15,  3.70it/s] 19%|█▊        | 115/615 [00:35<02:15,  3.70it/s] 19%|█▉        | 116/615 [00:35<02:15,  3.67it/s] 19%|█▉        | 117/615 [00:35<02:15,  3.68it/s] 19%|█▉        | 118/615 [00:36<02:14,  3.68it/s] 19%|█▉        | 119/615 [00:36<02:14,  3.69it/s] 20%|█▉        | 120/615 [00:36<02:14,  3.69it/s] 20%|█▉        | 121/615 [00:37<02:13,  3.69it/s] 20%|█▉        | 122/615 [00:37<02:13,  3.69it/s] 20%|██        | 123/615 [00:37<02:13,  3.69it/s][INFO|trainer.py:2140] 2023-08-29 14:09:46,814 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:09:46,814 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 14:09:46,814 >>   Batch size = 8

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 58.11it/s][A
  1%|          | 12/1071 [00:00<00:20, 51.23it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 49.48it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.78it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 48.39it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 48.14it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 47.84it/s][A
  4%|▍         | 43/1071 [00:00<00:21, 47.44it/s][A
  4%|▍         | 48/1071 [00:00<00:21, 47.28it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 47.22it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 47.28it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 47.38it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 47.44it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 47.46it/s][A
  7%|▋         | 78/1071 [00:01<00:20, 47.49it/s][A
  8%|▊         | 83/1071 [00:01<00:20, 47.47it/s][A
  8%|▊         | 88/1071 [00:01<00:20, 47.37it/s][A
  9%|▊         | 93/1071 [00:01<00:20, 47.27it/s][A
  9%|▉         | 98/1071 [00:02<00:20, 47.02it/s][A
 10%|▉         | 103/1071 [00:02<00:20, 47.12it/s][A
 10%|█         | 108/1071 [00:02<00:20, 47.18it/s][A
 11%|█         | 113/1071 [00:02<00:20, 47.27it/s][A
 11%|█         | 118/1071 [00:02<00:20, 47.30it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 47.31it/s][A
 12%|█▏        | 128/1071 [00:02<00:19, 47.33it/s][A
 12%|█▏        | 133/1071 [00:02<00:19, 47.30it/s][A
 13%|█▎        | 138/1071 [00:02<00:19, 47.21it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 47.12it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 47.19it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 47.16it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 47.15it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 47.26it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 47.28it/s][A
 16%|█▌        | 173/1071 [00:03<00:18, 47.28it/s][A
 17%|█▋        | 178/1071 [00:03<00:18, 47.26it/s][A
 17%|█▋        | 183/1071 [00:03<00:18, 47.20it/s][A
 18%|█▊        | 188/1071 [00:03<00:18, 47.09it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 47.11it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 47.17it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 47.14it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 47.11it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 47.23it/s][A
 20%|██        | 218/1071 [00:04<00:18, 47.26it/s][A
 21%|██        | 223/1071 [00:04<00:17, 47.26it/s][A
 21%|██▏       | 228/1071 [00:04<00:17, 47.21it/s][A
 22%|██▏       | 233/1071 [00:04<00:17, 47.13it/s][A
 22%|██▏       | 238/1071 [00:05<00:17, 47.09it/s][A
 23%|██▎       | 243/1071 [00:05<00:17, 47.11it/s][A
 23%|██▎       | 248/1071 [00:05<00:17, 47.13it/s][A
 24%|██▎       | 253/1071 [00:05<00:17, 47.10it/s][A
 24%|██▍       | 258/1071 [00:05<00:17, 47.19it/s][A
 25%|██▍       | 263/1071 [00:05<00:17, 47.30it/s][A
 25%|██▌       | 268/1071 [00:05<00:16, 47.31it/s][A
 25%|██▌       | 273/1071 [00:05<00:16, 47.24it/s][A
 26%|██▌       | 278/1071 [00:05<00:16, 47.23it/s][A
 26%|██▋       | 283/1071 [00:05<00:16, 47.19it/s][A
 27%|██▋       | 288/1071 [00:06<00:16, 47.16it/s][A
 27%|██▋       | 293/1071 [00:06<00:16, 47.11it/s][A
 28%|██▊       | 298/1071 [00:06<00:16, 47.17it/s][A
 28%|██▊       | 303/1071 [00:06<00:16, 47.24it/s][A
 29%|██▉       | 308/1071 [00:06<00:16, 47.25it/s][A
 29%|██▉       | 313/1071 [00:06<00:16, 47.31it/s][A
 30%|██▉       | 318/1071 [00:06<00:15, 47.26it/s][A
 30%|███       | 323/1071 [00:06<00:15, 47.22it/s][A
 31%|███       | 328/1071 [00:06<00:15, 47.26it/s][A
 31%|███       | 333/1071 [00:07<00:15, 47.28it/s][A
 32%|███▏      | 338/1071 [00:07<00:15, 47.23it/s][A
 32%|███▏      | 343/1071 [00:07<00:15, 47.19it/s][A
 32%|███▏      | 348/1071 [00:07<00:15, 47.33it/s][A
 33%|███▎      | 353/1071 [00:07<00:15, 47.36it/s][A
 33%|███▎      | 358/1071 [00:07<00:15, 47.36it/s][A
 34%|███▍      | 363/1071 [00:07<00:14, 47.35it/s][A
 34%|███▍      | 368/1071 [00:07<00:14, 47.36it/s][A
 35%|███▍      | 373/1071 [00:07<00:14, 47.34it/s][A
 35%|███▌      | 378/1071 [00:07<00:14, 47.31it/s][A
 36%|███▌      | 383/1071 [00:08<00:14, 47.30it/s][A
 36%|███▌      | 388/1071 [00:08<00:14, 47.21it/s][A
 37%|███▋      | 393/1071 [00:08<00:14, 47.26it/s][A
 37%|███▋      | 398/1071 [00:08<00:14, 47.32it/s][A
 38%|███▊      | 403/1071 [00:08<00:14, 47.32it/s][A
 38%|███▊      | 408/1071 [00:08<00:14, 47.32it/s][A
 39%|███▊      | 413/1071 [00:08<00:13, 47.29it/s][A
 39%|███▉      | 418/1071 [00:08<00:13, 47.29it/s][A
 39%|███▉      | 423/1071 [00:08<00:13, 47.28it/s][A
 40%|███▉      | 428/1071 [00:09<00:13, 47.21it/s][A
 40%|████      | 433/1071 [00:09<00:13, 47.17it/s][A
 41%|████      | 438/1071 [00:09<00:13, 47.20it/s][A
 41%|████▏     | 443/1071 [00:09<00:13, 47.20it/s][A
 42%|████▏     | 448/1071 [00:09<00:13, 47.25it/s][A
 42%|████▏     | 453/1071 [00:09<00:13, 47.34it/s][A
 43%|████▎     | 458/1071 [00:09<00:12, 47.28it/s][A
 43%|████▎     | 463/1071 [00:09<00:12, 47.18it/s][A
 44%|████▎     | 468/1071 [00:09<00:12, 47.22it/s][A
 44%|████▍     | 473/1071 [00:09<00:12, 47.16it/s][A
 45%|████▍     | 478/1071 [00:10<00:12, 47.10it/s][A
 45%|████▌     | 483/1071 [00:10<00:12, 47.15it/s][A
 46%|████▌     | 488/1071 [00:10<00:12, 47.24it/s][A
 46%|████▌     | 493/1071 [00:10<00:12, 47.26it/s][A
 46%|████▋     | 498/1071 [00:10<00:12, 47.25it/s][A
 47%|████▋     | 503/1071 [00:10<00:11, 47.34it/s][A
 47%|████▋     | 508/1071 [00:10<00:11, 47.27it/s][A
 48%|████▊     | 513/1071 [00:10<00:11, 47.22it/s][A
 48%|████▊     | 518/1071 [00:10<00:11, 47.21it/s][A
 49%|████▉     | 523/1071 [00:11<00:11, 47.24it/s][A
 49%|████▉     | 528/1071 [00:11<00:11, 47.21it/s][A
 50%|████▉     | 533/1071 [00:11<00:11, 47.24it/s][A
 50%|█████     | 538/1071 [00:11<00:11, 47.33it/s][A
 51%|█████     | 543/1071 [00:11<00:11, 47.31it/s][A
 51%|█████     | 548/1071 [00:11<00:11, 47.33it/s][A
 52%|█████▏    | 553/1071 [00:11<00:10, 47.31it/s][A
 52%|█████▏    | 558/1071 [00:11<00:10, 47.07it/s][A
 53%|█████▎    | 563/1071 [00:11<00:10, 47.17it/s][A
 53%|█████▎    | 568/1071 [00:11<00:10, 47.18it/s][A
 54%|█████▎    | 573/1071 [00:12<00:10, 47.23it/s][A
 54%|█████▍    | 578/1071 [00:12<00:10, 47.17it/s][A
 54%|█████▍    | 583/1071 [00:12<00:10, 47.22it/s][A
 55%|█████▍    | 588/1071 [00:12<00:10, 47.30it/s][A
 55%|█████▌    | 593/1071 [00:12<00:10, 47.31it/s][A
 56%|█████▌    | 598/1071 [00:12<00:10, 47.23it/s][A
 56%|█████▋    | 603/1071 [00:12<00:09, 47.25it/s][A
 57%|█████▋    | 608/1071 [00:12<00:09, 47.16it/s][A
 57%|█████▋    | 613/1071 [00:12<00:09, 47.05it/s][A
 58%|█████▊    | 618/1071 [00:13<00:09, 47.12it/s][A
 58%|█████▊    | 623/1071 [00:13<00:09, 47.19it/s][A
 59%|█████▊    | 628/1071 [00:13<00:09, 47.23it/s][A
 59%|█████▉    | 633/1071 [00:13<00:09, 47.22it/s][A
 60%|█████▉    | 638/1071 [00:13<00:09, 47.25it/s][A
 60%|██████    | 643/1071 [00:13<00:09, 47.22it/s][A
 61%|██████    | 648/1071 [00:13<00:08, 47.17it/s][A
 61%|██████    | 653/1071 [00:13<00:08, 47.21it/s][A
 61%|██████▏   | 658/1071 [00:13<00:08, 47.15it/s][A
 62%|██████▏   | 663/1071 [00:14<00:08, 47.12it/s][A
 62%|██████▏   | 668/1071 [00:14<00:08, 47.17it/s][A
 63%|██████▎   | 673/1071 [00:14<00:08, 47.15it/s][A
 63%|██████▎   | 678/1071 [00:14<00:08, 47.23it/s][A
 64%|██████▍   | 683/1071 [00:14<00:08, 47.20it/s][A
 64%|██████▍   | 688/1071 [00:14<00:08, 47.23it/s][A
 65%|██████▍   | 693/1071 [00:14<00:08, 47.18it/s][A
 65%|██████▌   | 698/1071 [00:14<00:07, 47.13it/s][A
 66%|██████▌   | 703/1071 [00:14<00:07, 47.10it/s][A
 66%|██████▌   | 708/1071 [00:14<00:07, 47.06it/s][A
 67%|██████▋   | 713/1071 [00:15<00:07, 47.10it/s][A
 67%|██████▋   | 718/1071 [00:15<00:07, 47.21it/s][A
 68%|██████▊   | 723/1071 [00:15<00:07, 47.24it/s][A
 68%|██████▊   | 728/1071 [00:15<00:07, 47.16it/s][A
 68%|██████▊   | 733/1071 [00:15<00:07, 47.16it/s][A
 69%|██████▉   | 738/1071 [00:15<00:07, 47.22it/s][A
 69%|██████▉   | 743/1071 [00:15<00:06, 47.20it/s][A
 70%|██████▉   | 748/1071 [00:15<00:06, 47.14it/s][A
 70%|███████   | 753/1071 [00:15<00:06, 47.13it/s][A
 71%|███████   | 758/1071 [00:16<00:06, 47.15it/s][A
 71%|███████   | 763/1071 [00:16<00:06, 47.13it/s][A
 72%|███████▏  | 768/1071 [00:16<00:06, 47.18it/s][A
 72%|███████▏  | 773/1071 [00:16<00:06, 47.22it/s][A
 73%|███████▎  | 778/1071 [00:16<00:06, 47.17it/s][A
 73%|███████▎  | 783/1071 [00:16<00:06, 47.18it/s][A
 74%|███████▎  | 788/1071 [00:16<00:05, 47.20it/s][A
 74%|███████▍  | 793/1071 [00:16<00:05, 47.11it/s][A
 75%|███████▍  | 798/1071 [00:16<00:05, 46.97it/s][A
 75%|███████▍  | 803/1071 [00:16<00:05, 46.97it/s][A
 75%|███████▌  | 808/1071 [00:17<00:05, 46.91it/s][A
 76%|███████▌  | 813/1071 [00:17<00:05, 46.94it/s][A
 76%|███████▋  | 818/1071 [00:17<00:05, 47.07it/s][A
 77%|███████▋  | 823/1071 [00:17<00:05, 47.13it/s][A
 77%|███████▋  | 828/1071 [00:17<00:05, 47.08it/s][A
 78%|███████▊  | 833/1071 [00:17<00:05, 47.11it/s][A
 78%|███████▊  | 838/1071 [00:17<00:04, 47.13it/s][A
 79%|███████▊  | 843/1071 [00:17<00:04, 47.00it/s][A
 79%|███████▉  | 848/1071 [00:17<00:04, 47.08it/s][A
 80%|███████▉  | 853/1071 [00:18<00:04, 47.08it/s][A
 80%|████████  | 858/1071 [00:18<00:04, 44.89it/s][A
 81%|████████  | 863/1071 [00:18<00:04, 45.60it/s][A
 81%|████████  | 868/1071 [00:18<00:04, 46.10it/s][A
 82%|████████▏ | 873/1071 [00:18<00:04, 46.46it/s][A
 82%|████████▏ | 878/1071 [00:18<00:04, 46.73it/s][A
 82%|████████▏ | 883/1071 [00:18<00:04, 46.87it/s][A
 83%|████████▎ | 888/1071 [00:18<00:03, 46.97it/s][A
 83%|████████▎ | 893/1071 [00:18<00:03, 47.00it/s][A
 84%|████████▍ | 898/1071 [00:19<00:03, 46.81it/s][A
 84%|████████▍ | 903/1071 [00:19<00:03, 46.87it/s][A
 85%|████████▍ | 908/1071 [00:19<00:03, 46.86it/s][A
 85%|████████▌ | 913/1071 [00:19<00:03, 46.97it/s][A
 86%|████████▌ | 918/1071 [00:19<00:03, 47.12it/s][A
 86%|████████▌ | 923/1071 [00:19<00:03, 47.18it/s][A
 87%|████████▋ | 928/1071 [00:19<00:03, 47.20it/s][A
 87%|████████▋ | 933/1071 [00:19<00:02, 47.24it/s][A
 88%|████████▊ | 938/1071 [00:19<00:02, 47.18it/s][A
 88%|████████▊ | 943/1071 [00:19<00:02, 46.97it/s][A
 89%|████████▊ | 948/1071 [00:20<00:02, 46.97it/s][A
 89%|████████▉ | 953/1071 [00:20<00:02, 46.99it/s][A
 89%|████████▉ | 958/1071 [00:20<00:02, 47.03it/s][A
 90%|████████▉ | 963/1071 [00:20<00:02, 47.09it/s][A
 90%|█████████ | 968/1071 [00:20<00:02, 47.16it/s][A
 91%|█████████ | 973/1071 [00:20<00:02, 47.21it/s][A
 91%|█████████▏| 978/1071 [00:20<00:01, 47.23it/s][A
 92%|█████████▏| 983/1071 [00:20<00:01, 47.25it/s][A
 92%|█████████▏| 988/1071 [00:20<00:01, 47.04it/s][A
 93%|█████████▎| 993/1071 [00:21<00:01, 46.95it/s][A
 93%|█████████▎| 998/1071 [00:21<00:01, 47.01it/s][A
 94%|█████████▎| 1003/1071 [00:21<00:01, 46.93it/s][A
 94%|█████████▍| 1008/1071 [00:21<00:01, 46.85it/s][A
 95%|█████████▍| 1013/1071 [00:21<00:01, 46.97it/s][A
 95%|█████████▌| 1018/1071 [00:21<00:01, 47.05it/s][A
 96%|█████████▌| 1023/1071 [00:21<00:01, 47.13it/s][A
 96%|█████████▌| 1028/1071 [00:21<00:00, 47.15it/s][A
 96%|█████████▋| 1033/1071 [00:21<00:00, 47.10it/s][A
 97%|█████████▋| 1038/1071 [00:21<00:00, 47.00it/s][A
 97%|█████████▋| 1043/1071 [00:22<00:00, 46.98it/s][A
 98%|█████████▊| 1048/1071 [00:22<00:00, 47.02it/s][A
 98%|█████████▊| 1053/1071 [00:22<00:00, 46.18it/s][A
 99%|█████████▉| 1058/1071 [00:22<00:00, 46.46it/s][A
 99%|█████████▉| 1063/1071 [00:22<00:00, 46.61it/s][A
100%|█████████▉| 1068/1071 [00:22<00:00, 46.76it/s][A                                                 
                                                   [A 20%|██        | 123/615 [01:00<02:13,  3.69it/s]
100%|██████████| 1071/1071 [00:22<00:00, 46.76it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 14:10:09,554 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-123
[INFO|configuration_utils.py:351] 2023-08-29 14:10:09,580 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-123/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:10:12,025 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-123/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:10:12,043 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-123/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:10:12,051 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-123/special_tokens_map.json
 20%|██        | 124/615 [01:03<1:05:05,  7.95s/it] 20%|██        | 125/615 [01:03<46:08,  5.65s/it]   20%|██        | 126/615 [01:04<32:53,  4.04s/it] 21%|██        | 127/615 [01:04<23:38,  2.91s/it] 21%|██        | 128/615 [01:04<17:10,  2.12s/it] 21%|██        | 129/615 [01:04<12:39,  1.56s/it] 21%|██        | 130/615 [01:05<09:29,  1.17s/it] 21%|██▏       | 131/615 [01:05<07:17,  1.11it/s] 21%|██▏       | 132/615 [01:05<05:44,  1.40it/s] 22%|██▏       | 133/615 [01:05<04:39,  1.72it/s] 22%|██▏       | 134/615 [01:06<03:54,  2.05it/s] 22%|██▏       | 135/615 [01:06<03:23,  2.36it/s] 22%|██▏       | 136/615 [01:06<03:01,  2.65it/s] 22%|██▏       | 137/615 [01:07<02:45,  2.89it/s] 22%|██▏       | 138/615 [01:07<02:34,  3.09it/s] 23%|██▎       | 139/615 [01:07<02:26,  3.25it/s] 23%|██▎       | 140/615 [01:07<02:21,  3.37it/s] 23%|██▎       | 141/615 [01:08<02:17,  3.46it/s] 23%|██▎       | 142/615 [01:08<02:14,  3.52it/s] 23%|██▎       | 143/615 [01:08<02:12,  3.57it/s] 23%|██▎       | 144/615 [01:08<02:10,  3.60it/s] 24%|██▎       | 145/615 [01:09<02:09,  3.63it/s] 24%|██▎       | 146/615 [01:09<02:08,  3.65it/s] 24%|██▍       | 147/615 [01:09<02:08,  3.65it/s] 24%|██▍       | 148/615 [01:10<02:07,  3.66it/s] 24%|██▍       | 149/615 [01:10<02:07,  3.67it/s] 24%|██▍       | 150/615 [01:10<02:06,  3.67it/s] 25%|██▍       | 151/615 [01:10<02:06,  3.68it/s] 25%|██▍       | 152/615 [01:11<02:05,  3.68it/s] 25%|██▍       | 153/615 [01:11<02:05,  3.68it/s] 25%|██▌       | 154/615 [01:11<02:05,  3.68it/s] 25%|██▌       | 155/615 [01:11<02:05,  3.68it/s] 25%|██▌       | 156/615 [01:12<02:04,  3.68it/s] 26%|██▌       | 157/615 [01:12<02:04,  3.68it/s] 26%|██▌       | 158/615 [01:12<02:04,  3.68it/s] 26%|██▌       | 159/615 [01:13<02:11,  3.48it/s] 26%|██▌       | 160/615 [01:13<02:08,  3.54it/s] 26%|██▌       | 161/615 [01:13<02:06,  3.58it/s] 26%|██▋       | 162/615 [01:13<02:05,  3.61it/s] 27%|██▋       | 163/615 [01:14<02:04,  3.64it/s] 27%|██▋       | 164/615 [01:14<02:03,  3.65it/s] 27%|██▋       | 165/615 [01:14<02:07,  3.52it/s] 27%|██▋       | 166/615 [01:15<02:43,  2.74it/s]/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
 27%|██▋       | 167/615 [01:15<02:39,  2.80it/s] 27%|██▋       | 168/615 [01:15<02:29,  2.99it/s] 27%|██▋       | 169/615 [01:16<02:20,  3.16it/s] 28%|██▊       | 170/615 [01:16<02:14,  3.30it/s] 28%|██▊       | 171/615 [01:16<02:10,  3.41it/s] 28%|██▊       | 172/615 [01:16<02:07,  3.49it/s] 28%|██▊       | 173/615 [01:17<02:04,  3.55it/s] 28%|██▊       | 174/615 [01:17<02:02,  3.59it/s] 28%|██▊       | 175/615 [01:17<02:02,  3.60it/s] 29%|██▊       | 176/615 [01:18<02:01,  3.63it/s] 29%|██▉       | 177/615 [01:18<02:00,  3.64it/s] 29%|██▉       | 178/615 [01:18<01:59,  3.65it/s] 29%|██▉       | 179/615 [01:18<01:59,  3.65it/s] 29%|██▉       | 180/615 [01:19<01:58,  3.66it/s] 29%|██▉       | 181/615 [01:19<01:58,  3.67it/s] 30%|██▉       | 182/615 [01:19<01:57,  3.67it/s] 30%|██▉       | 183/615 [01:19<01:57,  3.67it/s] 30%|██▉       | 184/615 [01:20<01:57,  3.67it/s] 30%|███       | 185/615 [01:20<01:57,  3.67it/s] 30%|███       | 186/615 [01:20<01:56,  3.67it/s] 30%|███       | 187/615 [01:21<01:56,  3.67it/s] 31%|███       | 188/615 [01:21<01:56,  3.67it/s] 31%|███       | 189/615 [01:21<01:56,  3.67it/s] 31%|███       | 190/615 [01:21<01:55,  3.67it/s] 31%|███       | 191/615 [01:22<01:55,  3.68it/s] 31%|███       | 192/615 [01:22<01:55,  3.68it/s] 31%|███▏      | 193/615 [01:22<01:54,  3.68it/s] 32%|███▏      | 194/615 [01:22<01:54,  3.68it/s] 32%|███▏      | 195/615 [01:23<01:54,  3.68it/s] 32%|███▏      | 196/615 [01:23<01:53,  3.68it/s] 32%|███▏      | 197/615 [01:23<01:53,  3.68it/s] 32%|███▏      | 198/615 [01:24<01:53,  3.68it/s] 32%|███▏      | 199/615 [01:24<01:53,  3.67it/s] 33%|███▎      | 200/615 [01:24<01:53,  3.67it/s] 33%|███▎      | 201/615 [01:24<01:52,  3.67it/s] 33%|███▎      | 202/615 [01:25<01:52,  3.67it/s] 33%|███▎      | 203/615 [01:25<01:52,  3.67it/s] 33%|███▎      | 204/615 [01:25<01:51,  3.67it/s] 33%|███▎      | 205/615 [01:25<01:51,  3.68it/s] 33%|███▎      | 206/615 [01:26<01:51,  3.68it/s] 34%|███▎      | 207/615 [01:26<01:50,  3.68it/s] 34%|███▍      | 208/615 [01:26<01:50,  3.68it/s] 34%|███▍      | 209/615 [01:27<01:50,  3.68it/s] 34%|███▍      | 210/615 [01:27<01:50,  3.68it/s] 34%|███▍      | 211/615 [01:27<01:50,  3.66it/s] 34%|███▍      | 212/615 [01:27<01:49,  3.67it/s] 35%|███▍      | 213/615 [01:28<01:49,  3.67it/s] 35%|███▍      | 214/615 [01:28<01:49,  3.67it/s] 35%|███▍      | 215/615 [01:28<01:48,  3.67it/s] 35%|███▌      | 216/615 [01:28<01:48,  3.67it/s] 35%|███▌      | 217/615 [01:29<01:48,  3.67it/s] 35%|███▌      | 218/615 [01:29<01:48,  3.67it/s] 36%|███▌      | 219/615 [01:29<01:47,  3.67it/s] 36%|███▌      | 220/615 [01:30<01:47,  3.67it/s] 36%|███▌      | 221/615 [01:30<01:47,  3.67it/s] 36%|███▌      | 222/615 [01:30<01:46,  3.67it/s] 36%|███▋      | 223/615 [01:30<01:46,  3.67it/s] 36%|███▋      | 224/615 [01:31<01:46,  3.67it/s] 37%|███▋      | 225/615 [01:31<01:46,  3.67it/s] 37%|███▋      | 226/615 [01:31<01:45,  3.67it/s] 37%|███▋      | 227/615 [01:31<01:45,  3.68it/s] 37%|███▋      | 228/615 [01:32<01:45,  3.68it/s] 37%|███▋      | 229/615 [01:32<01:44,  3.68it/s] 37%|███▋      | 230/615 [01:32<01:44,  3.67it/s] 38%|███▊      | 231/615 [01:33<01:44,  3.67it/s] 38%|███▊      | 232/615 [01:33<01:44,  3.67it/s] 38%|███▊      | 233/615 [01:33<01:43,  3.67it/s] 38%|███▊      | 234/615 [01:33<01:43,  3.68it/s] 38%|███▊      | 235/615 [01:34<01:43,  3.66it/s] 38%|███▊      | 236/615 [01:34<01:43,  3.67it/s] 39%|███▊      | 237/615 [01:34<01:43,  3.67it/s] 39%|███▊      | 238/615 [01:34<01:42,  3.67it/s] 39%|███▉      | 239/615 [01:35<01:42,  3.67it/s] 39%|███▉      | 240/615 [01:35<01:42,  3.67it/s] 39%|███▉      | 241/615 [01:35<01:41,  3.67it/s] 39%|███▉      | 242/615 [01:36<01:41,  3.67it/s] 40%|███▉      | 243/615 [01:36<01:41,  3.67it/s] 40%|███▉      | 244/615 [01:36<01:41,  3.67it/s] 40%|███▉      | 245/615 [01:36<01:40,  3.67it/s] 40%|████      | 246/615 [01:37<01:40,  3.67it/s][INFO|trainer.py:2140] 2023-08-29 14:10:46,315 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:10:46,315 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 14:10:46,315 >>   Batch size = 8
{'eval_loss': 0.9968060255050659, 'eval_runtime': 22.7223, 'eval_samples_per_second': 377.075, 'eval_steps_per_second': 47.134, 'epoch': 1.0}

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 57.22it/s][A
  1%|          | 12/1071 [00:00<00:20, 50.69it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 48.92it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.21it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 47.80it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 47.53it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 47.30it/s][A
  4%|▍         | 43/1071 [00:00<00:21, 46.94it/s][A
  4%|▍         | 48/1071 [00:01<00:21, 46.80it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 46.88it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 46.85it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 46.84it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 46.90it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 46.95it/s][A
  7%|▋         | 78/1071 [00:01<00:21, 46.93it/s][A
  8%|▊         | 83/1071 [00:01<00:21, 46.94it/s][A
  8%|▊         | 88/1071 [00:01<00:21, 46.73it/s][A
  9%|▊         | 93/1071 [00:01<00:20, 46.62it/s][A
  9%|▉         | 98/1071 [00:02<00:20, 46.73it/s][A
 10%|▉         | 103/1071 [00:02<00:20, 46.70it/s][A
 10%|█         | 108/1071 [00:02<00:20, 46.74it/s][A
 11%|█         | 113/1071 [00:02<00:20, 46.77it/s][A
 11%|█         | 118/1071 [00:02<00:20, 46.81it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 46.84it/s][A
 12%|█▏        | 128/1071 [00:02<00:20, 46.82it/s][A
 12%|█▏        | 133/1071 [00:02<00:20, 46.71it/s][A
 13%|█▎        | 138/1071 [00:02<00:20, 46.61it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 46.63it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 46.66it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 46.76it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 46.82it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 46.84it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 46.86it/s][A
 16%|█▌        | 173/1071 [00:03<00:19, 46.83it/s][A
 17%|█▋        | 178/1071 [00:03<00:19, 46.74it/s][A
 17%|█▋        | 183/1071 [00:03<00:19, 46.72it/s][A
 18%|█▊        | 188/1071 [00:03<00:18, 46.69it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 46.70it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 46.80it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 46.86it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 46.79it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 46.87it/s][A
 20%|██        | 218/1071 [00:04<00:18, 46.81it/s][A
 21%|██        | 223/1071 [00:04<00:18, 46.75it/s][A
 21%|██▏       | 228/1071 [00:04<00:18, 46.68it/s][A
 22%|██▏       | 233/1071 [00:04<00:17, 46.61it/s][A
 22%|██▏       | 238/1071 [00:05<00:17, 46.69it/s][A
 23%|██▎       | 243/1071 [00:05<00:17, 46.80it/s][A
 23%|██▎       | 248/1071 [00:05<00:17, 46.87it/s][A
 24%|██▎       | 253/1071 [00:05<00:17, 46.78it/s][A
 24%|██▍       | 258/1071 [00:05<00:17, 46.79it/s][A
 25%|██▍       | 263/1071 [00:05<00:17, 46.77it/s][A
 25%|██▌       | 268/1071 [00:05<00:17, 46.77it/s][A
 25%|██▌       | 273/1071 [00:05<00:17, 46.71it/s][A
 26%|██▌       | 278/1071 [00:05<00:17, 46.63it/s][A
 26%|██▋       | 283/1071 [00:06<00:16, 46.73it/s][A
 27%|██▋       | 288/1071 [00:06<00:16, 46.82it/s][A
 27%|██▋       | 293/1071 [00:06<00:16, 46.82it/s][A
 28%|██▊       | 298/1071 [00:06<00:16, 46.87it/s][A
 28%|██▊       | 303/1071 [00:06<00:16, 46.85it/s][A
 29%|██▉       | 308/1071 [00:06<00:16, 46.73it/s][A
 29%|██▉       | 313/1071 [00:06<00:16, 46.74it/s][A
 30%|██▉       | 318/1071 [00:06<00:16, 46.66it/s][A
 30%|███       | 323/1071 [00:06<00:16, 46.63it/s][A
 31%|███       | 328/1071 [00:06<00:15, 46.68it/s][A
 31%|███       | 333/1071 [00:07<00:15, 46.70it/s][A
 32%|███▏      | 338/1071 [00:07<00:15, 46.76it/s][A
 32%|███▏      | 343/1071 [00:07<00:15, 46.84it/s][A
 32%|███▏      | 348/1071 [00:07<00:15, 46.84it/s][A
 33%|███▎      | 353/1071 [00:07<00:15, 46.82it/s][A
 33%|███▎      | 358/1071 [00:07<00:15, 46.79it/s][A
 34%|███▍      | 363/1071 [00:07<00:15, 46.71it/s][A
 34%|███▍      | 368/1071 [00:07<00:15, 46.66it/s][A
 35%|███▍      | 373/1071 [00:07<00:14, 46.67it/s][A
 35%|███▌      | 378/1071 [00:08<00:14, 46.66it/s][A
 36%|███▌      | 383/1071 [00:08<00:14, 46.74it/s][A
 36%|███▌      | 388/1071 [00:08<00:14, 46.83it/s][A
 37%|███▋      | 393/1071 [00:08<00:14, 46.82it/s][A
 37%|███▋      | 398/1071 [00:08<00:14, 46.83it/s][A
 38%|███▊      | 403/1071 [00:08<00:14, 46.78it/s][A
 38%|███▊      | 408/1071 [00:08<00:14, 46.67it/s][A
 39%|███▊      | 413/1071 [00:08<00:14, 46.70it/s][A
 39%|███▉      | 418/1071 [00:08<00:14, 46.63it/s][A
 39%|███▉      | 423/1071 [00:09<00:13, 46.70it/s][A
 40%|███▉      | 428/1071 [00:09<00:13, 46.78it/s][A
 40%|████      | 433/1071 [00:09<00:13, 46.86it/s][A
 41%|████      | 438/1071 [00:09<00:13, 46.82it/s][A
 41%|████▏     | 443/1071 [00:09<00:13, 46.82it/s][A
 42%|████▏     | 448/1071 [00:09<00:13, 46.81it/s][A
 42%|████▏     | 453/1071 [00:09<00:13, 46.73it/s][A
 43%|████▎     | 458/1071 [00:09<00:13, 46.72it/s][A
 43%|████▎     | 463/1071 [00:09<00:13, 46.62it/s][A
 44%|████▎     | 468/1071 [00:09<00:12, 46.68it/s][A
 44%|████▍     | 473/1071 [00:10<00:12, 46.70it/s][A
 45%|████▍     | 478/1071 [00:10<00:12, 46.73it/s][A
 45%|████▌     | 483/1071 [00:10<00:12, 46.83it/s][A
 46%|████▌     | 488/1071 [00:10<00:12, 46.82it/s][A
 46%|████▌     | 493/1071 [00:10<00:12, 46.77it/s][A
 46%|████▋     | 498/1071 [00:10<00:12, 46.73it/s][A
 47%|████▋     | 503/1071 [00:10<00:12, 46.63it/s][A
 47%|████▋     | 508/1071 [00:10<00:12, 46.49it/s][A
 48%|████▊     | 513/1071 [00:10<00:12, 46.49it/s][A
 48%|████▊     | 518/1071 [00:11<00:11, 46.49it/s][A
 49%|████▉     | 523/1071 [00:11<00:11, 46.48it/s][A
 49%|████▉     | 528/1071 [00:11<00:11, 46.67it/s][A
 50%|████▉     | 533/1071 [00:11<00:11, 46.71it/s][A
 50%|█████     | 538/1071 [00:11<00:11, 46.72it/s][A
 51%|█████     | 543/1071 [00:11<00:11, 46.72it/s][A
 51%|█████     | 548/1071 [00:11<00:11, 46.69it/s][A
 52%|█████▏    | 553/1071 [00:11<00:11, 46.69it/s][A
 52%|█████▏    | 558/1071 [00:11<00:10, 46.67it/s][A
 53%|█████▎    | 563/1071 [00:12<00:10, 46.64it/s][A
 53%|█████▎    | 568/1071 [00:12<00:10, 46.69it/s][A
 54%|█████▎    | 573/1071 [00:12<00:10, 46.69it/s][A
 54%|█████▍    | 578/1071 [00:12<00:10, 46.76it/s][A
 54%|█████▍    | 583/1071 [00:12<00:10, 46.60it/s][A
 55%|█████▍    | 588/1071 [00:12<00:10, 46.68it/s][A
 55%|█████▌    | 593/1071 [00:12<00:10, 46.67it/s][A
 56%|█████▌    | 598/1071 [00:12<00:10, 46.67it/s][A
 56%|█████▋    | 603/1071 [00:12<00:10, 46.69it/s][A
 57%|█████▋    | 608/1071 [00:12<00:09, 46.73it/s][A
 57%|█████▋    | 613/1071 [00:13<00:09, 46.72it/s][A
 58%|█████▊    | 618/1071 [00:13<00:09, 46.72it/s][A
 58%|█████▊    | 623/1071 [00:13<00:09, 46.78it/s][A
 59%|█████▊    | 628/1071 [00:13<00:09, 46.69it/s][A
 59%|█████▉    | 633/1071 [00:13<00:09, 46.67it/s][A
 60%|█████▉    | 638/1071 [00:13<00:09, 46.74it/s][A
 60%|██████    | 643/1071 [00:13<00:09, 46.70it/s][A
 61%|██████    | 648/1071 [00:13<00:09, 46.66it/s][A
 61%|██████    | 653/1071 [00:13<00:08, 46.75it/s][A
 61%|██████▏   | 658/1071 [00:14<00:08, 46.76it/s][A
 62%|██████▏   | 663/1071 [00:14<00:08, 46.72it/s][A
 62%|██████▏   | 668/1071 [00:14<00:08, 46.79it/s][A
 63%|██████▎   | 673/1071 [00:14<00:08, 46.78it/s][A
 63%|██████▎   | 678/1071 [00:14<00:08, 46.77it/s][A
 64%|██████▍   | 683/1071 [00:14<00:08, 46.76it/s][A
 64%|██████▍   | 688/1071 [00:14<00:08, 46.72it/s][A
 65%|██████▍   | 693/1071 [00:14<00:08, 46.68it/s][A
 65%|██████▌   | 698/1071 [00:14<00:07, 46.70it/s][A
 66%|██████▌   | 703/1071 [00:15<00:07, 46.68it/s][A
 66%|██████▌   | 708/1071 [00:15<00:07, 46.74it/s][A
 67%|██████▋   | 713/1071 [00:15<00:07, 46.75it/s][A
 67%|██████▋   | 718/1071 [00:15<00:07, 46.75it/s][A
 68%|██████▊   | 723/1071 [00:15<00:07, 46.76it/s][A
 68%|██████▊   | 728/1071 [00:15<00:07, 46.67it/s][A
 68%|██████▊   | 733/1071 [00:15<00:07, 46.66it/s][A
 69%|██████▉   | 738/1071 [00:15<00:07, 46.68it/s][A
 69%|██████▉   | 743/1071 [00:15<00:07, 46.69it/s][A
 70%|██████▉   | 748/1071 [00:15<00:06, 46.65it/s][A
 70%|███████   | 753/1071 [00:16<00:06, 46.72it/s][A
 71%|███████   | 758/1071 [00:16<00:06, 46.73it/s][A
 71%|███████   | 763/1071 [00:16<00:06, 46.48it/s][A
 72%|███████▏  | 768/1071 [00:16<00:06, 46.61it/s][A
 72%|███████▏  | 773/1071 [00:16<00:06, 46.62it/s][A
 73%|███████▎  | 778/1071 [00:16<00:06, 46.65it/s][A
 73%|███████▎  | 783/1071 [00:16<00:06, 46.67it/s][A
 74%|███████▎  | 788/1071 [00:16<00:06, 46.65it/s][A
 74%|███████▍  | 793/1071 [00:16<00:05, 46.66it/s][A
 75%|███████▍  | 798/1071 [00:17<00:05, 46.67it/s][A
 75%|███████▍  | 803/1071 [00:17<00:05, 46.67it/s][A
 75%|███████▌  | 808/1071 [00:17<00:05, 46.66it/s][A
 76%|███████▌  | 813/1071 [00:17<00:05, 46.66it/s][A
 76%|███████▋  | 818/1071 [00:17<00:05, 46.72it/s][A
 77%|███████▋  | 823/1071 [00:17<00:05, 46.73it/s][A
 77%|███████▋  | 828/1071 [00:17<00:05, 46.71it/s][A
 78%|███████▊  | 833/1071 [00:17<00:05, 46.69it/s][A
 78%|███████▊  | 838/1071 [00:17<00:04, 46.68it/s][A
 79%|███████▊  | 843/1071 [00:18<00:04, 46.66it/s][A
 79%|███████▉  | 848/1071 [00:18<00:04, 46.67it/s][A
 80%|███████▉  | 853/1071 [00:18<00:04, 46.70it/s][A
 80%|████████  | 858/1071 [00:18<00:04, 46.68it/s][A
 81%|████████  | 863/1071 [00:18<00:04, 46.74it/s][A
 81%|████████  | 868/1071 [00:18<00:04, 46.76it/s][A
 82%|████████▏ | 873/1071 [00:18<00:04, 46.70it/s][A
 82%|████████▏ | 878/1071 [00:18<00:04, 46.70it/s][A
 82%|████████▏ | 883/1071 [00:18<00:04, 46.72it/s][A
 83%|████████▎ | 888/1071 [00:18<00:03, 46.73it/s][A
 83%|████████▎ | 893/1071 [00:19<00:03, 46.65it/s][A
 84%|████████▍ | 898/1071 [00:19<00:03, 46.65it/s][A
 84%|████████▍ | 903/1071 [00:19<00:03, 46.70it/s][A
 85%|████████▍ | 908/1071 [00:19<00:03, 46.78it/s][A
 85%|████████▌ | 913/1071 [00:19<00:03, 46.81it/s][A
 86%|████████▌ | 918/1071 [00:19<00:03, 46.74it/s][A
 86%|████████▌ | 923/1071 [00:19<00:03, 46.74it/s][A
 87%|████████▋ | 928/1071 [00:19<00:03, 46.74it/s][A
 87%|████████▋ | 933/1071 [00:19<00:02, 46.78it/s][A
 88%|████████▊ | 938/1071 [00:20<00:02, 46.70it/s][A
 88%|████████▊ | 943/1071 [00:20<00:02, 46.62it/s][A
 89%|████████▊ | 948/1071 [00:20<00:02, 46.68it/s][A
 89%|████████▉ | 953/1071 [00:20<00:02, 46.68it/s][A
 89%|████████▉ | 958/1071 [00:20<00:02, 46.66it/s][A
 90%|████████▉ | 963/1071 [00:20<00:02, 46.65it/s][A
 90%|█████████ | 968/1071 [00:20<00:02, 46.63it/s][A
 91%|█████████ | 973/1071 [00:20<00:02, 46.65it/s][A
 91%|█████████▏| 978/1071 [00:20<00:01, 46.66it/s][A
 92%|█████████▏| 983/1071 [00:21<00:01, 46.64it/s][A
 92%|█████████▏| 988/1071 [00:21<00:01, 46.59it/s][A
 93%|█████████▎| 993/1071 [00:21<00:01, 46.62it/s][A
 93%|█████████▎| 998/1071 [00:21<00:01, 46.66it/s][A
 94%|█████████▎| 1003/1071 [00:21<00:01, 46.70it/s][A
 94%|█████████▍| 1008/1071 [00:21<00:01, 46.69it/s][A
 95%|█████████▍| 1013/1071 [00:21<00:01, 46.65it/s][A
 95%|█████████▌| 1018/1071 [00:21<00:01, 46.68it/s][A
 96%|█████████▌| 1023/1071 [00:21<00:01, 46.70it/s][A
 96%|█████████▌| 1028/1071 [00:21<00:00, 46.68it/s][A
 96%|█████████▋| 1033/1071 [00:22<00:00, 46.60it/s][A
 97%|█████████▋| 1038/1071 [00:22<00:00, 46.63it/s][A
 97%|█████████▋| 1043/1071 [00:22<00:00, 46.70it/s][A
 98%|█████████▊| 1048/1071 [00:22<00:00, 46.73it/s][A
 98%|█████████▊| 1053/1071 [00:22<00:00, 46.71it/s][A
 99%|█████████▉| 1058/1071 [00:22<00:00, 46.70it/s][A
 99%|█████████▉| 1063/1071 [00:22<00:00, 45.03it/s][A
100%|█████████▉| 1069/1071 [00:22<00:00, 46.65it/s][A                                                 
                                                   [A 40%|████      | 246/615 [02:00<01:40,  3.67it/s]
100%|██████████| 1071/1071 [00:22<00:00, 46.65it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 14:11:09,261 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-246
[INFO|configuration_utils.py:351] 2023-08-29 14:11:09,282 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-246/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:11:11,693 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-246/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:11:11,718 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-246/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:11:11,726 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-246/special_tokens_map.json
 40%|████      | 247/615 [02:03<49:06,  8.01s/it] 40%|████      | 248/615 [02:03<34:46,  5.69s/it] 40%|████      | 249/615 [02:03<24:47,  4.06s/it] 41%|████      | 250/615 [02:03<17:47,  2.93s/it] 41%|████      | 251/615 [02:04<12:55,  2.13s/it] 41%|████      | 252/615 [02:04<09:30,  1.57s/it] 41%|████      | 253/615 [02:04<07:08,  1.18s/it] 41%|████▏     | 254/615 [02:05<05:28,  1.10it/s] 41%|████▏     | 255/615 [02:05<04:18,  1.39it/s] 42%|████▏     | 256/615 [02:05<03:29,  1.71it/s] 42%|████▏     | 257/615 [02:05<02:55,  2.04it/s] 42%|████▏     | 258/615 [02:06<02:31,  2.35it/s] 42%|████▏     | 259/615 [02:06<02:15,  2.63it/s] 42%|████▏     | 260/615 [02:06<02:03,  2.87it/s] 42%|████▏     | 261/615 [02:06<01:55,  3.07it/s] 43%|████▎     | 262/615 [02:07<01:49,  3.23it/s] 43%|████▎     | 263/615 [02:07<01:45,  3.35it/s] 43%|████▎     | 264/615 [02:07<01:41,  3.44it/s] 43%|████▎     | 265/615 [02:08<01:39,  3.50it/s] 43%|████▎     | 266/615 [02:08<01:38,  3.55it/s] 43%|████▎     | 267/615 [02:08<01:37,  3.58it/s] 44%|████▎     | 268/615 [02:08<01:36,  3.61it/s] 44%|████▎     | 269/615 [02:09<01:35,  3.63it/s] 44%|████▍     | 270/615 [02:09<01:34,  3.64it/s] 44%|████▍     | 271/615 [02:09<01:34,  3.64it/s] 44%|████▍     | 272/615 [02:09<01:34,  3.65it/s] 44%|████▍     | 273/615 [02:10<01:33,  3.65it/s] 45%|████▍     | 274/615 [02:10<01:33,  3.66it/s] 45%|████▍     | 275/615 [02:10<01:32,  3.66it/s] 45%|████▍     | 276/615 [02:11<01:32,  3.67it/s] 45%|████▌     | 277/615 [02:11<01:32,  3.67it/s] 45%|████▌     | 278/615 [02:11<01:31,  3.67it/s] 45%|████▌     | 279/615 [02:11<01:31,  3.67it/s] 46%|████▌     | 280/615 [02:12<01:31,  3.67it/s] 46%|████▌     | 281/615 [02:12<01:31,  3.67it/s] 46%|████▌     | 282/615 [02:12<01:31,  3.65it/s] 46%|████▌     | 283/615 [02:12<01:30,  3.66it/s] 46%|████▌     | 284/615 [02:13<01:30,  3.66it/s] 46%|████▋     | 285/615 [02:13<01:30,  3.66it/s] 47%|████▋     | 286/615 [02:13<01:29,  3.66it/s] 47%|████▋     | 287/615 [02:14<01:29,  3.66it/s] 47%|████▋     | 288/615 [02:14<01:29,  3.66it/s] 47%|████▋     | 289/615 [02:14<01:28,  3.66it/s] 47%|████▋     | 290/615 [02:14<01:28,  3.66it/s] 47%|████▋     | 291/615 [02:15<01:29,  3.62it/s] 47%|████▋     | 292/615 [02:15<01:29,  3.62it/s] 48%|████▊     | 293/615 [02:15<01:28,  3.62it/s] 48%|████▊     | 294/615 [02:16<01:28,  3.64it/s] 48%|████▊     | 295/615 [02:16<01:27,  3.65it/s] 48%|████▊     | 296/615 [02:16<01:27,  3.65it/s] 48%|████▊     | 297/615 [02:16<01:27,  3.65it/s] 48%|████▊     | 298/615 [02:17<01:26,  3.66it/s] 49%|████▊     | 299/615 [02:17<01:26,  3.66it/s] 49%|████▉     | 300/615 [02:17<01:26,  3.66it/s] 49%|████▉     | 301/615 [02:17<01:25,  3.66it/s] 49%|████▉     | 302/615 [02:18<01:25,  3.66it/s] 49%|████▉     | 303/615 [02:18<01:25,  3.67it/s] 49%|████▉     | 304/615 [02:18<01:24,  3.67it/s] 50%|████▉     | 305/615 [02:19<01:24,  3.66it/s] 50%|████▉     | 306/615 [02:19<01:24,  3.66it/s] 50%|████▉     | 307/615 [02:19<01:24,  3.67it/s] 50%|█████     | 308/615 [02:19<01:23,  3.66it/s] 50%|█████     | 309/615 [02:20<01:23,  3.66it/s] 50%|█████     | 310/615 [02:20<01:23,  3.66it/s] 51%|█████     | 311/615 [02:20<01:23,  3.66it/s] 51%|█████     | 312/615 [02:20<01:22,  3.66it/s] 51%|█████     | 313/615 [02:21<01:22,  3.66it/s] 51%|█████     | 314/615 [02:21<01:22,  3.66it/s] 51%|█████     | 315/615 [02:21<01:21,  3.66it/s] 51%|█████▏    | 316/615 [02:22<01:21,  3.65it/s] 52%|█████▏    | 317/615 [02:22<01:21,  3.66it/s] 52%|█████▏    | 318/615 [02:22<01:21,  3.66it/s] 52%|█████▏    | 319/615 [02:22<01:20,  3.67it/s] 52%|█████▏    | 320/615 [02:23<01:20,  3.67it/s] 52%|█████▏    | 321/615 [02:23<01:20,  3.67it/s] 52%|█████▏    | 322/615 [02:23<01:19,  3.67it/s] 53%|█████▎    | 323/615 [02:23<01:19,  3.67it/s] 53%|█████▎    | 324/615 [02:24<01:19,  3.67it/s] 53%|█████▎    | 325/615 [02:24<01:19,  3.67it/s] 53%|█████▎    | 326/615 [02:24<01:18,  3.66it/s] 53%|█████▎    | 327/615 [02:25<01:19,  3.63it/s] 53%|█████▎    | 328/615 [02:25<01:18,  3.64it/s] 53%|█████▎    | 329/615 [02:25<01:18,  3.65it/s] 54%|█████▎    | 330/615 [02:25<01:17,  3.66it/s] 54%|█████▍    | 331/615 [02:26<01:17,  3.66it/s] 54%|█████▍    | 332/615 [02:26<01:17,  3.67it/s] 54%|█████▍    | 333/615 [02:26<01:16,  3.67it/s] 54%|█████▍    | 334/615 [02:26<01:16,  3.67it/s] 54%|█████▍    | 335/615 [02:27<01:16,  3.67it/s] 55%|█████▍    | 336/615 [02:27<01:16,  3.67it/s] 55%|█████▍    | 337/615 [02:27<01:15,  3.67it/s] 55%|█████▍    | 338/615 [02:28<01:15,  3.67it/s] 55%|█████▌    | 339/615 [02:28<01:15,  3.67it/s] 55%|█████▌    | 340/615 [02:28<01:15,  3.66it/s] 55%|█████▌    | 341/615 [02:28<01:14,  3.66it/s] 56%|█████▌    | 342/615 [02:29<01:14,  3.66it/s] 56%|█████▌    | 343/615 [02:29<01:14,  3.65it/s] 56%|█████▌    | 344/615 [02:29<01:14,  3.65it/s] 56%|█████▌    | 345/615 [02:29<01:13,  3.65it/s] 56%|█████▋    | 346/615 [02:30<01:13,  3.65it/s] 56%|█████▋    | 347/615 [02:30<01:13,  3.65it/s] 57%|█████▋    | 348/615 [02:30<01:13,  3.65it/s] 57%|█████▋    | 349/615 [02:31<01:12,  3.65it/s] 57%|█████▋    | 350/615 [02:31<01:12,  3.65it/s] 57%|█████▋    | 351/615 [02:31<01:12,  3.65it/s] 57%|█████▋    | 352/615 [02:31<01:11,  3.65it/s] 57%|█████▋    | 353/615 [02:32<01:11,  3.65it/s] 58%|█████▊    | 354/615 [02:32<01:11,  3.64it/s] 58%|█████▊    | 355/615 [02:32<01:11,  3.64it/s] 58%|█████▊    | 356/615 [02:32<01:10,  3.65it/s] 58%|█████▊    | 357/615 [02:33<01:10,  3.65it/s] 58%|█████▊    | 358/615 [02:33<01:10,  3.65it/s] 58%|█████▊    | 359/615 [02:33<01:10,  3.66it/s] 59%|█████▊    | 360/615 [02:34<01:09,  3.66it/s] 59%|█████▊    | 361/615 [02:34<01:09,  3.66it/s] 59%|█████▉    | 362/615 [02:34<01:09,  3.66it/s] 59%|█████▉    | 363/615 [02:34<01:08,  3.66it/s] 59%|█████▉    | 364/615 [02:35<01:08,  3.66it/s] 59%|█████▉    | 365/615 [02:35<01:08,  3.64it/s] 60%|█████▉    | 366/615 [02:35<01:08,  3.65it/s] 60%|█████▉    | 367/615 [02:35<01:07,  3.65it/s] 60%|█████▉    | 368/615 [02:36<01:07,  3.65it/s] 60%|██████    | 369/615 [02:36<01:07,  3.65it/s][INFO|trainer.py:2140] 2023-08-29 14:11:45,713 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:11:45,713 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 14:11:45,713 >>   Batch size = 8
{'eval_loss': 0.9968060255050659, 'eval_runtime': 22.9296, 'eval_samples_per_second': 373.665, 'eval_steps_per_second': 46.708, 'epoch': 2.0}

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 56.92it/s][A
  1%|          | 12/1071 [00:00<00:20, 50.48it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 48.77it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.04it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 47.65it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 47.39it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 47.06it/s][A
  4%|▍         | 43/1071 [00:00<00:22, 46.68it/s][A
  4%|▍         | 48/1071 [00:01<00:21, 46.57it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 46.60it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 46.59it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 46.62it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 46.67it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 46.71it/s][A
  7%|▋         | 78/1071 [00:01<00:21, 46.74it/s][A
  8%|▊         | 83/1071 [00:01<00:21, 46.69it/s][A
  8%|▊         | 88/1071 [00:01<00:21, 46.56it/s][A
  9%|▊         | 93/1071 [00:01<00:21, 46.50it/s][A
  9%|▉         | 98/1071 [00:02<00:21, 45.51it/s][A
 10%|▉         | 103/1071 [00:02<00:21, 45.87it/s][A
 10%|█         | 108/1071 [00:02<00:20, 46.04it/s][A
 11%|█         | 113/1071 [00:02<00:20, 46.18it/s][A
 11%|█         | 118/1071 [00:02<00:20, 46.35it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 46.27it/s][A
 12%|█▏        | 128/1071 [00:02<00:20, 46.41it/s][A
 12%|█▏        | 133/1071 [00:02<00:20, 46.42it/s][A
 13%|█▎        | 138/1071 [00:02<00:20, 46.41it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 46.52it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 46.58it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 46.59it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 46.62it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 46.64it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 46.57it/s][A
 16%|█▌        | 173/1071 [00:03<00:19, 46.52it/s][A
 17%|█▋        | 178/1071 [00:03<00:19, 46.34it/s][A
 17%|█▋        | 183/1071 [00:03<00:19, 46.26it/s][A
 18%|█▊        | 188/1071 [00:04<00:19, 46.25it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 46.36it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 46.39it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 46.39it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 46.47it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 46.47it/s][A
 20%|██        | 218/1071 [00:04<00:18, 46.51it/s][A
 21%|██        | 223/1071 [00:04<00:18, 46.47it/s][A
 21%|██▏       | 228/1071 [00:04<00:18, 46.34it/s][A
 22%|██▏       | 233/1071 [00:04<00:18, 46.29it/s][A
 22%|██▏       | 238/1071 [00:05<00:18, 46.24it/s][A
 23%|██▎       | 243/1071 [00:05<00:17, 46.28it/s][A
 23%|██▎       | 248/1071 [00:05<00:17, 46.36it/s][A
 24%|██▎       | 253/1071 [00:05<00:17, 46.38it/s][A
 24%|██▍       | 258/1071 [00:05<00:17, 46.45it/s][A
 25%|██▍       | 263/1071 [00:05<00:17, 46.51it/s][A
 25%|██▌       | 268/1071 [00:05<00:17, 46.49it/s][A
 25%|██▌       | 273/1071 [00:05<00:17, 46.46it/s][A
 26%|██▌       | 278/1071 [00:05<00:17, 46.45it/s][A
 26%|██▋       | 283/1071 [00:06<00:16, 46.50it/s][A
 27%|██▋       | 288/1071 [00:06<00:16, 46.49it/s][A
 27%|██▋       | 293/1071 [00:06<00:16, 46.47it/s][A
 28%|██▊       | 298/1071 [00:06<00:16, 46.52it/s][A
 28%|██▊       | 303/1071 [00:06<00:16, 46.51it/s][A
 29%|██▉       | 308/1071 [00:06<00:16, 46.49it/s][A
 29%|██▉       | 313/1071 [00:06<00:16, 46.51it/s][A
 30%|██▉       | 318/1071 [00:06<00:16, 46.49it/s][A
 30%|███       | 323/1071 [00:06<00:16, 46.47it/s][A
 31%|███       | 328/1071 [00:07<00:16, 46.42it/s][A
 31%|███       | 333/1071 [00:07<00:15, 46.43it/s][A
 32%|███▏      | 338/1071 [00:07<00:15, 46.50it/s][A
 32%|███▏      | 343/1071 [00:07<00:15, 46.50it/s][A
 32%|███▏      | 348/1071 [00:07<00:15, 46.51it/s][A
 33%|███▎      | 353/1071 [00:07<00:15, 46.52it/s][A
 33%|███▎      | 358/1071 [00:07<00:15, 46.49it/s][A
 34%|███▍      | 363/1071 [00:07<00:15, 46.51it/s][A
 34%|███▍      | 368/1071 [00:07<00:15, 46.51it/s][A
 35%|███▍      | 373/1071 [00:08<00:15, 46.49it/s][A
 35%|███▌      | 378/1071 [00:08<00:14, 46.51it/s][A
 36%|███▌      | 383/1071 [00:08<00:14, 46.50it/s][A
 36%|███▌      | 388/1071 [00:08<00:14, 46.52it/s][A
 37%|███▋      | 393/1071 [00:08<00:14, 46.52it/s][A
 37%|███▋      | 398/1071 [00:08<00:14, 46.51it/s][A
 38%|███▊      | 403/1071 [00:08<00:14, 46.53it/s][A
 38%|███▊      | 408/1071 [00:08<00:14, 46.52it/s][A
 39%|███▊      | 413/1071 [00:08<00:14, 46.52it/s][A
 39%|███▉      | 418/1071 [00:08<00:14, 46.54it/s][A
 39%|███▉      | 423/1071 [00:09<00:13, 46.55it/s][A
 40%|███▉      | 428/1071 [00:09<00:13, 46.50it/s][A
 40%|████      | 433/1071 [00:09<00:13, 46.53it/s][A
 41%|████      | 438/1071 [00:09<00:13, 46.54it/s][A
 41%|████▏     | 443/1071 [00:09<00:13, 46.62it/s][A
 42%|████▏     | 448/1071 [00:09<00:13, 46.60it/s][A
 42%|████▏     | 453/1071 [00:09<00:13, 46.57it/s][A
 43%|████▎     | 458/1071 [00:09<00:13, 46.62it/s][A
 43%|████▎     | 463/1071 [00:09<00:13, 46.61it/s][A
 44%|████▎     | 468/1071 [00:10<00:12, 46.57it/s][A
 44%|████▍     | 473/1071 [00:10<00:12, 46.58it/s][A
 45%|████▍     | 478/1071 [00:10<00:12, 46.58it/s][A
 45%|████▌     | 483/1071 [00:10<00:12, 46.53it/s][A
 46%|████▌     | 488/1071 [00:10<00:12, 46.54it/s][A
 46%|████▌     | 493/1071 [00:10<00:12, 46.56it/s][A
 46%|████▋     | 498/1071 [00:10<00:12, 46.64it/s][A
 47%|████▋     | 503/1071 [00:10<00:12, 46.64it/s][A
 47%|████▋     | 508/1071 [00:10<00:12, 46.60it/s][A
 48%|████▊     | 513/1071 [00:11<00:11, 46.63it/s][A
 48%|████▊     | 518/1071 [00:11<00:11, 46.61it/s][A
 49%|████▉     | 523/1071 [00:11<00:11, 46.59it/s][A
 49%|████▉     | 528/1071 [00:11<00:11, 46.51it/s][A
 50%|████▉     | 533/1071 [00:11<00:11, 46.50it/s][A
 50%|█████     | 538/1071 [00:11<00:11, 46.59it/s][A
 51%|█████     | 543/1071 [00:11<00:11, 46.71it/s][A
 51%|█████     | 548/1071 [00:11<00:11, 46.68it/s][A
 52%|█████▏    | 553/1071 [00:11<00:11, 46.74it/s][A
 52%|█████▏    | 558/1071 [00:11<00:10, 46.67it/s][A
 53%|█████▎    | 563/1071 [00:12<00:10, 46.63it/s][A
 53%|█████▎    | 568/1071 [00:12<00:10, 46.71it/s][A
 54%|█████▎    | 573/1071 [00:12<00:10, 46.59it/s][A
 54%|█████▍    | 578/1071 [00:12<00:10, 46.55it/s][A
 54%|█████▍    | 583/1071 [00:12<00:10, 46.53it/s][A
 55%|█████▍    | 588/1071 [00:12<00:10, 46.58it/s][A
 55%|█████▌    | 593/1071 [00:12<00:10, 46.67it/s][A
 56%|█████▌    | 598/1071 [00:12<00:10, 46.67it/s][A
 56%|█████▋    | 603/1071 [00:12<00:10, 46.66it/s][A
 57%|█████▋    | 608/1071 [00:13<00:09, 46.68it/s][A
 57%|█████▋    | 613/1071 [00:13<00:09, 46.67it/s][A
 58%|█████▊    | 618/1071 [00:13<00:09, 46.54it/s][A
 58%|█████▊    | 623/1071 [00:13<00:09, 46.57it/s][A
 59%|█████▊    | 628/1071 [00:13<00:09, 46.59it/s][A
 59%|█████▉    | 633/1071 [00:13<00:09, 46.63it/s][A
 60%|█████▉    | 638/1071 [00:13<00:09, 46.65it/s][A
 60%|██████    | 643/1071 [00:13<00:09, 46.63it/s][A
 61%|██████    | 648/1071 [00:13<00:09, 46.64it/s][A
 61%|██████    | 653/1071 [00:14<00:08, 46.68it/s][A
 61%|██████▏   | 658/1071 [00:14<00:08, 46.61it/s][A
 62%|██████▏   | 663/1071 [00:14<00:08, 46.57it/s][A
 62%|██████▏   | 668/1071 [00:14<00:08, 46.52it/s][A
 63%|██████▎   | 673/1071 [00:14<00:08, 46.54it/s][A
 63%|██████▎   | 678/1071 [00:14<00:08, 46.57it/s][A
 64%|██████▍   | 683/1071 [00:14<00:08, 46.63it/s][A
 64%|██████▍   | 688/1071 [00:14<00:08, 46.60it/s][A
 65%|██████▍   | 693/1071 [00:14<00:08, 46.55it/s][A
 65%|██████▌   | 698/1071 [00:14<00:08, 46.55it/s][A
 66%|██████▌   | 703/1071 [00:15<00:07, 46.62it/s][A
 66%|██████▌   | 708/1071 [00:15<00:07, 46.61it/s][A
 67%|██████▋   | 713/1071 [00:15<00:07, 46.53it/s][A
 67%|██████▋   | 718/1071 [00:15<00:07, 46.56it/s][A
 68%|██████▊   | 723/1071 [00:15<00:07, 46.56it/s][A
 68%|██████▊   | 728/1071 [00:15<00:07, 46.63it/s][A
 68%|██████▊   | 733/1071 [00:15<00:07, 46.71it/s][A
 69%|██████▉   | 738/1071 [00:15<00:07, 46.70it/s][A
 69%|██████▉   | 743/1071 [00:15<00:07, 46.63it/s][A
 70%|██████▉   | 748/1071 [00:16<00:06, 46.57it/s][A
 70%|███████   | 753/1071 [00:16<00:06, 46.59it/s][A
 71%|███████   | 758/1071 [00:16<00:06, 46.52it/s][A
 71%|███████   | 763/1071 [00:16<00:06, 46.51it/s][A
 72%|███████▏  | 768/1071 [00:16<00:06, 46.55it/s][A
 72%|███████▏  | 773/1071 [00:16<00:06, 46.61it/s][A
 73%|███████▎  | 778/1071 [00:16<00:06, 46.59it/s][A
 73%|███████▎  | 783/1071 [00:16<00:06, 46.64it/s][A
 74%|███████▎  | 788/1071 [00:16<00:06, 46.64it/s][A
 74%|███████▍  | 793/1071 [00:17<00:05, 46.61it/s][A
 75%|███████▍  | 798/1071 [00:17<00:05, 46.61it/s][A
 75%|███████▍  | 803/1071 [00:17<00:05, 46.57it/s][A
 75%|███████▌  | 808/1071 [00:17<00:05, 46.51it/s][A
 76%|███████▌  | 813/1071 [00:17<00:05, 46.58it/s][A
 76%|███████▋  | 818/1071 [00:17<00:05, 46.62it/s][A
 77%|███████▋  | 823/1071 [00:17<00:05, 46.64it/s][A
 77%|███████▋  | 828/1071 [00:17<00:05, 46.68it/s][A
 78%|███████▊  | 833/1071 [00:17<00:05, 46.62it/s][A
 78%|███████▊  | 838/1071 [00:17<00:04, 46.66it/s][A
 79%|███████▊  | 843/1071 [00:18<00:04, 46.64it/s][A
 79%|███████▉  | 848/1071 [00:18<00:04, 46.55it/s][A
 80%|███████▉  | 853/1071 [00:18<00:04, 46.53it/s][A
 80%|████████  | 858/1071 [00:18<00:04, 46.57it/s][A
 81%|████████  | 863/1071 [00:18<00:04, 46.59it/s][A
 81%|████████  | 868/1071 [00:18<00:04, 46.62it/s][A
 82%|████████▏ | 873/1071 [00:18<00:04, 46.65it/s][A
 82%|████████▏ | 878/1071 [00:18<00:04, 46.63it/s][A
 82%|████████▏ | 883/1071 [00:18<00:04, 46.66it/s][A
 83%|████████▎ | 888/1071 [00:19<00:03, 46.62it/s][A
 83%|████████▎ | 893/1071 [00:19<00:03, 46.56it/s][A
 84%|████████▍ | 898/1071 [00:19<00:03, 46.58it/s][A
 84%|████████▍ | 903/1071 [00:19<00:03, 46.59it/s][A
 85%|████████▍ | 908/1071 [00:19<00:03, 46.62it/s][A
 85%|████████▌ | 913/1071 [00:19<00:03, 46.65it/s][A
 86%|████████▌ | 918/1071 [00:19<00:03, 46.63it/s][A
 86%|████████▌ | 923/1071 [00:19<00:03, 46.60it/s][A
 87%|████████▋ | 928/1071 [00:19<00:03, 46.62it/s][A
 87%|████████▋ | 933/1071 [00:20<00:02, 46.66it/s][A
 88%|████████▊ | 938/1071 [00:20<00:02, 46.66it/s][A
 88%|████████▊ | 943/1071 [00:20<00:02, 46.64it/s][A
 89%|████████▊ | 948/1071 [00:20<00:02, 46.65it/s][A
 89%|████████▉ | 953/1071 [00:20<00:02, 46.66it/s][A
 89%|████████▉ | 958/1071 [00:20<00:02, 46.65it/s][A
 90%|████████▉ | 963/1071 [00:20<00:02, 46.64it/s][A
 90%|█████████ | 968/1071 [00:20<00:02, 46.61it/s][A
 91%|█████████ | 973/1071 [00:20<00:02, 46.58it/s][A
 91%|█████████▏| 978/1071 [00:20<00:01, 46.62it/s][A
 92%|█████████▏| 983/1071 [00:21<00:01, 46.64it/s][A
 92%|█████████▏| 988/1071 [00:21<00:01, 46.63it/s][A
 93%|█████████▎| 993/1071 [00:21<00:01, 46.62it/s][A
 93%|█████████▎| 998/1071 [00:21<00:01, 46.67it/s][A
 94%|█████████▎| 1003/1071 [00:21<00:01, 46.65it/s][A
 94%|█████████▍| 1008/1071 [00:21<00:01, 46.66it/s][A
 95%|█████████▍| 1013/1071 [00:21<00:01, 46.61it/s][A
 95%|█████████▌| 1018/1071 [00:21<00:01, 46.59it/s][A
 96%|█████████▌| 1023/1071 [00:21<00:01, 46.61it/s][A
 96%|█████████▌| 1028/1071 [00:22<00:00, 46.63it/s][A
 96%|█████████▋| 1033/1071 [00:22<00:00, 46.72it/s][A
 97%|█████████▋| 1038/1071 [00:22<00:00, 46.67it/s][A
 97%|█████████▋| 1043/1071 [00:22<00:00, 46.61it/s][A
 98%|█████████▊| 1048/1071 [00:22<00:00, 46.64it/s][A
 98%|█████████▊| 1053/1071 [00:22<00:00, 46.65it/s][A
 99%|█████████▉| 1058/1071 [00:22<00:00, 46.66it/s][A
 99%|█████████▉| 1063/1071 [00:22<00:00, 46.58it/s][A
100%|█████████▉| 1068/1071 [00:22<00:00, 46.55it/s][A                                                 
                                                   [A 60%|██████    | 369/615 [02:59<01:07,  3.65it/s]
100%|██████████| 1071/1071 [00:22<00:00, 46.55it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 14:12:08,727 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-369
[INFO|configuration_utils.py:351] 2023-08-29 14:12:08,745 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-369/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:12:14,138 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-369/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:12:14,514 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-369/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:12:14,606 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-369/special_tokens_map.json
 60%|██████    | 370/615 [03:07<38:17,  9.38s/it] 60%|██████    | 371/615 [03:07<27:01,  6.65s/it] 60%|██████    | 372/615 [03:07<19:10,  4.73s/it] 61%|██████    | 373/615 [03:07<13:41,  3.39s/it] 61%|██████    | 374/615 [03:08<09:52,  2.46s/it] 61%|██████    | 375/615 [03:08<07:14,  1.81s/it] 61%|██████    | 376/615 [03:08<05:22,  1.35s/it] 61%|██████▏   | 377/615 [03:09<04:04,  1.03s/it] 61%|██████▏   | 378/615 [03:09<03:09,  1.25it/s] 62%|██████▏   | 379/615 [03:09<02:31,  1.56it/s] 62%|██████▏   | 380/615 [03:09<02:04,  1.89it/s] 62%|██████▏   | 381/615 [03:10<01:45,  2.21it/s] 62%|██████▏   | 382/615 [03:10<01:32,  2.51it/s] 62%|██████▏   | 383/615 [03:10<01:23,  2.78it/s] 62%|██████▏   | 384/615 [03:10<01:16,  3.00it/s] 63%|██████▎   | 385/615 [03:11<01:12,  3.18it/s] 63%|██████▎   | 386/615 [03:11<01:12,  3.17it/s] 63%|██████▎   | 387/615 [03:11<01:08,  3.31it/s] 63%|██████▎   | 388/615 [03:12<01:06,  3.41it/s] 63%|██████▎   | 389/615 [03:12<01:04,  3.49it/s] 63%|██████▎   | 390/615 [03:12<01:03,  3.55it/s] 64%|██████▎   | 391/615 [03:12<01:02,  3.59it/s] 64%|██████▎   | 392/615 [03:13<01:01,  3.62it/s] 64%|██████▍   | 393/615 [03:13<01:01,  3.64it/s] 64%|██████▍   | 394/615 [03:13<01:00,  3.65it/s] 64%|██████▍   | 395/615 [03:13<01:00,  3.66it/s] 64%|██████▍   | 396/615 [03:14<00:59,  3.67it/s] 65%|██████▍   | 397/615 [03:14<01:01,  3.53it/s] 65%|██████▍   | 398/615 [03:14<01:00,  3.57it/s] 65%|██████▍   | 399/615 [03:15<01:02,  3.47it/s] 65%|██████▌   | 400/615 [03:15<01:03,  3.39it/s] 65%|██████▌   | 401/615 [03:15<01:02,  3.44it/s] 65%|██████▌   | 402/615 [03:16<01:00,  3.51it/s] 66%|██████▌   | 403/615 [03:16<00:59,  3.56it/s] 66%|██████▌   | 404/615 [03:16<00:58,  3.60it/s] 66%|██████▌   | 405/615 [03:16<00:57,  3.62it/s] 66%|██████▌   | 406/615 [03:17<00:57,  3.64it/s] 66%|██████▌   | 407/615 [03:17<00:56,  3.66it/s] 66%|██████▋   | 408/615 [03:17<00:58,  3.53it/s] 67%|██████▋   | 409/615 [03:17<00:57,  3.57it/s] 67%|██████▋   | 410/615 [03:18<00:56,  3.61it/s] 67%|██████▋   | 411/615 [03:18<00:56,  3.63it/s] 67%|██████▋   | 412/615 [03:18<00:55,  3.65it/s] 67%|██████▋   | 413/615 [03:19<00:55,  3.66it/s] 67%|██████▋   | 414/615 [03:19<00:54,  3.67it/s] 67%|██████▋   | 415/615 [03:19<00:54,  3.67it/s] 68%|██████▊   | 416/615 [03:19<00:54,  3.68it/s] 68%|██████▊   | 417/615 [03:20<00:53,  3.68it/s] 68%|██████▊   | 418/615 [03:20<00:53,  3.68it/s] 68%|██████▊   | 419/615 [03:20<00:55,  3.52it/s] 68%|██████▊   | 420/615 [03:20<00:54,  3.57it/s] 68%|██████▊   | 421/615 [03:21<00:53,  3.60it/s] 69%|██████▊   | 422/615 [03:21<00:53,  3.62it/s] 69%|██████▉   | 423/615 [03:21<00:52,  3.64it/s] 69%|██████▉   | 424/615 [03:22<00:52,  3.65it/s] 69%|██████▉   | 425/615 [03:22<00:51,  3.66it/s] 69%|██████▉   | 426/615 [03:22<00:51,  3.67it/s] 69%|██████▉   | 427/615 [03:22<00:51,  3.68it/s] 70%|██████▉   | 428/615 [03:23<00:50,  3.68it/s] 70%|██████▉   | 429/615 [03:23<00:50,  3.68it/s] 70%|██████▉   | 430/615 [03:23<00:52,  3.56it/s] 70%|███████   | 431/615 [03:23<00:51,  3.60it/s] 70%|███████   | 432/615 [03:24<00:50,  3.62it/s] 70%|███████   | 433/615 [03:24<00:49,  3.64it/s] 71%|███████   | 434/615 [03:24<00:49,  3.65it/s] 71%|███████   | 435/615 [03:25<00:49,  3.66it/s] 71%|███████   | 436/615 [03:25<00:48,  3.67it/s] 71%|███████   | 437/615 [03:25<00:48,  3.67it/s] 71%|███████   | 438/615 [03:25<00:48,  3.68it/s] 71%|███████▏  | 439/615 [03:26<00:47,  3.68it/s] 72%|███████▏  | 440/615 [03:26<00:47,  3.68it/s] 72%|███████▏  | 441/615 [03:26<00:49,  3.51it/s] 72%|███████▏  | 442/615 [03:27<00:48,  3.56it/s] 72%|███████▏  | 443/615 [03:27<00:47,  3.60it/s] 72%|███████▏  | 444/615 [03:27<00:47,  3.62it/s] 72%|███████▏  | 445/615 [03:27<00:46,  3.64it/s] 73%|███████▎  | 446/615 [03:28<00:46,  3.65it/s] 73%|███████▎  | 447/615 [03:28<00:45,  3.66it/s] 73%|███████▎  | 448/615 [03:28<00:45,  3.67it/s] 73%|███████▎  | 449/615 [03:28<00:45,  3.67it/s] 73%|███████▎  | 450/615 [03:29<00:44,  3.68it/s] 73%|███████▎  | 451/615 [03:29<00:44,  3.68it/s] 73%|███████▎  | 452/615 [03:29<00:46,  3.51it/s] 74%|███████▎  | 453/615 [03:30<00:45,  3.56it/s] 74%|███████▍  | 454/615 [03:30<00:44,  3.60it/s] 74%|███████▍  | 455/615 [03:30<00:44,  3.62it/s] 74%|███████▍  | 456/615 [03:30<00:43,  3.64it/s] 74%|███████▍  | 457/615 [03:31<00:43,  3.65it/s] 74%|███████▍  | 458/615 [03:31<00:42,  3.66it/s] 75%|███████▍  | 459/615 [03:31<00:42,  3.67it/s] 75%|███████▍  | 460/615 [03:31<00:42,  3.67it/s] 75%|███████▍  | 461/615 [03:32<00:41,  3.68it/s] 75%|███████▌  | 462/615 [03:32<00:41,  3.68it/s] 75%|███████▌  | 463/615 [03:32<00:42,  3.54it/s] 75%|███████▌  | 464/615 [03:33<00:42,  3.58it/s] 76%|███████▌  | 465/615 [03:33<00:41,  3.61it/s] 76%|███████▌  | 466/615 [03:33<00:40,  3.63it/s] 76%|███████▌  | 467/615 [03:33<00:40,  3.65it/s] 76%|███████▌  | 468/615 [03:37<03:19,  1.35s/it] 76%|███████▋  | 469/615 [03:38<02:30,  1.03s/it] 76%|███████▋  | 470/615 [03:38<01:56,  1.25it/s] 77%|███████▋  | 471/615 [03:38<01:32,  1.55it/s] 77%|███████▋  | 472/615 [03:38<01:16,  1.88it/s] 77%|███████▋  | 473/615 [03:39<01:04,  2.20it/s] 77%|███████▋  | 474/615 [03:39<00:56,  2.50it/s] 77%|███████▋  | 475/615 [03:39<00:50,  2.76it/s] 77%|███████▋  | 476/615 [03:39<00:46,  2.98it/s] 78%|███████▊  | 477/615 [03:40<00:43,  3.16it/s] 78%|███████▊  | 478/615 [03:40<00:41,  3.29it/s] 78%|███████▊  | 479/615 [03:40<00:40,  3.40it/s] 78%|███████▊  | 480/615 [03:41<00:38,  3.47it/s] 78%|███████▊  | 481/615 [03:41<00:37,  3.53it/s] 78%|███████▊  | 482/615 [03:41<00:37,  3.57it/s] 79%|███████▊  | 483/615 [03:41<00:36,  3.59it/s] 79%|███████▊  | 484/615 [03:42<00:36,  3.61it/s] 79%|███████▉  | 485/615 [03:42<00:35,  3.63it/s] 79%|███████▉  | 486/615 [03:42<00:35,  3.64it/s] 79%|███████▉  | 487/615 [03:42<00:35,  3.65it/s] 79%|███████▉  | 488/615 [03:43<00:34,  3.65it/s] 80%|███████▉  | 489/615 [03:43<00:34,  3.65it/s] 80%|███████▉  | 490/615 [03:43<00:34,  3.65it/s] 80%|███████▉  | 491/615 [03:44<00:34,  3.64it/s] 80%|████████  | 492/615 [03:44<00:33,  3.64it/s][INFO|trainer.py:2140] 2023-08-29 14:12:53,519 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:12:53,519 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 14:12:53,519 >>   Batch size = 8
{'eval_loss': 0.9968060255050659, 'eval_runtime': 23.0076, 'eval_samples_per_second': 372.399, 'eval_steps_per_second': 46.55, 'epoch': 3.0}

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 57.81it/s][A
  1%|          | 12/1071 [00:00<00:20, 50.81it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 48.94it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.27it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 47.82it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 47.54it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 47.28it/s][A
  4%|▍         | 43/1071 [00:00<00:21, 46.91it/s][A
  4%|▍         | 48/1071 [00:01<00:21, 46.87it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 46.91it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 46.88it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 46.85it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 46.90it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 46.92it/s][A
  7%|▋         | 78/1071 [00:01<00:21, 46.90it/s][A
  8%|▊         | 83/1071 [00:01<00:21, 46.88it/s][A
  8%|▊         | 88/1071 [00:01<00:21, 46.75it/s][A
  9%|▊         | 93/1071 [00:01<00:20, 46.73it/s][A
  9%|▉         | 98/1071 [00:02<00:20, 46.78it/s][A
 10%|▉         | 103/1071 [00:02<00:20, 46.82it/s][A
 10%|█         | 108/1071 [00:02<00:20, 46.81it/s][A
 11%|█         | 113/1071 [00:02<00:20, 46.87it/s][A
 11%|█         | 118/1071 [00:02<00:20, 46.89it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 46.87it/s][A
 12%|█▏        | 128/1071 [00:02<00:20, 46.83it/s][A
 12%|█▏        | 133/1071 [00:02<00:20, 46.78it/s][A
 13%|█▎        | 138/1071 [00:02<00:19, 46.74it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 46.77it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 46.74it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 46.79it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 46.84it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 46.84it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 46.83it/s][A
 16%|█▌        | 173/1071 [00:03<00:19, 46.81it/s][A
 17%|█▋        | 178/1071 [00:03<00:19, 46.72it/s][A
 17%|█▋        | 183/1071 [00:03<00:18, 46.74it/s][A
 18%|█▊        | 188/1071 [00:03<00:18, 46.81it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 46.76it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 46.82it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 46.86it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 46.79it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 46.80it/s][A
 20%|██        | 218/1071 [00:04<00:18, 46.85it/s][A
 21%|██        | 223/1071 [00:04<00:18, 46.76it/s][A
 21%|██▏       | 228/1071 [00:04<00:18, 46.76it/s][A
 22%|██▏       | 233/1071 [00:04<00:17, 46.74it/s][A
 22%|██▏       | 238/1071 [00:05<00:17, 46.70it/s][A
 23%|██▎       | 243/1071 [00:05<00:47, 17.58it/s][A
 23%|██▎       | 248/1071 [00:05<00:38, 21.64it/s][A
 24%|██▎       | 253/1071 [00:09<00:31, 25.82it/s][A
 24%|██▍       | 258/1071 [00:26<03:15,  4.16it/s][A
 24%|██▍       | 258/1071 [00:26<03:15,  4.16it/s][A
 24%|██▍       | 259/1071 [00:27<21:43,  1.60s/it][A
 25%|██▍       | 264/1071 [00:27<13:54,  1.03s/it][A
 25%|██▌       | 269/1071 [00:27<09:12,  1.45it/s][A
 26%|██▌       | 274/1071 [00:27<06:15,  2.12it/s][A
 26%|██▌       | 279/1071 [00:27<04:19,  3.05it/s][A
 27%|██▋       | 284/1071 [00:27<03:02,  4.31it/s][A
 27%|██▋       | 289/1071 [00:27<02:10,  6.00it/s][A
 27%|██▋       | 294/1071 [00:27<01:34,  8.19it/s][A
 28%|██▊       | 299/1071 [00:27<01:10, 10.95it/s][A
 28%|██▊       | 304/1071 [00:27<00:53, 14.25it/s][A
 29%|██▉       | 309/1071 [00:28<00:42, 18.05it/s][A
 29%|██▉       | 314/1071 [00:28<00:34, 22.17it/s][A
 30%|██▉       | 319/1071 [00:28<00:28, 26.39it/s][A
 30%|███       | 324/1071 [00:28<00:24, 30.44it/s][A
 31%|███       | 329/1071 [00:28<00:21, 34.11it/s][A
 31%|███       | 334/1071 [00:28<00:19, 37.27it/s][A
 32%|███▏      | 339/1071 [00:28<00:18, 39.85it/s][A
 32%|███▏      | 344/1071 [00:28<00:17, 41.91it/s][A
 33%|███▎      | 349/1071 [00:28<00:16, 43.34it/s][A
 33%|███▎      | 354/1071 [00:29<00:16, 44.33it/s][A
 34%|███▎      | 359/1071 [00:29<00:15, 45.12it/s][A
 34%|███▍      | 364/1071 [00:29<00:15, 45.66it/s][A
 34%|███▍      | 369/1071 [00:29<00:15, 46.16it/s][A
 35%|███▍      | 374/1071 [00:29<00:14, 46.52it/s][A
 35%|███▌      | 379/1071 [00:29<00:14, 46.77it/s][A
 36%|███▌      | 384/1071 [00:29<00:14, 46.99it/s][A
 36%|███▋      | 389/1071 [00:29<00:14, 47.13it/s][A
 37%|███▋      | 394/1071 [00:29<00:14, 47.19it/s][A
 37%|███▋      | 399/1071 [00:30<00:14, 47.17it/s][A
 38%|███▊      | 404/1071 [00:30<00:14, 47.07it/s][A
 38%|███▊      | 409/1071 [00:30<00:14, 47.09it/s][A
 39%|███▊      | 414/1071 [00:30<00:13, 47.09it/s][A
 39%|███▉      | 419/1071 [00:30<00:13, 47.09it/s][A
 40%|███▉      | 424/1071 [00:30<00:13, 47.20it/s][A
 40%|████      | 429/1071 [00:30<00:13, 47.33it/s][A
 41%|████      | 434/1071 [00:30<00:17, 37.26it/s][A
 41%|████      | 440/1071 [00:30<00:15, 40.69it/s][A
 42%|████▏     | 445/1071 [00:31<00:15, 39.93it/s][A
 42%|████▏     | 450/1071 [00:31<00:14, 41.79it/s][A
 42%|████▏     | 455/1071 [00:31<00:14, 43.36it/s][A
 43%|████▎     | 460/1071 [00:31<00:13, 44.55it/s][A
 43%|████▎     | 465/1071 [00:31<00:13, 45.33it/s][A
 44%|████▍     | 470/1071 [00:31<00:13, 45.92it/s][A
 44%|████▍     | 475/1071 [00:31<00:12, 46.26it/s][A
 45%|████▍     | 480/1071 [00:31<00:12, 46.52it/s][A
 45%|████▌     | 485/1071 [00:31<00:12, 46.56it/s][A
 46%|████▌     | 490/1071 [00:32<00:12, 46.56it/s][A
 46%|████▌     | 495/1071 [00:32<00:12, 46.74it/s][A
 47%|████▋     | 500/1071 [00:32<00:12, 46.93it/s][A
 47%|████▋     | 505/1071 [00:32<00:12, 47.05it/s][A
 48%|████▊     | 510/1071 [00:32<00:11, 47.13it/s][A
 48%|████▊     | 515/1071 [00:32<00:11, 47.25it/s][A
 49%|████▊     | 520/1071 [00:32<00:11, 47.29it/s][A
 49%|████▉     | 525/1071 [00:32<00:11, 47.30it/s][A
 49%|████▉     | 530/1071 [00:32<00:11, 47.11it/s][A
 50%|████▉     | 535/1071 [00:32<00:11, 47.04it/s][A
 50%|█████     | 540/1071 [00:33<00:11, 46.98it/s][A
 51%|█████     | 545/1071 [00:33<00:11, 47.04it/s][A
 51%|█████▏    | 550/1071 [00:33<00:11, 47.14it/s][A
 52%|█████▏    | 555/1071 [00:33<00:10, 47.21it/s][A
 52%|█████▏    | 560/1071 [00:33<00:10, 47.24it/s][A
 53%|█████▎    | 565/1071 [00:33<00:10, 47.26it/s][A
 53%|█████▎    | 570/1071 [00:33<00:10, 47.29it/s][A
 54%|█████▎    | 575/1071 [00:33<00:10, 47.14it/s][A
 54%|█████▍    | 580/1071 [00:33<00:10, 47.03it/s][A
 55%|█████▍    | 585/1071 [00:34<00:10, 47.02it/s][A
 55%|█████▌    | 590/1071 [00:34<00:10, 47.03it/s][A
 56%|█████▌    | 595/1071 [00:34<00:10, 47.07it/s][A
 56%|█████▌    | 600/1071 [00:34<00:09, 47.16it/s][A
 56%|█████▋    | 605/1071 [00:34<00:09, 47.22it/s][A
 57%|█████▋    | 610/1071 [00:34<00:09, 47.17it/s][A
 57%|█████▋    | 615/1071 [00:34<00:09, 47.22it/s][A
 58%|█████▊    | 620/1071 [00:34<00:09, 47.17it/s][A
 58%|█████▊    | 625/1071 [00:34<00:09, 47.04it/s][A
 59%|█████▉    | 630/1071 [00:35<00:09, 47.04it/s][A
 59%|█████▉    | 635/1071 [00:35<00:09, 46.97it/s][A
 60%|█████▉    | 640/1071 [00:35<00:09, 46.98it/s][A
 60%|██████    | 645/1071 [00:35<00:09, 47.06it/s][A
 61%|██████    | 650/1071 [00:35<00:08, 47.13it/s][A
 61%|██████    | 655/1071 [00:35<00:08, 47.18it/s][A
 62%|██████▏   | 660/1071 [00:35<00:08, 47.19it/s][A
 62%|██████▏   | 665/1071 [00:35<00:08, 47.24it/s][A
 63%|██████▎   | 670/1071 [00:35<00:08, 47.19it/s][A
 63%|██████▎   | 675/1071 [00:35<00:08, 47.09it/s][A
 63%|██████▎   | 680/1071 [00:36<00:08, 47.09it/s][A
 64%|██████▍   | 685/1071 [00:36<00:08, 47.00it/s][A
 64%|██████▍   | 690/1071 [00:36<00:08, 46.79it/s][A
 65%|██████▍   | 695/1071 [00:36<00:08, 46.95it/s][A
 65%|██████▌   | 700/1071 [00:36<00:07, 46.99it/s][A
 66%|██████▌   | 705/1071 [00:36<00:07, 46.99it/s][A
 66%|██████▋   | 710/1071 [00:36<00:07, 47.08it/s][A
 67%|██████▋   | 715/1071 [00:36<00:07, 47.11it/s][A
 67%|██████▋   | 720/1071 [00:36<00:07, 47.08it/s][A
 68%|██████▊   | 725/1071 [00:37<00:07, 47.04it/s][A
 68%|██████▊   | 730/1071 [00:37<00:07, 46.95it/s][A
 69%|██████▊   | 735/1071 [00:37<00:07, 46.94it/s][A
 69%|██████▉   | 740/1071 [00:37<00:07, 47.04it/s][A
 70%|██████▉   | 745/1071 [00:37<00:06, 47.11it/s][A
 70%|███████   | 750/1071 [00:37<00:06, 47.10it/s][A
 70%|███████   | 755/1071 [00:37<00:06, 47.12it/s][A
 71%|███████   | 760/1071 [00:37<00:06, 47.12it/s][A
 71%|███████▏  | 765/1071 [00:37<00:06, 47.11it/s][A
 72%|███████▏  | 770/1071 [00:37<00:06, 47.02it/s][A
 72%|███████▏  | 775/1071 [00:38<00:06, 47.02it/s][A
 73%|███████▎  | 780/1071 [00:38<00:06, 46.93it/s][A
 73%|███████▎  | 785/1071 [00:38<00:06, 46.91it/s][A
 74%|███████▍  | 790/1071 [00:38<00:05, 47.02it/s][A
 74%|███████▍  | 795/1071 [00:38<00:05, 47.06it/s][A
 75%|███████▍  | 800/1071 [00:38<00:05, 47.04it/s][A
 75%|███████▌  | 805/1071 [00:38<00:05, 47.08it/s][A
 76%|███████▌  | 810/1071 [00:38<00:05, 47.08it/s][A
 76%|███████▌  | 815/1071 [00:38<00:05, 43.58it/s][A
 77%|███████▋  | 820/1071 [00:39<00:05, 44.63it/s][A
 77%|███████▋  | 825/1071 [00:39<00:05, 45.40it/s][A
 77%|███████▋  | 830/1071 [00:39<00:05, 45.96it/s][A
 78%|███████▊  | 835/1071 [00:39<00:05, 46.36it/s][A
 78%|███████▊  | 840/1071 [00:39<00:04, 46.65it/s][A
 79%|███████▉  | 845/1071 [00:39<00:04, 46.79it/s][A
 79%|███████▉  | 850/1071 [00:39<00:04, 46.92it/s][A
 80%|███████▉  | 855/1071 [00:39<00:04, 46.61it/s][A
 80%|████████  | 860/1071 [00:39<00:04, 46.58it/s][A
 81%|████████  | 865/1071 [00:40<00:04, 46.72it/s][A
 81%|████████  | 870/1071 [00:40<00:04, 46.83it/s][A
 82%|████████▏ | 875/1071 [00:40<00:04, 46.92it/s][A
 82%|████████▏ | 880/1071 [00:40<00:04, 47.05it/s][A
 83%|████████▎ | 885/1071 [00:40<00:03, 47.14it/s][A
 83%|████████▎ | 890/1071 [00:40<00:03, 47.13it/s][A
 84%|████████▎ | 895/1071 [00:40<00:03, 47.15it/s][A
 84%|████████▍ | 900/1071 [00:40<00:03, 46.93it/s][A
 85%|████████▍ | 905/1071 [00:40<00:03, 46.74it/s][A
 85%|████████▍ | 910/1071 [00:40<00:03, 46.81it/s][A
 85%|████████▌ | 915/1071 [00:41<00:03, 46.89it/s][A
 86%|████████▌ | 920/1071 [00:41<00:03, 46.96it/s][A
 86%|████████▋ | 925/1071 [00:41<00:03, 47.07it/s][A
 87%|████████▋ | 930/1071 [00:41<00:02, 47.10it/s][A
 87%|████████▋ | 935/1071 [00:41<00:02, 47.09it/s][A
 88%|████████▊ | 940/1071 [00:41<00:02, 47.14it/s][A
 88%|████████▊ | 945/1071 [00:41<00:02, 47.00it/s][A
 89%|████████▊ | 950/1071 [00:41<00:02, 46.83it/s][A
 89%|████████▉ | 955/1071 [00:41<00:02, 43.96it/s][A
 90%|████████▉ | 960/1071 [00:42<00:02, 44.85it/s][A
 90%|█████████ | 965/1071 [00:42<00:02, 45.51it/s][A
 91%|█████████ | 970/1071 [00:42<00:02, 46.00it/s][A
 91%|█████████ | 975/1071 [00:42<00:02, 46.32it/s][A
 92%|█████████▏| 980/1071 [00:42<00:01, 46.54it/s][A
 92%|█████████▏| 985/1071 [00:42<00:01, 46.74it/s][A
 92%|█████████▏| 990/1071 [00:42<00:01, 46.83it/s][A
 93%|█████████▎| 995/1071 [00:42<00:01, 46.59it/s][A
 93%|█████████▎| 1000/1071 [00:42<00:01, 46.62it/s][A
 94%|█████████▍| 1005/1071 [00:43<00:01, 46.66it/s][A
 94%|█████████▍| 1010/1071 [00:43<00:01, 46.78it/s][A
 95%|█████████▍| 1015/1071 [00:43<00:01, 46.91it/s][A
 95%|█████████▌| 1020/1071 [00:43<00:01, 46.94it/s][A
 96%|█████████▌| 1025/1071 [00:43<00:00, 46.98it/s][A
 96%|█████████▌| 1030/1071 [00:43<00:00, 47.04it/s][A
 97%|█████████▋| 1035/1071 [00:43<00:00, 47.04it/s][A
 97%|█████████▋| 1040/1071 [00:43<00:00, 46.88it/s][A
 98%|█████████▊| 1045/1071 [00:43<00:00, 46.83it/s][A
 98%|█████████▊| 1050/1071 [00:44<00:00, 46.82it/s][A
 99%|█████████▊| 1055/1071 [00:44<00:00, 46.81it/s][A
 99%|█████████▉| 1060/1071 [00:44<00:00, 46.93it/s][A
 99%|█████████▉| 1065/1071 [00:44<00:00, 46.97it/s][A
100%|█████████▉| 1070/1071 [00:44<00:00, 46.99it/s][A                                                 
                                                   [A 80%|████████  | 492/615 [04:28<00:33,  3.64it/s]
100%|██████████| 1071/1071 [00:44<00:00, 46.99it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 14:13:38,305 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-492
[INFO|configuration_utils.py:351] 2023-08-29 14:13:38,516 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-492/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:13:42,707 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-492/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:13:42,895 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-492/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:13:42,986 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-492/special_tokens_map.json
 80%|████████  | 493/615 [04:35<31:34, 15.53s/it] 80%|████████  | 494/615 [04:35<22:04, 10.95s/it] 80%|████████  | 495/615 [04:35<15:29,  7.75s/it] 81%|████████  | 496/615 [04:36<10:54,  5.50s/it] 81%|████████  | 497/615 [04:36<07:44,  3.93s/it] 81%|████████  | 498/615 [04:36<05:31,  2.83s/it] 81%|████████  | 499/615 [04:37<04:01,  2.08s/it] 81%|████████▏ | 500/615 [04:37<02:56,  1.54s/it]                                                  81%|████████▏ | 500/615 [04:37<02:56,  1.54s/it] 81%|████████▏ | 501/615 [04:37<02:11,  1.16s/it] 82%|████████▏ | 502/615 [04:37<01:40,  1.12it/s] 82%|████████▏ | 503/615 [04:38<01:18,  1.42it/s] 82%|████████▏ | 504/615 [04:38<01:03,  1.74it/s] 82%|████████▏ | 505/615 [04:38<00:53,  2.07it/s] 82%|████████▏ | 506/615 [04:38<00:45,  2.38it/s] 82%|████████▏ | 507/615 [04:39<00:40,  2.67it/s] 83%|████████▎ | 508/615 [04:39<00:36,  2.91it/s] 83%|████████▎ | 509/615 [04:39<00:34,  3.11it/s] 83%|████████▎ | 510/615 [04:40<00:33,  3.16it/s] 83%|████████▎ | 511/615 [04:40<00:31,  3.31it/s] 83%|████████▎ | 512/615 [04:40<00:30,  3.41it/s] 83%|████████▎ | 513/615 [04:40<00:29,  3.48it/s] 84%|████████▎ | 514/615 [04:41<00:28,  3.54it/s] 84%|████████▎ | 515/615 [04:41<00:27,  3.58it/s] 84%|████████▍ | 516/615 [04:41<00:27,  3.61it/s] 84%|████████▍ | 517/615 [04:42<00:26,  3.64it/s] 84%|████████▍ | 518/615 [04:42<00:26,  3.65it/s] 84%|████████▍ | 519/615 [04:42<00:26,  3.67it/s] 85%|████████▍ | 520/615 [04:42<00:25,  3.68it/s] 85%|████████▍ | 521/615 [04:43<00:25,  3.68it/s] 85%|████████▍ | 522/615 [04:43<00:25,  3.68it/s] 85%|████████▌ | 523/615 [04:43<00:25,  3.68it/s] 85%|████████▌ | 524/615 [04:43<00:24,  3.67it/s] 85%|████████▌ | 525/615 [04:44<00:24,  3.67it/s] 86%|████████▌ | 526/615 [04:44<00:24,  3.68it/s] 86%|████████▌ | 527/615 [04:44<00:23,  3.68it/s] 86%|████████▌ | 528/615 [04:45<00:23,  3.67it/s] 86%|████████▌ | 529/615 [04:45<00:23,  3.67it/s] 86%|████████▌ | 530/615 [04:45<00:23,  3.67it/s] 86%|████████▋ | 531/615 [04:45<00:22,  3.68it/s] 87%|████████▋ | 532/615 [04:46<00:22,  3.67it/s] 87%|████████▋ | 533/615 [04:46<00:22,  3.68it/s] 87%|████████▋ | 534/615 [04:46<00:22,  3.68it/s] 87%|████████▋ | 535/615 [04:46<00:21,  3.68it/s] 87%|████████▋ | 536/615 [04:47<00:21,  3.68it/s] 87%|████████▋ | 537/615 [04:47<00:21,  3.65it/s] 87%|████████▋ | 538/615 [04:47<00:21,  3.66it/s] 88%|████████▊ | 539/615 [04:48<00:20,  3.67it/s] 88%|████████▊ | 540/615 [04:48<00:20,  3.65it/s] 88%|████████▊ | 541/615 [04:48<00:20,  3.66it/s] 88%|████████▊ | 542/615 [04:48<00:19,  3.67it/s] 88%|████████▊ | 543/615 [04:49<00:19,  3.67it/s] 88%|████████▊ | 544/615 [04:49<00:19,  3.67it/s] 89%|████████▊ | 545/615 [04:49<00:19,  3.67it/s] 89%|████████▉ | 546/615 [04:49<00:18,  3.67it/s] 89%|████████▉ | 547/615 [04:50<00:18,  3.67it/s] 89%|████████▉ | 548/615 [04:50<00:18,  3.67it/s] 89%|████████▉ | 549/615 [04:50<00:17,  3.67it/s] 89%|████████▉ | 550/615 [04:50<00:17,  3.68it/s] 90%|████████▉ | 551/615 [04:51<00:17,  3.68it/s] 90%|████████▉ | 552/615 [04:51<00:17,  3.66it/s] 90%|████████▉ | 553/615 [04:51<00:16,  3.67it/s] 90%|█████████ | 554/615 [04:52<00:16,  3.67it/s] 90%|█████████ | 555/615 [04:52<00:16,  3.67it/s] 90%|█████████ | 556/615 [04:52<00:16,  3.67it/s] 91%|█████████ | 557/615 [04:52<00:15,  3.67it/s] 91%|█████████ | 558/615 [04:53<00:15,  3.67it/s] 91%|█████████ | 559/615 [04:53<00:15,  3.67it/s] 91%|█████████ | 560/615 [04:53<00:15,  3.66it/s] 91%|█████████ | 561/615 [04:53<00:14,  3.67it/s] 91%|█████████▏| 562/615 [04:54<00:14,  3.66it/s] 92%|█████████▏| 563/615 [04:54<00:14,  3.64it/s] 92%|█████████▏| 564/615 [04:54<00:14,  3.64it/s] 92%|█████████▏| 565/615 [04:55<00:13,  3.65it/s] 92%|█████████▏| 566/615 [04:55<00:13,  3.66it/s] 92%|█████████▏| 567/615 [04:55<00:13,  3.67it/s] 92%|█████████▏| 568/615 [04:55<00:12,  3.67it/s] 93%|█████████▎| 569/615 [04:56<00:12,  3.67it/s] 93%|█████████▎| 570/615 [04:56<00:12,  3.67it/s] 93%|█████████▎| 571/615 [04:56<00:11,  3.67it/s] 93%|█████████▎| 572/615 [04:57<00:11,  3.66it/s] 93%|█████████▎| 573/615 [04:57<00:11,  3.66it/s] 93%|█████████▎| 574/615 [04:57<00:11,  3.65it/s] 93%|█████████▎| 575/615 [04:57<00:10,  3.65it/s] 94%|█████████▎| 576/615 [04:58<00:10,  3.65it/s] 94%|█████████▍| 577/615 [04:58<00:10,  3.65it/s] 94%|█████████▍| 578/615 [04:58<00:10,  3.65it/s] 94%|█████████▍| 579/615 [04:58<00:09,  3.65it/s] 94%|█████████▍| 580/615 [04:59<00:09,  3.65it/s] 94%|█████████▍| 581/615 [04:59<00:09,  3.66it/s] 95%|█████████▍| 582/615 [04:59<00:09,  3.66it/s] 95%|█████████▍| 583/615 [05:00<00:08,  3.67it/s] 95%|█████████▍| 584/615 [05:00<00:08,  3.67it/s] 95%|█████████▌| 585/615 [05:00<00:08,  3.53it/s] 95%|█████████▌| 586/615 [05:00<00:08,  3.57it/s] 95%|█████████▌| 587/615 [05:01<00:07,  3.60it/s] 96%|█████████▌| 588/615 [05:01<00:07,  3.62it/s] 96%|█████████▌| 589/615 [05:01<00:07,  3.63it/s] 96%|█████████▌| 590/615 [05:01<00:06,  3.64it/s] 96%|█████████▌| 591/615 [05:02<00:06,  3.65it/s] 96%|█████████▋| 592/615 [05:02<00:06,  3.66it/s] 96%|█████████▋| 593/615 [05:02<00:06,  3.67it/s] 97%|█████████▋| 594/615 [05:03<00:05,  3.67it/s] 97%|█████████▋| 595/615 [05:03<00:05,  3.67it/s] 97%|█████████▋| 596/615 [05:03<00:05,  3.65it/s] 97%|█████████▋| 597/615 [05:03<00:04,  3.66it/s] 97%|█████████▋| 598/615 [05:04<00:04,  3.66it/s] 97%|█████████▋| 599/615 [05:04<00:04,  3.67it/s] 98%|█████████▊| 600/615 [05:04<00:04,  3.67it/s] 98%|█████████▊| 601/615 [05:04<00:03,  3.67it/s] 98%|█████████▊| 602/615 [05:05<00:03,  3.67it/s] 98%|█████████▊| 603/615 [05:05<00:03,  3.67it/s] 98%|█████████▊| 604/615 [05:05<00:02,  3.67it/s] 98%|█████████▊| 605/615 [05:06<00:02,  3.67it/s] 99%|█████████▊| 606/615 [05:06<00:02,  3.67it/s] 99%|█████████▊| 607/615 [05:06<00:02,  3.65it/s] 99%|█████████▉| 608/615 [05:06<00:01,  3.66it/s] 99%|█████████▉| 609/615 [05:07<00:01,  3.67it/s] 99%|█████████▉| 610/615 [05:07<00:01,  3.67it/s] 99%|█████████▉| 611/615 [05:07<00:01,  3.67it/s]100%|█████████▉| 612/615 [05:07<00:00,  3.67it/s]100%|█████████▉| 613/615 [05:08<00:00,  3.67it/s]100%|█████████▉| 614/615 [05:08<00:00,  3.67it/s]100%|██████████| 615/615 [05:08<00:00,  3.68it/s][INFO|trainer.py:2140] 2023-08-29 14:14:17,849 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:14:17,849 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 14:14:17,849 >>   Batch size = 8
{'eval_loss': 0.9968060255050659, 'eval_runtime': 44.4727, 'eval_samples_per_second': 192.658, 'eval_steps_per_second': 24.082, 'epoch': 4.0}
{'loss': nan, 'learning_rate': 1.7134146341463415e-05, 'epoch': 4.06}

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 57.09it/s][A
  1%|          | 12/1071 [00:00<00:20, 50.74it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 48.95it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.31it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 47.85it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 47.61it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 47.23it/s][A
  4%|▍         | 43/1071 [00:00<00:21, 46.90it/s][A
  4%|▍         | 48/1071 [00:01<00:21, 46.77it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 46.79it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 46.87it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 46.93it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 46.91it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 46.95it/s][A
  7%|▋         | 78/1071 [00:01<00:21, 46.95it/s][A
  8%|▊         | 83/1071 [00:01<00:21, 46.87it/s][A
  8%|▊         | 88/1071 [00:01<00:21, 46.74it/s][A
  9%|▊         | 93/1071 [00:01<00:20, 46.65it/s][A
  9%|▉         | 98/1071 [00:02<00:20, 46.72it/s][A
 10%|▉         | 103/1071 [00:02<00:20, 46.81it/s][A
 10%|█         | 108/1071 [00:02<00:20, 46.79it/s][A
 11%|█         | 113/1071 [00:02<00:20, 46.75it/s][A
 11%|█         | 118/1071 [00:02<00:20, 46.83it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 46.10it/s][A
 12%|█▏        | 128/1071 [00:02<00:20, 47.08it/s][A
 12%|█▏        | 133/1071 [00:02<00:20, 46.88it/s][A
 13%|█▎        | 138/1071 [00:02<00:19, 46.72it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 46.78it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 46.74it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 46.78it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 46.86it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 46.92it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 46.86it/s][A
 16%|█▌        | 173/1071 [00:03<00:19, 46.86it/s][A
 17%|█▋        | 178/1071 [00:03<00:19, 46.77it/s][A
 17%|█▋        | 183/1071 [00:03<00:19, 46.65it/s][A
 18%|█▊        | 188/1071 [00:03<00:18, 46.66it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 46.68it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 46.70it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 46.79it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 46.86it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 46.90it/s][A
 20%|██        | 218/1071 [00:04<00:18, 46.86it/s][A
 21%|██        | 223/1071 [00:04<00:18, 46.80it/s][A
 21%|██▏       | 228/1071 [00:04<00:18, 46.70it/s][A
 22%|██▏       | 233/1071 [00:04<00:17, 46.72it/s][A
 22%|██▏       | 238/1071 [00:05<00:17, 46.67it/s][A
 23%|██▎       | 243/1071 [00:05<00:17, 46.66it/s][A
 23%|██▎       | 248/1071 [00:05<00:17, 46.67it/s][A
 24%|██▎       | 253/1071 [00:05<00:17, 46.74it/s][A
 24%|██▍       | 258/1071 [00:05<00:17, 46.80it/s][A
 25%|██▍       | 263/1071 [00:05<00:17, 46.87it/s][A
 25%|██▌       | 268/1071 [00:05<00:17, 46.82it/s][A
 25%|██▌       | 273/1071 [00:05<00:17, 46.79it/s][A
 26%|██▌       | 278/1071 [00:05<00:16, 46.78it/s][A
 26%|██▋       | 283/1071 [00:06<00:16, 46.71it/s][A
 27%|██▋       | 288/1071 [00:06<00:16, 46.73it/s][A
 27%|██▋       | 293/1071 [00:06<00:16, 46.75it/s][A
 28%|██▊       | 298/1071 [00:06<00:16, 46.72it/s][A
 28%|██▊       | 303/1071 [00:06<00:16, 46.80it/s][A
 29%|██▉       | 308/1071 [00:06<00:16, 46.81it/s][A
 29%|██▉       | 313/1071 [00:06<00:16, 45.94it/s][A
 30%|██▉       | 318/1071 [00:06<00:16, 47.04it/s][A
 30%|███       | 323/1071 [00:06<00:15, 46.94it/s][A
 31%|███       | 328/1071 [00:06<00:15, 46.83it/s][A
 31%|███       | 333/1071 [00:07<00:15, 46.78it/s][A
 32%|███▏      | 338/1071 [00:07<00:15, 46.67it/s][A
 32%|███▏      | 343/1071 [00:07<00:15, 46.64it/s][A
 32%|███▏      | 348/1071 [00:07<00:15, 46.66it/s][A
 33%|███▎      | 353/1071 [00:07<00:15, 46.74it/s][A
 33%|███▎      | 358/1071 [00:07<00:15, 46.79it/s][A
 34%|███▍      | 363/1071 [00:07<00:15, 46.75it/s][A
 34%|███▍      | 368/1071 [00:07<00:15, 46.71it/s][A
 35%|███▍      | 373/1071 [00:07<00:14, 46.72it/s][A
 35%|███▌      | 378/1071 [00:08<00:14, 46.73it/s][A
 36%|███▌      | 383/1071 [00:08<00:14, 46.66it/s][A
 36%|███▌      | 388/1071 [00:08<00:14, 46.60it/s][A
 37%|███▋      | 393/1071 [00:08<00:14, 46.58it/s][A
 37%|███▋      | 398/1071 [00:08<00:14, 46.70it/s][A
 38%|███▊      | 403/1071 [00:08<00:14, 46.72it/s][A
 38%|███▊      | 408/1071 [00:08<00:14, 46.70it/s][A
 39%|███▊      | 413/1071 [00:08<00:14, 46.70it/s][A
 39%|███▉      | 418/1071 [00:08<00:13, 46.66it/s][A
 39%|███▉      | 423/1071 [00:09<00:13, 46.69it/s][A
 40%|███▉      | 428/1071 [00:09<00:13, 46.80it/s][A
 40%|████      | 433/1071 [00:09<00:13, 46.74it/s][A
 41%|████      | 438/1071 [00:09<00:13, 46.65it/s][A
 41%|████▏     | 443/1071 [00:09<00:13, 46.75it/s][A
 42%|████▏     | 448/1071 [00:09<00:13, 46.71it/s][A
 42%|████▏     | 453/1071 [00:09<00:13, 46.72it/s][A
 43%|████▎     | 458/1071 [00:09<00:13, 46.67it/s][A
 43%|████▎     | 463/1071 [00:09<00:13, 46.71it/s][A
 44%|████▎     | 468/1071 [00:09<00:12, 46.71it/s][A
 44%|████▍     | 473/1071 [00:10<00:12, 46.69it/s][A
 45%|████▍     | 478/1071 [00:10<00:12, 46.71it/s][A
 45%|████▌     | 483/1071 [00:10<00:12, 46.68it/s][A
 46%|████▌     | 488/1071 [00:10<00:12, 46.67it/s][A
 46%|████▌     | 493/1071 [00:10<00:12, 46.67it/s][A
 46%|████▋     | 498/1071 [00:10<00:12, 46.68it/s][A
 47%|████▋     | 503/1071 [00:10<00:12, 46.64it/s][A
 47%|████▋     | 508/1071 [00:10<00:12, 46.61it/s][A
 48%|████▊     | 513/1071 [00:10<00:11, 46.61it/s][A
 48%|████▊     | 518/1071 [00:11<00:11, 46.65it/s][A
 49%|████▉     | 523/1071 [00:11<00:11, 46.63it/s][A
 49%|████▉     | 528/1071 [00:11<00:11, 46.64it/s][A
 50%|████▉     | 533/1071 [00:11<00:11, 46.66it/s][A
 50%|█████     | 538/1071 [00:11<00:11, 46.74it/s][A
 51%|█████     | 543/1071 [00:11<00:11, 46.76it/s][A
 51%|█████     | 548/1071 [00:11<00:11, 46.74it/s][A
 52%|█████▏    | 553/1071 [00:11<00:11, 46.67it/s][A
 52%|█████▏    | 558/1071 [00:11<00:10, 46.69it/s][A
 53%|█████▎    | 563/1071 [00:12<00:10, 46.68it/s][A
 53%|█████▎    | 568/1071 [00:12<00:10, 46.60it/s][A
 54%|█████▎    | 573/1071 [00:12<00:10, 46.50it/s][A
 54%|█████▍    | 578/1071 [00:12<00:10, 46.58it/s][A
 54%|█████▍    | 583/1071 [00:12<00:10, 46.63it/s][A
 55%|█████▍    | 588/1071 [00:12<00:10, 46.70it/s][A
 55%|█████▌    | 593/1071 [00:12<00:10, 46.68it/s][A
 56%|█████▌    | 598/1071 [00:12<00:10, 46.68it/s][A
 56%|█████▋    | 603/1071 [00:12<00:10, 46.60it/s][A
 57%|█████▋    | 608/1071 [00:12<00:09, 46.65it/s][A
 57%|█████▋    | 613/1071 [00:13<00:09, 46.67it/s][A
 58%|█████▊    | 618/1071 [00:13<00:09, 46.61it/s][A
 58%|█████▊    | 623/1071 [00:13<00:09, 46.67it/s][A
 59%|█████▊    | 628/1071 [00:13<00:09, 46.67it/s][A
 59%|█████▉    | 633/1071 [00:13<00:09, 46.68it/s][A
 60%|█████▉    | 638/1071 [00:13<00:09, 46.77it/s][A
 60%|██████    | 643/1071 [00:13<00:09, 46.72it/s][A
 61%|██████    | 648/1071 [00:13<00:09, 46.70it/s][A
 61%|██████    | 653/1071 [00:13<00:08, 46.69it/s][A
 61%|██████▏   | 658/1071 [00:14<00:08, 46.60it/s][A
 62%|██████▏   | 663/1071 [00:14<00:08, 46.63it/s][A
 62%|██████▏   | 668/1071 [00:14<00:08, 46.65it/s][A
 63%|██████▎   | 673/1071 [00:14<00:08, 46.64it/s][A
 63%|██████▎   | 678/1071 [00:14<00:08, 46.65it/s][A
 64%|██████▍   | 683/1071 [00:14<00:08, 46.68it/s][A
 64%|██████▍   | 688/1071 [00:14<00:08, 46.65it/s][A
 65%|██████▍   | 693/1071 [00:14<00:08, 46.70it/s][A
 65%|██████▌   | 698/1071 [00:14<00:08, 46.59it/s][A
 66%|██████▌   | 703/1071 [00:15<00:07, 46.61it/s][A
 66%|██████▌   | 708/1071 [00:15<00:07, 46.61it/s][A
 67%|██████▋   | 713/1071 [00:15<00:07, 46.66it/s][A
 67%|██████▋   | 718/1071 [00:15<00:07, 46.63it/s][A
 68%|██████▊   | 723/1071 [00:15<00:07, 46.58it/s][A
 68%|██████▊   | 728/1071 [00:15<00:07, 46.55it/s][A
 68%|██████▊   | 733/1071 [00:15<00:07, 46.66it/s][A
 69%|██████▉   | 738/1071 [00:15<00:07, 46.69it/s][A
 69%|██████▉   | 743/1071 [00:15<00:07, 46.63it/s][A
 70%|██████▉   | 748/1071 [00:15<00:06, 46.55it/s][A
 70%|███████   | 753/1071 [00:16<00:06, 46.59it/s][A
 71%|███████   | 758/1071 [00:16<00:06, 46.60it/s][A
 71%|███████   | 763/1071 [00:16<00:06, 46.62it/s][A
 72%|███████▏  | 768/1071 [00:16<00:06, 46.62it/s][A
 72%|███████▏  | 773/1071 [00:16<00:06, 46.59it/s][A
 73%|███████▎  | 778/1071 [00:16<00:06, 46.62it/s][A
 73%|███████▎  | 783/1071 [00:16<00:06, 46.67it/s][A
 74%|███████▎  | 788/1071 [00:16<00:06, 46.72it/s][A
 74%|███████▍  | 793/1071 [00:16<00:05, 46.71it/s][A
 75%|███████▍  | 798/1071 [00:17<00:05, 46.67it/s][A
 75%|███████▍  | 803/1071 [00:17<00:05, 46.65it/s][A
 75%|███████▌  | 808/1071 [00:17<00:05, 46.67it/s][A
 76%|███████▌  | 813/1071 [00:17<00:05, 46.61it/s][A
 76%|███████▋  | 818/1071 [00:17<00:05, 46.58it/s][A
 77%|███████▋  | 823/1071 [00:17<00:05, 46.56it/s][A
 77%|███████▋  | 828/1071 [00:17<00:05, 46.63it/s][A
 78%|███████▊  | 833/1071 [00:17<00:05, 46.73it/s][A
 78%|███████▊  | 838/1071 [00:17<00:04, 46.73it/s][A
 79%|███████▊  | 843/1071 [00:18<00:04, 46.69it/s][A
 79%|███████▉  | 848/1071 [00:18<00:04, 46.59it/s][A
 80%|███████▉  | 853/1071 [00:18<00:04, 46.60it/s][A
 80%|████████  | 858/1071 [00:18<00:04, 46.64it/s][A
 81%|████████  | 863/1071 [00:18<00:04, 46.61it/s][A
 81%|████████  | 868/1071 [00:18<00:04, 46.57it/s][A
 82%|████████▏ | 873/1071 [00:18<00:04, 46.63it/s][A
 82%|████████▏ | 878/1071 [00:18<00:04, 46.67it/s][A
 82%|████████▏ | 883/1071 [00:18<00:04, 46.67it/s][A
 83%|████████▎ | 888/1071 [00:18<00:03, 46.65it/s][A
 83%|████████▎ | 893/1071 [00:19<00:03, 46.58it/s][A
 84%|████████▍ | 898/1071 [00:19<00:03, 46.60it/s][A
 84%|████████▍ | 903/1071 [00:19<00:03, 46.30it/s][A
 85%|████████▍ | 908/1071 [00:19<00:03, 46.61it/s][A
 85%|████████▌ | 913/1071 [00:19<00:03, 46.60it/s][A
 86%|████████▌ | 918/1071 [00:19<00:03, 46.55it/s][A
 86%|████████▌ | 923/1071 [00:19<00:03, 46.63it/s][A
 87%|████████▋ | 928/1071 [00:19<00:03, 46.69it/s][A
 87%|████████▋ | 933/1071 [00:19<00:02, 46.67it/s][A
 88%|████████▊ | 938/1071 [00:20<00:02, 46.63it/s][A
 88%|████████▊ | 943/1071 [00:20<00:02, 46.62it/s][A
 89%|████████▊ | 948/1071 [00:20<00:02, 46.56it/s][A
 89%|████████▉ | 953/1071 [00:20<00:02, 46.56it/s][A
 89%|████████▉ | 958/1071 [00:20<00:02, 46.57it/s][A
 90%|████████▉ | 963/1071 [00:20<00:02, 46.54it/s][A
 90%|█████████ | 968/1071 [00:20<00:02, 46.62it/s][A
 91%|█████████ | 973/1071 [00:20<00:02, 46.61it/s][A
 91%|█████████▏| 978/1071 [00:20<00:01, 46.64it/s][A
 92%|█████████▏| 983/1071 [00:21<00:01, 46.58it/s][A
 92%|█████████▏| 988/1071 [00:21<00:01, 46.60it/s][A
 93%|█████████▎| 993/1071 [00:21<00:01, 46.58it/s][A
 93%|█████████▎| 998/1071 [00:21<00:01, 46.51it/s][A
 94%|█████████▎| 1003/1071 [00:21<00:01, 46.55it/s][A
 94%|█████████▍| 1008/1071 [00:21<00:01, 46.60it/s][A
 95%|█████████▍| 1013/1071 [00:21<00:01, 46.67it/s][A
 95%|█████████▌| 1018/1071 [00:21<00:01, 46.61it/s][A
 96%|█████████▌| 1023/1071 [00:21<00:01, 45.97it/s][A
 96%|█████████▌| 1028/1071 [00:22<00:00, 46.15it/s][A
 96%|█████████▋| 1033/1071 [00:22<00:00, 46.33it/s][A
 97%|█████████▋| 1038/1071 [00:22<00:00, 46.37it/s][A
 97%|█████████▋| 1043/1071 [00:22<00:00, 46.42it/s][A
 98%|█████████▊| 1048/1071 [00:22<00:00, 46.42it/s][A
 98%|█████████▊| 1053/1071 [00:22<00:00, 46.45it/s][A
 99%|█████████▉| 1058/1071 [00:22<00:00, 46.58it/s][A
 99%|█████████▉| 1063/1071 [00:22<00:00, 46.58it/s][A
100%|█████████▉| 1068/1071 [00:22<00:00, 46.53it/s][A                                                 
                                                   [A100%|██████████| 615/615 [05:31<00:00,  3.68it/s]
100%|██████████| 1071/1071 [00:22<00:00, 46.53it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 14:14:40,825 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-615
[INFO|configuration_utils.py:351] 2023-08-29 14:14:40,852 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-615/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:14:43,253 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-615/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:14:43,268 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-615/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:14:43,278 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-615/special_tokens_map.json
[INFO|trainer.py:1343] 2023-08-29 14:14:43,490 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:1352] 2023-08-29 14:14:43,490 >> Loading best model from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-123 (score: 0.9968060255050659).
                                                 100%|██████████| 615/615 [05:36<00:00,  3.68it/s]100%|██████████| 615/615 [05:36<00:00,  1.83it/s]
[INFO|trainer.py:1894] 2023-08-29 14:14:45,306 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model
[INFO|configuration_utils.py:351] 2023-08-29 14:14:45,320 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/config.json
[INFO|modeling_utils.py:886] 2023-08-29 14:14:47,606 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 14:14:47,643 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 14:14:47,658 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/special_tokens_map.json
[INFO|trainer_pt_utils.py:908] 2023-08-29 14:14:47,822 >> ***** train metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:14:47,823 >>   epoch                    =        5.0
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:14:47,823 >>   train_loss               =        nan
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:14:47,823 >>   train_runtime            = 0:05:36.21
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:14:47,823 >>   train_samples            =       7899
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:14:47,823 >>   train_samples_per_second =    117.471
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:14:47,823 >>   train_steps_per_second   =      1.829
{'eval_loss': 0.9968060255050659, 'eval_runtime': 22.9493, 'eval_samples_per_second': 373.345, 'eval_steps_per_second': 46.668, 'epoch': 5.0}
{'train_runtime': 336.2104, 'train_samples_per_second': 117.471, 'train_steps_per_second': 1.829, 'train_loss': nan, 'epoch': 5.0}
08/29/2023 14:14:47 - INFO - transformer_base.run_clm_rl -   *** Evaluate ***
[INFO|trainer.py:2140] 2023-08-29 14:14:47,885 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 14:14:47,885 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 14:14:47,885 >>   Batch size = 8
  0%|          | 0/1071 [00:00<?, ?it/s]  1%|          | 6/1071 [00:00<00:18, 58.50it/s]  1%|          | 12/1071 [00:00<00:20, 51.26it/s]  2%|▏         | 18/1071 [00:00<00:21, 49.20it/s]  2%|▏         | 23/1071 [00:00<00:21, 48.35it/s]  3%|▎         | 28/1071 [00:00<00:21, 47.81it/s]  3%|▎         | 33/1071 [00:00<00:21, 47.56it/s]  4%|▎         | 38/1071 [00:00<00:21, 47.31it/s]  4%|▍         | 43/1071 [00:00<00:21, 47.20it/s]  4%|▍         | 48/1071 [00:00<00:21, 47.03it/s]  5%|▍         | 53/1071 [00:01<00:21, 47.00it/s]  5%|▌         | 58/1071 [00:01<00:21, 46.95it/s]  6%|▌         | 63/1071 [00:01<00:21, 46.83it/s]  6%|▋         | 68/1071 [00:01<00:21, 46.70it/s]  7%|▋         | 73/1071 [00:01<00:21, 46.56it/s]  7%|▋         | 78/1071 [00:01<00:21, 46.67it/s]  8%|▊         | 83/1071 [00:01<00:21, 46.64it/s]  8%|▊         | 88/1071 [00:01<00:21, 46.61it/s]  9%|▊         | 93/1071 [00:01<00:20, 46.69it/s]  9%|▉         | 98/1071 [00:02<00:20, 46.79it/s] 10%|▉         | 103/1071 [00:02<00:20, 46.78it/s] 10%|█         | 108/1071 [00:02<00:20, 46.74it/s] 11%|█         | 113/1071 [00:02<00:20, 46.79it/s] 11%|█         | 118/1071 [00:02<00:20, 46.31it/s] 11%|█▏        | 123/1071 [00:03<00:51, 18.57it/s] 12%|█▏        | 128/1071 [00:03<00:41, 22.58it/s] 12%|█▏        | 133/1071 [00:03<00:35, 26.75it/s] 13%|█▎        | 138/1071 [00:03<00:30, 30.73it/s] 13%|█▎        | 143/1071 [00:03<00:27, 34.29it/s] 14%|█▍        | 148/1071 [00:03<00:24, 37.33it/s] 14%|█▍        | 153/1071 [00:03<00:23, 39.80it/s] 15%|█▍        | 158/1071 [00:03<00:21, 41.73it/s] 15%|█▌        | 163/1071 [00:03<00:21, 43.18it/s] 16%|█▌        | 168/1071 [00:04<00:20, 43.87it/s] 16%|█▌        | 173/1071 [00:04<00:20, 44.59it/s] 17%|█▋        | 178/1071 [00:04<00:19, 45.28it/s] 17%|█▋        | 183/1071 [00:04<00:19, 45.78it/s] 18%|█▊        | 188/1071 [00:04<00:19, 46.11it/s] 18%|█▊        | 193/1071 [00:04<00:18, 46.38it/s] 18%|█▊        | 198/1071 [00:04<00:18, 46.17it/s] 19%|█▉        | 203/1071 [00:04<00:18, 46.42it/s] 19%|█▉        | 208/1071 [00:04<00:18, 46.47it/s] 20%|█▉        | 213/1071 [00:05<00:18, 46.42it/s] 20%|██        | 218/1071 [00:05<00:18, 46.50it/s] 21%|██        | 223/1071 [00:05<00:18, 46.56it/s] 21%|██▏       | 228/1071 [00:05<00:18, 46.60it/s] 22%|██▏       | 233/1071 [00:05<00:17, 46.71it/s] 22%|██▏       | 238/1071 [00:05<00:17, 46.75it/s] 23%|██▎       | 243/1071 [00:05<00:17, 46.76it/s] 23%|██▎       | 248/1071 [00:05<00:17, 46.82it/s] 24%|██▎       | 253/1071 [00:05<00:17, 46.79it/s] 24%|██▍       | 258/1071 [00:06<00:17, 46.69it/s] 25%|██▍       | 263/1071 [00:06<00:17, 46.69it/s] 25%|██▌       | 268/1071 [00:06<00:17, 46.67it/s] 25%|██▌       | 273/1071 [00:06<00:17, 46.72it/s] 26%|██▌       | 278/1071 [00:06<00:16, 46.71it/s] 26%|██▋       | 283/1071 [00:06<00:16, 46.71it/s] 27%|██▋       | 288/1071 [00:06<00:16, 46.81it/s] 27%|██▋       | 293/1071 [00:06<00:16, 46.83it/s] 28%|██▊       | 298/1071 [00:06<00:16, 46.78it/s] 28%|██▊       | 303/1071 [00:06<00:16, 46.80it/s] 29%|██▉       | 308/1071 [00:07<00:16, 46.70it/s] 29%|██▉       | 313/1071 [00:07<00:16, 46.63it/s] 30%|██▉       | 318/1071 [00:07<00:16, 46.70it/s] 30%|███       | 323/1071 [00:07<00:16, 46.72it/s] 31%|███       | 328/1071 [00:07<00:15, 46.72it/s] 31%|███       | 333/1071 [00:07<00:15, 46.75it/s] 32%|███▏      | 338/1071 [00:07<00:15, 46.76it/s] 32%|███▏      | 343/1071 [00:07<00:15, 46.78it/s] 32%|███▏      | 348/1071 [00:07<00:15, 46.71it/s] 33%|███▎      | 353/1071 [00:08<00:15, 46.59it/s] 33%|███▎      | 358/1071 [00:08<00:15, 46.59it/s] 34%|███▍      | 363/1071 [00:08<00:15, 46.63it/s] 34%|███▍      | 368/1071 [00:08<00:15, 46.65it/s] 35%|███▍      | 373/1071 [00:08<00:14, 46.73it/s] 35%|███▌      | 378/1071 [00:08<00:14, 46.74it/s] 36%|███▌      | 383/1071 [00:08<00:14, 46.73it/s] 36%|███▌      | 388/1071 [00:08<00:14, 46.80it/s] 37%|███▋      | 393/1071 [00:08<00:14, 46.79it/s] 37%|███▋      | 398/1071 [00:09<00:14, 46.73it/s] 38%|███▊      | 403/1071 [00:09<00:14, 46.70it/s] 38%|███▊      | 408/1071 [00:09<00:14, 46.65it/s] 39%|███▊      | 413/1071 [00:09<00:14, 46.69it/s] 39%|███▉      | 418/1071 [00:09<00:13, 46.77it/s] 39%|███▉      | 423/1071 [00:09<00:13, 46.81it/s] 40%|███▉      | 428/1071 [00:09<00:13, 46.76it/s] 40%|████      | 433/1071 [00:09<00:13, 46.82it/s] 41%|████      | 438/1071 [00:09<00:13, 46.79it/s] 41%|████▏     | 443/1071 [00:09<00:13, 46.71it/s] 42%|████▏     | 448/1071 [00:10<00:13, 46.66it/s] 42%|████▏     | 453/1071 [00:10<00:13, 46.60it/s] 43%|████▎     | 458/1071 [00:10<00:13, 46.63it/s] 43%|████▎     | 463/1071 [00:10<00:13, 46.65it/s] 44%|████▎     | 468/1071 [00:10<00:12, 46.67it/s] 44%|████▍     | 473/1071 [00:10<00:12, 46.70it/s] 45%|████▍     | 478/1071 [00:10<00:12, 46.69it/s] 45%|████▌     | 483/1071 [00:10<00:12, 46.72it/s] 46%|████▌     | 488/1071 [00:10<00:12, 46.74it/s] 46%|████▌     | 493/1071 [00:11<00:12, 46.71it/s] 46%|████▋     | 498/1071 [00:11<00:12, 46.66it/s] 47%|████▋     | 503/1071 [00:11<00:12, 46.63it/s] 47%|████▋     | 508/1071 [00:11<00:12, 46.63it/s] 48%|████▊     | 513/1071 [00:11<00:11, 46.70it/s] 48%|████▊     | 518/1071 [00:11<00:11, 46.68it/s] 49%|████▉     | 523/1071 [00:11<00:11, 46.62it/s] 49%|████▉     | 528/1071 [00:11<00:11, 46.75it/s] 50%|████▉     | 533/1071 [00:11<00:11, 46.75it/s] 50%|█████     | 538/1071 [00:12<00:11, 46.68it/s] 51%|█████     | 543/1071 [00:12<00:11, 46.63it/s] 51%|█████     | 548/1071 [00:12<00:11, 46.55it/s] 52%|█████▏    | 553/1071 [00:12<00:11, 46.60it/s] 52%|█████▏    | 558/1071 [00:12<00:11, 46.62it/s] 53%|█████▎    | 563/1071 [00:12<00:10, 46.57it/s] 53%|█████▎    | 568/1071 [00:12<00:10, 46.64it/s] 54%|█████▎    | 573/1071 [00:12<00:10, 46.65it/s] 54%|█████▍    | 578/1071 [00:12<00:10, 46.66it/s] 54%|█████▍    | 583/1071 [00:12<00:10, 46.67it/s] 55%|█████▍    | 588/1071 [00:13<00:10, 46.62it/s] 55%|█████▌    | 593/1071 [00:13<00:10, 46.53it/s] 56%|█████▌    | 598/1071 [00:13<00:10, 46.57it/s] 56%|█████▋    | 603/1071 [00:13<00:10, 46.58it/s] 57%|█████▋    | 608/1071 [00:13<00:09, 46.53it/s] 57%|█████▋    | 613/1071 [00:13<00:09, 46.57it/s] 58%|█████▊    | 618/1071 [00:13<00:09, 46.61it/s] 58%|█████▊    | 623/1071 [00:13<00:09, 46.68it/s] 59%|█████▊    | 628/1071 [00:13<00:09, 46.71it/s] 59%|█████▉    | 633/1071 [00:14<00:09, 46.64it/s] 60%|█████▉    | 638/1071 [00:14<00:09, 46.62it/s] 60%|██████    | 643/1071 [00:14<00:09, 46.58it/s] 61%|██████    | 648/1071 [00:14<00:09, 46.58it/s] 61%|██████    | 653/1071 [00:14<00:08, 46.59it/s] 61%|██████▏   | 658/1071 [00:14<00:08, 46.57it/s] 62%|██████▏   | 663/1071 [00:14<00:08, 46.65it/s] 62%|██████▏   | 668/1071 [00:14<00:08, 46.70it/s] 63%|██████▎   | 673/1071 [00:14<00:08, 46.65it/s] 63%|██████▎   | 678/1071 [00:15<00:08, 46.61it/s] 64%|██████▍   | 683/1071 [00:15<00:08, 46.55it/s] 64%|██████▍   | 688/1071 [00:15<00:08, 46.40it/s] 65%|██████▍   | 693/1071 [00:15<00:08, 46.51it/s] 65%|██████▌   | 698/1071 [00:15<00:08, 46.52it/s] 66%|██████▌   | 703/1071 [00:15<00:07, 46.53it/s] 66%|██████▌   | 708/1071 [00:15<00:07, 46.60it/s] 67%|██████▋   | 713/1071 [00:15<00:07, 46.62it/s] 67%|██████▋   | 718/1071 [00:15<00:07, 46.70it/s] 68%|██████▊   | 723/1071 [00:16<00:07, 46.68it/s] 68%|██████▊   | 728/1071 [00:16<00:07, 46.57it/s] 68%|██████▊   | 733/1071 [00:16<00:07, 46.56it/s] 69%|██████▉   | 738/1071 [00:16<00:07, 46.58it/s] 69%|██████▉   | 743/1071 [00:16<00:07, 46.54it/s] 70%|██████▉   | 748/1071 [00:16<00:06, 46.61it/s] 70%|███████   | 753/1071 [00:16<00:06, 46.53it/s] 71%|███████   | 758/1071 [00:16<00:06, 46.53it/s] 71%|███████   | 763/1071 [00:16<00:06, 46.58it/s] 72%|███████▏  | 768/1071 [00:16<00:06, 46.62it/s] 72%|███████▏  | 773/1071 [00:17<00:06, 46.61it/s] 73%|███████▎  | 778/1071 [00:17<00:06, 46.55it/s] 73%|███████▎  | 783/1071 [00:17<00:06, 46.52it/s] 74%|███████▎  | 788/1071 [00:17<00:06, 46.57it/s] 74%|███████▍  | 793/1071 [00:17<00:05, 46.59it/s] 75%|███████▍  | 798/1071 [00:17<00:05, 46.60it/s] 75%|███████▍  | 803/1071 [00:17<00:05, 46.64it/s] 75%|███████▌  | 808/1071 [00:17<00:05, 46.61it/s] 76%|███████▌  | 813/1071 [00:17<00:05, 46.62it/s] 76%|███████▋  | 818/1071 [00:18<00:05, 46.62it/s] 77%|███████▋  | 823/1071 [00:18<00:05, 46.56it/s] 77%|███████▋  | 828/1071 [00:18<00:05, 46.56it/s] 78%|███████▊  | 833/1071 [00:18<00:05, 46.50it/s] 78%|███████▊  | 838/1071 [00:18<00:05, 46.52it/s] 79%|███████▊  | 843/1071 [00:18<00:04, 46.59it/s] 79%|███████▉  | 848/1071 [00:18<00:04, 46.65it/s] 80%|███████▉  | 853/1071 [00:18<00:04, 46.62it/s] 80%|████████  | 858/1071 [00:18<00:04, 46.64it/s] 81%|████████  | 863/1071 [00:19<00:04, 46.64it/s] 81%|████████  | 868/1071 [00:19<00:04, 46.64it/s] 82%|████████▏ | 873/1071 [00:19<00:04, 46.59it/s] 82%|████████▏ | 878/1071 [00:19<00:04, 46.49it/s] 82%|████████▏ | 883/1071 [00:19<00:04, 46.54it/s] 83%|████████▎ | 888/1071 [00:19<00:03, 46.59it/s] 83%|████████▎ | 893/1071 [00:19<00:03, 46.61it/s] 84%|████████▍ | 898/1071 [00:19<00:03, 46.65it/s] 84%|████████▍ | 903/1071 [00:19<00:03, 46.58it/s] 85%|████████▍ | 908/1071 [00:19<00:03, 46.64it/s] 85%|████████▌ | 913/1071 [00:20<00:03, 46.65it/s] 86%|████████▌ | 918/1071 [00:20<00:03, 46.57it/s] 86%|████████▌ | 923/1071 [00:20<00:03, 46.52it/s] 87%|████████▋ | 928/1071 [00:20<00:03, 46.48it/s] 87%|████████▋ | 933/1071 [00:20<00:02, 46.52it/s] 88%|████████▊ | 938/1071 [00:20<00:02, 46.61it/s] 88%|████████▊ | 943/1071 [00:20<00:02, 46.64it/s] 89%|████████▊ | 948/1071 [00:20<00:02, 46.61it/s] 89%|████████▉ | 953/1071 [00:20<00:02, 46.66it/s] 89%|████████▉ | 958/1071 [00:21<00:02, 46.65it/s] 90%|████████▉ | 963/1071 [00:21<00:02, 46.63it/s] 90%|█████████ | 968/1071 [00:21<00:02, 46.55it/s] 91%|█████████ | 973/1071 [00:21<00:02, 46.44it/s] 91%|█████████▏| 978/1071 [00:21<00:02, 46.48it/s] 92%|█████████▏| 983/1071 [00:21<00:01, 46.49it/s] 92%|█████████▏| 988/1071 [00:21<00:01, 46.59it/s] 93%|█████████▎| 993/1071 [00:21<00:01, 46.64it/s] 93%|█████████▎| 998/1071 [00:21<00:01, 46.67it/s] 94%|█████████▎| 1003/1071 [00:22<00:01, 46.66it/s] 94%|█████████▍| 1008/1071 [00:22<00:01, 46.60it/s] 95%|█████████▍| 1013/1071 [00:22<00:01, 46.52it/s] 95%|█████████▌| 1018/1071 [00:22<00:01, 46.48it/s] 96%|█████████▌| 1023/1071 [00:22<00:01, 46.47it/s] 96%|█████████▌| 1028/1071 [00:22<00:00, 46.44it/s] 96%|█████████▋| 1033/1071 [00:22<00:00, 46.53it/s] 97%|█████████▋| 1038/1071 [00:22<00:00, 46.58it/s] 97%|█████████▋| 1043/1071 [00:22<00:00, 46.64it/s] 98%|█████████▊| 1048/1071 [00:22<00:00, 46.65it/s] 98%|█████████▊| 1053/1071 [00:23<00:00, 46.56it/s] 99%|█████████▉| 1058/1071 [00:23<00:00, 46.58it/s] 99%|█████████▉| 1063/1071 [00:23<00:00, 46.54it/s]100%|█████████▉| 1068/1071 [00:23<00:00, 46.47it/s]100%|██████████| 1071/1071 [00:23<00:00, 45.57it/s]
[INFO|trainer_pt_utils.py:908] 2023-08-29 14:15:11,417 >> ***** eval metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:15:11,418 >>   epoch                   =        5.0
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:15:11,418 >>   eval_loss               =     0.9968
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:15:11,418 >>   eval_runtime            = 0:00:23.52
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:15:11,418 >>   eval_samples            =       8568
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:15:11,418 >>   eval_samples_per_second =    364.215
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:15:11,418 >>   eval_steps_per_second   =     45.527
[INFO|trainer_pt_utils.py:913] 2023-08-29 14:15:11,418 >>   perplexity              =     2.7096
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:21,805 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:21,812 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:21,812 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:21,813 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:21,813 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 14:15:22,438 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 14:15:22,439 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:15:23,009 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 14:15:25,691 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:15:25,691 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:28,540 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:28,545 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:28,546 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:28,546 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:15:28,546 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 14:15:29,306 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 14:15:29,307 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:15:29,869 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 14:15:30,351 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:15:30,352 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-615
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-369
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-246
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-492
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/checkpoint-123
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_in_all_single_is_eval_True.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_out_filter_all_single_is_eval_True.jsonl'}}
predict vocab size: 21439
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 21539, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1190: UserWarning: operator() sees varying value in profiling, ignoring and this should be handled by GUARD logic (Triggered internally at ../torch/csrc/jit/codegen/cuda/parser.cpp:3668.)
  return forward_call(*input, **kwargs)
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1190: UserWarning: operator() profile_node %91 : int[] = prim::profile_ivalue[profile_failed="varying profile values"](%89)
 does not have profile information (Triggered internally at ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:105.)
  return forward_call(*input, **kwargs)
Extractor Predicting: 1it [00:17, 17.52s/it]Extractor Predicting: 2it [00:18,  7.90s/it]Extractor Predicting: 3it [00:19,  4.56s/it]Extractor Predicting: 4it [00:19,  2.99s/it]Extractor Predicting: 5it [00:20,  2.12s/it]Extractor Predicting: 6it [00:21,  1.60s/it]Extractor Predicting: 7it [00:22,  1.45s/it]Extractor Predicting: 8it [00:22,  1.19s/it]Extractor Predicting: 9it [00:23,  1.01s/it]Extractor Predicting: 10it [00:24,  1.13it/s]Extractor Predicting: 11it [00:24,  1.20it/s]Extractor Predicting: 12it [00:25,  1.27it/s]Extractor Predicting: 13it [00:25,  1.41it/s]Extractor Predicting: 14it [00:26,  1.49it/s]Extractor Predicting: 15it [00:27,  1.20it/s]Extractor Predicting: 16it [00:28,  1.33it/s]Extractor Predicting: 17it [00:28,  1.41it/s]Extractor Predicting: 18it [00:29,  1.52it/s]Extractor Predicting: 19it [00:30,  1.57it/s]Extractor Predicting: 20it [00:30,  1.63it/s]Extractor Predicting: 21it [00:31,  1.65it/s]Extractor Predicting: 22it [00:31,  1.71it/s]Extractor Predicting: 23it [00:32,  1.77it/s]Extractor Predicting: 24it [00:32,  1.71it/s]Extractor Predicting: 25it [00:35,  1.10s/it]Extractor Predicting: 26it [00:35,  1.05it/s]Extractor Predicting: 27it [00:36,  1.20it/s]Extractor Predicting: 28it [00:36,  1.32it/s]Extractor Predicting: 29it [00:37,  1.44it/s]Extractor Predicting: 30it [00:38,  1.45it/s]Extractor Predicting: 31it [00:38,  1.51it/s]Extractor Predicting: 32it [00:39,  1.58it/s]Extractor Predicting: 33it [00:39,  1.64it/s]Extractor Predicting: 34it [00:40,  1.70it/s]Extractor Predicting: 35it [00:40,  1.78it/s]Extractor Predicting: 36it [00:41,  1.76it/s]Extractor Predicting: 37it [00:41,  1.84it/s]Extractor Predicting: 38it [00:42,  1.82it/s]Extractor Predicting: 39it [00:43,  1.79it/s]Extractor Predicting: 40it [00:43,  1.79it/s]Extractor Predicting: 41it [00:44,  1.81it/s]Extractor Predicting: 42it [00:44,  1.84it/s]Extractor Predicting: 43it [00:45,  1.83it/s]Extractor Predicting: 44it [00:45,  1.78it/s]Extractor Predicting: 45it [00:46,  1.82it/s]Extractor Predicting: 46it [00:47,  1.77it/s]Extractor Predicting: 47it [00:47,  1.75it/s]Extractor Predicting: 48it [00:48,  1.79it/s]Extractor Predicting: 49it [00:48,  1.81it/s]Extractor Predicting: 50it [00:49,  1.86it/s]Extractor Predicting: 51it [00:49,  1.86it/s]Extractor Predicting: 52it [00:50,  1.85it/s]Extractor Predicting: 53it [00:50,  1.88it/s]Extractor Predicting: 54it [00:51,  1.86it/s]Extractor Predicting: 55it [00:51,  1.86it/s]Extractor Predicting: 56it [00:52,  1.86it/s]Extractor Predicting: 57it [00:52,  1.90it/s]Extractor Predicting: 58it [00:53,  1.94it/s]Extractor Predicting: 59it [00:54,  1.81it/s]Extractor Predicting: 60it [00:54,  1.81it/s]Extractor Predicting: 61it [00:55,  1.79it/s]Extractor Predicting: 62it [00:55,  1.80it/s]Extractor Predicting: 63it [00:56,  1.78it/s]Extractor Predicting: 64it [00:56,  1.84it/s]Extractor Predicting: 65it [00:57,  1.89it/s]Extractor Predicting: 66it [00:57,  1.86it/s]Extractor Predicting: 67it [00:58,  1.83it/s]Extractor Predicting: 68it [00:58,  1.82it/s]Extractor Predicting: 69it [00:59,  1.85it/s]Extractor Predicting: 70it [01:00,  1.78it/s]Extractor Predicting: 71it [01:00,  1.82it/s]Extractor Predicting: 72it [01:01,  1.78it/s]Extractor Predicting: 73it [01:01,  1.75it/s]Extractor Predicting: 74it [01:02,  1.73it/s]Extractor Predicting: 75it [01:02,  1.74it/s]Extractor Predicting: 76it [01:03,  1.69it/s]Extractor Predicting: 77it [01:04,  1.66it/s]Extractor Predicting: 78it [01:04,  1.68it/s]Extractor Predicting: 79it [01:05,  1.64it/s]Extractor Predicting: 80it [01:06,  1.61it/s]Extractor Predicting: 81it [01:06,  1.58it/s]Extractor Predicting: 82it [01:07,  1.56it/s]Extractor Predicting: 83it [01:07,  1.57it/s]Extractor Predicting: 84it [01:08,  1.55it/s]Extractor Predicting: 85it [01:09,  1.55it/s]Extractor Predicting: 86it [01:09,  1.57it/s]Extractor Predicting: 87it [01:10,  1.57it/s]Extractor Predicting: 88it [01:11,  1.57it/s]Extractor Predicting: 89it [01:11,  1.59it/s]Extractor Predicting: 90it [01:12,  1.59it/s]Extractor Predicting: 91it [01:13,  1.56it/s]Extractor Predicting: 92it [01:13,  1.57it/s]Extractor Predicting: 93it [01:14,  1.54it/s]Extractor Predicting: 94it [01:15,  1.55it/s]Extractor Predicting: 95it [01:15,  1.56it/s]Extractor Predicting: 96it [01:16,  1.58it/s]Extractor Predicting: 97it [01:16,  1.60it/s]Extractor Predicting: 98it [01:17,  1.61it/s]Extractor Predicting: 99it [01:18,  1.60it/s]Extractor Predicting: 100it [01:18,  1.60it/s]Extractor Predicting: 101it [01:19,  1.60it/s]Extractor Predicting: 102it [01:20,  1.55it/s]Extractor Predicting: 103it [01:20,  1.57it/s]Extractor Predicting: 104it [01:21,  1.55it/s]Extractor Predicting: 105it [01:22,  1.56it/s]Extractor Predicting: 106it [01:22,  1.56it/s]Extractor Predicting: 107it [01:23,  1.56it/s]Extractor Predicting: 108it [01:23,  1.58it/s]Extractor Predicting: 109it [01:24,  1.57it/s]Extractor Predicting: 110it [01:25,  1.61it/s]Extractor Predicting: 111it [01:25,  1.61it/s]Extractor Predicting: 112it [01:26,  1.64it/s]Extractor Predicting: 113it [01:26,  1.64it/s]Extractor Predicting: 114it [01:27,  1.63it/s]Extractor Predicting: 115it [01:28,  1.54it/s]Extractor Predicting: 116it [01:29,  1.42it/s]Extractor Predicting: 117it [01:29,  1.47it/s]Extractor Predicting: 118it [01:30,  1.49it/s]Extractor Predicting: 119it [01:31,  1.49it/s]Extractor Predicting: 120it [01:31,  1.53it/s]Extractor Predicting: 121it [01:32,  1.57it/s]Extractor Predicting: 122it [01:33,  1.52it/s]Extractor Predicting: 123it [01:33,  1.55it/s]Extractor Predicting: 124it [01:34,  1.55it/s]Extractor Predicting: 125it [01:34,  1.56it/s]Extractor Predicting: 126it [01:35,  1.60it/s]Extractor Predicting: 127it [01:36,  1.67it/s]Extractor Predicting: 128it [01:36,  1.69it/s]Extractor Predicting: 129it [01:37,  1.70it/s]Extractor Predicting: 130it [01:37,  1.65it/s]Extractor Predicting: 131it [01:38,  1.68it/s]Extractor Predicting: 132it [01:39,  1.63it/s]Extractor Predicting: 133it [01:39,  1.63it/s]Extractor Predicting: 134it [01:40,  1.64it/s]Extractor Predicting: 135it [01:40,  1.66it/s]Extractor Predicting: 136it [01:41,  1.71it/s]Extractor Predicting: 137it [01:41,  1.72it/s]Extractor Predicting: 138it [01:42,  1.72it/s]Extractor Predicting: 139it [01:43,  1.73it/s]Extractor Predicting: 140it [01:43,  1.74it/s]Extractor Predicting: 141it [01:44,  1.75it/s]Extractor Predicting: 142it [01:44,  1.71it/s]Extractor Predicting: 143it [01:45,  1.67it/s]Extractor Predicting: 144it [01:46,  1.68it/s]Extractor Predicting: 145it [01:46,  1.73it/s]Extractor Predicting: 146it [01:47,  1.76it/s]Extractor Predicting: 147it [01:47,  1.74it/s]Extractor Predicting: 148it [01:48,  1.76it/s]Extractor Predicting: 149it [01:48,  1.73it/s]Extractor Predicting: 150it [01:49,  1.75it/s]Extractor Predicting: 151it [01:50,  1.70it/s]Extractor Predicting: 152it [01:50,  1.70it/s]Extractor Predicting: 153it [01:51,  1.70it/s]Extractor Predicting: 154it [01:51,  1.63it/s]Extractor Predicting: 155it [01:52,  1.62it/s]Extractor Predicting: 156it [01:53,  1.62it/s]Extractor Predicting: 157it [01:53,  1.63it/s]Extractor Predicting: 158it [01:54,  1.61it/s]Extractor Predicting: 159it [01:55,  1.62it/s]Extractor Predicting: 160it [01:55,  1.65it/s]Extractor Predicting: 161it [01:56,  1.65it/s]Extractor Predicting: 162it [01:56,  1.70it/s]Extractor Predicting: 163it [01:57,  1.85it/s]Extractor Predicting: 164it [01:57,  1.98it/s]Extractor Predicting: 165it [01:58,  1.99it/s]Extractor Predicting: 166it [01:58,  1.94it/s]Extractor Predicting: 167it [01:59,  1.85it/s]Extractor Predicting: 168it [01:59,  1.77it/s]Extractor Predicting: 169it [02:00,  1.70it/s]Extractor Predicting: 170it [02:01,  1.70it/s]Extractor Predicting: 171it [02:01,  1.71it/s]Extractor Predicting: 172it [02:02,  1.68it/s]Extractor Predicting: 173it [02:02,  1.68it/s]Extractor Predicting: 174it [02:03,  1.68it/s]Extractor Predicting: 175it [02:04,  1.66it/s]Extractor Predicting: 176it [02:04,  1.65it/s]Extractor Predicting: 177it [02:05,  1.64it/s]Extractor Predicting: 178it [02:05,  1.67it/s]Extractor Predicting: 179it [02:06,  1.61it/s]Extractor Predicting: 180it [02:07,  1.63it/s]Extractor Predicting: 181it [02:07,  1.66it/s]Extractor Predicting: 182it [02:08,  1.68it/s]Extractor Predicting: 183it [02:08,  1.64it/s]Extractor Predicting: 184it [02:09,  1.64it/s]Extractor Predicting: 185it [02:10,  1.61it/s]Extractor Predicting: 186it [02:10,  1.65it/s]Extractor Predicting: 187it [02:11,  1.66it/s]Extractor Predicting: 188it [02:12,  1.65it/s]Extractor Predicting: 189it [02:12,  1.66it/s]Extractor Predicting: 190it [02:13,  1.65it/s]Extractor Predicting: 191it [02:13,  1.67it/s]Extractor Predicting: 192it [02:14,  1.69it/s]Extractor Predicting: 193it [02:14,  1.69it/s]Extractor Predicting: 194it [02:15,  1.71it/s]Extractor Predicting: 195it [02:16,  1.66it/s]Extractor Predicting: 196it [02:16,  1.68it/s]Extractor Predicting: 197it [02:17,  1.65it/s]Extractor Predicting: 198it [02:18,  1.64it/s]Extractor Predicting: 199it [02:18,  1.63it/s]Extractor Predicting: 200it [02:19,  1.62it/s]Extractor Predicting: 201it [02:19,  1.58it/s]Extractor Predicting: 202it [02:20,  1.60it/s]Extractor Predicting: 203it [02:21,  1.59it/s]Extractor Predicting: 204it [02:21,  1.60it/s]Extractor Predicting: 205it [02:22,  1.45it/s]Extractor Predicting: 206it [02:23,  1.50it/s]Extractor Predicting: 207it [02:23,  1.59it/s]Extractor Predicting: 208it [02:24,  1.64it/s]Extractor Predicting: 209it [02:24,  1.64it/s]Extractor Predicting: 210it [02:25,  1.65it/s]Extractor Predicting: 211it [02:26,  1.65it/s]Extractor Predicting: 212it [02:26,  1.63it/s]Extractor Predicting: 213it [02:27,  1.60it/s]Extractor Predicting: 214it [02:28,  1.64it/s]Extractor Predicting: 215it [02:28,  1.67it/s]Extractor Predicting: 216it [02:29,  1.66it/s]Extractor Predicting: 217it [02:29,  1.64it/s]Extractor Predicting: 218it [02:30,  1.63it/s]Extractor Predicting: 219it [02:31,  1.65it/s]Extractor Predicting: 220it [02:31,  1.65it/s]Extractor Predicting: 221it [02:32,  1.68it/s]Extractor Predicting: 222it [02:32,  1.67it/s]Extractor Predicting: 223it [02:33,  1.68it/s]Extractor Predicting: 224it [02:33,  1.71it/s]Extractor Predicting: 225it [02:34,  1.76it/s]Extractor Predicting: 226it [02:35,  1.72it/s]Extractor Predicting: 227it [02:35,  1.71it/s]Extractor Predicting: 228it [02:36,  1.71it/s]Extractor Predicting: 229it [02:37,  1.61it/s]Extractor Predicting: 230it [02:37,  1.68it/s]Extractor Predicting: 231it [02:38,  1.69it/s]Extractor Predicting: 232it [02:38,  1.67it/s]Extractor Predicting: 233it [02:39,  1.65it/s]Extractor Predicting: 234it [02:40,  1.61it/s]Extractor Predicting: 235it [02:40,  1.63it/s]Extractor Predicting: 236it [02:41,  1.59it/s]Extractor Predicting: 237it [02:41,  1.53it/s]Extractor Predicting: 238it [02:42,  1.53it/s]Extractor Predicting: 239it [02:43,  1.49it/s]Extractor Predicting: 240it [02:44,  1.50it/s]Extractor Predicting: 241it [02:44,  1.55it/s]Extractor Predicting: 242it [02:45,  1.53it/s]Extractor Predicting: 243it [02:45,  1.58it/s]Extractor Predicting: 244it [02:46,  1.58it/s]Extractor Predicting: 245it [02:47,  1.65it/s]Extractor Predicting: 246it [02:47,  1.67it/s]Extractor Predicting: 247it [02:48,  1.69it/s]Extractor Predicting: 248it [02:48,  1.72it/s]Extractor Predicting: 249it [02:49,  1.76it/s]Extractor Predicting: 250it [02:49,  1.70it/s]Extractor Predicting: 251it [02:50,  1.75it/s]Extractor Predicting: 252it [02:51,  1.71it/s]Extractor Predicting: 253it [02:51,  1.70it/s]Extractor Predicting: 254it [02:52,  1.72it/s]Extractor Predicting: 255it [02:52,  1.73it/s]Extractor Predicting: 256it [02:53,  1.71it/s]Extractor Predicting: 257it [02:53,  1.72it/s]Extractor Predicting: 258it [02:54,  1.73it/s]Extractor Predicting: 259it [02:55,  1.69it/s]Extractor Predicting: 260it [02:55,  1.69it/s]Extractor Predicting: 261it [02:56,  1.66it/s]Extractor Predicting: 262it [02:57,  1.64it/s]Extractor Predicting: 263it [02:57,  1.66it/s]Extractor Predicting: 264it [02:58,  1.66it/s]Extractor Predicting: 265it [02:58,  1.67it/s]Extractor Predicting: 266it [02:59,  1.66it/s]Extractor Predicting: 267it [03:00,  1.65it/s]Extractor Predicting: 268it [03:00,  1.63it/s]Extractor Predicting: 269it [03:01,  1.61it/s]Extractor Predicting: 270it [03:01,  1.66it/s]Extractor Predicting: 271it [03:02,  1.68it/s]Extractor Predicting: 272it [03:02,  1.74it/s]Extractor Predicting: 273it [03:03,  1.75it/s]Extractor Predicting: 274it [03:04,  1.75it/s]Extractor Predicting: 275it [03:04,  1.70it/s]Extractor Predicting: 276it [03:05,  1.70it/s]Extractor Predicting: 277it [03:05,  1.71it/s]Extractor Predicting: 278it [03:06,  1.68it/s]Extractor Predicting: 279it [03:07,  1.70it/s]Extractor Predicting: 280it [03:07,  1.77it/s]Extractor Predicting: 281it [03:08,  1.75it/s]Extractor Predicting: 282it [03:08,  1.72it/s]Extractor Predicting: 283it [03:09,  1.68it/s]Extractor Predicting: 284it [03:10,  1.67it/s]Extractor Predicting: 285it [03:10,  1.62it/s]Extractor Predicting: 286it [03:11,  1.64it/s]Extractor Predicting: 287it [03:11,  1.62it/s]Extractor Predicting: 288it [03:12,  1.62it/s]Extractor Predicting: 289it [03:13,  1.59it/s]Extractor Predicting: 290it [03:13,  1.60it/s]Extractor Predicting: 291it [03:14,  1.64it/s]Extractor Predicting: 292it [03:14,  1.67it/s]Extractor Predicting: 293it [03:15,  1.66it/s]Extractor Predicting: 294it [03:16,  1.60it/s]Extractor Predicting: 295it [03:16,  1.61it/s]Extractor Predicting: 296it [03:17,  1.59it/s]Extractor Predicting: 297it [03:18,  1.56it/s]Extractor Predicting: 298it [03:18,  1.54it/s]Extractor Predicting: 299it [03:19,  1.53it/s]Extractor Predicting: 300it [03:20,  1.54it/s]Extractor Predicting: 301it [03:20,  1.49it/s]Extractor Predicting: 302it [03:21,  1.49it/s]Extractor Predicting: 303it [03:22,  1.37it/s]Extractor Predicting: 303it [03:22,  1.50it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:04,138 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:04,142 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:04,142 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:04,142 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:04,142 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 14:19:04,775 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 14:19:04,776 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:19:05,361 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 14:19:06,465 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:19:06,465 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:09,310 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:09,314 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:09,314 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:09,314 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:19:09,314 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 14:19:09,922 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 14:19:09,924 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:19:10,545 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 14:19:10,718 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:19:10,718 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_out_filter_all_single_is_eval_True.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_in_all_single_is_eval_True.jsonl",
  "precision": 0,
  "recall": 0,
  "score": 0,
  "mode": "all_single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/results_all_single_is_eval_True.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_in_single_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_out_filter_single_is_eval_False.jsonl'}}
predict vocab size: 20815
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 20915, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.76it/s]Extractor Predicting: 2it [00:01,  1.67it/s]Extractor Predicting: 3it [00:01,  1.70it/s]Extractor Predicting: 4it [00:02,  1.73it/s]Extractor Predicting: 5it [00:02,  1.76it/s]Extractor Predicting: 6it [00:03,  1.72it/s]Extractor Predicting: 7it [00:04,  1.71it/s]Extractor Predicting: 8it [00:04,  1.72it/s]Extractor Predicting: 9it [00:05,  1.64it/s]Extractor Predicting: 10it [00:05,  1.66it/s]Extractor Predicting: 11it [00:06,  1.71it/s]Extractor Predicting: 12it [00:07,  1.74it/s]Extractor Predicting: 13it [00:07,  1.74it/s]Extractor Predicting: 14it [00:08,  1.72it/s]Extractor Predicting: 15it [00:08,  1.75it/s]Extractor Predicting: 16it [00:09,  1.73it/s]Extractor Predicting: 17it [00:09,  1.71it/s]Extractor Predicting: 18it [00:10,  1.67it/s]Extractor Predicting: 19it [00:11,  1.68it/s]Extractor Predicting: 20it [00:11,  1.66it/s]Extractor Predicting: 21it [00:12,  1.66it/s]Extractor Predicting: 22it [00:13,  1.62it/s]Extractor Predicting: 23it [00:13,  1.66it/s]Extractor Predicting: 24it [00:14,  1.67it/s]Extractor Predicting: 25it [00:14,  1.70it/s]Extractor Predicting: 26it [00:15,  1.69it/s]Extractor Predicting: 27it [00:15,  1.68it/s]Extractor Predicting: 28it [00:16,  1.69it/s]Extractor Predicting: 29it [00:17,  1.65it/s]Extractor Predicting: 30it [00:17,  1.68it/s]Extractor Predicting: 31it [00:18,  1.69it/s]Extractor Predicting: 32it [00:18,  1.68it/s]Extractor Predicting: 33it [00:19,  1.69it/s]Extractor Predicting: 34it [00:20,  1.67it/s]Extractor Predicting: 35it [00:20,  1.65it/s]Extractor Predicting: 36it [00:21,  1.69it/s]Extractor Predicting: 37it [00:21,  1.67it/s]Extractor Predicting: 38it [00:22,  1.67it/s]Extractor Predicting: 39it [00:23,  1.72it/s]Extractor Predicting: 40it [00:23,  1.71it/s]Extractor Predicting: 41it [00:24,  1.70it/s]Extractor Predicting: 42it [00:24,  1.59it/s]Extractor Predicting: 43it [00:25,  1.59it/s]Extractor Predicting: 44it [00:26,  1.57it/s]Extractor Predicting: 45it [00:26,  1.58it/s]Extractor Predicting: 46it [00:27,  1.58it/s]Extractor Predicting: 47it [00:28,  1.60it/s]Extractor Predicting: 48it [00:28,  1.62it/s]Extractor Predicting: 49it [00:29,  1.63it/s]Extractor Predicting: 50it [00:29,  1.69it/s]Extractor Predicting: 51it [00:30,  1.70it/s]Extractor Predicting: 52it [00:31,  1.71it/s]Extractor Predicting: 53it [00:31,  1.72it/s]Extractor Predicting: 54it [00:32,  1.67it/s]Extractor Predicting: 55it [00:32,  1.72it/s]Extractor Predicting: 56it [00:33,  1.71it/s]Extractor Predicting: 57it [00:33,  1.72it/s]Extractor Predicting: 58it [00:34,  1.69it/s]Extractor Predicting: 59it [00:35,  1.69it/s]Extractor Predicting: 60it [00:35,  1.69it/s]Extractor Predicting: 61it [00:36,  1.68it/s]Extractor Predicting: 62it [00:36,  1.69it/s]Extractor Predicting: 63it [00:37,  1.71it/s]Extractor Predicting: 64it [00:38,  1.73it/s]Extractor Predicting: 65it [00:38,  1.60it/s]Extractor Predicting: 66it [00:39,  1.65it/s]Extractor Predicting: 67it [00:39,  1.68it/s]Extractor Predicting: 68it [00:40,  1.66it/s]Extractor Predicting: 69it [00:41,  1.65it/s]Extractor Predicting: 70it [00:41,  1.67it/s]Extractor Predicting: 71it [00:42,  1.68it/s]Extractor Predicting: 72it [00:42,  1.71it/s]Extractor Predicting: 73it [00:43,  1.72it/s]Extractor Predicting: 74it [00:44,  1.71it/s]Extractor Predicting: 75it [00:44,  1.68it/s]Extractor Predicting: 76it [00:45,  1.71it/s]Extractor Predicting: 77it [00:45,  1.70it/s]Extractor Predicting: 78it [00:46,  1.70it/s]Extractor Predicting: 79it [00:47,  1.70it/s]Extractor Predicting: 80it [00:47,  1.70it/s]Extractor Predicting: 81it [00:48,  1.71it/s]Extractor Predicting: 82it [00:48,  1.73it/s]Extractor Predicting: 83it [00:49,  1.72it/s]Extractor Predicting: 84it [00:49,  1.71it/s]Extractor Predicting: 85it [00:50,  1.70it/s]Extractor Predicting: 86it [00:51,  1.72it/s]Extractor Predicting: 87it [00:51,  1.67it/s]Extractor Predicting: 88it [00:52,  1.66it/s]Extractor Predicting: 89it [00:52,  1.66it/s]Extractor Predicting: 90it [00:53,  1.67it/s]Extractor Predicting: 91it [00:54,  1.68it/s]Extractor Predicting: 92it [00:54,  1.69it/s]Extractor Predicting: 93it [00:55,  1.66it/s]Extractor Predicting: 94it [00:55,  1.67it/s]Extractor Predicting: 95it [00:56,  1.69it/s]Extractor Predicting: 96it [00:57,  1.68it/s]Extractor Predicting: 97it [00:57,  1.64it/s]Extractor Predicting: 98it [00:58,  1.69it/s]Extractor Predicting: 99it [00:58,  1.69it/s]Extractor Predicting: 100it [00:59,  1.65it/s]Extractor Predicting: 101it [01:00,  1.67it/s]Extractor Predicting: 102it [01:00,  1.66it/s]Extractor Predicting: 103it [01:01,  1.65it/s]Extractor Predicting: 104it [01:01,  1.66it/s]Extractor Predicting: 105it [01:02,  1.65it/s]Extractor Predicting: 106it [01:03,  1.65it/s]Extractor Predicting: 107it [01:03,  1.68it/s]Extractor Predicting: 108it [01:04,  1.65it/s]Extractor Predicting: 109it [01:04,  1.65it/s]Extractor Predicting: 110it [01:05,  1.66it/s]Extractor Predicting: 111it [01:06,  1.71it/s]Extractor Predicting: 112it [01:06,  1.71it/s]Extractor Predicting: 113it [01:07,  1.73it/s]Extractor Predicting: 114it [01:07,  1.69it/s]Extractor Predicting: 115it [01:08,  1.70it/s]Extractor Predicting: 116it [01:09,  1.70it/s]Extractor Predicting: 117it [01:09,  1.67it/s]Extractor Predicting: 118it [01:10,  1.67it/s]Extractor Predicting: 119it [01:10,  1.67it/s]Extractor Predicting: 120it [01:11,  1.66it/s]Extractor Predicting: 121it [01:12,  1.69it/s]Extractor Predicting: 122it [01:12,  1.67it/s]Extractor Predicting: 123it [01:13,  1.70it/s]Extractor Predicting: 124it [01:13,  1.69it/s]Extractor Predicting: 125it [01:14,  1.71it/s]Extractor Predicting: 126it [01:14,  1.68it/s]Extractor Predicting: 127it [01:15,  1.66it/s]Extractor Predicting: 128it [01:16,  1.67it/s]Extractor Predicting: 129it [01:16,  1.73it/s]Extractor Predicting: 130it [01:17,  1.75it/s]Extractor Predicting: 131it [01:17,  1.73it/s]Extractor Predicting: 132it [01:18,  1.68it/s]Extractor Predicting: 133it [01:19,  1.61it/s]Extractor Predicting: 134it [01:19,  1.61it/s]Extractor Predicting: 135it [01:20,  1.63it/s]Extractor Predicting: 136it [01:21,  1.47it/s]Extractor Predicting: 137it [01:21,  1.50it/s]Extractor Predicting: 138it [01:22,  1.53it/s]Extractor Predicting: 139it [01:23,  1.56it/s]Extractor Predicting: 140it [01:23,  1.59it/s]Extractor Predicting: 141it [01:24,  1.59it/s]Extractor Predicting: 142it [01:24,  1.59it/s]Extractor Predicting: 143it [01:25,  1.61it/s]Extractor Predicting: 144it [01:26,  1.62it/s]Extractor Predicting: 145it [01:26,  1.62it/s]Extractor Predicting: 146it [01:27,  1.63it/s]Extractor Predicting: 147it [01:28,  1.61it/s]Extractor Predicting: 148it [01:28,  1.66it/s]Extractor Predicting: 149it [01:29,  1.64it/s]Extractor Predicting: 150it [01:29,  1.63it/s]Extractor Predicting: 151it [01:30,  1.63it/s]Extractor Predicting: 152it [01:30,  1.70it/s]Extractor Predicting: 153it [01:31,  1.72it/s]Extractor Predicting: 154it [01:32,  1.70it/s]Extractor Predicting: 155it [01:32,  1.70it/s]Extractor Predicting: 156it [01:33,  1.70it/s]Extractor Predicting: 157it [01:33,  1.71it/s]Extractor Predicting: 158it [01:34,  1.68it/s]Extractor Predicting: 159it [01:35,  1.66it/s]Extractor Predicting: 160it [01:35,  1.68it/s]Extractor Predicting: 161it [01:36,  1.69it/s]Extractor Predicting: 162it [01:36,  1.67it/s]Extractor Predicting: 163it [01:37,  1.69it/s]Extractor Predicting: 164it [01:38,  1.68it/s]Extractor Predicting: 165it [01:38,  1.73it/s]Extractor Predicting: 166it [01:39,  1.74it/s]Extractor Predicting: 167it [01:39,  1.70it/s]Extractor Predicting: 168it [01:40,  1.72it/s]Extractor Predicting: 169it [01:40,  1.72it/s]Extractor Predicting: 170it [01:41,  1.69it/s]Extractor Predicting: 171it [01:42,  1.63it/s]Extractor Predicting: 172it [01:42,  1.65it/s]Extractor Predicting: 173it [01:43,  1.65it/s]Extractor Predicting: 174it [01:44,  1.70it/s]Extractor Predicting: 175it [01:44,  1.73it/s]Extractor Predicting: 176it [01:45,  1.66it/s]Extractor Predicting: 177it [01:45,  1.67it/s]Extractor Predicting: 178it [01:46,  1.64it/s]Extractor Predicting: 179it [01:47,  1.64it/s]Extractor Predicting: 180it [01:47,  1.70it/s]Extractor Predicting: 181it [01:48,  1.70it/s]Extractor Predicting: 182it [01:48,  1.67it/s]Extractor Predicting: 183it [01:49,  1.70it/s]Extractor Predicting: 184it [01:49,  1.73it/s]Extractor Predicting: 185it [01:50,  1.71it/s]Extractor Predicting: 186it [01:51,  1.73it/s]Extractor Predicting: 187it [01:51,  1.73it/s]Extractor Predicting: 188it [01:52,  1.70it/s]Extractor Predicting: 189it [01:52,  1.65it/s]Extractor Predicting: 190it [01:53,  1.62it/s]Extractor Predicting: 191it [01:54,  1.66it/s]Extractor Predicting: 192it [01:54,  1.68it/s]Extractor Predicting: 193it [01:55,  1.65it/s]Extractor Predicting: 194it [01:55,  1.64it/s]Extractor Predicting: 195it [01:56,  1.68it/s]Extractor Predicting: 196it [01:57,  1.73it/s]Extractor Predicting: 197it [01:57,  1.72it/s]Extractor Predicting: 198it [01:58,  1.74it/s]Extractor Predicting: 199it [01:58,  1.73it/s]Extractor Predicting: 200it [01:59,  1.69it/s]Extractor Predicting: 201it [01:59,  1.70it/s]Extractor Predicting: 202it [02:00,  1.70it/s]Extractor Predicting: 203it [02:01,  1.71it/s]Extractor Predicting: 204it [02:01,  1.71it/s]Extractor Predicting: 205it [02:02,  1.73it/s]Extractor Predicting: 206it [02:02,  1.70it/s]Extractor Predicting: 207it [02:03,  1.72it/s]Extractor Predicting: 208it [02:04,  1.76it/s]Extractor Predicting: 209it [02:04,  1.76it/s]Extractor Predicting: 210it [02:05,  1.73it/s]Extractor Predicting: 211it [02:05,  1.73it/s]Extractor Predicting: 212it [02:06,  1.70it/s]Extractor Predicting: 213it [02:06,  1.68it/s]Extractor Predicting: 214it [02:07,  1.68it/s]Extractor Predicting: 215it [02:08,  1.67it/s]Extractor Predicting: 216it [02:08,  1.67it/s]Extractor Predicting: 217it [02:09,  1.64it/s]Extractor Predicting: 218it [02:09,  1.71it/s]Extractor Predicting: 219it [02:10,  1.72it/s]Extractor Predicting: 220it [02:11,  1.70it/s]Extractor Predicting: 221it [02:11,  1.65it/s]Extractor Predicting: 222it [02:12,  1.68it/s]Extractor Predicting: 223it [02:12,  1.69it/s]Extractor Predicting: 224it [02:13,  1.69it/s]Extractor Predicting: 225it [02:14,  1.72it/s]Extractor Predicting: 226it [02:14,  1.73it/s]Extractor Predicting: 227it [02:15,  1.74it/s]Extractor Predicting: 228it [02:15,  1.71it/s]Extractor Predicting: 229it [02:16,  1.72it/s]Extractor Predicting: 230it [02:17,  1.68it/s]Extractor Predicting: 231it [02:17,  1.72it/s]Extractor Predicting: 232it [02:18,  1.68it/s]Extractor Predicting: 233it [02:18,  1.68it/s]Extractor Predicting: 234it [02:19,  1.67it/s]Extractor Predicting: 235it [02:19,  1.68it/s]Extractor Predicting: 236it [02:20,  1.67it/s]Extractor Predicting: 237it [02:21,  1.68it/s]Extractor Predicting: 238it [02:21,  1.67it/s]Extractor Predicting: 239it [02:22,  1.73it/s]Extractor Predicting: 240it [02:22,  1.69it/s]Extractor Predicting: 241it [02:23,  1.67it/s]Extractor Predicting: 242it [02:24,  1.69it/s]Extractor Predicting: 243it [02:24,  1.73it/s]Extractor Predicting: 244it [02:25,  1.76it/s]Extractor Predicting: 245it [02:25,  1.60it/s]Extractor Predicting: 246it [02:26,  1.70it/s]Extractor Predicting: 247it [02:27,  1.70it/s]Extractor Predicting: 248it [02:27,  1.74it/s]Extractor Predicting: 249it [02:28,  1.74it/s]Extractor Predicting: 250it [02:28,  1.76it/s]Extractor Predicting: 251it [02:29,  1.76it/s]Extractor Predicting: 252it [02:29,  1.78it/s]Extractor Predicting: 253it [02:30,  1.78it/s]Extractor Predicting: 254it [02:30,  1.78it/s]Extractor Predicting: 255it [02:31,  1.83it/s]Extractor Predicting: 256it [02:32,  1.80it/s]Extractor Predicting: 257it [02:32,  1.79it/s]Extractor Predicting: 258it [02:33,  1.77it/s]Extractor Predicting: 259it [02:33,  1.76it/s]Extractor Predicting: 260it [02:34,  1.76it/s]Extractor Predicting: 261it [02:34,  1.78it/s]Extractor Predicting: 262it [02:35,  1.80it/s]Extractor Predicting: 263it [02:35,  1.85it/s]Extractor Predicting: 264it [02:36,  1.77it/s]Extractor Predicting: 265it [02:37,  1.73it/s]Extractor Predicting: 266it [02:37,  1.70it/s]Extractor Predicting: 267it [02:38,  1.67it/s]Extractor Predicting: 268it [02:38,  1.70it/s]Extractor Predicting: 269it [02:39,  1.73it/s]Extractor Predicting: 270it [02:40,  1.73it/s]Extractor Predicting: 271it [02:40,  1.73it/s]Extractor Predicting: 272it [02:41,  1.71it/s]Extractor Predicting: 273it [02:41,  1.75it/s]Extractor Predicting: 274it [02:42,  1.75it/s]Extractor Predicting: 275it [02:42,  1.78it/s]Extractor Predicting: 276it [02:43,  1.74it/s]Extractor Predicting: 277it [02:44,  1.66it/s]Extractor Predicting: 278it [02:44,  1.71it/s]Extractor Predicting: 279it [02:45,  1.76it/s]Extractor Predicting: 280it [02:45,  1.78it/s]Extractor Predicting: 281it [02:46,  1.81it/s]Extractor Predicting: 282it [02:46,  1.81it/s]Extractor Predicting: 283it [02:47,  1.81it/s]Extractor Predicting: 284it [02:48,  1.80it/s]Extractor Predicting: 285it [02:48,  1.73it/s]Extractor Predicting: 286it [02:49,  1.79it/s]Extractor Predicting: 287it [02:49,  1.77it/s]Extractor Predicting: 288it [02:50,  1.76it/s]Extractor Predicting: 289it [02:50,  1.75it/s]Extractor Predicting: 290it [02:51,  1.78it/s]Extractor Predicting: 291it [02:51,  1.79it/s]Extractor Predicting: 292it [02:52,  1.74it/s]Extractor Predicting: 293it [02:53,  1.74it/s]Extractor Predicting: 294it [02:53,  1.73it/s]Extractor Predicting: 295it [02:54,  1.73it/s]Extractor Predicting: 296it [02:54,  1.74it/s]Extractor Predicting: 297it [02:55,  1.72it/s]Extractor Predicting: 298it [02:56,  1.77it/s]Extractor Predicting: 299it [02:56,  1.70it/s]Extractor Predicting: 300it [02:57,  1.66it/s]Extractor Predicting: 301it [02:58,  1.58it/s]Extractor Predicting: 302it [02:58,  1.60it/s]Extractor Predicting: 303it [02:59,  1.58it/s]Extractor Predicting: 304it [02:59,  1.59it/s]Extractor Predicting: 305it [03:00,  1.58it/s]Extractor Predicting: 306it [03:01,  1.56it/s]Extractor Predicting: 306it [03:01,  1.69it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:20,380 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:20,381 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:20,381 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:20,381 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:20,381 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 14:22:20,986 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 14:22:20,988 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:22:21,677 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 14:22:22,750 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:22:22,750 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:25,598 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:25,599 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:25,599 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:25,599 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:22:25,599 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 14:22:26,256 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 14:22:26,258 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:22:26,846 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 14:22:27,023 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:22:27,023 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_out_filter_single_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_in_single_is_eval_False.jsonl",
  "precision": 0,
  "recall": 0,
  "score": 0,
  "mode": "single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/results_single_is_eval_False.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_in_multi_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_out_filter_multi_is_eval_False.jsonl'}}
predict vocab size: 6322
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 6422, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.61it/s]Extractor Predicting: 2it [00:01,  1.60it/s]Extractor Predicting: 3it [00:01,  1.61it/s]Extractor Predicting: 4it [00:02,  1.66it/s]Extractor Predicting: 5it [00:03,  1.64it/s]Extractor Predicting: 6it [00:03,  1.60it/s]Extractor Predicting: 7it [00:04,  1.64it/s]Extractor Predicting: 8it [00:04,  1.66it/s]Extractor Predicting: 9it [00:05,  1.65it/s]Extractor Predicting: 10it [00:06,  1.69it/s]Extractor Predicting: 11it [00:06,  1.64it/s]Extractor Predicting: 12it [00:07,  1.65it/s]Extractor Predicting: 13it [00:07,  1.66it/s]Extractor Predicting: 14it [00:08,  1.64it/s]Extractor Predicting: 15it [00:09,  1.65it/s]Extractor Predicting: 16it [00:09,  1.62it/s]Extractor Predicting: 17it [00:10,  1.60it/s]Extractor Predicting: 18it [00:11,  1.62it/s]Extractor Predicting: 19it [00:11,  1.65it/s]Extractor Predicting: 20it [00:12,  1.63it/s]Extractor Predicting: 21it [00:12,  1.61it/s]Extractor Predicting: 22it [00:13,  1.63it/s]Extractor Predicting: 23it [00:14,  1.67it/s]Extractor Predicting: 24it [00:14,  1.70it/s]Extractor Predicting: 25it [00:15,  1.71it/s]Extractor Predicting: 26it [00:15,  1.72it/s]Extractor Predicting: 27it [00:16,  1.71it/s]Extractor Predicting: 28it [00:16,  1.73it/s]Extractor Predicting: 29it [00:17,  1.69it/s]Extractor Predicting: 30it [00:18,  1.73it/s]Extractor Predicting: 31it [00:18,  1.72it/s]Extractor Predicting: 32it [00:19,  1.72it/s]Extractor Predicting: 33it [00:19,  1.71it/s]Extractor Predicting: 34it [00:20,  1.74it/s]Extractor Predicting: 35it [00:20,  1.74it/s]Extractor Predicting: 36it [00:21,  1.78it/s]Extractor Predicting: 37it [00:22,  1.76it/s]Extractor Predicting: 38it [00:22,  1.79it/s]Extractor Predicting: 39it [00:23,  1.76it/s]Extractor Predicting: 40it [00:23,  1.74it/s]Extractor Predicting: 41it [00:24,  1.73it/s]Extractor Predicting: 42it [00:24,  1.71it/s]Extractor Predicting: 43it [00:25,  1.67it/s]Extractor Predicting: 44it [00:26,  1.67it/s]Extractor Predicting: 45it [00:26,  1.68it/s]Extractor Predicting: 46it [00:27,  1.62it/s]Extractor Predicting: 47it [00:28,  1.66it/s]Extractor Predicting: 48it [00:28,  1.68it/s]Extractor Predicting: 49it [00:29,  1.68it/s]Extractor Predicting: 50it [00:29,  1.67it/s]Extractor Predicting: 51it [00:30,  1.69it/s]Extractor Predicting: 52it [00:31,  1.66it/s]Extractor Predicting: 53it [00:31,  1.56it/s]Extractor Predicting: 54it [00:32,  1.61it/s]Extractor Predicting: 55it [00:32,  1.63it/s]Extractor Predicting: 56it [00:33,  1.65it/s]Extractor Predicting: 57it [00:34,  1.61it/s]Extractor Predicting: 58it [00:34,  1.62it/s]Extractor Predicting: 59it [00:35,  1.61it/s]Extractor Predicting: 60it [00:36,  1.35it/s]Extractor Predicting: 60it [00:36,  1.65it/s]
[INFO|configuration_utils.py:515] 2023-08-29 14:23:04,286 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 14:23:04,287 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 14:23:04,291 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 14:23:04,292 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|modeling_utils.py:1150] 2023-08-29 14:23:04,294 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 14:23:07,812 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.

[INFO|modeling_utils.py:1345] 2023-08-29 14:23:07,824 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.
[INFO|configuration_utils.py:515] 2023-08-29 14:23:07,847 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 14:23:07,847 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter2/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 14:23:07,853 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:23:07,858 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:23:07,858 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:23:07,858 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:23:07,858 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:23:07,858 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 14:23:07,858 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model/tokenizer_config.json
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_out_filter_multi_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/pred_in_multi_is_eval_False.jsonl",
  "precision": 0,
  "recall": 0,
  "score": 0,
  "mode": "multi",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/results_multi_is_eval_False.json"
}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
Generating:   0%|          | 0/15 [00:00<?, ?it/s][WARNING|generation_utils.py:914] 2023-08-29 14:23:08,184 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:08,992 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:09,841 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:10,547 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:11,231 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:12,026 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:12,932 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:13,595 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:14,269 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:14,969 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:15,655 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:16,458 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:17,197 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:18,051 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:18,753 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:19,429 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:20,157 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:20,947 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:21,754 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:22,484 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:23,283 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:24,065 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:24,704 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:   7%|▋         | 1/15 [00:17<04:00, 17.17s/it][WARNING|generation_utils.py:914] 2023-08-29 14:23:25,327 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:26,075 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:26,976 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:27,772 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:28,562 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:29,312 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:30,158 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:31,041 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:31,871 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:32,742 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:33,494 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:34,265 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:34,952 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:35,772 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:36,618 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:37,321 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:38,005 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:39,004 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:39,873 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:40,763 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:41,579 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:42,448 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:43,209 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:43,973 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  13%|█▎        | 2/15 [00:36<04:00, 18.51s/it][WARNING|generation_utils.py:914] 2023-08-29 14:23:44,769 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:45,466 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:46,228 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:46,881 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:47,663 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:48,408 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:49,072 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:49,759 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:50,483 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:51,122 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:51,915 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:52,639 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:53,354 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:54,053 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:54,805 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:55,472 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:56,186 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:56,815 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:57,530 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:58,238 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:59,011 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:23:59,848 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:00,733 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:01,468 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  20%|██        | 3/15 [00:54<03:37, 18.10s/it][WARNING|generation_utils.py:914] 2023-08-29 14:24:02,380 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:03,095 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:03,755 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:04,472 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:05,276 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:05,960 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:06,688 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:07,371 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:08,215 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:08,938 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:09,730 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:10,448 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:11,164 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:11,840 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:12,566 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:13,315 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:14,035 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:14,849 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:15,524 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:16,211 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:16,899 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:17,628 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  27%|██▋       | 4/15 [01:10<03:09, 17.25s/it][WARNING|generation_utils.py:914] 2023-08-29 14:24:18,335 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:19,054 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:19,742 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:20,514 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:21,199 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:21,926 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:22,738 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:23,412 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:24,075 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:24,990 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:26,009 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:26,661 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:27,322 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:27,942 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:28,737 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:29,555 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:30,401 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:31,244 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:31,906 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:32,684 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:33,444 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:34,170 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:35,005 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  33%|███▎      | 5/15 [01:27<02:53, 17.32s/it][WARNING|generation_utils.py:914] 2023-08-29 14:24:35,767 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:36,482 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:37,272 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:37,900 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:38,574 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:39,388 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:40,107 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:41,047 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:41,805 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:42,448 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:43,143 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:43,848 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:44,489 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:45,212 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:45,887 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:46,594 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:47,250 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:47,922 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:48,683 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:49,399 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:50,160 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:50,931 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:51,679 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:52,345 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:53,082 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  40%|████      | 6/15 [01:45<02:38, 17.58s/it][WARNING|generation_utils.py:914] 2023-08-29 14:24:53,864 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:54,484 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:55,488 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:56,248 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:57,007 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:57,669 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:58,366 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:59,095 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:24:59,909 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:00,618 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:01,375 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:02,149 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:02,843 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:03,484 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:04,114 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:04,830 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:05,550 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:06,223 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:06,917 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:07,632 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:08,283 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:08,957 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:09,693 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:10,457 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  47%|████▋     | 7/15 [02:03<02:20, 17.50s/it][WARNING|generation_utils.py:914] 2023-08-29 14:25:11,196 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:11,923 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:12,805 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:13,541 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:14,215 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:14,879 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:15,708 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:16,498 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:17,148 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:18,241 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:18,940 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:19,712 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:20,539 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:21,228 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:21,880 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:22,587 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:23,388 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:24,268 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:25,082 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:25,803 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:26,519 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:27,299 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:28,028 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:28,715 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  53%|█████▎    | 8/15 [02:21<02:04, 17.74s/it][WARNING|generation_utils.py:914] 2023-08-29 14:25:29,446 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:30,408 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:31,386 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:32,127 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:32,811 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:33,529 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:34,182 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:34,920 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:35,748 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:36,480 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:37,164 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:37,923 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:38,641 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:39,381 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:40,142 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:40,913 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:41,599 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:42,351 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:43,165 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:43,903 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:44,609 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:45,369 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:46,027 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  60%|██████    | 9/15 [02:38<01:45, 17.59s/it][WARNING|generation_utils.py:914] 2023-08-29 14:25:46,714 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:47,484 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:48,232 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:48,972 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:49,626 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:50,494 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:51,276 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:51,951 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:52,735 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:53,420 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:54,179 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:54,842 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:55,622 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:56,355 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:57,096 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:57,821 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:58,567 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:25:59,295 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:00,006 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:00,749 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:01,481 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:02,255 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:02,980 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  67%|██████▋   | 10/15 [02:55<01:26, 17.40s/it][WARNING|generation_utils.py:914] 2023-08-29 14:26:03,684 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:04,505 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:05,282 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:05,975 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:06,710 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:07,444 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:08,100 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:08,853 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:09,534 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:10,366 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:11,086 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:11,774 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:12,565 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:13,211 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:14,061 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:14,844 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:15,445 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:16,442 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:17,096 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:17,815 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:18,612 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:19,252 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:20,136 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  73%|███████▎  | 11/15 [03:12<01:09, 17.34s/it][WARNING|generation_utils.py:914] 2023-08-29 14:26:20,889 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:21,629 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:22,370 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:23,211 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:24,042 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:24,915 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:25,594 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:26,369 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:27,122 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:27,940 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:28,716 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:29,527 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:30,324 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:31,100 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:31,810 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:32,549 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:33,325 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:34,038 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:34,729 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:35,527 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:36,413 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  80%|████████  | 12/15 [03:28<00:50, 17.00s/it][WARNING|generation_utils.py:914] 2023-08-29 14:26:37,112 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:37,836 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:38,514 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:39,358 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:40,089 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:40,823 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:41,579 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:42,324 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:43,036 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:43,843 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:44,531 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:45,254 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:46,129 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:46,817 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:47,549 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:48,317 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:48,965 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:49,813 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:50,570 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:51,269 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:51,945 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  87%|████████▋ | 13/15 [03:44<00:33, 16.55s/it][WARNING|generation_utils.py:914] 2023-08-29 14:26:52,634 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:53,389 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:54,059 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:54,802 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:55,478 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:56,211 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:56,963 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:57,707 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:58,476 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:59,222 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:26:59,976 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:00,631 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:01,373 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:02,149 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:02,852 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:03,652 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:04,353 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:05,225 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:05,864 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:06,575 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:07,273 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:08,132 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:08,837 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:09,616 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:10,545 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating:  93%|█████████▎| 14/15 [04:03<00:17, 17.19s/it][WARNING|generation_utils.py:914] 2023-08-29 14:27:11,279 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:12,042 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:12,752 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:13,466 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:14,262 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:14,962 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:15,729 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:16,594 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:17,414 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:18,243 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:19,250 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:20,111 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:20,814 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:21,580 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:22,300 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:23,021 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:23,839 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:24,549 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:25,293 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:26,027 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:26,824 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:27,565 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:28,371 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:29,150 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
[WARNING|generation_utils.py:914] 2023-08-29 14:27:29,915 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Generating: 100%|██████████| 15/15 [04:22<00:00, 17.86s/it]Generating: 100%|██████████| 15/15 [04:22<00:00, 17.50s/it]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:37,320 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:37,323 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:37,323 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:37,323 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:37,323 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 14:27:38,053 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 14:27:38,054 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:27:38,628 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 14:27:39,725 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:27:39,725 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:42,646 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:42,649 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:42,649 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:42,649 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:27:42,649 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 14:27:43,446 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 14:27:43,447 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:27:44,148 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 14:27:44,312 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:27:44,312 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
['Relation : country . Context : The World Cup won the inaugural competition under the FIFA Confederation Cup 1994 , but at different times it had been contested in different competitions around the world . Head Entity : World Cup , Tail Entity : Brazil .\n']
{'target': 600, 'success': 22, 'raw': 32}
{'target': 600, 'success': 50, 'raw': 64}
{'target': 600, 'success': 74, 'raw': 96}
{'target': 600, 'success': 99, 'raw': 128}
{'target': 600, 'success': 121, 'raw': 160}
{'target': 600, 'success': 148, 'raw': 192}
{'target': 600, 'success': 175, 'raw': 224}
{'target': 600, 'success': 198, 'raw': 256}
{'target': 600, 'success': 226, 'raw': 288}
{'target': 600, 'success': 253, 'raw': 320}
{'target': 600, 'success': 277, 'raw': 352}
{'target': 600, 'success': 304, 'raw': 384}
{'target': 600, 'success': 332, 'raw': 416}
{'target': 600, 'success': 359, 'raw': 448}
{'target': 600, 'success': 387, 'raw': 480}
{'target': 600, 'success': 413, 'raw': 512}
{'target': 600, 'success': 437, 'raw': 544}
{'target': 600, 'success': 468, 'raw': 576}
{'target': 600, 'success': 494, 'raw': 608}
{'target': 600, 'success': 523, 'raw': 640}
{'target': 600, 'success': 548, 'raw': 672}
{'target': 600, 'success': 573, 'raw': 704}
{'target': 600, 'success': 601, 'raw': 736}
{'prompt': 'Relation : country .', 'success_rate': 0.8165760869565217, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 27, 'raw': 32}
{'target': 600, 'success': 52, 'raw': 64}
{'target': 600, 'success': 77, 'raw': 96}
{'target': 600, 'success': 102, 'raw': 128}
{'target': 600, 'success': 128, 'raw': 160}
{'target': 600, 'success': 151, 'raw': 192}
{'target': 600, 'success': 176, 'raw': 224}
{'target': 600, 'success': 206, 'raw': 256}
{'target': 600, 'success': 230, 'raw': 288}
{'target': 600, 'success': 256, 'raw': 320}
{'target': 600, 'success': 283, 'raw': 352}
{'target': 600, 'success': 305, 'raw': 384}
{'target': 600, 'success': 331, 'raw': 416}
{'target': 600, 'success': 359, 'raw': 448}
{'target': 600, 'success': 384, 'raw': 480}
{'target': 600, 'success': 405, 'raw': 512}
{'target': 600, 'success': 431, 'raw': 544}
{'target': 600, 'success': 454, 'raw': 576}
{'target': 600, 'success': 477, 'raw': 608}
{'target': 600, 'success': 503, 'raw': 640}
{'target': 600, 'success': 529, 'raw': 672}
{'target': 600, 'success': 555, 'raw': 704}
{'target': 600, 'success': 580, 'raw': 736}
{'target': 600, 'success': 602, 'raw': 768}
{'prompt': 'Relation : place of death .', 'success_rate': 0.7838541666666666, 'errors': {'', 'not enough values to unpack (expected 2, got 1)', 'too many values to unpack (expected 2)'}}
{'target': 600, 'success': 24, 'raw': 32}
{'target': 600, 'success': 48, 'raw': 64}
{'target': 600, 'success': 73, 'raw': 96}
{'target': 600, 'success': 101, 'raw': 128}
{'target': 600, 'success': 128, 'raw': 160}
{'target': 600, 'success': 155, 'raw': 192}
{'target': 600, 'success': 181, 'raw': 224}
{'target': 600, 'success': 202, 'raw': 256}
{'target': 600, 'success': 226, 'raw': 288}
{'target': 600, 'success': 251, 'raw': 320}
{'target': 600, 'success': 276, 'raw': 352}
{'target': 600, 'success': 302, 'raw': 384}
{'target': 600, 'success': 324, 'raw': 416}
{'target': 600, 'success': 350, 'raw': 448}
{'target': 600, 'success': 374, 'raw': 480}
{'target': 600, 'success': 398, 'raw': 512}
{'target': 600, 'success': 421, 'raw': 544}
{'target': 600, 'success': 445, 'raw': 576}
{'target': 600, 'success': 470, 'raw': 608}
{'target': 600, 'success': 499, 'raw': 640}
{'target': 600, 'success': 526, 'raw': 672}
{'target': 600, 'success': 552, 'raw': 704}
{'target': 600, 'success': 583, 'raw': 736}
{'target': 600, 'success': 604, 'raw': 768}
{'prompt': 'Relation : production company .', 'success_rate': 0.7864583333333334, 'errors': {'', 'too many values to unpack (expected 2)'}}
{'target': 600, 'success': 28, 'raw': 32}
{'target': 600, 'success': 56, 'raw': 64}
{'target': 600, 'success': 82, 'raw': 96}
{'target': 600, 'success': 107, 'raw': 128}
{'target': 600, 'success': 132, 'raw': 160}
{'target': 600, 'success': 160, 'raw': 192}
{'target': 600, 'success': 185, 'raw': 224}
{'target': 600, 'success': 213, 'raw': 256}
{'target': 600, 'success': 242, 'raw': 288}
{'target': 600, 'success': 269, 'raw': 320}
{'target': 600, 'success': 295, 'raw': 352}
{'target': 600, 'success': 323, 'raw': 384}
{'target': 600, 'success': 350, 'raw': 416}
{'target': 600, 'success': 376, 'raw': 448}
{'target': 600, 'success': 405, 'raw': 480}
{'target': 600, 'success': 435, 'raw': 512}
{'target': 600, 'success': 463, 'raw': 544}
{'target': 600, 'success': 489, 'raw': 576}
{'target': 600, 'success': 519, 'raw': 608}
{'target': 600, 'success': 547, 'raw': 640}
{'target': 600, 'success': 575, 'raw': 672}
{'target': 600, 'success': 605, 'raw': 704}
{'prompt': 'Relation : screenwriter .', 'success_rate': 0.859375, 'errors': {'', 'not enough values to unpack (expected 2, got 1)', 'too many values to unpack (expected 2)'}}
{'target': 600, 'success': 28, 'raw': 32}
{'target': 600, 'success': 55, 'raw': 64}
{'target': 600, 'success': 83, 'raw': 96}
{'target': 600, 'success': 110, 'raw': 128}
{'target': 600, 'success': 136, 'raw': 160}
{'target': 600, 'success': 162, 'raw': 192}
{'target': 600, 'success': 188, 'raw': 224}
{'target': 600, 'success': 213, 'raw': 256}
{'target': 600, 'success': 241, 'raw': 288}
{'target': 600, 'success': 268, 'raw': 320}
{'target': 600, 'success': 294, 'raw': 352}
{'target': 600, 'success': 322, 'raw': 384}
{'target': 600, 'success': 349, 'raw': 416}
{'target': 600, 'success': 374, 'raw': 448}
{'target': 600, 'success': 402, 'raw': 480}
{'target': 600, 'success': 432, 'raw': 512}
{'target': 600, 'success': 457, 'raw': 544}
{'target': 600, 'success': 480, 'raw': 576}
{'target': 600, 'success': 504, 'raw': 608}
{'target': 600, 'success': 530, 'raw': 640}
{'target': 600, 'success': 558, 'raw': 672}
{'target': 600, 'success': 586, 'raw': 704}
{'target': 600, 'success': 613, 'raw': 736}
{'prompt': 'Relation : subsidiary .', 'success_rate': 0.8328804347826086, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
['Relation : continent . Context : The Ciancian is a class of mountain range s that is located north of the Andes , between the Andes and the Pangaea , in what is now western Peru . Head Entity : The Andes , Tail Entity : Peru .\n']
{'target': 600, 'success': 24, 'raw': 32}
{'target': 600, 'success': 47, 'raw': 64}
{'target': 600, 'success': 73, 'raw': 96}
{'target': 600, 'success': 101, 'raw': 128}
{'target': 600, 'success': 128, 'raw': 160}
{'target': 600, 'success': 151, 'raw': 192}
{'target': 600, 'success': 174, 'raw': 224}
{'target': 600, 'success': 203, 'raw': 256}
{'target': 600, 'success': 231, 'raw': 288}
{'target': 600, 'success': 256, 'raw': 320}
{'target': 600, 'success': 280, 'raw': 352}
{'target': 600, 'success': 302, 'raw': 384}
{'target': 600, 'success': 327, 'raw': 416}
{'target': 600, 'success': 354, 'raw': 448}
{'target': 600, 'success': 379, 'raw': 480}
{'target': 600, 'success': 402, 'raw': 512}
{'target': 600, 'success': 427, 'raw': 544}
{'target': 600, 'success': 455, 'raw': 576}
{'target': 600, 'success': 482, 'raw': 608}
{'target': 600, 'success': 506, 'raw': 640}
{'target': 600, 'success': 523, 'raw': 672}
{'target': 600, 'success': 546, 'raw': 704}
{'target': 600, 'success': 571, 'raw': 736}
{'target': 600, 'success': 591, 'raw': 768}
{'target': 600, 'success': 614, 'raw': 800}
{'prompt': 'Relation : continent .', 'success_rate': 0.7675, 'errors': {'', 'not enough values to unpack (expected 2, got 1)', "('Royal Navy', 'continent', '', 'Sir John O. Kiefferford was the grandson of Major O. Kiefferford ( 1829 1882 ) , who later became Royal Navy captain .')"}}
['Relation : field of this occupation . Context : The song was nominated for the Grammy Award for Best New Artist at the 2004 MTV Video Music Awards , alongside artists such as Ariana Grande , Kacey Musgraves , and Katy Perry . Head Entity : Ariana Grande , Tail Entity : the song .\n']
{'target': 600, 'success': 24, 'raw': 32}
{'target': 600, 'success': 45, 'raw': 64}
{'target': 600, 'success': 72, 'raw': 96}
{'target': 600, 'success': 96, 'raw': 128}
{'target': 600, 'success': 126, 'raw': 160}
{'target': 600, 'success': 153, 'raw': 192}
{'target': 600, 'success': 182, 'raw': 224}
{'target': 600, 'success': 210, 'raw': 256}
{'target': 600, 'success': 230, 'raw': 288}
{'target': 600, 'success': 256, 'raw': 320}
{'target': 600, 'success': 283, 'raw': 352}
{'target': 600, 'success': 309, 'raw': 384}
{'target': 600, 'success': 338, 'raw': 416}
{'target': 600, 'success': 364, 'raw': 448}
{'target': 600, 'success': 387, 'raw': 480}
{'target': 600, 'success': 409, 'raw': 512}
{'target': 600, 'success': 437, 'raw': 544}
{'target': 600, 'success': 461, 'raw': 576}
{'target': 600, 'success': 487, 'raw': 608}
{'target': 600, 'success': 514, 'raw': 640}
{'target': 600, 'success': 543, 'raw': 672}
{'target': 600, 'success': 570, 'raw': 704}
{'target': 600, 'success': 596, 'raw': 736}
{'target': 600, 'success': 624, 'raw': 768}
{'prompt': 'Relation : field of this occupation .', 'success_rate': 0.8125, 'errors': {''}}
{'target': 600, 'success': 27, 'raw': 32}
{'target': 600, 'success': 54, 'raw': 64}
{'target': 600, 'success': 79, 'raw': 96}
{'target': 600, 'success': 105, 'raw': 128}
{'target': 600, 'success': 130, 'raw': 160}
{'target': 600, 'success': 156, 'raw': 192}
{'target': 600, 'success': 180, 'raw': 224}
{'target': 600, 'success': 206, 'raw': 256}
{'target': 600, 'success': 230, 'raw': 288}
{'target': 600, 'success': 254, 'raw': 320}
{'target': 600, 'success': 274, 'raw': 352}
{'target': 600, 'success': 300, 'raw': 384}
{'target': 600, 'success': 325, 'raw': 416}
{'target': 600, 'success': 354, 'raw': 448}
{'target': 600, 'success': 383, 'raw': 480}
{'target': 600, 'success': 409, 'raw': 512}
{'target': 600, 'success': 435, 'raw': 544}
{'target': 600, 'success': 463, 'raw': 576}
{'target': 600, 'success': 488, 'raw': 608}
{'target': 600, 'success': 510, 'raw': 640}
{'target': 600, 'success': 537, 'raw': 672}
{'target': 600, 'success': 563, 'raw': 704}
{'target': 600, 'success': 588, 'raw': 736}
{'target': 600, 'success': 613, 'raw': 768}
{'prompt': 'Relation : field of work .', 'success_rate': 0.7981770833333334, 'errors': {'', "('Royal Navy', 'field of work', '', 'He was commissioned to the Royal Navy in 1916 , where he was appointed Royal Pilot of the Royal Navy .')", 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 28, 'raw': 32}
{'target': 600, 'success': 52, 'raw': 64}
{'target': 600, 'success': 79, 'raw': 96}
{'target': 600, 'success': 105, 'raw': 128}
{'target': 600, 'success': 129, 'raw': 160}
{'target': 600, 'success': 156, 'raw': 192}
{'target': 600, 'success': 182, 'raw': 224}
{'target': 600, 'success': 208, 'raw': 256}
{'target': 600, 'success': 235, 'raw': 288}
{'target': 600, 'success': 263, 'raw': 320}
{'target': 600, 'success': 290, 'raw': 352}
{'target': 600, 'success': 316, 'raw': 384}
{'target': 600, 'success': 342, 'raw': 416}
{'target': 600, 'success': 367, 'raw': 448}
{'target': 600, 'success': 396, 'raw': 480}
{'target': 600, 'success': 424, 'raw': 512}
{'target': 600, 'success': 449, 'raw': 544}
{'target': 600, 'success': 475, 'raw': 576}
{'target': 600, 'success': 499, 'raw': 608}
{'target': 600, 'success': 528, 'raw': 640}
{'target': 600, 'success': 553, 'raw': 672}
{'target': 600, 'success': 577, 'raw': 704}
{'target': 600, 'success': 601, 'raw': 736}
{'prompt': 'Relation : founded by .', 'success_rate': 0.8165760869565217, 'errors': {''}}
{'target': 600, 'success': 26, 'raw': 32}
{'target': 600, 'success': 54, 'raw': 64}
{'target': 600, 'success': 80, 'raw': 96}
{'target': 600, 'success': 109, 'raw': 128}
{'target': 600, 'success': 137, 'raw': 160}
{'target': 600, 'success': 164, 'raw': 192}
{'target': 600, 'success': 191, 'raw': 224}
{'target': 600, 'success': 217, 'raw': 256}
{'target': 600, 'success': 244, 'raw': 288}
{'target': 600, 'success': 268, 'raw': 320}
{'target': 600, 'success': 296, 'raw': 352}
{'target': 600, 'success': 326, 'raw': 384}
{'target': 600, 'success': 349, 'raw': 416}
{'target': 600, 'success': 371, 'raw': 448}
{'target': 600, 'success': 401, 'raw': 480}
{'target': 600, 'success': 424, 'raw': 512}
{'target': 600, 'success': 446, 'raw': 544}
{'target': 600, 'success': 470, 'raw': 576}
{'target': 600, 'success': 501, 'raw': 608}
{'target': 600, 'success': 531, 'raw': 640}
{'target': 600, 'success': 552, 'raw': 672}
{'target': 600, 'success': 576, 'raw': 704}
{'target': 600, 'success': 604, 'raw': 736}
{'prompt': 'Relation : movement .', 'success_rate': 0.8206521739130435, 'errors': {'', 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 28, 'raw': 32}
{'target': 600, 'success': 55, 'raw': 64}
{'target': 600, 'success': 83, 'raw': 96}
{'target': 600, 'success': 110, 'raw': 128}
{'target': 600, 'success': 138, 'raw': 160}
{'target': 600, 'success': 163, 'raw': 192}
{'target': 600, 'success': 188, 'raw': 224}
{'target': 600, 'success': 217, 'raw': 256}
{'target': 600, 'success': 242, 'raw': 288}
{'target': 600, 'success': 273, 'raw': 320}
{'target': 600, 'success': 300, 'raw': 352}
{'target': 600, 'success': 329, 'raw': 384}
{'target': 600, 'success': 356, 'raw': 416}
{'target': 600, 'success': 381, 'raw': 448}
{'target': 600, 'success': 407, 'raw': 480}
{'target': 600, 'success': 435, 'raw': 512}
{'target': 600, 'success': 460, 'raw': 544}
{'target': 600, 'success': 488, 'raw': 576}
{'target': 600, 'success': 514, 'raw': 608}
{'target': 600, 'success': 541, 'raw': 640}
{'target': 600, 'success': 565, 'raw': 672}
{'target': 600, 'success': 589, 'raw': 704}
{'target': 600, 'success': 617, 'raw': 736}
{'prompt': 'Relation : owned by .', 'success_rate': 0.8383152173913043, 'errors': {''}}
{'target': 600, 'success': 30, 'raw': 32}
{'target': 600, 'success': 59, 'raw': 64}
{'target': 600, 'success': 86, 'raw': 96}
{'target': 600, 'success': 115, 'raw': 128}
{'target': 600, 'success': 147, 'raw': 160}
{'target': 600, 'success': 176, 'raw': 192}
{'target': 600, 'success': 205, 'raw': 224}
{'target': 600, 'success': 235, 'raw': 256}
{'target': 600, 'success': 264, 'raw': 288}
{'target': 600, 'success': 294, 'raw': 320}
{'target': 600, 'success': 323, 'raw': 352}
{'target': 600, 'success': 352, 'raw': 384}
{'target': 600, 'success': 380, 'raw': 416}
{'target': 600, 'success': 406, 'raw': 448}
{'target': 600, 'success': 437, 'raw': 480}
{'target': 600, 'success': 466, 'raw': 512}
{'target': 600, 'success': 497, 'raw': 544}
{'target': 600, 'success': 525, 'raw': 576}
{'target': 600, 'success': 554, 'raw': 608}
{'target': 600, 'success': 583, 'raw': 640}
{'target': 600, 'success': 611, 'raw': 672}
{'prompt': 'Relation : performer .', 'success_rate': 0.9092261904761905, 'errors': {'', "('The Sun', 'performer', '', 'The night was also attended by performances by the BBC as well as The Edge , The Wire , The Voice , The Good Wife , and The Sun .')", 'not enough values to unpack (expected 2, got 1)'}}
{'target': 600, 'success': 29, 'raw': 32}
{'target': 600, 'success': 58, 'raw': 64}
{'target': 600, 'success': 86, 'raw': 96}
{'target': 600, 'success': 112, 'raw': 128}
{'target': 600, 'success': 142, 'raw': 160}
{'target': 600, 'success': 172, 'raw': 192}
{'target': 600, 'success': 198, 'raw': 224}
{'target': 600, 'success': 229, 'raw': 256}
{'target': 600, 'success': 259, 'raw': 288}
{'target': 600, 'success': 288, 'raw': 320}
{'target': 600, 'success': 317, 'raw': 352}
{'target': 600, 'success': 347, 'raw': 384}
{'target': 600, 'success': 378, 'raw': 416}
{'target': 600, 'success': 404, 'raw': 448}
{'target': 600, 'success': 431, 'raw': 480}
{'target': 600, 'success': 463, 'raw': 512}
{'target': 600, 'success': 494, 'raw': 544}
{'target': 600, 'success': 518, 'raw': 576}
{'target': 600, 'success': 547, 'raw': 608}
{'target': 600, 'success': 576, 'raw': 640}
{'target': 600, 'success': 607, 'raw': 672}
{'prompt': 'Relation : producer .', 'success_rate': 0.9032738095238095, 'errors': {''}}
['Relation : record label . Context : Later in 2008 , he recorded his third studio album , The All Day , entitled All Day And I , released in September 2010 . Head Entity : The All Day , Tail Entity : Record label .\n']
{'target': 600, 'success': 22, 'raw': 32}
{'target': 600, 'success': 48, 'raw': 64}
{'target': 600, 'success': 75, 'raw': 96}
{'target': 600, 'success': 97, 'raw': 128}
{'target': 600, 'success': 121, 'raw': 160}
{'target': 600, 'success': 148, 'raw': 192}
{'target': 600, 'success': 172, 'raw': 224}
{'target': 600, 'success': 196, 'raw': 256}
{'target': 600, 'success': 219, 'raw': 288}
{'target': 600, 'success': 247, 'raw': 320}
{'target': 600, 'success': 272, 'raw': 352}
{'target': 600, 'success': 296, 'raw': 384}
{'target': 600, 'success': 321, 'raw': 416}
{'target': 600, 'success': 343, 'raw': 448}
{'target': 600, 'success': 368, 'raw': 480}
{'target': 600, 'success': 397, 'raw': 512}
{'target': 600, 'success': 422, 'raw': 544}
{'target': 600, 'success': 446, 'raw': 576}
{'target': 600, 'success': 465, 'raw': 608}
{'target': 600, 'success': 487, 'raw': 640}
{'target': 600, 'success': 511, 'raw': 672}
{'target': 600, 'success': 535, 'raw': 704}
{'target': 600, 'success': 555, 'raw': 736}
{'target': 600, 'success': 581, 'raw': 768}
{'target': 600, 'success': 604, 'raw': 800}
{'prompt': 'Relation : record label .', 'success_rate': 0.755, 'errors': {'', 'not enough values to unpack (expected 2, got 1)', "('George Hormatsky', 'record label', '', 'A compilation album released in 2008 , it featured EPs All The Way Down ( with Keith Urban ) , I Wanna Leave You ( with Dave Chappelle ) and My Uncle , My Cousin Vinny ( with George Hormatsky ) .')"}}
{'target': 600, 'success': 23, 'raw': 32}
{'target': 600, 'success': 47, 'raw': 64}
{'target': 600, 'success': 70, 'raw': 96}
{'target': 600, 'success': 94, 'raw': 128}
{'target': 600, 'success': 122, 'raw': 160}
{'target': 600, 'success': 149, 'raw': 192}
{'target': 600, 'success': 173, 'raw': 224}
{'target': 600, 'success': 201, 'raw': 256}
{'target': 600, 'success': 230, 'raw': 288}
{'target': 600, 'success': 254, 'raw': 320}
{'target': 600, 'success': 283, 'raw': 352}
{'target': 600, 'success': 306, 'raw': 384}
{'target': 600, 'success': 336, 'raw': 416}
{'target': 600, 'success': 362, 'raw': 448}
{'target': 600, 'success': 388, 'raw': 480}
{'target': 600, 'success': 412, 'raw': 512}
{'target': 600, 'success': 434, 'raw': 544}
{'target': 600, 'success': 458, 'raw': 576}
{'target': 600, 'success': 477, 'raw': 608}
{'target': 600, 'success': 501, 'raw': 640}
{'target': 600, 'success': 529, 'raw': 672}
{'target': 600, 'success': 551, 'raw': 704}
{'target': 600, 'success': 572, 'raw': 736}
{'target': 600, 'success': 597, 'raw': 768}
{'target': 600, 'success': 619, 'raw': 800}
{'prompt': 'Relation : replaces .', 'success_rate': 0.77375, 'errors': {'', "('Cimmerian', 'replaces', '', 'According to Greek law , Nefarius lived at the shrine of Bacchus ( The Temple of Bacchus ) for 100 years until he surrendered to the Phrygian Cimmerian , who led the Greeks to believe that the god Bacchus is nefarius .')", 'not enough values to unpack (expected 2, got 1)', 'too many values to unpack (expected 2)'}}
{'estimate': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/4.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/4_ext.jsonl'}}
estimate vocab size: 14774
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 14874, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/data/estimate.txt
Extractor Estimating: 0it [00:00, ?it/s]Extractor Estimating: 1it [00:00,  1.31it/s]Extractor Estimating: 2it [00:01,  1.35it/s]Extractor Estimating: 3it [00:02,  1.44it/s]Extractor Estimating: 4it [00:02,  1.54it/s]Extractor Estimating: 5it [00:03,  1.54it/s]Extractor Estimating: 6it [00:04,  1.54it/s]Extractor Estimating: 7it [00:04,  1.52it/s]Extractor Estimating: 8it [00:05,  1.52it/s]Extractor Estimating: 9it [00:05,  1.52it/s]Extractor Estimating: 10it [00:06,  1.54it/s]Extractor Estimating: 11it [00:07,  1.19it/s]Extractor Estimating: 12it [00:08,  1.28it/s]Extractor Estimating: 13it [00:09,  1.38it/s]Extractor Estimating: 14it [00:09,  1.36it/s]Extractor Estimating: 15it [00:10,  1.43it/s]Extractor Estimating: 16it [00:11,  1.46it/s]Extractor Estimating: 17it [00:11,  1.47it/s]Extractor Estimating: 18it [00:12,  1.47it/s]Extractor Estimating: 19it [00:13,  1.45it/s]Extractor Estimating: 20it [00:13,  1.46it/s]Extractor Estimating: 21it [00:14,  1.50it/s]Extractor Estimating: 22it [00:15,  1.53it/s]Extractor Estimating: 23it [00:15,  1.49it/s]Extractor Estimating: 24it [00:16,  1.50it/s]Extractor Estimating: 25it [00:17,  1.56it/s]Extractor Estimating: 26it [00:17,  1.53it/s]Extractor Estimating: 27it [00:18,  1.47it/s]Extractor Estimating: 28it [00:19,  1.46it/s]Extractor Estimating: 29it [00:19,  1.43it/s]Extractor Estimating: 30it [00:20,  1.39it/s]Extractor Estimating: 31it [00:22,  1.11s/it]Extractor Estimating: 32it [00:23,  1.02it/s]Extractor Estimating: 33it [00:24,  1.12it/s]Extractor Estimating: 34it [00:24,  1.22it/s]Extractor Estimating: 35it [00:25,  1.25it/s]Extractor Estimating: 36it [00:26,  1.29it/s]Extractor Estimating: 37it [00:26,  1.32it/s]Extractor Estimating: 38it [00:27,  1.37it/s]Extractor Estimating: 39it [00:28,  1.40it/s]Extractor Estimating: 40it [00:28,  1.42it/s]Extractor Estimating: 41it [00:29,  1.40it/s]Extractor Estimating: 42it [00:30,  1.43it/s]Extractor Estimating: 43it [00:31,  1.38it/s]Extractor Estimating: 44it [00:31,  1.40it/s]Extractor Estimating: 45it [00:32,  1.41it/s]Extractor Estimating: 46it [00:33,  1.42it/s]Extractor Estimating: 47it [00:33,  1.41it/s]Extractor Estimating: 48it [00:34,  1.43it/s]Extractor Estimating: 49it [00:35,  1.42it/s]Extractor Estimating: 50it [00:36,  1.39it/s]Extractor Estimating: 51it [00:36,  1.43it/s]Extractor Estimating: 52it [00:37,  1.46it/s]Extractor Estimating: 53it [00:38,  1.49it/s]Extractor Estimating: 54it [00:38,  1.47it/s]Extractor Estimating: 55it [00:39,  1.45it/s]Extractor Estimating: 56it [00:40,  1.45it/s]Extractor Estimating: 57it [00:40,  1.46it/s]Extractor Estimating: 58it [00:41,  1.45it/s]Extractor Estimating: 59it [00:42,  1.45it/s]Extractor Estimating: 60it [00:42,  1.48it/s]Extractor Estimating: 61it [00:43,  1.53it/s]Extractor Estimating: 62it [00:44,  1.50it/s]Extractor Estimating: 63it [00:44,  1.50it/s]Extractor Estimating: 64it [00:45,  1.52it/s]Extractor Estimating: 65it [00:46,  1.48it/s]Extractor Estimating: 66it [00:46,  1.51it/s]Extractor Estimating: 67it [00:47,  1.51it/s]Extractor Estimating: 68it [00:48,  1.57it/s]Extractor Estimating: 69it [00:48,  1.54it/s]Extractor Estimating: 70it [00:49,  1.52it/s]Extractor Estimating: 71it [00:50,  1.51it/s]Extractor Estimating: 72it [00:50,  1.49it/s]Extractor Estimating: 73it [00:51,  1.43it/s]Extractor Estimating: 74it [00:52,  1.48it/s]Extractor Estimating: 75it [00:52,  1.44it/s]Extractor Estimating: 76it [00:53,  1.47it/s]Extractor Estimating: 77it [00:54,  1.50it/s]Extractor Estimating: 78it [00:54,  1.51it/s]Extractor Estimating: 79it [00:55,  1.48it/s]Extractor Estimating: 80it [00:56,  1.51it/s]Extractor Estimating: 81it [00:56,  1.49it/s]Extractor Estimating: 82it [00:57,  1.48it/s]Extractor Estimating: 83it [00:58,  1.49it/s]Extractor Estimating: 84it [00:59,  1.15it/s]Extractor Estimating: 85it [01:00,  1.26it/s]Extractor Estimating: 86it [01:00,  1.28it/s]Extractor Estimating: 87it [01:01,  1.34it/s]Extractor Estimating: 88it [01:02,  1.35it/s]Extractor Estimating: 89it [01:02,  1.39it/s]Extractor Estimating: 90it [01:03,  1.42it/s]Extractor Estimating: 91it [01:04,  1.44it/s]Extractor Estimating: 92it [01:04,  1.49it/s]Extractor Estimating: 93it [01:05,  1.50it/s]Extractor Estimating: 94it [01:06,  1.49it/s]Extractor Estimating: 95it [01:06,  1.51it/s]Extractor Estimating: 96it [01:07,  1.48it/s]Extractor Estimating: 97it [01:08,  1.52it/s]Extractor Estimating: 98it [01:08,  1.50it/s]Extractor Estimating: 99it [01:09,  1.50it/s]Extractor Estimating: 100it [01:10,  1.47it/s]Extractor Estimating: 101it [01:10,  1.49it/s]Extractor Estimating: 102it [01:11,  1.49it/s]Extractor Estimating: 103it [01:12,  1.48it/s]Extractor Estimating: 104it [01:12,  1.52it/s]Extractor Estimating: 105it [01:13,  1.55it/s]Extractor Estimating: 106it [01:14,  1.54it/s]Extractor Estimating: 107it [01:15,  1.42it/s]Extractor Estimating: 108it [01:15,  1.47it/s]Extractor Estimating: 109it [01:16,  1.46it/s]Extractor Estimating: 110it [01:17,  1.45it/s]Extractor Estimating: 111it [01:17,  1.42it/s]Extractor Estimating: 112it [01:18,  1.48it/s]Extractor Estimating: 113it [01:19,  1.50it/s]Extractor Estimating: 114it [01:19,  1.53it/s]Extractor Estimating: 115it [01:20,  1.49it/s]Extractor Estimating: 116it [01:21,  1.42it/s]Extractor Estimating: 117it [01:21,  1.49it/s]Extractor Estimating: 118it [01:22,  1.50it/s]Extractor Estimating: 119it [01:23,  1.43it/s]Extractor Estimating: 120it [01:23,  1.46it/s]Extractor Estimating: 121it [01:24,  1.48it/s]Extractor Estimating: 122it [01:25,  1.43it/s]Extractor Estimating: 123it [01:25,  1.44it/s]Extractor Estimating: 124it [01:26,  1.50it/s]Extractor Estimating: 125it [01:27,  1.46it/s]Extractor Estimating: 126it [01:27,  1.50it/s]Extractor Estimating: 127it [01:28,  1.50it/s]Extractor Estimating: 128it [01:29,  1.56it/s]Extractor Estimating: 129it [01:29,  1.61it/s]Extractor Estimating: 130it [01:30,  1.60it/s]Extractor Estimating: 131it [01:30,  1.60it/s]Extractor Estimating: 132it [01:32,  1.19it/s]Extractor Estimating: 133it [01:32,  1.26it/s]Extractor Estimating: 134it [01:33,  1.32it/s]Extractor Estimating: 135it [01:34,  1.39it/s]Extractor Estimating: 136it [01:34,  1.45it/s]Extractor Estimating: 137it [01:35,  1.51it/s]Extractor Estimating: 138it [01:36,  1.52it/s]Extractor Estimating: 139it [01:36,  1.55it/s]Extractor Estimating: 140it [01:37,  1.55it/s]Extractor Estimating: 141it [01:37,  1.59it/s]Extractor Estimating: 142it [01:38,  1.62it/s]Extractor Estimating: 143it [01:39,  1.51it/s]Extractor Estimating: 144it [01:39,  1.55it/s]Extractor Estimating: 145it [01:40,  1.56it/s]Extractor Estimating: 146it [01:41,  1.52it/s]Extractor Estimating: 147it [01:41,  1.57it/s]Extractor Estimating: 148it [01:42,  1.56it/s]Extractor Estimating: 149it [01:43,  1.55it/s]Extractor Estimating: 150it [01:43,  1.57it/s]Extractor Estimating: 151it [01:44,  1.58it/s]Extractor Estimating: 152it [01:45,  1.59it/s]Extractor Estimating: 153it [01:45,  1.57it/s]Extractor Estimating: 154it [01:46,  1.55it/s]Extractor Estimating: 155it [01:46,  1.56it/s]Extractor Estimating: 156it [01:47,  1.54it/s]Extractor Estimating: 157it [01:48,  1.53it/s]Extractor Estimating: 158it [01:49,  1.50it/s]Extractor Estimating: 159it [01:49,  1.45it/s]Extractor Estimating: 160it [01:50,  1.44it/s]Extractor Estimating: 161it [01:51,  1.45it/s]Extractor Estimating: 162it [01:51,  1.43it/s]Extractor Estimating: 163it [01:52,  1.45it/s]Extractor Estimating: 164it [01:53,  1.47it/s]Extractor Estimating: 165it [01:53,  1.48it/s]Extractor Estimating: 166it [01:54,  1.51it/s]Extractor Estimating: 167it [01:55,  1.52it/s]Extractor Estimating: 168it [01:55,  1.54it/s]Extractor Estimating: 169it [01:56,  1.50it/s]Extractor Estimating: 170it [01:57,  1.51it/s]Extractor Estimating: 171it [01:57,  1.56it/s]Extractor Estimating: 172it [01:58,  1.57it/s]Extractor Estimating: 173it [01:59,  1.55it/s]Extractor Estimating: 174it [01:59,  1.51it/s]Extractor Estimating: 175it [02:00,  1.48it/s]Extractor Estimating: 176it [02:01,  1.47it/s]Extractor Estimating: 177it [02:01,  1.47it/s]Extractor Estimating: 178it [02:02,  1.45it/s]Extractor Estimating: 179it [02:03,  1.47it/s]Extractor Estimating: 180it [02:03,  1.51it/s]Extractor Estimating: 181it [02:04,  1.44it/s]Extractor Estimating: 182it [02:05,  1.46it/s]Extractor Estimating: 183it [02:05,  1.48it/s]Extractor Estimating: 184it [02:06,  1.45it/s]Extractor Estimating: 185it [02:07,  1.46it/s]Extractor Estimating: 186it [02:07,  1.45it/s]Extractor Estimating: 187it [02:08,  1.49it/s]Extractor Estimating: 188it [02:09,  1.47it/s]Extractor Estimating: 189it [02:09,  1.52it/s]Extractor Estimating: 190it [02:10,  1.49it/s]Extractor Estimating: 191it [02:11,  1.52it/s]Extractor Estimating: 192it [02:11,  1.48it/s]Extractor Estimating: 193it [02:12,  1.46it/s]Extractor Estimating: 194it [02:13,  1.50it/s]Extractor Estimating: 195it [02:13,  1.54it/s]Extractor Estimating: 196it [02:14,  1.54it/s]Extractor Estimating: 197it [02:15,  1.51it/s]Extractor Estimating: 198it [02:15,  1.56it/s]Extractor Estimating: 199it [02:16,  1.55it/s]Extractor Estimating: 200it [02:17,  1.46it/s]Extractor Estimating: 201it [02:17,  1.49it/s]Extractor Estimating: 202it [02:18,  1.33it/s]Extractor Estimating: 203it [02:19,  1.34it/s]Extractor Estimating: 204it [02:20,  1.39it/s]Extractor Estimating: 205it [02:20,  1.41it/s]Extractor Estimating: 206it [02:21,  1.44it/s]Extractor Estimating: 207it [02:22,  1.45it/s]Extractor Estimating: 208it [02:22,  1.45it/s]Extractor Estimating: 209it [02:23,  1.47it/s]Extractor Estimating: 210it [02:24,  1.48it/s]Extractor Estimating: 211it [02:24,  1.47it/s]Extractor Estimating: 212it [02:25,  1.48it/s]Extractor Estimating: 213it [02:26,  1.49it/s]Extractor Estimating: 214it [02:26,  1.48it/s]Extractor Estimating: 215it [02:27,  1.49it/s]Extractor Estimating: 216it [02:28,  1.50it/s]Extractor Estimating: 217it [02:28,  1.53it/s]Extractor Estimating: 218it [02:29,  1.47it/s]Extractor Estimating: 219it [02:30,  1.48it/s]Extractor Estimating: 220it [02:30,  1.50it/s]Extractor Estimating: 221it [02:31,  1.47it/s]Extractor Estimating: 222it [02:32,  1.45it/s]Extractor Estimating: 223it [02:32,  1.50it/s]Extractor Estimating: 224it [02:33,  1.51it/s]Extractor Estimating: 225it [02:34,  1.51it/s]Extractor Estimating: 226it [02:34,  1.48it/s]Extractor Estimating: 227it [02:35,  1.48it/s]Extractor Estimating: 228it [02:36,  1.47it/s]Extractor Estimating: 229it [02:37,  1.48it/s]Extractor Estimating: 230it [02:37,  1.45it/s]Extractor Estimating: 231it [02:38,  1.40it/s]Extractor Estimating: 232it [02:39,  1.43it/s]Extractor Estimating: 233it [02:39,  1.44it/s]Extractor Estimating: 234it [02:40,  1.50it/s]Extractor Estimating: 235it [02:41,  1.49it/s]Extractor Estimating: 236it [02:41,  1.53it/s]Extractor Estimating: 237it [02:42,  1.50it/s]Extractor Estimating: 238it [02:43,  1.55it/s]Extractor Estimating: 239it [02:43,  1.57it/s]Extractor Estimating: 240it [02:44,  1.52it/s]Extractor Estimating: 241it [02:45,  1.52it/s]Extractor Estimating: 242it [02:45,  1.48it/s]Extractor Estimating: 243it [02:46,  1.47it/s]Extractor Estimating: 244it [02:47,  1.46it/s]Extractor Estimating: 245it [02:47,  1.45it/s]Extractor Estimating: 246it [02:48,  1.46it/s]Extractor Estimating: 247it [02:49,  1.45it/s]Extractor Estimating: 248it [02:49,  1.49it/s]Extractor Estimating: 249it [02:50,  1.49it/s]Extractor Estimating: 250it [02:51,  1.51it/s]Extractor Estimating: 251it [02:51,  1.47it/s]Extractor Estimating: 252it [02:52,  1.47it/s]Extractor Estimating: 253it [02:53,  1.49it/s]Extractor Estimating: 254it [02:53,  1.52it/s]Extractor Estimating: 255it [02:54,  1.58it/s]Extractor Estimating: 256it [02:55,  1.58it/s]Extractor Estimating: 257it [02:55,  1.58it/s]Extractor Estimating: 258it [02:56,  1.58it/s]Extractor Estimating: 259it [02:56,  1.57it/s]Extractor Estimating: 260it [02:57,  1.51it/s]Extractor Estimating: 261it [02:58,  1.50it/s]Extractor Estimating: 262it [02:58,  1.54it/s]Extractor Estimating: 263it [02:59,  1.54it/s]Extractor Estimating: 264it [03:00,  1.56it/s]Extractor Estimating: 265it [03:00,  1.54it/s]Extractor Estimating: 266it [03:01,  1.51it/s]Extractor Estimating: 267it [03:02,  1.55it/s]Extractor Estimating: 268it [03:02,  1.58it/s]Extractor Estimating: 269it [03:03,  1.43it/s]Extractor Estimating: 270it [03:04,  1.50it/s]Extractor Estimating: 271it [03:05,  1.38it/s]Extractor Estimating: 272it [03:05,  1.39it/s]Extractor Estimating: 273it [03:06,  1.47it/s]Extractor Estimating: 274it [03:07,  1.49it/s]Extractor Estimating: 275it [03:07,  1.51it/s]Extractor Estimating: 276it [03:08,  1.51it/s]Extractor Estimating: 277it [03:09,  1.46it/s]Extractor Estimating: 278it [03:09,  1.46it/s]Extractor Estimating: 279it [03:10,  1.45it/s]Extractor Estimating: 280it [03:11,  1.48it/s]Extractor Estimating: 281it [03:11,  1.47it/s]Extractor Estimating: 282it [03:12,  1.50it/s]Extractor Estimating: 283it [03:13,  1.52it/s]Extractor Estimating: 284it [03:13,  1.51it/s]Extractor Estimating: 285it [03:14,  1.50it/s]Extractor Estimating: 286it [03:15,  1.49it/s]Extractor Estimating: 287it [03:15,  1.45it/s]Extractor Estimating: 288it [03:16,  1.46it/s]Extractor Estimating: 289it [03:17,  1.44it/s]Extractor Estimating: 290it [03:17,  1.50it/s]Extractor Estimating: 291it [03:18,  1.52it/s]Extractor Estimating: 292it [03:19,  1.53it/s]Extractor Estimating: 293it [03:19,  1.55it/s]Extractor Estimating: 294it [03:20,  1.52it/s]Extractor Estimating: 295it [03:21,  1.53it/s]Extractor Estimating: 296it [03:21,  1.50it/s]Extractor Estimating: 297it [03:22,  1.51it/s]Extractor Estimating: 298it [03:23,  1.49it/s]Extractor Estimating: 299it [03:23,  1.50it/s]Extractor Estimating: 300it [03:24,  1.49it/s]Extractor Estimating: 301it [03:25,  1.50it/s]Extractor Estimating: 302it [03:25,  1.49it/s]Extractor Estimating: 303it [03:26,  1.48it/s]Extractor Estimating: 304it [03:27,  1.49it/s]Extractor Estimating: 305it [03:27,  1.48it/s]Extractor Estimating: 306it [03:28,  1.47it/s]Extractor Estimating: 307it [03:29,  1.45it/s]Extractor Estimating: 308it [03:29,  1.43it/s]Extractor Estimating: 309it [03:30,  1.50it/s]Extractor Estimating: 310it [03:31,  1.51it/s]Extractor Estimating: 311it [03:31,  1.51it/s]Extractor Estimating: 312it [03:32,  1.51it/s]Extractor Estimating: 313it [03:33,  1.50it/s]Extractor Estimating: 314it [03:33,  1.45it/s]Extractor Estimating: 315it [03:34,  1.52it/s]Extractor Estimating: 316it [03:35,  1.53it/s]Extractor Estimating: 317it [03:35,  1.48it/s]Extractor Estimating: 318it [03:36,  1.53it/s]Extractor Estimating: 319it [03:37,  1.52it/s]Extractor Estimating: 320it [03:37,  1.43it/s]Extractor Estimating: 321it [03:38,  1.43it/s]Extractor Estimating: 322it [03:39,  1.44it/s]Extractor Estimating: 323it [03:39,  1.48it/s]Extractor Estimating: 324it [03:40,  1.48it/s]Extractor Estimating: 325it [03:41,  1.48it/s]Extractor Estimating: 326it [03:42,  1.46it/s]Extractor Estimating: 327it [03:42,  1.43it/s]Extractor Estimating: 328it [03:43,  1.47it/s]Extractor Estimating: 329it [03:44,  1.44it/s]Extractor Estimating: 330it [03:44,  1.43it/s]Extractor Estimating: 331it [03:45,  1.42it/s]Extractor Estimating: 332it [03:46,  1.46it/s]Extractor Estimating: 333it [03:46,  1.49it/s]Extractor Estimating: 334it [03:47,  1.44it/s]Extractor Estimating: 335it [03:48,  1.46it/s]Extractor Estimating: 336it [03:48,  1.43it/s]Extractor Estimating: 337it [03:49,  1.44it/s]Extractor Estimating: 338it [03:50,  1.41it/s]Extractor Estimating: 339it [03:51,  1.37it/s]Extractor Estimating: 340it [03:51,  1.41it/s]Extractor Estimating: 341it [03:52,  1.43it/s]Extractor Estimating: 342it [03:53,  1.36it/s]Extractor Estimating: 343it [03:53,  1.42it/s]Extractor Estimating: 344it [03:54,  1.40it/s]Extractor Estimating: 345it [03:55,  1.36it/s]Extractor Estimating: 346it [03:56,  1.33it/s]Extractor Estimating: 347it [03:57,  1.25it/s]Extractor Estimating: 348it [03:57,  1.27it/s]Extractor Estimating: 349it [03:58,  1.29it/s]Extractor Estimating: 350it [03:59,  1.35it/s]Extractor Estimating: 351it [04:00,  1.39it/s]Extractor Estimating: 352it [04:00,  1.46it/s]Extractor Estimating: 353it [04:01,  1.44it/s]Extractor Estimating: 354it [04:02,  1.44it/s]Extractor Estimating: 355it [04:02,  1.48it/s]Extractor Estimating: 356it [04:03,  1.50it/s]Extractor Estimating: 357it [04:04,  1.47it/s]Extractor Estimating: 358it [04:04,  1.45it/s]Extractor Estimating: 359it [04:05,  1.43it/s]Extractor Estimating: 360it [04:06,  1.42it/s]Extractor Estimating: 361it [04:06,  1.41it/s]Extractor Estimating: 362it [04:07,  1.42it/s]Extractor Estimating: 363it [04:08,  1.46it/s]Extractor Estimating: 364it [04:08,  1.42it/s]Extractor Estimating: 365it [04:09,  1.42it/s]Extractor Estimating: 366it [04:10,  1.46it/s]Extractor Estimating: 367it [04:11,  1.42it/s]Extractor Estimating: 368it [04:11,  1.44it/s]Extractor Estimating: 369it [04:12,  1.44it/s]Extractor Estimating: 370it [04:13,  1.46it/s]Extractor Estimating: 371it [04:13,  1.46it/s]Extractor Estimating: 372it [04:14,  1.47it/s]Extractor Estimating: 373it [04:15,  1.48it/s]Extractor Estimating: 374it [04:15,  1.50it/s]Extractor Estimating: 375it [04:16,  1.81it/s]Extractor Estimating: 375it [04:16,  1.46it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:17,716 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:17,720 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:17,720 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:17,720 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:17,720 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 14:32:18,382 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 14:32:18,383 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:32:18,954 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 14:32:20,066 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:32:20,066 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:22,897 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:22,901 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:22,901 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:22,901 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 14:32:22,901 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 14:32:23,571 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 14:32:23,572 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 14:32:24,267 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 14:32:24,435 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 14:32:24,435 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/module.py:1113: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[INFO|training_args.py:725] 2023-08-29 17:29:00,687 >> PyTorch: setting up devices
[INFO|training_args.py:625] 2023-08-29 17:29:00,708 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
{'filter_data_nb_rel': {'path_pseudo': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/synthetic/4_ext.jsonl', 'path_train': 'zero_rte/wiki/unseen_10_seed_3/train.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/4.jsonl', 'total_pseudo_per_label': 500, 'pseudo_ratio': 1.0, 'with_train': True, 'by_rel': False, 'version': 'all', 'rescale_train': False}}
{'num_pseudo': 7500, 'num_train': 0}
num of filtered data: 7681 mean pseudo reward: nan
fit {'path_train': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/filtered/4.jsonl', 'path_dev': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl'}
train vocab size: 27594
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 27694, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/data/train.txt
{"train_model: args: ModelArguments(model_class='JointModel', model_read_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter4/model', model_write_ckpt='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/model', pretrained_wv='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/data/train.txt', label_config=None, batch_size=24, evaluate_interval=500, max_steps=10000, max_epoches=20, decay_rate=0.05, token_emb_dim=100, char_encoder='lstm', char_emb_dim=30, cased=False, hidden_dim=200, num_layers=3, crf=None, loss_reduction='sum', maxlen=None, dropout=0.5, optimizer='adam', lr=0.001, vocab_size=27694, vocab_file=None, ner_tag_vocab_size=64, re_tag_vocab_size=250, lm_emb_dim=1024, lm_emb_path='albert-large-v2', head_emb_dim=384, tag_form='iob2', warm_steps=1000, grad_period=1, device='cuda', seed=42)"}
warm up: learning rate was adjusted to 1e-06
warm up: learning rate was adjusted to 1.1e-05
warm up: learning rate was adjusted to 2.1000000000000002e-05
warm up: learning rate was adjusted to 3.1e-05
warm up: learning rate was adjusted to 4.1e-05
warm up: learning rate was adjusted to 5.1000000000000006e-05
warm up: learning rate was adjusted to 6.1e-05
warm up: learning rate was adjusted to 7.1e-05
warm up: learning rate was adjusted to 8.1e-05
warm up: learning rate was adjusted to 9.1e-05
g_step 100, step 100, avg_time 1.563, loss:nan
warm up: learning rate was adjusted to 0.000101
warm up: learning rate was adjusted to 0.000111
warm up: learning rate was adjusted to 0.000121
warm up: learning rate was adjusted to 0.000131
warm up: learning rate was adjusted to 0.000141
warm up: learning rate was adjusted to 0.00015099999999999998
warm up: learning rate was adjusted to 0.000161
warm up: learning rate was adjusted to 0.000171
warm up: learning rate was adjusted to 0.00018099999999999998
warm up: learning rate was adjusted to 0.000191
g_step 200, step 200, avg_time 1.192, loss:nan
warm up: learning rate was adjusted to 0.000201
warm up: learning rate was adjusted to 0.000211
warm up: learning rate was adjusted to 0.000221
warm up: learning rate was adjusted to 0.000231
warm up: learning rate was adjusted to 0.000241
warm up: learning rate was adjusted to 0.000251
warm up: learning rate was adjusted to 0.000261
warm up: learning rate was adjusted to 0.00027100000000000003
warm up: learning rate was adjusted to 0.00028100000000000005
warm up: learning rate was adjusted to 0.00029099999999999997
g_step 300, step 300, avg_time 1.179, loss:nan
warm up: learning rate was adjusted to 0.000301
warm up: learning rate was adjusted to 0.000311
warm up: learning rate was adjusted to 0.000321
warm up: learning rate was adjusted to 0.000331
warm up: learning rate was adjusted to 0.00034100000000000005
warm up: learning rate was adjusted to 0.000351
warm up: learning rate was adjusted to 0.000361
warm up: learning rate was adjusted to 0.000371
warm up: learning rate was adjusted to 0.000381
warm up: learning rate was adjusted to 0.000391
g_step 400, step 79, avg_time 1.199, loss:nan
warm up: learning rate was adjusted to 0.00040100000000000004
warm up: learning rate was adjusted to 0.000411
warm up: learning rate was adjusted to 0.000421
warm up: learning rate was adjusted to 0.000431
warm up: learning rate was adjusted to 0.000441
warm up: learning rate was adjusted to 0.000451
warm up: learning rate was adjusted to 0.00046100000000000004
warm up: learning rate was adjusted to 0.000471
warm up: learning rate was adjusted to 0.000481
warm up: learning rate was adjusted to 0.000491
g_step 500, step 179, avg_time 1.206, loss:nan
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
new max entity f1 on valid!
new max relation f1 on valid!
new max relation f1 with NER on valid!
new max averaged entity f1 and relation f1 on valid!
new max averaged entity f1 and relation f1 with NER on valid!
warm up: learning rate was adjusted to 0.000501
warm up: learning rate was adjusted to 0.0005110000000000001
warm up: learning rate was adjusted to 0.000521
warm up: learning rate was adjusted to 0.000531
warm up: learning rate was adjusted to 0.000541
warm up: learning rate was adjusted to 0.0005510000000000001
warm up: learning rate was adjusted to 0.0005610000000000001
warm up: learning rate was adjusted to 0.0005710000000000001
warm up: learning rate was adjusted to 0.0005809999999999999
warm up: learning rate was adjusted to 0.0005909999999999999
g_step 600, step 279, avg_time 3.626, loss:nan
warm up: learning rate was adjusted to 0.000601
warm up: learning rate was adjusted to 0.000611
warm up: learning rate was adjusted to 0.000621
warm up: learning rate was adjusted to 0.000631
warm up: learning rate was adjusted to 0.000641
warm up: learning rate was adjusted to 0.000651
warm up: learning rate was adjusted to 0.000661
warm up: learning rate was adjusted to 0.000671
warm up: learning rate was adjusted to 0.0006810000000000001
warm up: learning rate was adjusted to 0.0006910000000000001
g_step 700, step 58, avg_time 1.197, loss:nan
warm up: learning rate was adjusted to 0.000701
warm up: learning rate was adjusted to 0.0007109999999999999
warm up: learning rate was adjusted to 0.000721
warm up: learning rate was adjusted to 0.000731
warm up: learning rate was adjusted to 0.000741
warm up: learning rate was adjusted to 0.000751
warm up: learning rate was adjusted to 0.000761
warm up: learning rate was adjusted to 0.000771
warm up: learning rate was adjusted to 0.000781
warm up: learning rate was adjusted to 0.000791
g_step 800, step 158, avg_time 1.189, loss:nan
warm up: learning rate was adjusted to 0.0008010000000000001
warm up: learning rate was adjusted to 0.0008110000000000001
warm up: learning rate was adjusted to 0.0008210000000000001
warm up: learning rate was adjusted to 0.000831
warm up: learning rate was adjusted to 0.000841
warm up: learning rate was adjusted to 0.000851
warm up: learning rate was adjusted to 0.000861
warm up: learning rate was adjusted to 0.000871
warm up: learning rate was adjusted to 0.0008810000000000001
warm up: learning rate was adjusted to 0.000891
g_step 900, step 258, avg_time 1.205, loss:nan
warm up: learning rate was adjusted to 0.000901
warm up: learning rate was adjusted to 0.000911
warm up: learning rate was adjusted to 0.000921
warm up: learning rate was adjusted to 0.0009310000000000001
warm up: learning rate was adjusted to 0.0009410000000000001
warm up: learning rate was adjusted to 0.000951
warm up: learning rate was adjusted to 0.0009609999999999999
warm up: learning rate was adjusted to 0.000971
warm up: learning rate was adjusted to 0.0009809999999999999
warm up: learning rate was adjusted to 0.000991
g_step 1000, step 37, avg_time 1.196, loss:nan
learning rate was adjusted to 0.0009523809523809524
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 1100, step 137, avg_time 3.636, loss:nan
g_step 1200, step 237, avg_time 1.186, loss:nan
g_step 1300, step 16, avg_time 1.159, loss:nan
g_step 1400, step 116, avg_time 1.179, loss:nan
g_step 1500, step 216, avg_time 1.180, loss:nan
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 1600, step 316, avg_time 3.595, loss:nan
g_step 1700, step 95, avg_time 1.163, loss:nan
g_step 1800, step 195, avg_time 1.202, loss:nan
g_step 1900, step 295, avg_time 1.195, loss:nan
g_step 2000, step 74, avg_time 1.194, loss:nan
learning rate was adjusted to 0.0009090909090909091
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 2100, step 174, avg_time 3.612, loss:nan
g_step 2200, step 274, avg_time 1.182, loss:nan
g_step 2300, step 53, avg_time 1.198, loss:nan
g_step 2400, step 153, avg_time 1.199, loss:nan
g_step 2500, step 253, avg_time 1.198, loss:nan
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 2600, step 32, avg_time 3.636, loss:nan
g_step 2700, step 132, avg_time 1.202, loss:nan
g_step 2800, step 232, avg_time 1.189, loss:nan
g_step 2900, step 11, avg_time 1.188, loss:nan
g_step 3000, step 111, avg_time 1.193, loss:nan
learning rate was adjusted to 0.0008695652173913044
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 3100, step 211, avg_time 3.613, loss:nan
g_step 3200, step 311, avg_time 1.182, loss:nan
g_step 3300, step 90, avg_time 1.200, loss:nan
g_step 3400, step 190, avg_time 1.186, loss:nan
g_step 3500, step 290, avg_time 1.193, loss:nan
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 3600, step 69, avg_time 3.609, loss:nan
g_step 3700, step 169, avg_time 1.185, loss:nan
g_step 3800, step 269, avg_time 1.172, loss:nan
g_step 3900, step 48, avg_time 1.202, loss:nan
g_step 4000, step 148, avg_time 1.199, loss:nan
learning rate was adjusted to 0.0008333333333333334
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 4100, step 248, avg_time 3.609, loss:nan
g_step 4200, step 27, avg_time 1.196, loss:nan
g_step 4300, step 127, avg_time 1.186, loss:nan
g_step 4400, step 227, avg_time 1.188, loss:nan
g_step 4500, step 6, avg_time 1.198, loss:nan
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 4600, step 106, avg_time 3.619, loss:nan
g_step 4700, step 206, avg_time 1.213, loss:nan
g_step 4800, step 306, avg_time 1.196, loss:nan
g_step 4900, step 85, avg_time 1.177, loss:nan
g_step 5000, step 185, avg_time 1.205, loss:nan
learning rate was adjusted to 0.0008
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 5100, step 285, avg_time 3.601, loss:nan
g_step 5200, step 64, avg_time 1.193, loss:nan
g_step 5300, step 164, avg_time 1.193, loss:nan
g_step 5400, step 264, avg_time 1.194, loss:nan
g_step 5500, step 43, avg_time 1.213, loss:nan
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 5600, step 143, avg_time 3.642, loss:nan
g_step 5700, step 243, avg_time 1.194, loss:nan
g_step 5800, step 22, avg_time 1.183, loss:nan
g_step 5900, step 122, avg_time 1.174, loss:nan
g_step 6000, step 222, avg_time 1.176, loss:nan
learning rate was adjusted to 0.0007692307692307692
>> valid entity prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation prec:0.0000, rec:0.0000, f1:0.0000
>> valid relation with NER prec:0.0000, rec:0.0000, f1:0.0000
g_step 6100, step 1, avg_time 3.601, loss:nan
g_step 6200, step 101, avg_time 1.191, loss:nan
g_step 6300, step 201, avg_time 1.178, loss:nan
g_step 6400, step 301, avg_time 1.188, loss:nan
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
{'select_model': RelationGenerator(model_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model', data_dir='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/data', model_name='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model', do_pretrain=False, encoder_name='generate', pipe_name='text-generation', batch_size=32, grad_accumulation=2, random_seed=42, warmup_ratio=0.2, lr_pretrain=0.0003, lr_finetune=3e-05, epochs_pretrain=3, epochs_finetune=5, train_fp16=True, block_size=128)}
08/29/2023 17:29:00 - WARNING - transformer_base.run_clm_rl -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True
08/29/2023 17:29:00 - INFO - transformer_base.run_clm_rl -   Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=2,
greater_is_better=False,
group_by_length=False,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_on_each_node=True,
logging_dir=runs/Aug29_17-29-00_ctolab01.scc.idea,
logging_first_step=False,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=5,
output_dir=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
08/29/2023 17:29:01 - WARNING - datasets.builder -   Using custom data configuration default-47739b71079d01d3
Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/xuting/.cache/huggingface/datasets/json/default-47739b71079d01d3/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...
0 tables [00:00, ? tables/s]1 tables [00:00,  9.33 tables/s]                                0 tables [00:00, ? tables/s]                            [INFO|configuration_utils.py:515] 2023-08-29 17:29:02,203 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 17:29:02,204 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|configuration_utils.py:515] 2023-08-29 17:29:02,205 >> loading configuration file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/config.json
[INFO|configuration_utils.py:553] 2023-08-29 17:29:02,206 >> Model config GPT2Config {
  "_name_or_path": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter3/model",
  "activation_function": "gelu_new",
  "architectures": [
    "Model"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "gradient_checkpointing": false,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "resid_pdrop": 0.1,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.7.0",
  "use_cache": true,
  "vocab_size": 50257
}

[INFO|tokenization_utils_base.py:1651] 2023-08-29 17:29:02,217 >> Didn't find file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/added_tokens.json. We won't load it.
[INFO|tokenization_utils_base.py:1715] 2023-08-29 17:29:02,221 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/vocab.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 17:29:02,221 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/merges.txt
[INFO|tokenization_utils_base.py:1715] 2023-08-29 17:29:02,222 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/tokenizer.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 17:29:02,222 >> loading file None
[INFO|tokenization_utils_base.py:1715] 2023-08-29 17:29:02,222 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/special_tokens_map.json
[INFO|tokenization_utils_base.py:1715] 2023-08-29 17:29:02,222 >> loading file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/tokenizer_config.json
[INFO|modeling_utils.py:1150] 2023-08-29 17:29:02,356 >> loading weights file outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model/pytorch_model.bin
[INFO|modeling_utils.py:1336] 2023-08-29 17:29:05,480 >> All model checkpoint weights were used when initializing Model.

[INFO|modeling_utils.py:1345] 2023-08-29 17:29:05,483 >> All the weights of Model were initialized from the model checkpoint at outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Model for predictions without further training.
Dataset json downloaded and prepared to /home/xuting/.cache/huggingface/datasets/json/default-47739b71079d01d3/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.
PreTrainedTokenizerFast(name_or_path='outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter4/model', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'})
  0%|          | 0/8 [00:00<?, ?ba/s] 12%|█▎        | 1/8 [00:00<00:02,  2.77ba/s] 25%|██▌       | 2/8 [00:00<00:01,  3.64ba/s] 38%|███▊      | 3/8 [00:00<00:01,  4.11ba/s] 50%|█████     | 4/8 [00:00<00:00,  4.34ba/s] 62%|██████▎   | 5/8 [00:01<00:00,  4.47ba/s] 75%|███████▌  | 6/8 [00:01<00:00,  4.55ba/s] 88%|████████▊ | 7/8 [00:01<00:00,  4.60ba/s]100%|██████████| 8/8 [00:01<00:00,  5.09ba/s]100%|██████████| 8/8 [00:01<00:00,  4.50ba/s]
  0%|          | 0/9 [00:00<?, ?ba/s] 11%|█         | 1/9 [00:00<00:01,  4.06ba/s] 22%|██▏       | 2/9 [00:00<00:01,  4.42ba/s] 33%|███▎      | 3/9 [00:00<00:01,  4.54ba/s] 44%|████▍     | 4/9 [00:00<00:01,  4.56ba/s] 56%|█████▌    | 5/9 [00:01<00:00,  4.57ba/s] 67%|██████▋   | 6/9 [00:01<00:00,  4.58ba/s] 78%|███████▊  | 7/9 [00:01<00:00,  4.63ba/s] 89%|████████▉ | 8/9 [00:01<00:00,  4.65ba/s]100%|██████████| 9/9 [00:01<00:00,  5.38ba/s]100%|██████████| 9/9 [00:01<00:00,  4.81ba/s]
  0%|          | 0/8 [00:00<?, ?ba/s] 12%|█▎        | 1/8 [00:00<00:01,  4.54ba/s] 38%|███▊      | 3/8 [00:00<00:00,  7.72ba/s] 50%|█████     | 4/8 [00:00<00:00,  6.11ba/s] 75%|███████▌  | 6/8 [00:00<00:00,  7.67ba/s]100%|██████████| 8/8 [00:01<00:00,  9.06ba/s]100%|██████████| 8/8 [00:01<00:00,  7.99ba/s]
  0%|          | 0/9 [00:00<?, ?ba/s] 11%|█         | 1/9 [00:00<00:00,  8.00ba/s] 22%|██▏       | 2/9 [00:00<00:00,  9.04ba/s] 44%|████▍     | 4/9 [00:00<00:00,  9.78ba/s] 67%|██████▋   | 6/9 [00:00<00:00, 10.01ba/s] 89%|████████▉ | 8/9 [00:00<00:00, 10.05ba/s]100%|██████████| 9/9 [00:00<00:00, 10.35ba/s]
[INFO|trainer.py:414] 2023-08-29 17:29:11,721 >> Using amp fp16 backend
[INFO|trainer.py:1147] 2023-08-29 17:29:11,738 >> ***** Running training *****
[INFO|trainer.py:1148] 2023-08-29 17:29:11,738 >>   Num examples = 7700
[INFO|trainer.py:1149] 2023-08-29 17:29:11,738 >>   Num Epochs = 5
[INFO|trainer.py:1150] 2023-08-29 17:29:11,738 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1151] 2023-08-29 17:29:11,738 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1152] 2023-08-29 17:29:11,738 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1153] 2023-08-29 17:29:11,738 >>   Total optimization steps = 600
  0%|          | 0/600 [00:00<?, ?it/s]  0%|          | 1/600 [00:00<03:52,  2.57it/s]  0%|          | 2/600 [00:00<03:12,  3.10it/s]  0%|          | 3/600 [00:00<02:58,  3.35it/s]  1%|          | 4/600 [00:01<03:00,  3.30it/s]  1%|          | 5/600 [00:01<02:53,  3.43it/s]  1%|          | 6/600 [00:01<02:48,  3.52it/s]  1%|          | 7/600 [00:02<02:45,  3.57it/s]  1%|▏         | 8/600 [00:02<02:43,  3.61it/s]  2%|▏         | 9/600 [00:02<02:42,  3.64it/s]  2%|▏         | 10/600 [00:02<02:41,  3.65it/s]  2%|▏         | 11/600 [00:03<02:40,  3.67it/s]  2%|▏         | 12/600 [00:03<02:40,  3.67it/s]  2%|▏         | 13/600 [00:03<02:39,  3.69it/s]  2%|▏         | 14/600 [00:03<02:38,  3.69it/s]  2%|▎         | 15/600 [00:04<02:39,  3.67it/s]  3%|▎         | 16/600 [00:04<02:39,  3.67it/s]  3%|▎         | 17/600 [00:04<02:38,  3.67it/s]  3%|▎         | 18/600 [00:05<02:38,  3.67it/s]  3%|▎         | 19/600 [00:05<02:38,  3.67it/s]  3%|▎         | 20/600 [00:05<02:38,  3.67it/s]  4%|▎         | 21/600 [00:05<02:37,  3.67it/s]  4%|▎         | 22/600 [00:06<02:37,  3.66it/s]  4%|▍         | 23/600 [00:06<02:37,  3.66it/s]  4%|▍         | 24/600 [00:06<02:37,  3.66it/s]  4%|▍         | 25/600 [00:06<02:36,  3.67it/s]  4%|▍         | 26/600 [00:07<03:08,  3.05it/s]  4%|▍         | 27/600 [00:07<02:59,  3.19it/s]  5%|▍         | 28/600 [00:07<02:51,  3.33it/s]  5%|▍         | 29/600 [00:08<02:46,  3.44it/s]  5%|▌         | 30/600 [00:08<02:43,  3.49it/s]  5%|▌         | 31/600 [00:08<02:40,  3.54it/s]  5%|▌         | 32/600 [00:09<02:38,  3.59it/s]  6%|▌         | 33/600 [00:09<02:36,  3.62it/s]  6%|▌         | 34/600 [00:09<02:35,  3.64it/s]  6%|▌         | 35/600 [00:09<02:34,  3.66it/s]  6%|▌         | 36/600 [00:10<02:33,  3.67it/s]  6%|▌         | 37/600 [00:10<02:33,  3.67it/s]  6%|▋         | 38/600 [00:10<02:32,  3.68it/s]  6%|▋         | 39/600 [00:10<02:32,  3.69it/s]  7%|▋         | 40/600 [00:11<02:31,  3.69it/s]  7%|▋         | 41/600 [00:11<02:31,  3.69it/s]  7%|▋         | 42/600 [00:11<02:31,  3.69it/s]  7%|▋         | 43/600 [00:12<02:30,  3.70it/s]  7%|▋         | 44/600 [00:12<02:30,  3.70it/s]  8%|▊         | 45/600 [00:12<02:30,  3.70it/s]  8%|▊         | 46/600 [00:12<02:29,  3.70it/s]  8%|▊         | 47/600 [00:13<02:29,  3.70it/s]  8%|▊         | 48/600 [00:13<02:29,  3.70it/s]  8%|▊         | 49/600 [00:13<02:29,  3.69it/s]  8%|▊         | 50/600 [00:13<02:29,  3.69it/s]  8%|▊         | 51/600 [00:14<02:28,  3.69it/s]  9%|▊         | 52/600 [00:14<02:28,  3.69it/s]  9%|▉         | 53/600 [00:14<02:28,  3.69it/s]  9%|▉         | 54/600 [00:14<02:27,  3.69it/s]  9%|▉         | 55/600 [00:15<02:27,  3.69it/s]  9%|▉         | 56/600 [00:15<02:27,  3.70it/s] 10%|▉         | 57/600 [00:15<02:26,  3.70it/s] 10%|▉         | 58/600 [00:16<02:26,  3.70it/s] 10%|▉         | 59/600 [00:16<02:26,  3.70it/s] 10%|█         | 60/600 [00:16<02:26,  3.70it/s] 10%|█         | 61/600 [00:16<02:26,  3.67it/s] 10%|█         | 62/600 [00:17<02:26,  3.68it/s] 10%|█         | 63/600 [00:17<02:25,  3.68it/s] 11%|█         | 64/600 [00:17<02:25,  3.69it/s] 11%|█         | 65/600 [00:17<02:24,  3.69it/s] 11%|█         | 66/600 [00:18<02:24,  3.69it/s] 11%|█         | 67/600 [00:18<02:24,  3.69it/s] 11%|█▏        | 68/600 [00:18<02:24,  3.69it/s] 12%|█▏        | 69/600 [00:19<02:23,  3.69it/s] 12%|█▏        | 70/600 [00:19<02:23,  3.69it/s] 12%|█▏        | 71/600 [00:19<02:23,  3.68it/s] 12%|█▏        | 72/600 [00:19<02:23,  3.68it/s] 12%|█▏        | 73/600 [00:20<02:23,  3.66it/s] 12%|█▏        | 74/600 [00:20<02:23,  3.66it/s] 12%|█▎        | 75/600 [00:20<02:23,  3.66it/s] 13%|█▎        | 76/600 [00:20<02:23,  3.66it/s] 13%|█▎        | 77/600 [00:21<02:22,  3.66it/s] 13%|█▎        | 78/600 [00:21<02:22,  3.66it/s] 13%|█▎        | 79/600 [00:21<02:22,  3.66it/s] 13%|█▎        | 80/600 [00:22<02:22,  3.66it/s] 14%|█▎        | 81/600 [00:22<02:22,  3.65it/s] 14%|█▎        | 82/600 [00:22<02:21,  3.65it/s] 14%|█▍        | 83/600 [00:22<02:21,  3.65it/s] 14%|█▍        | 84/600 [00:23<02:22,  3.63it/s] 14%|█▍        | 85/600 [00:23<02:21,  3.64it/s] 14%|█▍        | 86/600 [00:23<02:21,  3.64it/s] 14%|█▍        | 87/600 [00:23<02:20,  3.65it/s] 15%|█▍        | 88/600 [00:24<02:20,  3.65it/s] 15%|█▍        | 89/600 [00:24<02:19,  3.65it/s] 15%|█▌        | 90/600 [00:24<02:19,  3.66it/s] 15%|█▌        | 91/600 [00:25<02:19,  3.65it/s] 15%|█▌        | 92/600 [00:25<02:19,  3.65it/s] 16%|█▌        | 93/600 [00:25<02:18,  3.65it/s] 16%|█▌        | 94/600 [00:25<02:18,  3.65it/s] 16%|█▌        | 95/600 [00:26<02:18,  3.65it/s] 16%|█▌        | 96/600 [00:26<02:17,  3.66it/s] 16%|█▌        | 97/600 [00:26<02:17,  3.66it/s] 16%|█▋        | 98/600 [00:27<02:16,  3.66it/s] 16%|█▋        | 99/600 [00:27<02:16,  3.67it/s] 17%|█▋        | 100/600 [00:27<02:15,  3.68it/s] 17%|█▋        | 101/600 [00:27<02:15,  3.68it/s] 17%|█▋        | 102/600 [00:28<02:15,  3.67it/s] 17%|█▋        | 103/600 [00:28<02:15,  3.67it/s] 17%|█▋        | 104/600 [00:28<02:15,  3.67it/s] 18%|█▊        | 105/600 [00:28<02:16,  3.63it/s] 18%|█▊        | 106/600 [00:29<02:15,  3.64it/s] 18%|█▊        | 107/600 [00:29<02:14,  3.66it/s] 18%|█▊        | 108/600 [00:29<02:14,  3.67it/s] 18%|█▊        | 109/600 [00:30<02:13,  3.67it/s] 18%|█▊        | 110/600 [00:30<02:13,  3.68it/s] 18%|█▊        | 111/600 [00:30<02:12,  3.68it/s] 19%|█▊        | 112/600 [00:30<02:12,  3.68it/s] 19%|█▉        | 113/600 [00:31<02:12,  3.68it/s] 19%|█▉        | 114/600 [00:31<02:11,  3.68it/s] 19%|█▉        | 115/600 [00:31<02:11,  3.69it/s] 19%|█▉        | 116/600 [00:31<02:11,  3.69it/s] 20%|█▉        | 117/600 [00:32<02:11,  3.67it/s] 20%|█▉        | 118/600 [00:32<02:11,  3.67it/s] 20%|█▉        | 119/600 [00:32<02:10,  3.68it/s] 20%|██        | 120/600 [00:32<02:10,  3.68it/s][INFO|trainer.py:2140] 2023-08-29 17:29:44,772 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 17:29:44,772 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 17:29:44,773 >>   Batch size = 8

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 57.42it/s][A
  1%|          | 12/1071 [00:00<00:20, 50.92it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 49.21it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.53it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 48.10it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 47.86it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 47.57it/s][A
  4%|▍         | 43/1071 [00:00<00:21, 47.11it/s][A
  4%|▍         | 48/1071 [00:00<00:21, 47.06it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 47.04it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 47.02it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 47.14it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 47.18it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 47.12it/s][A
  7%|▋         | 78/1071 [00:01<00:21, 47.22it/s][A
  8%|▊         | 83/1071 [00:01<00:20, 47.13it/s][A
  8%|▊         | 88/1071 [00:01<00:20, 46.91it/s][A
  9%|▊         | 93/1071 [00:01<00:20, 46.91it/s][A
  9%|▉         | 98/1071 [00:02<00:20, 46.92it/s][A
 10%|▉         | 103/1071 [00:02<00:20, 46.85it/s][A
 10%|█         | 108/1071 [00:02<00:20, 46.99it/s][A
 11%|█         | 113/1071 [00:02<00:20, 47.08it/s][A
 11%|█         | 118/1071 [00:02<00:20, 47.07it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 47.13it/s][A
 12%|█▏        | 128/1071 [00:02<00:20, 47.10it/s][A
 12%|█▏        | 133/1071 [00:02<00:19, 46.98it/s][A
 13%|█▎        | 138/1071 [00:02<00:19, 46.95it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 46.91it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 46.84it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 46.82it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 46.91it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 46.94it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 46.98it/s][A
 16%|█▌        | 173/1071 [00:03<00:19, 47.04it/s][A
 17%|█▋        | 178/1071 [00:03<00:19, 46.97it/s][A
 17%|█▋        | 183/1071 [00:03<00:18, 46.92it/s][A
 18%|█▊        | 188/1071 [00:03<00:18, 46.84it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 46.76it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 46.85it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 46.98it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 46.99it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 46.97it/s][A
 20%|██        | 218/1071 [00:04<00:18, 47.03it/s][A
 21%|██        | 223/1071 [00:04<00:18, 46.97it/s][A
 21%|██▏       | 228/1071 [00:04<00:17, 46.91it/s][A
 22%|██▏       | 233/1071 [00:04<00:17, 46.91it/s][A
 22%|██▏       | 238/1071 [00:05<00:17, 46.85it/s][A
 23%|██▎       | 243/1071 [00:05<00:17, 46.86it/s][A
 23%|██▎       | 248/1071 [00:05<00:17, 46.98it/s][A
 24%|██▎       | 253/1071 [00:05<00:17, 47.01it/s][A
 24%|██▍       | 258/1071 [00:05<00:17, 46.96it/s][A
 25%|██▍       | 263/1071 [00:05<00:17, 47.01it/s][A
 25%|██▌       | 268/1071 [00:05<00:17, 46.97it/s][A
 25%|██▌       | 273/1071 [00:05<00:17, 46.89it/s][A
 26%|██▌       | 278/1071 [00:05<00:16, 46.87it/s][A
 26%|██▋       | 283/1071 [00:06<00:16, 46.79it/s][A
 27%|██▋       | 288/1071 [00:06<00:16, 46.82it/s][A
 27%|██▋       | 293/1071 [00:06<00:16, 46.95it/s][A
 28%|██▊       | 298/1071 [00:06<00:16, 47.01it/s][A
 28%|██▊       | 303/1071 [00:06<00:16, 46.97it/s][A
 29%|██▉       | 308/1071 [00:06<00:16, 47.04it/s][A
 29%|██▉       | 313/1071 [00:06<00:16, 47.04it/s][A
 30%|██▉       | 318/1071 [00:06<00:16, 46.89it/s][A
 30%|███       | 323/1071 [00:06<00:15, 46.86it/s][A
 31%|███       | 328/1071 [00:06<00:15, 46.82it/s][A
 31%|███       | 333/1071 [00:07<00:15, 46.79it/s][A
 32%|███▏      | 338/1071 [00:07<00:15, 46.92it/s][A
 32%|███▏      | 343/1071 [00:07<00:15, 47.00it/s][A
 32%|███▏      | 348/1071 [00:07<00:15, 46.98it/s][A
 33%|███▎      | 353/1071 [00:07<00:15, 46.95it/s][A
 33%|███▎      | 358/1071 [00:07<00:15, 46.92it/s][A
 34%|███▍      | 363/1071 [00:07<00:15, 46.86it/s][A
 34%|███▍      | 368/1071 [00:07<00:15, 46.86it/s][A
 35%|███▍      | 373/1071 [00:07<00:14, 46.78it/s][A
 35%|███▌      | 378/1071 [00:08<00:14, 46.76it/s][A
 36%|███▌      | 383/1071 [00:08<00:14, 46.95it/s][A
 36%|███▌      | 388/1071 [00:08<00:14, 46.99it/s][A
 37%|███▋      | 393/1071 [00:08<00:14, 46.90it/s][A
 37%|███▋      | 398/1071 [00:08<00:14, 47.00it/s][A
 38%|███▊      | 403/1071 [00:08<00:14, 47.06it/s][A
 38%|███▊      | 408/1071 [00:08<00:14, 47.03it/s][A
 39%|███▊      | 413/1071 [00:08<00:14, 46.98it/s][A
 39%|███▉      | 418/1071 [00:08<00:13, 46.94it/s][A
 39%|███▉      | 423/1071 [00:08<00:13, 46.90it/s][A
 40%|███▉      | 428/1071 [00:09<00:13, 46.97it/s][A
 40%|████      | 433/1071 [00:09<00:13, 47.05it/s][A
 41%|████      | 438/1071 [00:09<00:13, 46.71it/s][A
 41%|████▏     | 443/1071 [00:09<00:13, 47.15it/s][A
 42%|████▏     | 448/1071 [00:09<00:13, 47.18it/s][A
 42%|████▏     | 453/1071 [00:09<00:13, 47.14it/s][A
 43%|████▎     | 458/1071 [00:09<00:13, 47.05it/s][A
 43%|████▎     | 463/1071 [00:09<00:12, 47.01it/s][A
 44%|████▎     | 468/1071 [00:09<00:12, 46.90it/s][A
 44%|████▍     | 473/1071 [00:10<00:12, 46.90it/s][A
 45%|████▍     | 478/1071 [00:10<00:12, 46.99it/s][A
 45%|████▌     | 483/1071 [00:10<00:12, 47.07it/s][A
 46%|████▌     | 488/1071 [00:10<00:12, 47.13it/s][A
 46%|████▌     | 493/1071 [00:10<00:12, 47.15it/s][A
 46%|████▋     | 498/1071 [00:10<00:12, 47.19it/s][A
 47%|████▋     | 503/1071 [00:10<00:12, 47.09it/s][A
 47%|████▋     | 508/1071 [00:10<00:11, 47.03it/s][A
 48%|████▊     | 513/1071 [00:10<00:11, 46.92it/s][A
 48%|████▊     | 518/1071 [00:11<00:11, 46.88it/s][A
 49%|████▉     | 523/1071 [00:11<00:11, 46.99it/s][A
 49%|████▉     | 528/1071 [00:11<00:11, 47.00it/s][A
 50%|████▉     | 533/1071 [00:11<00:11, 47.02it/s][A
 50%|█████     | 538/1071 [00:11<00:11, 47.10it/s][A
 51%|█████     | 543/1071 [00:11<00:11, 47.15it/s][A
 51%|█████     | 548/1071 [00:11<00:11, 47.12it/s][A
 52%|█████▏    | 553/1071 [00:11<00:11, 47.05it/s][A
 52%|█████▏    | 558/1071 [00:11<00:10, 46.95it/s][A
 53%|█████▎    | 563/1071 [00:11<00:10, 46.88it/s][A
 53%|█████▎    | 568/1071 [00:12<00:10, 46.90it/s][A
 54%|█████▎    | 573/1071 [00:12<00:10, 47.03it/s][A
 54%|█████▍    | 578/1071 [00:12<00:10, 47.07it/s][A
 54%|█████▍    | 583/1071 [00:12<00:10, 47.05it/s][A
 55%|█████▍    | 588/1071 [00:12<00:10, 47.13it/s][A
 55%|█████▌    | 593/1071 [00:12<00:10, 47.11it/s][A
 56%|█████▌    | 598/1071 [00:12<00:10, 47.02it/s][A
 56%|█████▋    | 603/1071 [00:12<00:09, 47.00it/s][A
 57%|█████▋    | 608/1071 [00:12<00:09, 46.98it/s][A
 57%|█████▋    | 613/1071 [00:13<00:09, 46.92it/s][A
 58%|█████▊    | 618/1071 [00:13<00:09, 47.03it/s][A
 58%|█████▊    | 623/1071 [00:13<00:09, 47.11it/s][A
 59%|█████▊    | 628/1071 [00:13<00:09, 47.07it/s][A
 59%|█████▉    | 633/1071 [00:13<00:09, 47.09it/s][A
 60%|█████▉    | 638/1071 [00:13<00:09, 47.09it/s][A
 60%|██████    | 643/1071 [00:13<00:09, 47.07it/s][A
 61%|██████    | 648/1071 [00:13<00:09, 46.97it/s][A
 61%|██████    | 653/1071 [00:13<00:08, 46.99it/s][A
 61%|██████▏   | 658/1071 [00:13<00:08, 46.91it/s][A
 62%|██████▏   | 663/1071 [00:14<00:08, 45.73it/s][A
 62%|██████▏   | 669/1071 [00:14<00:08, 47.24it/s][A
 63%|██████▎   | 674/1071 [00:14<00:08, 47.17it/s][A
 63%|██████▎   | 679/1071 [00:14<00:08, 47.16it/s][A
 64%|██████▍   | 684/1071 [00:14<00:08, 47.13it/s][A
 64%|██████▍   | 689/1071 [00:14<00:08, 47.05it/s][A
 65%|██████▍   | 694/1071 [00:14<00:08, 47.02it/s][A
 65%|██████▌   | 699/1071 [00:14<00:07, 47.02it/s][A
 66%|██████▌   | 704/1071 [00:14<00:07, 46.95it/s][A
 66%|██████▌   | 709/1071 [00:15<00:07, 46.98it/s][A
 67%|██████▋   | 714/1071 [00:15<00:07, 47.08it/s][A
 67%|██████▋   | 719/1071 [00:15<00:07, 47.09it/s][A
 68%|██████▊   | 724/1071 [00:15<00:07, 47.05it/s][A
 68%|██████▊   | 729/1071 [00:15<00:07, 47.07it/s][A
 69%|██████▊   | 734/1071 [00:15<00:07, 47.01it/s][A
 69%|██████▉   | 739/1071 [00:15<00:07, 46.96it/s][A
 69%|██████▉   | 744/1071 [00:15<00:06, 47.02it/s][A
 70%|██████▉   | 749/1071 [00:15<00:06, 46.20it/s][A
 70%|███████   | 754/1071 [00:16<00:06, 46.57it/s][A
 71%|███████   | 759/1071 [00:16<00:06, 46.70it/s][A
 71%|███████▏  | 764/1071 [00:16<00:06, 46.78it/s][A
 72%|███████▏  | 769/1071 [00:16<00:06, 46.92it/s][A
 72%|███████▏  | 774/1071 [00:16<00:06, 46.95it/s][A
 73%|███████▎  | 779/1071 [00:16<00:06, 46.94it/s][A
 73%|███████▎  | 784/1071 [00:16<00:06, 46.91it/s][A
 74%|███████▎  | 789/1071 [00:16<00:06, 46.94it/s][A
 74%|███████▍  | 794/1071 [00:16<00:05, 46.85it/s][A
 75%|███████▍  | 799/1071 [00:16<00:05, 46.92it/s][A
 75%|███████▌  | 804/1071 [00:17<00:05, 46.98it/s][A
 76%|███████▌  | 809/1071 [00:17<00:05, 46.99it/s][A
 76%|███████▌  | 814/1071 [00:17<00:05, 47.01it/s][A
 76%|███████▋  | 819/1071 [00:17<00:05, 47.07it/s][A
 77%|███████▋  | 824/1071 [00:17<00:05, 47.03it/s][A
 77%|███████▋  | 829/1071 [00:17<00:05, 46.98it/s][A
 78%|███████▊  | 834/1071 [00:17<00:05, 47.01it/s][A
 78%|███████▊  | 839/1071 [00:17<00:04, 46.93it/s][A
 79%|███████▉  | 844/1071 [00:17<00:04, 46.85it/s][A
 79%|███████▉  | 849/1071 [00:18<00:04, 46.88it/s][A
 80%|███████▉  | 854/1071 [00:18<00:04, 46.91it/s][A
 80%|████████  | 859/1071 [00:18<00:04, 46.95it/s][A
 81%|████████  | 864/1071 [00:18<00:04, 47.06it/s][A
 81%|████████  | 869/1071 [00:18<00:04, 47.03it/s][A
 82%|████████▏ | 874/1071 [00:18<00:04, 46.96it/s][A
 82%|████████▏ | 879/1071 [00:18<00:04, 47.00it/s][A
 83%|████████▎ | 884/1071 [00:18<00:03, 46.96it/s][A
 83%|████████▎ | 889/1071 [00:18<00:03, 46.84it/s][A
 83%|████████▎ | 894/1071 [00:19<00:03, 46.89it/s][A
 84%|████████▍ | 899/1071 [00:19<00:03, 46.93it/s][A
 84%|████████▍ | 904/1071 [00:19<00:03, 46.92it/s][A
 85%|████████▍ | 909/1071 [00:19<00:03, 47.01it/s][A
 85%|████████▌ | 914/1071 [00:19<00:03, 47.04it/s][A
 86%|████████▌ | 919/1071 [00:19<00:03, 46.96it/s][A
 86%|████████▋ | 924/1071 [00:19<00:03, 47.00it/s][A
 87%|████████▋ | 929/1071 [00:19<00:03, 46.98it/s][A
 87%|████████▋ | 934/1071 [00:19<00:02, 46.82it/s][A
 88%|████████▊ | 939/1071 [00:19<00:02, 46.84it/s][A
 88%|████████▊ | 944/1071 [00:20<00:02, 46.89it/s][A
 89%|████████▊ | 949/1071 [00:20<00:02, 46.90it/s][A
 89%|████████▉ | 954/1071 [00:20<00:02, 47.00it/s][A
 90%|████████▉ | 959/1071 [00:20<00:02, 47.01it/s][A
 90%|█████████ | 964/1071 [00:20<00:02, 46.95it/s][A
 90%|█████████ | 969/1071 [00:20<00:02, 46.97it/s][A
 91%|█████████ | 974/1071 [00:20<00:02, 46.96it/s][A
 91%|█████████▏| 979/1071 [00:20<00:01, 46.81it/s][A
 92%|█████████▏| 984/1071 [00:20<00:01, 46.85it/s][A
 92%|█████████▏| 989/1071 [00:21<00:01, 46.88it/s][A
 93%|█████████▎| 994/1071 [00:21<00:01, 46.91it/s][A
 93%|█████████▎| 999/1071 [00:21<00:01, 47.01it/s][A
 94%|█████████▎| 1004/1071 [00:21<00:01, 47.04it/s][A
 94%|█████████▍| 1009/1071 [00:21<00:01, 46.98it/s][A
 95%|█████████▍| 1014/1071 [00:21<00:01, 46.96it/s][A
 95%|█████████▌| 1019/1071 [00:21<00:01, 46.94it/s][A
 96%|█████████▌| 1024/1071 [00:21<00:01, 46.87it/s][A
 96%|█████████▌| 1029/1071 [00:21<00:00, 46.50it/s][A
 97%|█████████▋| 1034/1071 [00:21<00:00, 46.89it/s][A
 97%|█████████▋| 1039/1071 [00:22<00:00, 46.91it/s][A
 97%|█████████▋| 1044/1071 [00:22<00:00, 47.01it/s][A
 98%|█████████▊| 1049/1071 [00:22<00:00, 47.04it/s][A
 98%|█████████▊| 1054/1071 [00:22<00:00, 46.99it/s][A
 99%|█████████▉| 1059/1071 [00:22<00:00, 46.94it/s][A
 99%|█████████▉| 1064/1071 [00:22<00:00, 46.93it/s][A
100%|█████████▉| 1069/1071 [00:22<00:00, 46.89it/s][A                                                 
                                                   [A 20%|██        | 120/600 [00:55<02:10,  3.68it/s]
100%|██████████| 1071/1071 [00:22<00:00, 46.89it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 17:30:07,651 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-120
[INFO|configuration_utils.py:351] 2023-08-29 17:30:07,673 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-120/config.json
[INFO|modeling_utils.py:886] 2023-08-29 17:30:10,060 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-120/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 17:30:10,084 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-120/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 17:30:10,092 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-120/special_tokens_map.json
 20%|██        | 121/600 [00:58<1:03:37,  7.97s/it] 20%|██        | 122/600 [00:59<45:05,  5.66s/it]   20%|██        | 123/600 [00:59<32:09,  4.04s/it] 21%|██        | 124/600 [00:59<23:08,  2.92s/it] 21%|██        | 125/600 [01:00<16:48,  2.12s/it] 21%|██        | 126/600 [01:00<12:23,  1.57s/it] 21%|██        | 127/600 [01:00<09:17,  1.18s/it] 21%|██▏       | 128/600 [01:00<07:08,  1.10it/s] 22%|██▏       | 129/600 [01:01<05:37,  1.39it/s] 22%|██▏       | 130/600 [01:01<04:34,  1.71it/s] 22%|██▏       | 131/600 [01:01<03:50,  2.04it/s] 22%|██▏       | 132/600 [01:01<03:18,  2.35it/s] 22%|██▏       | 133/600 [01:02<02:57,  2.64it/s] 22%|██▏       | 134/600 [01:02<02:41,  2.88it/s] 22%|██▎       | 135/600 [01:02<02:31,  3.07it/s] 23%|██▎       | 136/600 [01:03<02:23,  3.23it/s] 23%|██▎       | 137/600 [01:03<02:18,  3.35it/s] 23%|██▎       | 138/600 [01:03<02:14,  3.44it/s] 23%|██▎       | 139/600 [01:03<02:11,  3.50it/s] 23%|██▎       | 140/600 [01:04<02:09,  3.55it/s] 24%|██▎       | 141/600 [01:04<02:08,  3.58it/s] 24%|██▎       | 142/600 [01:04<02:07,  3.60it/s] 24%|██▍       | 143/600 [01:04<02:06,  3.62it/s] 24%|██▍       | 144/600 [01:05<02:05,  3.64it/s] 24%|██▍       | 145/600 [01:05<02:04,  3.64it/s] 24%|██▍       | 146/600 [01:05<02:05,  3.62it/s] 24%|██▍       | 147/600 [01:06<02:04,  3.64it/s] 25%|██▍       | 148/600 [01:06<02:04,  3.64it/s] 25%|██▍       | 149/600 [01:06<02:03,  3.65it/s] 25%|██▌       | 150/600 [01:06<02:03,  3.65it/s] 25%|██▌       | 151/600 [01:07<02:02,  3.66it/s] 25%|██▌       | 152/600 [01:07<02:02,  3.64it/s] 26%|██▌       | 153/600 [01:07<02:02,  3.65it/s] 26%|██▌       | 154/600 [01:07<02:02,  3.65it/s] 26%|██▌       | 155/600 [01:08<02:01,  3.66it/s] 26%|██▌       | 156/600 [01:08<02:01,  3.66it/s] 26%|██▌       | 157/600 [01:08<02:01,  3.64it/s] 26%|██▋       | 158/600 [01:09<02:01,  3.65it/s] 26%|██▋       | 159/600 [01:09<02:00,  3.65it/s] 27%|██▋       | 160/600 [01:09<02:00,  3.66it/s] 27%|██▋       | 161/600 [01:09<01:59,  3.66it/s] 27%|██▋       | 162/600 [01:10<01:59,  3.66it/s] 27%|██▋       | 163/600 [01:10<01:59,  3.66it/s] 27%|██▋       | 164/600 [01:10<01:59,  3.66it/s] 28%|██▊       | 165/600 [01:10<01:58,  3.66it/s] 28%|██▊       | 166/600 [01:11<01:58,  3.66it/s]/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
 28%|██▊       | 167/600 [01:11<01:58,  3.66it/s] 28%|██▊       | 168/600 [01:11<01:58,  3.65it/s] 28%|██▊       | 169/600 [01:12<01:57,  3.66it/s] 28%|██▊       | 170/600 [01:12<01:57,  3.66it/s] 28%|██▊       | 171/600 [01:12<01:57,  3.66it/s] 29%|██▊       | 172/600 [01:12<01:56,  3.66it/s] 29%|██▉       | 173/600 [01:13<01:56,  3.66it/s] 29%|██▉       | 174/600 [01:13<01:56,  3.66it/s] 29%|██▉       | 175/600 [01:13<01:56,  3.66it/s] 29%|██▉       | 176/600 [01:13<01:55,  3.66it/s] 30%|██▉       | 177/600 [01:14<01:55,  3.66it/s] 30%|██▉       | 178/600 [01:14<01:55,  3.66it/s] 30%|██▉       | 179/600 [01:14<01:55,  3.65it/s] 30%|███       | 180/600 [01:15<01:54,  3.66it/s] 30%|███       | 181/600 [01:15<01:54,  3.66it/s] 30%|███       | 182/600 [01:15<01:54,  3.66it/s] 30%|███       | 183/600 [01:15<01:53,  3.66it/s] 31%|███       | 184/600 [01:16<01:53,  3.66it/s] 31%|███       | 185/600 [01:16<01:53,  3.66it/s] 31%|███       | 186/600 [01:16<01:53,  3.66it/s] 31%|███       | 187/600 [01:16<01:52,  3.66it/s] 31%|███▏      | 188/600 [01:17<01:52,  3.66it/s] 32%|███▏      | 189/600 [01:17<01:52,  3.66it/s] 32%|███▏      | 190/600 [01:17<01:52,  3.64it/s] 32%|███▏      | 191/600 [01:18<01:52,  3.65it/s] 32%|███▏      | 192/600 [01:18<01:51,  3.65it/s] 32%|███▏      | 193/600 [01:18<01:51,  3.65it/s] 32%|███▏      | 194/600 [01:18<01:51,  3.66it/s] 32%|███▎      | 195/600 [01:19<01:50,  3.66it/s] 33%|███▎      | 196/600 [01:19<01:50,  3.66it/s] 33%|███▎      | 197/600 [01:19<01:50,  3.66it/s] 33%|███▎      | 198/600 [01:19<01:49,  3.66it/s] 33%|███▎      | 199/600 [01:20<01:49,  3.66it/s] 33%|███▎      | 200/600 [01:20<01:49,  3.66it/s] 34%|███▎      | 201/600 [01:20<01:49,  3.64it/s] 34%|███▎      | 202/600 [01:21<01:49,  3.65it/s] 34%|███▍      | 203/600 [01:21<01:48,  3.65it/s] 34%|███▍      | 204/600 [01:21<01:48,  3.66it/s] 34%|███▍      | 205/600 [01:21<01:47,  3.66it/s] 34%|███▍      | 206/600 [01:22<01:47,  3.66it/s] 34%|███▍      | 207/600 [01:22<01:47,  3.66it/s] 35%|███▍      | 208/600 [01:22<01:47,  3.66it/s] 35%|███▍      | 209/600 [01:22<01:46,  3.66it/s] 35%|███▌      | 210/600 [01:23<01:46,  3.66it/s] 35%|███▌      | 211/600 [01:23<01:46,  3.66it/s] 35%|███▌      | 212/600 [01:23<01:45,  3.66it/s] 36%|███▌      | 213/600 [01:24<01:45,  3.66it/s] 36%|███▌      | 214/600 [01:24<01:45,  3.66it/s] 36%|███▌      | 215/600 [01:24<01:45,  3.66it/s] 36%|███▌      | 216/600 [01:24<01:44,  3.66it/s] 36%|███▌      | 217/600 [01:25<01:45,  3.64it/s] 36%|███▋      | 218/600 [01:25<01:44,  3.65it/s] 36%|███▋      | 219/600 [01:25<01:44,  3.65it/s] 37%|███▋      | 220/600 [01:25<01:44,  3.65it/s] 37%|███▋      | 221/600 [01:26<01:44,  3.64it/s] 37%|███▋      | 222/600 [01:26<01:43,  3.65it/s] 37%|███▋      | 223/600 [01:26<01:43,  3.65it/s] 37%|███▋      | 224/600 [01:27<01:43,  3.65it/s] 38%|███▊      | 225/600 [01:27<01:42,  3.65it/s] 38%|███▊      | 226/600 [01:27<01:42,  3.65it/s] 38%|███▊      | 227/600 [01:27<01:42,  3.65it/s] 38%|███▊      | 228/600 [01:28<01:41,  3.65it/s] 38%|███▊      | 229/600 [01:28<01:41,  3.65it/s] 38%|███▊      | 230/600 [01:28<01:41,  3.65it/s] 38%|███▊      | 231/600 [01:29<01:41,  3.65it/s] 39%|███▊      | 232/600 [01:29<01:40,  3.65it/s] 39%|███▉      | 233/600 [01:29<01:40,  3.65it/s] 39%|███▉      | 234/600 [01:29<01:40,  3.65it/s] 39%|███▉      | 235/600 [01:30<01:39,  3.65it/s] 39%|███▉      | 236/600 [01:30<01:39,  3.64it/s] 40%|███▉      | 237/600 [01:30<01:39,  3.65it/s] 40%|███▉      | 238/600 [01:30<01:39,  3.64it/s] 40%|███▉      | 239/600 [01:31<01:38,  3.65it/s] 40%|████      | 240/600 [01:31<01:38,  3.65it/s][INFO|trainer.py:2140] 2023-08-29 17:30:43,265 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 17:30:43,265 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 17:30:43,265 >>   Batch size = 8
{'eval_loss': 0.9968060255050659, 'eval_runtime': 22.8482, 'eval_samples_per_second': 374.997, 'eval_steps_per_second': 46.875, 'epoch': 1.0}

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 57.44it/s][A
  1%|          | 12/1071 [00:00<00:20, 50.78it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 48.89it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.19it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 47.78it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 47.41it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 47.08it/s][A
  4%|▍         | 43/1071 [00:00<00:22, 46.65it/s][A
  4%|▍         | 48/1071 [00:01<00:21, 46.69it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 46.73it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 46.70it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 46.73it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 46.75it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 46.74it/s][A
  7%|▋         | 78/1071 [00:01<00:21, 46.77it/s][A
  8%|▊         | 83/1071 [00:01<00:21, 46.62it/s][A
  8%|▊         | 88/1071 [00:01<00:21, 46.50it/s][A
  9%|▊         | 93/1071 [00:01<00:21, 46.50it/s][A
  9%|▉         | 98/1071 [00:02<00:20, 46.53it/s][A
 10%|▉         | 103/1071 [00:02<00:20, 46.64it/s][A
 10%|█         | 108/1071 [00:02<00:20, 46.73it/s][A
 11%|█         | 113/1071 [00:02<00:20, 46.71it/s][A
 11%|█         | 118/1071 [00:02<00:20, 46.76it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 46.77it/s][A
 12%|█▏        | 128/1071 [00:02<00:20, 46.64it/s][A
 12%|█▏        | 133/1071 [00:02<00:20, 46.60it/s][A
 13%|█▎        | 138/1071 [00:02<00:20, 46.53it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 46.55it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 46.58it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 46.63it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 46.70it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 46.75it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 46.74it/s][A
 16%|█▌        | 173/1071 [00:03<00:19, 46.70it/s][A
 17%|█▋        | 178/1071 [00:03<00:19, 46.61it/s][A
 17%|█▋        | 183/1071 [00:03<00:19, 46.50it/s][A
 18%|█▊        | 188/1071 [00:04<00:18, 46.51it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 46.52it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 46.60it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 46.66it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 46.70it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 46.68it/s][A
 20%|██        | 218/1071 [00:04<00:18, 46.62it/s][A
 21%|██        | 223/1071 [00:04<00:18, 46.53it/s][A
 21%|██▏       | 228/1071 [00:04<00:18, 46.48it/s][A
 22%|██▏       | 233/1071 [00:04<00:18, 46.46it/s][A
 22%|██▏       | 238/1071 [00:05<00:17, 46.51it/s][A
 23%|██▎       | 243/1071 [00:05<00:17, 46.60it/s][A
 23%|██▎       | 248/1071 [00:05<00:17, 46.64it/s][A
 24%|██▎       | 253/1071 [00:05<00:17, 46.69it/s][A
 24%|██▍       | 258/1071 [00:05<00:17, 46.70it/s][A
 25%|██▍       | 263/1071 [00:05<00:17, 46.62it/s][A
 25%|██▌       | 268/1071 [00:05<00:17, 46.62it/s][A
 25%|██▌       | 273/1071 [00:05<00:17, 46.54it/s][A
 26%|██▌       | 278/1071 [00:05<00:17, 46.50it/s][A
 26%|██▋       | 283/1071 [00:06<00:16, 46.52it/s][A
 27%|██▋       | 288/1071 [00:06<00:16, 46.50it/s][A
 27%|██▋       | 293/1071 [00:06<00:16, 46.57it/s][A
 28%|██▊       | 298/1071 [00:06<00:16, 46.62it/s][A
 28%|██▊       | 303/1071 [00:06<00:16, 46.65it/s][A
 29%|██▉       | 308/1071 [00:06<00:16, 46.68it/s][A
 29%|██▉       | 313/1071 [00:06<00:16, 46.65it/s][A
 30%|██▉       | 318/1071 [00:06<00:16, 46.57it/s][A
 30%|███       | 323/1071 [00:06<00:16, 46.57it/s][A
 31%|███       | 328/1071 [00:07<00:15, 46.51it/s][A
 31%|███       | 333/1071 [00:07<00:15, 46.51it/s][A
 32%|███▏      | 338/1071 [00:07<00:15, 46.60it/s][A
 32%|███▏      | 343/1071 [00:07<00:15, 46.64it/s][A
 32%|███▏      | 348/1071 [00:07<00:15, 46.69it/s][A
 33%|███▎      | 353/1071 [00:07<00:15, 46.71it/s][A
 33%|███▎      | 358/1071 [00:07<00:15, 46.62it/s][A
 34%|███▍      | 363/1071 [00:07<00:15, 46.59it/s][A
 34%|███▍      | 368/1071 [00:07<00:15, 46.56it/s][A
 35%|███▍      | 373/1071 [00:07<00:15, 46.50it/s][A
 35%|███▌      | 378/1071 [00:08<00:14, 46.52it/s][A
 36%|███▌      | 383/1071 [00:08<00:14, 46.56it/s][A
 36%|███▌      | 388/1071 [00:08<00:14, 46.62it/s][A
 37%|███▋      | 393/1071 [00:08<00:14, 46.67it/s][A
 37%|███▋      | 398/1071 [00:08<00:14, 46.69it/s][A
 38%|███▊      | 403/1071 [00:08<00:14, 46.64it/s][A
 38%|███▊      | 408/1071 [00:08<00:14, 46.59it/s][A
 39%|███▊      | 413/1071 [00:08<00:14, 46.23it/s][A
 39%|███▉      | 418/1071 [00:08<00:14, 46.60it/s][A
 39%|███▉      | 423/1071 [00:09<00:13, 46.54it/s][A
 40%|███▉      | 428/1071 [00:09<00:13, 46.56it/s][A
 40%|████      | 433/1071 [00:09<00:13, 46.64it/s][A
 41%|████      | 438/1071 [00:09<00:13, 46.67it/s][A
 41%|████▏     | 443/1071 [00:09<00:13, 46.66it/s][A
 42%|████▏     | 448/1071 [00:09<00:13, 46.63it/s][A
 42%|████▏     | 453/1071 [00:09<00:13, 46.57it/s][A
 43%|████▎     | 458/1071 [00:09<00:13, 46.55it/s][A
 43%|████▎     | 463/1071 [00:09<00:13, 46.52it/s][A
 44%|████▎     | 468/1071 [00:10<00:12, 46.48it/s][A
 44%|████▍     | 473/1071 [00:10<00:12, 46.56it/s][A
 45%|████▍     | 478/1071 [00:10<00:12, 46.62it/s][A
 45%|████▌     | 483/1071 [00:10<00:12, 46.65it/s][A
 46%|████▌     | 488/1071 [00:10<00:12, 46.63it/s][A
 46%|████▌     | 493/1071 [00:10<00:12, 46.57it/s][A
 46%|████▋     | 498/1071 [00:10<00:12, 46.60it/s][A
 47%|████▋     | 503/1071 [00:10<00:12, 46.55it/s][A
 47%|████▋     | 508/1071 [00:10<00:12, 46.51it/s][A
 48%|████▊     | 513/1071 [00:10<00:11, 46.55it/s][A
 48%|████▊     | 518/1071 [00:11<00:11, 46.53it/s][A
 49%|████▉     | 523/1071 [00:11<00:11, 46.58it/s][A
 49%|████▉     | 528/1071 [00:11<00:11, 46.67it/s][A
 50%|████▉     | 533/1071 [00:11<00:11, 46.56it/s][A
 50%|█████     | 538/1071 [00:11<00:11, 46.55it/s][A
 51%|█████     | 543/1071 [00:11<00:11, 46.50it/s][A
 51%|█████     | 548/1071 [00:11<00:11, 46.48it/s][A
 52%|█████▏    | 553/1071 [00:11<00:11, 46.60it/s][A
 52%|█████▏    | 558/1071 [00:11<00:11, 46.54it/s][A
 53%|█████▎    | 563/1071 [00:12<00:10, 46.52it/s][A
 53%|█████▎    | 568/1071 [00:12<00:10, 46.62it/s][A
 54%|█████▎    | 573/1071 [00:12<00:10, 46.66it/s][A
 54%|█████▍    | 578/1071 [00:12<00:10, 46.65it/s][A
 54%|█████▍    | 583/1071 [00:12<00:10, 46.59it/s][A
 55%|█████▍    | 588/1071 [00:12<00:10, 46.55it/s][A
 55%|█████▌    | 593/1071 [00:12<00:10, 46.53it/s][A
 56%|█████▌    | 598/1071 [00:12<00:10, 46.50it/s][A
 56%|█████▋    | 603/1071 [00:12<00:10, 46.48it/s][A
 57%|█████▋    | 608/1071 [00:13<00:09, 46.50it/s][A
 57%|█████▋    | 613/1071 [00:13<00:09, 46.48it/s][A
 58%|█████▊    | 618/1071 [00:13<00:09, 46.55it/s][A
 58%|█████▊    | 623/1071 [00:13<00:09, 46.61it/s][A
 59%|█████▊    | 628/1071 [00:13<00:09, 46.63it/s][A
 59%|█████▉    | 633/1071 [00:13<00:09, 46.62it/s][A
 60%|█████▉    | 638/1071 [00:13<00:09, 46.54it/s][A
 60%|██████    | 643/1071 [00:13<00:09, 46.50it/s][A
 61%|██████    | 648/1071 [00:13<00:09, 46.34it/s][A
 61%|██████    | 653/1071 [00:13<00:09, 46.37it/s][A
 61%|██████▏   | 658/1071 [00:14<00:08, 46.44it/s][A
 62%|██████▏   | 663/1071 [00:14<00:08, 46.43it/s][A
 62%|██████▏   | 668/1071 [00:14<00:08, 46.44it/s][A
 63%|██████▎   | 673/1071 [00:14<00:08, 46.57it/s][A
 63%|██████▎   | 678/1071 [00:14<00:08, 46.61it/s][A
 64%|██████▍   | 683/1071 [00:14<00:08, 46.54it/s][A
 64%|██████▍   | 688/1071 [00:14<00:08, 46.55it/s][A
 65%|██████▍   | 693/1071 [00:14<00:08, 46.52it/s][A
 65%|██████▌   | 698/1071 [00:14<00:08, 46.53it/s][A
 66%|██████▌   | 703/1071 [00:15<00:07, 46.50it/s][A
 66%|██████▌   | 708/1071 [00:15<00:07, 46.48it/s][A
 67%|██████▋   | 713/1071 [00:15<00:07, 46.55it/s][A
 67%|██████▋   | 718/1071 [00:15<00:07, 46.58it/s][A
 68%|██████▊   | 723/1071 [00:15<00:07, 46.61it/s][A
 68%|██████▊   | 728/1071 [00:15<00:07, 45.06it/s][A
 69%|██████▊   | 734/1071 [00:15<00:07, 46.53it/s][A
 69%|██████▉   | 739/1071 [00:15<00:07, 46.58it/s][A
 69%|██████▉   | 744/1071 [00:15<00:07, 46.53it/s][A
 70%|██████▉   | 749/1071 [00:16<00:06, 46.52it/s][A
 70%|███████   | 754/1071 [00:16<00:06, 46.50it/s][A
 71%|███████   | 759/1071 [00:16<00:06, 46.49it/s][A
 71%|███████▏  | 764/1071 [00:16<00:06, 46.56it/s][A
 72%|███████▏  | 769/1071 [00:16<00:06, 46.59it/s][A
 72%|███████▏  | 774/1071 [00:16<00:06, 46.55it/s][A
 73%|███████▎  | 779/1071 [00:16<00:06, 46.60it/s][A
 73%|███████▎  | 784/1071 [00:16<00:06, 46.56it/s][A
 74%|███████▎  | 789/1071 [00:16<00:06, 46.56it/s][A
 74%|███████▍  | 794/1071 [00:17<00:05, 46.56it/s][A
 75%|███████▍  | 799/1071 [00:17<00:05, 46.53it/s][A
 75%|███████▌  | 804/1071 [00:17<00:05, 46.56it/s][A
 76%|███████▌  | 809/1071 [00:17<00:05, 46.52it/s][A
 76%|███████▌  | 814/1071 [00:17<00:05, 45.69it/s][A
 76%|███████▋  | 819/1071 [00:17<00:05, 46.01it/s][A
 77%|███████▋  | 824/1071 [00:17<00:05, 46.22it/s][A
 77%|███████▋  | 829/1071 [00:17<00:05, 46.37it/s][A
 78%|███████▊  | 834/1071 [00:17<00:05, 46.39it/s][A
 78%|███████▊  | 839/1071 [00:17<00:04, 46.46it/s][A
 79%|███████▉  | 844/1071 [00:18<00:04, 46.47it/s][A
 79%|███████▉  | 849/1071 [00:18<00:04, 46.46it/s][A
 80%|███████▉  | 854/1071 [00:18<00:04, 46.48it/s][A
 80%|████████  | 859/1071 [00:18<00:04, 46.39it/s][A
 81%|████████  | 864/1071 [00:18<00:04, 46.43it/s][A
 81%|████████  | 869/1071 [00:18<00:04, 46.55it/s][A
 82%|████████▏ | 874/1071 [00:18<00:04, 46.60it/s][A
 82%|████████▏ | 879/1071 [00:18<00:04, 46.60it/s][A
 83%|████████▎ | 884/1071 [00:18<00:04, 46.57it/s][A
 83%|████████▎ | 889/1071 [00:19<00:03, 46.50it/s][A
 83%|████████▎ | 894/1071 [00:19<00:03, 46.59it/s][A
 84%|████████▍ | 899/1071 [00:19<00:03, 46.54it/s][A
 84%|████████▍ | 904/1071 [00:19<00:03, 46.48it/s][A
 85%|████████▍ | 909/1071 [00:19<00:03, 46.50it/s][A
 85%|████████▌ | 914/1071 [00:19<00:03, 46.47it/s][A
 86%|████████▌ | 919/1071 [00:19<00:03, 46.52it/s][A
 86%|████████▋ | 924/1071 [00:19<00:03, 46.59it/s][A
 87%|████████▋ | 929/1071 [00:19<00:03, 46.56it/s][A
 87%|████████▋ | 934/1071 [00:20<00:02, 46.55it/s][A
 88%|████████▊ | 939/1071 [00:20<00:02, 46.58it/s][A
 88%|████████▊ | 944/1071 [00:20<00:02, 46.51it/s][A
 89%|████████▊ | 949/1071 [00:20<00:02, 46.56it/s][A
 89%|████████▉ | 954/1071 [00:20<00:02, 46.52it/s][A
 90%|████████▉ | 959/1071 [00:20<00:02, 46.54it/s][A
 90%|█████████ | 964/1071 [00:20<00:02, 46.61it/s][A
 90%|█████████ | 969/1071 [00:20<00:02, 46.56it/s][A
 91%|█████████ | 974/1071 [00:20<00:02, 46.58it/s][A
 91%|█████████▏| 979/1071 [00:21<00:01, 46.50it/s][A
 92%|█████████▏| 984/1071 [00:21<00:01, 46.51it/s][A
 92%|█████████▏| 989/1071 [00:21<00:01, 46.54it/s][A
 93%|█████████▎| 994/1071 [00:21<00:01, 46.52it/s][A
 93%|█████████▎| 999/1071 [00:21<00:01, 45.26it/s][A
 94%|█████████▎| 1004/1071 [00:21<00:01, 45.97it/s][A
 94%|█████████▍| 1009/1071 [00:21<00:01, 46.20it/s][A
 95%|█████████▍| 1014/1071 [00:21<00:01, 46.31it/s][A
 95%|█████████▌| 1019/1071 [00:21<00:01, 46.34it/s][A
 96%|█████████▌| 1024/1071 [00:21<00:01, 46.47it/s][A
 96%|█████████▌| 1029/1071 [00:22<00:00, 46.45it/s][A
 97%|█████████▋| 1034/1071 [00:22<00:00, 46.47it/s][A
 97%|█████████▋| 1039/1071 [00:22<00:00, 46.49it/s][A
 97%|█████████▋| 1044/1071 [00:22<00:00, 46.39it/s][A
 98%|█████████▊| 1049/1071 [00:22<00:00, 46.45it/s][A
 98%|█████████▊| 1054/1071 [00:22<00:00, 46.52it/s][A
 99%|█████████▉| 1059/1071 [00:22<00:00, 46.50it/s][A
 99%|█████████▉| 1064/1071 [00:22<00:00, 46.57it/s][A
100%|█████████▉| 1069/1071 [00:22<00:00, 46.53it/s][A                                                 
                                                   [A 40%|████      | 240/600 [01:54<01:38,  3.65it/s]
100%|██████████| 1071/1071 [00:23<00:00, 46.53it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 17:31:06,331 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-240
[INFO|configuration_utils.py:351] 2023-08-29 17:31:06,359 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-240/config.json
[INFO|modeling_utils.py:886] 2023-08-29 17:31:08,976 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-240/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 17:31:09,009 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-240/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 17:31:09,018 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-240/special_tokens_map.json
 40%|████      | 241/600 [01:57<48:30,  8.11s/it] 40%|████      | 242/600 [01:58<34:20,  5.76s/it] 40%|████      | 243/600 [01:58<24:27,  4.11s/it] 41%|████      | 244/600 [01:58<17:33,  2.96s/it] 41%|████      | 245/600 [01:58<12:44,  2.15s/it] 41%|████      | 246/600 [01:59<09:22,  1.59s/it] 41%|████      | 247/600 [01:59<07:01,  1.20s/it] 41%|████▏     | 248/600 [01:59<05:23,  1.09it/s] 42%|████▏     | 249/600 [02:00<04:14,  1.38it/s] 42%|████▏     | 250/600 [02:00<03:26,  1.70it/s] 42%|████▏     | 251/600 [02:00<02:53,  2.01it/s] 42%|████▏     | 252/600 [02:00<02:29,  2.33it/s] 42%|████▏     | 253/600 [02:01<02:12,  2.61it/s] 42%|████▏     | 254/600 [02:01<02:01,  2.85it/s] 42%|████▎     | 255/600 [02:01<01:52,  3.05it/s] 43%|████▎     | 256/600 [02:01<01:47,  3.21it/s] 43%|████▎     | 257/600 [02:02<01:42,  3.33it/s] 43%|████▎     | 258/600 [02:02<01:40,  3.42it/s] 43%|████▎     | 259/600 [02:02<01:37,  3.49it/s] 43%|████▎     | 260/600 [02:03<01:36,  3.53it/s] 44%|████▎     | 261/600 [02:03<01:35,  3.57it/s] 44%|████▎     | 262/600 [02:03<01:34,  3.58it/s] 44%|████▍     | 263/600 [02:03<01:33,  3.60it/s] 44%|████▍     | 264/600 [02:04<01:32,  3.61it/s] 44%|████▍     | 265/600 [02:04<01:32,  3.62it/s] 44%|████▍     | 266/600 [02:04<01:31,  3.63it/s] 44%|████▍     | 267/600 [02:04<01:31,  3.64it/s] 45%|████▍     | 268/600 [02:05<01:31,  3.64it/s] 45%|████▍     | 269/600 [02:05<01:30,  3.64it/s] 45%|████▌     | 270/600 [02:05<01:30,  3.64it/s] 45%|████▌     | 271/600 [02:06<01:30,  3.64it/s] 45%|████▌     | 272/600 [02:06<01:29,  3.65it/s] 46%|████▌     | 273/600 [02:06<01:30,  3.63it/s] 46%|████▌     | 274/600 [02:06<01:29,  3.63it/s] 46%|████▌     | 275/600 [02:07<01:29,  3.64it/s] 46%|████▌     | 276/600 [02:07<01:29,  3.62it/s] 46%|████▌     | 277/600 [02:07<01:29,  3.63it/s] 46%|████▋     | 278/600 [02:08<01:28,  3.64it/s] 46%|████▋     | 279/600 [02:08<01:28,  3.64it/s] 47%|████▋     | 280/600 [02:08<01:27,  3.64it/s] 47%|████▋     | 281/600 [02:08<01:27,  3.64it/s] 47%|████▋     | 282/600 [02:09<01:27,  3.65it/s] 47%|████▋     | 283/600 [02:09<01:26,  3.65it/s] 47%|████▋     | 284/600 [02:09<01:26,  3.63it/s] 48%|████▊     | 285/600 [02:09<01:26,  3.64it/s] 48%|████▊     | 286/600 [02:10<01:26,  3.64it/s] 48%|████▊     | 287/600 [02:10<01:25,  3.64it/s] 48%|████▊     | 288/600 [02:10<01:25,  3.64it/s] 48%|████▊     | 289/600 [02:11<01:25,  3.65it/s] 48%|████▊     | 290/600 [02:11<01:24,  3.65it/s] 48%|████▊     | 291/600 [02:11<01:24,  3.65it/s] 49%|████▊     | 292/600 [02:11<01:24,  3.65it/s] 49%|████▉     | 293/600 [02:12<01:24,  3.65it/s] 49%|████▉     | 294/600 [02:12<01:23,  3.65it/s] 49%|████▉     | 295/600 [02:12<01:23,  3.64it/s] 49%|████▉     | 296/600 [02:12<01:23,  3.64it/s] 50%|████▉     | 297/600 [02:13<01:23,  3.64it/s] 50%|████▉     | 298/600 [02:13<01:22,  3.65it/s] 50%|████▉     | 299/600 [02:13<01:22,  3.65it/s] 50%|█████     | 300/600 [02:14<01:22,  3.65it/s] 50%|█████     | 301/600 [02:14<01:21,  3.65it/s] 50%|█████     | 302/600 [02:14<01:21,  3.65it/s] 50%|█████     | 303/600 [02:14<01:21,  3.65it/s] 51%|█████     | 304/600 [02:15<01:21,  3.65it/s] 51%|█████     | 305/600 [02:15<01:20,  3.65it/s] 51%|█████     | 306/600 [02:15<01:20,  3.63it/s] 51%|█████     | 307/600 [02:15<01:20,  3.64it/s] 51%|█████▏    | 308/600 [02:16<01:20,  3.64it/s] 52%|█████▏    | 309/600 [02:16<01:19,  3.64it/s] 52%|█████▏    | 310/600 [02:16<01:19,  3.64it/s] 52%|█████▏    | 311/600 [02:17<01:19,  3.65it/s] 52%|█████▏    | 312/600 [02:17<01:18,  3.65it/s] 52%|█████▏    | 313/600 [02:17<01:18,  3.65it/s] 52%|█████▏    | 314/600 [02:17<01:18,  3.65it/s] 52%|█████▎    | 315/600 [02:18<01:18,  3.65it/s] 53%|█████▎    | 316/600 [02:18<01:17,  3.65it/s] 53%|█████▎    | 317/600 [02:18<01:17,  3.64it/s] 53%|█████▎    | 318/600 [02:18<01:17,  3.64it/s] 53%|█████▎    | 319/600 [02:19<01:17,  3.64it/s] 53%|█████▎    | 320/600 [02:19<01:16,  3.65it/s] 54%|█████▎    | 321/600 [02:19<01:16,  3.65it/s] 54%|█████▎    | 322/600 [02:20<01:16,  3.65it/s] 54%|█████▍    | 323/600 [02:20<01:15,  3.65it/s] 54%|█████▍    | 324/600 [02:20<01:15,  3.65it/s] 54%|█████▍    | 325/600 [02:20<01:15,  3.65it/s] 54%|█████▍    | 326/600 [02:21<01:15,  3.65it/s] 55%|█████▍    | 327/600 [02:21<01:14,  3.65it/s] 55%|█████▍    | 328/600 [02:21<01:15,  3.62it/s] 55%|█████▍    | 329/600 [02:22<01:14,  3.63it/s] 55%|█████▌    | 330/600 [02:22<01:14,  3.63it/s] 55%|█████▌    | 331/600 [02:22<01:13,  3.64it/s] 55%|█████▌    | 332/600 [02:22<01:13,  3.64it/s] 56%|█████▌    | 333/600 [02:23<01:13,  3.64it/s] 56%|█████▌    | 334/600 [02:23<01:12,  3.65it/s] 56%|█████▌    | 335/600 [02:23<01:12,  3.65it/s] 56%|█████▌    | 336/600 [02:23<01:12,  3.65it/s] 56%|█████▌    | 337/600 [02:24<01:12,  3.65it/s] 56%|█████▋    | 338/600 [02:24<01:11,  3.65it/s] 56%|█████▋    | 339/600 [02:24<01:11,  3.65it/s] 57%|█████▋    | 340/600 [02:25<01:11,  3.65it/s] 57%|█████▋    | 341/600 [02:25<01:10,  3.65it/s] 57%|█████▋    | 342/600 [02:25<01:10,  3.65it/s] 57%|█████▋    | 343/600 [02:25<01:10,  3.65it/s] 57%|█████▋    | 344/600 [02:26<01:10,  3.65it/s] 57%|█████▊    | 345/600 [02:26<01:09,  3.65it/s] 58%|█████▊    | 346/600 [02:26<01:10,  3.58it/s] 58%|█████▊    | 347/600 [02:26<01:10,  3.60it/s] 58%|█████▊    | 348/600 [02:27<01:09,  3.62it/s] 58%|█████▊    | 349/600 [02:27<01:09,  3.63it/s] 58%|█████▊    | 350/600 [02:27<01:08,  3.63it/s] 58%|█████▊    | 351/600 [02:28<01:08,  3.64it/s] 59%|█████▊    | 352/600 [02:28<01:08,  3.64it/s] 59%|█████▉    | 353/600 [02:28<01:07,  3.64it/s] 59%|█████▉    | 354/600 [02:28<01:07,  3.65it/s] 59%|█████▉    | 355/600 [02:29<01:07,  3.65it/s] 59%|█████▉    | 356/600 [02:29<01:06,  3.65it/s] 60%|█████▉    | 357/600 [02:29<01:06,  3.65it/s] 60%|█████▉    | 358/600 [02:29<01:06,  3.65it/s] 60%|█████▉    | 359/600 [02:30<01:06,  3.65it/s] 60%|██████    | 360/600 [02:30<01:05,  3.65it/s][INFO|trainer.py:2140] 2023-08-29 17:31:42,308 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 17:31:42,309 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 17:31:42,309 >>   Batch size = 8
{'eval_loss': 0.9968060255050659, 'eval_runtime': 23.0553, 'eval_samples_per_second': 371.629, 'eval_steps_per_second': 46.454, 'epoch': 2.0}

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 57.50it/s][A
  1%|          | 12/1071 [00:00<00:20, 50.58it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 48.73it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.02it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 47.59it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 47.32it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 46.99it/s][A
  4%|▍         | 43/1071 [00:00<00:22, 46.34it/s][A
  4%|▍         | 48/1071 [00:01<00:21, 46.54it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 46.60it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 46.64it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 46.66it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 46.68it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 46.75it/s][A
  7%|▋         | 78/1071 [00:01<00:21, 46.74it/s][A
  8%|▊         | 83/1071 [00:01<00:21, 46.65it/s][A
  8%|▊         | 88/1071 [00:01<00:21, 46.50it/s][A
  9%|▊         | 93/1071 [00:01<00:21, 46.46it/s][A
  9%|▉         | 98/1071 [00:02<00:20, 46.50it/s][A
 10%|▉         | 103/1071 [00:02<00:20, 46.57it/s][A
 10%|█         | 108/1071 [00:02<00:20, 46.61it/s][A
 11%|█         | 113/1071 [00:02<00:20, 46.68it/s][A
 11%|█         | 118/1071 [00:02<00:20, 46.71it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 46.72it/s][A
 12%|█▏        | 128/1071 [00:02<00:20, 46.66it/s][A
 12%|█▏        | 133/1071 [00:02<00:20, 46.52it/s][A
 13%|█▎        | 138/1071 [00:02<00:20, 46.43it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 46.51it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 46.49it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 46.56it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 46.61it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 46.35it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 46.51it/s][A
 16%|█▌        | 173/1071 [00:03<00:19, 46.56it/s][A
 17%|█▋        | 178/1071 [00:03<00:19, 46.48it/s][A
 17%|█▋        | 183/1071 [00:03<00:19, 46.50it/s][A
 18%|█▊        | 188/1071 [00:04<00:18, 46.48it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 46.52it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 46.59it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 46.58it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 46.63it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 46.67it/s][A
 20%|██        | 218/1071 [00:04<00:18, 46.62it/s][A
 21%|██        | 223/1071 [00:04<00:18, 46.61it/s][A
 21%|██▏       | 228/1071 [00:04<00:18, 46.56it/s][A
 22%|██▏       | 233/1071 [00:04<00:18, 46.50it/s][A
 22%|██▏       | 238/1071 [00:05<00:17, 46.51it/s][A
 23%|██▎       | 243/1071 [00:05<00:17, 46.51it/s][A
 23%|██▎       | 248/1071 [00:05<00:17, 46.57it/s][A
 24%|██▎       | 253/1071 [00:05<00:17, 46.60it/s][A
 24%|██▍       | 258/1071 [00:05<00:17, 46.60it/s][A
 25%|██▍       | 263/1071 [00:05<00:17, 46.68it/s][A
 25%|██▌       | 268/1071 [00:05<00:17, 46.64it/s][A
 25%|██▌       | 273/1071 [00:05<00:17, 46.58it/s][A
 26%|██▌       | 278/1071 [00:05<00:17, 46.55it/s][A
 26%|██▋       | 283/1071 [00:06<00:16, 46.52it/s][A
 27%|██▋       | 288/1071 [00:06<00:16, 46.55it/s][A
 27%|██▋       | 293/1071 [00:06<00:16, 46.52it/s][A
 28%|██▊       | 298/1071 [00:06<00:16, 46.49it/s][A
 28%|██▊       | 303/1071 [00:06<00:16, 46.60it/s][A
 29%|██▉       | 308/1071 [00:06<00:16, 46.64it/s][A
 29%|██▉       | 313/1071 [00:06<00:16, 46.63it/s][A
 30%|██▉       | 318/1071 [00:06<00:16, 46.60it/s][A
 30%|███       | 323/1071 [00:06<00:16, 46.56it/s][A
 31%|███       | 328/1071 [00:07<00:15, 46.56it/s][A
 31%|███       | 333/1071 [00:07<00:15, 46.52it/s][A
 32%|███▏      | 338/1071 [00:07<00:15, 46.49it/s][A
 32%|███▏      | 343/1071 [00:07<00:15, 46.57it/s][A
 32%|███▏      | 348/1071 [00:07<00:15, 46.62it/s][A
 33%|███▎      | 353/1071 [00:07<00:15, 46.62it/s][A
 33%|███▎      | 358/1071 [00:07<00:15, 46.62it/s][A
 34%|███▍      | 363/1071 [00:07<00:15, 46.57it/s][A
 34%|███▍      | 368/1071 [00:07<00:15, 46.57it/s][A
 35%|███▍      | 373/1071 [00:07<00:15, 46.53it/s][A
 35%|███▌      | 378/1071 [00:08<00:14, 46.50it/s][A
 36%|███▌      | 383/1071 [00:08<00:14, 46.55it/s][A
 36%|███▌      | 388/1071 [00:08<00:14, 46.52it/s][A
 37%|███▋      | 393/1071 [00:08<00:14, 46.51it/s][A
 37%|███▋      | 398/1071 [00:08<00:14, 46.57it/s][A
 38%|███▊      | 403/1071 [00:08<00:14, 46.58it/s][A
 38%|███▊      | 408/1071 [00:08<00:14, 46.55it/s][A
 39%|███▊      | 413/1071 [00:08<00:14, 46.56it/s][A
 39%|███▉      | 418/1071 [00:08<00:14, 46.52it/s][A
 39%|███▉      | 423/1071 [00:09<00:13, 46.51it/s][A
 40%|███▉      | 428/1071 [00:09<00:13, 46.48it/s][A
 40%|████      | 433/1071 [00:09<00:13, 46.48it/s][A
 41%|████      | 438/1071 [00:09<00:13, 46.57it/s][A
 41%|████▏     | 443/1071 [00:09<00:13, 46.62it/s][A
 42%|████▏     | 448/1071 [00:09<00:13, 46.61it/s][A
 42%|████▏     | 453/1071 [00:09<00:13, 46.57it/s][A
 43%|████▎     | 458/1071 [00:09<00:13, 46.53it/s][A
 43%|████▎     | 463/1071 [00:09<00:13, 46.55it/s][A
 44%|████▎     | 468/1071 [00:10<00:12, 46.52it/s][A
 44%|████▍     | 473/1071 [00:10<00:12, 46.48it/s][A
 45%|████▍     | 478/1071 [00:10<00:12, 46.51it/s][A
 45%|████▌     | 483/1071 [00:10<00:12, 46.48it/s][A
 46%|████▌     | 488/1071 [00:10<00:12, 46.52it/s][A
 46%|████▌     | 493/1071 [00:10<00:12, 46.61it/s][A
 46%|████▋     | 498/1071 [00:10<00:12, 46.58it/s][A
 47%|████▋     | 503/1071 [00:10<00:12, 46.59it/s][A
 47%|████▋     | 508/1071 [00:10<00:12, 46.56it/s][A
 48%|████▊     | 513/1071 [00:10<00:11, 46.50it/s][A
 48%|████▊     | 518/1071 [00:11<00:11, 46.60it/s][A
 49%|████▉     | 523/1071 [00:11<00:11, 46.55it/s][A
 49%|████▉     | 528/1071 [00:11<00:11, 46.54it/s][A
 50%|████▉     | 533/1071 [00:11<00:11, 46.60it/s][A
 50%|█████     | 538/1071 [00:11<00:11, 46.61it/s][A
 51%|█████     | 543/1071 [00:11<00:11, 46.59it/s][A
 51%|█████     | 548/1071 [00:11<00:11, 46.55it/s][A
 52%|█████▏    | 553/1071 [00:11<00:11, 46.49it/s][A
 52%|█████▏    | 558/1071 [00:11<00:11, 46.51it/s][A
 53%|█████▎    | 563/1071 [00:12<00:10, 46.52it/s][A
 53%|█████▎    | 568/1071 [00:12<00:10, 46.51it/s][A
 54%|█████▎    | 573/1071 [00:12<00:10, 46.53it/s][A
 54%|█████▍    | 578/1071 [00:12<00:10, 46.50it/s][A
 54%|█████▍    | 583/1071 [00:12<00:10, 46.57it/s][A
 55%|█████▍    | 588/1071 [00:12<00:10, 46.61it/s][A
 55%|█████▌    | 593/1071 [00:12<00:10, 46.56it/s][A
 56%|█████▌    | 598/1071 [00:12<00:10, 46.56it/s][A
 56%|█████▋    | 603/1071 [00:12<00:10, 46.52it/s][A
 57%|█████▋    | 608/1071 [00:13<00:09, 46.51it/s][A
 57%|█████▋    | 613/1071 [00:13<00:09, 46.53it/s][A
 58%|█████▊    | 618/1071 [00:13<00:09, 46.50it/s][A
 58%|█████▊    | 623/1071 [00:13<00:09, 46.52it/s][A
 59%|█████▊    | 628/1071 [00:13<00:09, 46.58it/s][A
 59%|█████▉    | 633/1071 [00:13<00:09, 46.57it/s][A
 60%|█████▉    | 638/1071 [00:13<00:09, 46.58it/s][A
 60%|██████    | 643/1071 [00:13<00:09, 46.55it/s][A
 61%|██████    | 648/1071 [00:13<00:09, 46.51it/s][A
 61%|██████    | 653/1071 [00:14<00:08, 46.53it/s][A
 61%|██████▏   | 658/1071 [00:14<00:08, 46.50it/s][A
 62%|██████▏   | 663/1071 [00:14<00:08, 46.51it/s][A
 62%|██████▏   | 668/1071 [00:14<00:08, 46.51it/s][A
 63%|██████▎   | 673/1071 [00:14<00:08, 46.48it/s][A
 63%|██████▎   | 678/1071 [00:14<00:08, 46.57it/s][A
 64%|██████▍   | 683/1071 [00:14<00:08, 46.61it/s][A
 64%|██████▍   | 688/1071 [00:14<00:08, 46.56it/s][A
 65%|██████▍   | 693/1071 [00:14<00:08, 46.57it/s][A
 65%|██████▌   | 698/1071 [00:14<00:08, 46.53it/s][A
 66%|██████▌   | 703/1071 [00:15<00:07, 46.54it/s][A
 66%|██████▌   | 708/1071 [00:15<00:07, 46.53it/s][A
 67%|██████▋   | 713/1071 [00:15<00:07, 46.51it/s][A
 67%|██████▋   | 718/1071 [00:15<00:07, 46.51it/s][A
 68%|██████▊   | 723/1071 [00:15<00:07, 46.49it/s][A
 68%|██████▊   | 728/1071 [00:15<00:07, 46.49it/s][A
 68%|██████▊   | 733/1071 [00:15<00:07, 46.59it/s][A
 69%|██████▉   | 738/1071 [00:15<00:07, 46.57it/s][A
 69%|██████▉   | 743/1071 [00:15<00:07, 46.56it/s][A
 70%|██████▉   | 748/1071 [00:16<00:06, 46.42it/s][A
 70%|███████   | 753/1071 [00:16<00:06, 46.42it/s][A
 71%|███████   | 758/1071 [00:16<00:06, 46.46it/s][A
 71%|███████   | 763/1071 [00:16<00:06, 46.46it/s][A
 72%|███████▏  | 768/1071 [00:16<00:06, 46.47it/s][A
 72%|███████▏  | 773/1071 [00:16<00:06, 46.49it/s][A
 73%|███████▎  | 778/1071 [00:16<00:06, 46.47it/s][A
 73%|███████▎  | 783/1071 [00:16<00:06, 46.55it/s][A
 74%|███████▎  | 788/1071 [00:16<00:06, 46.55it/s][A
 74%|███████▍  | 793/1071 [00:17<00:05, 46.52it/s][A
 75%|███████▍  | 798/1071 [00:17<00:05, 46.59it/s][A
 75%|███████▍  | 803/1071 [00:17<00:05, 46.55it/s][A
 75%|███████▌  | 808/1071 [00:17<00:05, 46.51it/s][A
 76%|███████▌  | 813/1071 [00:17<00:05, 46.52it/s][A
 76%|███████▋  | 818/1071 [00:17<00:05, 46.50it/s][A
 77%|███████▋  | 823/1071 [00:17<00:05, 46.54it/s][A
 77%|███████▋  | 828/1071 [00:17<00:05, 46.58it/s][A
 78%|███████▊  | 833/1071 [00:17<00:05, 46.54it/s][A
 78%|███████▊  | 838/1071 [00:17<00:05, 46.58it/s][A
 79%|███████▊  | 843/1071 [00:18<00:04, 46.55it/s][A
 79%|███████▉  | 848/1071 [00:18<00:04, 46.51it/s][A
 80%|███████▉  | 853/1071 [00:18<00:04, 46.53it/s][A
 80%|████████  | 858/1071 [00:18<00:04, 45.85it/s][A
 81%|████████  | 863/1071 [00:18<00:04, 45.57it/s][A
 81%|████████  | 868/1071 [00:18<00:04, 45.96it/s][A
 82%|████████▏ | 873/1071 [00:18<00:04, 46.17it/s][A
 82%|████████▏ | 878/1071 [00:18<00:04, 46.24it/s][A
 82%|████████▏ | 883/1071 [00:18<00:04, 46.32it/s][A
 83%|████████▎ | 888/1071 [00:19<00:03, 46.44it/s][A
 83%|████████▎ | 893/1071 [00:19<00:03, 46.43it/s][A
 84%|████████▍ | 898/1071 [00:19<00:03, 46.50it/s][A
 84%|████████▍ | 903/1071 [00:19<00:03, 46.49it/s][A
 85%|████████▍ | 908/1071 [00:19<00:03, 46.47it/s][A
 85%|████████▌ | 913/1071 [00:19<00:03, 46.55it/s][A
 86%|████████▌ | 918/1071 [00:19<00:03, 46.56it/s][A
 86%|████████▌ | 923/1071 [00:19<00:03, 46.50it/s][A
 87%|████████▋ | 928/1071 [00:19<00:03, 46.53it/s][A
 87%|████████▋ | 933/1071 [00:20<00:02, 46.50it/s][A
 88%|████████▊ | 938/1071 [00:20<00:02, 46.56it/s][A
 88%|████████▊ | 943/1071 [00:20<00:02, 46.54it/s][A
 89%|████████▊ | 948/1071 [00:20<00:02, 46.51it/s][A
 89%|████████▉ | 953/1071 [00:20<00:02, 46.54it/s][A
 89%|████████▉ | 958/1071 [00:20<00:02, 46.51it/s][A
 90%|████████▉ | 963/1071 [00:20<00:02, 46.50it/s][A
 90%|█████████ | 968/1071 [00:20<00:02, 46.55it/s][A
 91%|█████████ | 973/1071 [00:20<00:02, 46.52it/s][A
 91%|█████████▏| 978/1071 [00:20<00:01, 46.53it/s][A
 92%|█████████▏| 983/1071 [00:21<00:01, 46.56it/s][A
 92%|█████████▏| 988/1071 [00:21<00:01, 46.52it/s][A
 93%|█████████▎| 993/1071 [00:21<00:01, 46.43it/s][A
 93%|█████████▎| 998/1071 [00:21<00:01, 46.47it/s][A
 94%|█████████▎| 1003/1071 [00:21<00:01, 46.46it/s][A
 94%|█████████▍| 1008/1071 [00:21<00:01, 46.56it/s][A
 95%|█████████▍| 1013/1071 [00:21<00:01, 46.52it/s][A
 95%|█████████▌| 1018/1071 [00:21<00:01, 46.55it/s][A
 96%|█████████▌| 1023/1071 [00:21<00:01, 46.48it/s][A
 96%|█████████▌| 1028/1071 [00:22<00:00, 46.51it/s][A
 96%|█████████▋| 1033/1071 [00:22<00:00, 46.53it/s][A
 97%|█████████▋| 1038/1071 [00:22<00:00, 46.51it/s][A
 97%|█████████▋| 1043/1071 [00:22<00:00, 46.50it/s][A
 98%|█████████▊| 1048/1071 [00:22<00:00, 46.52it/s][A
 98%|█████████▊| 1053/1071 [00:22<00:00, 46.50it/s][A
 99%|█████████▉| 1058/1071 [00:22<00:00, 46.56it/s][A
 99%|█████████▉| 1063/1071 [00:22<00:00, 46.58it/s][A
100%|█████████▉| 1068/1071 [00:22<00:00, 46.54it/s][A                                                 
                                                   [A 60%|██████    | 360/600 [02:53<01:05,  3.65it/s]
100%|██████████| 1071/1071 [00:23<00:00, 46.54it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 17:32:05,378 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-360
[INFO|configuration_utils.py:351] 2023-08-29 17:32:05,405 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-360/config.json
[INFO|modeling_utils.py:886] 2023-08-29 17:32:07,855 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-360/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 17:32:07,875 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-360/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 17:32:07,884 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-360/special_tokens_map.json
 60%|██████    | 361/600 [02:56<32:01,  8.04s/it] 60%|██████    | 362/600 [02:56<22:39,  5.71s/it] 60%|██████    | 363/600 [02:57<16:06,  4.08s/it] 61%|██████    | 364/600 [02:57<11:33,  2.94s/it] 61%|██████    | 365/600 [02:57<08:22,  2.14s/it] 61%|██████    | 366/600 [02:58<06:09,  1.58s/it] 61%|██████    | 367/600 [02:58<04:36,  1.19s/it] 61%|██████▏   | 368/600 [02:58<03:31,  1.09it/s] 62%|██████▏   | 369/600 [02:58<02:46,  1.39it/s] 62%|██████▏   | 370/600 [02:59<02:15,  1.70it/s] 62%|██████▏   | 371/600 [02:59<01:52,  2.03it/s] 62%|██████▏   | 372/600 [02:59<01:37,  2.34it/s] 62%|██████▏   | 373/600 [02:59<01:26,  2.62it/s] 62%|██████▏   | 374/600 [03:00<01:18,  2.86it/s] 62%|██████▎   | 375/600 [03:00<01:14,  3.04it/s] 63%|██████▎   | 376/600 [03:00<01:10,  3.20it/s] 63%|██████▎   | 377/600 [03:01<01:07,  3.32it/s] 63%|██████▎   | 378/600 [03:01<01:05,  3.41it/s] 63%|██████▎   | 379/600 [03:01<01:03,  3.48it/s] 63%|██████▎   | 380/600 [03:01<01:02,  3.53it/s] 64%|██████▎   | 381/600 [03:02<01:01,  3.57it/s] 64%|██████▎   | 382/600 [03:02<01:00,  3.59it/s] 64%|██████▍   | 383/600 [03:02<01:00,  3.61it/s] 64%|██████▍   | 384/600 [03:02<00:59,  3.62it/s] 64%|██████▍   | 385/600 [03:03<00:59,  3.63it/s] 64%|██████▍   | 386/600 [03:03<00:59,  3.62it/s] 64%|██████▍   | 387/600 [03:03<00:58,  3.63it/s] 65%|██████▍   | 388/600 [03:04<00:58,  3.63it/s] 65%|██████▍   | 389/600 [03:04<00:57,  3.64it/s] 65%|██████▌   | 390/600 [03:04<00:57,  3.64it/s] 65%|██████▌   | 391/600 [03:04<00:57,  3.64it/s] 65%|██████▌   | 392/600 [03:05<00:57,  3.65it/s] 66%|██████▌   | 393/600 [03:05<00:56,  3.65it/s] 66%|██████▌   | 394/600 [03:05<00:56,  3.65it/s] 66%|██████▌   | 395/600 [03:06<00:56,  3.65it/s] 66%|██████▌   | 396/600 [03:06<00:55,  3.65it/s] 66%|██████▌   | 397/600 [03:06<00:55,  3.64it/s] 66%|██████▋   | 398/600 [03:06<00:55,  3.64it/s] 66%|██████▋   | 399/600 [03:07<00:55,  3.64it/s] 67%|██████▋   | 400/600 [03:07<00:55,  3.62it/s] 67%|██████▋   | 401/600 [03:07<00:54,  3.63it/s] 67%|██████▋   | 402/600 [03:07<00:54,  3.63it/s] 67%|██████▋   | 403/600 [03:08<00:54,  3.64it/s] 67%|██████▋   | 404/600 [03:08<00:53,  3.64it/s] 68%|██████▊   | 405/600 [03:08<00:53,  3.64it/s] 68%|██████▊   | 406/600 [03:09<00:53,  3.64it/s] 68%|██████▊   | 407/600 [03:09<00:52,  3.65it/s] 68%|██████▊   | 408/600 [03:09<00:53,  3.62it/s] 68%|██████▊   | 409/600 [03:09<00:52,  3.63it/s] 68%|██████▊   | 410/600 [03:10<00:52,  3.64it/s] 68%|██████▊   | 411/600 [03:10<00:51,  3.64it/s] 69%|██████▊   | 412/600 [03:10<00:51,  3.64it/s] 69%|██████▉   | 413/600 [03:10<00:51,  3.65it/s] 69%|██████▉   | 414/600 [03:11<00:50,  3.65it/s] 69%|██████▉   | 415/600 [03:11<00:50,  3.65it/s] 69%|██████▉   | 416/600 [03:11<00:50,  3.65it/s] 70%|██████▉   | 417/600 [03:12<00:50,  3.65it/s] 70%|██████▉   | 418/600 [03:12<00:49,  3.65it/s] 70%|██████▉   | 419/600 [03:12<00:49,  3.62it/s] 70%|███████   | 420/600 [03:12<00:49,  3.63it/s] 70%|███████   | 421/600 [03:13<00:49,  3.64it/s] 70%|███████   | 422/600 [03:13<00:48,  3.64it/s] 70%|███████   | 423/600 [03:13<00:48,  3.65it/s] 71%|███████   | 424/600 [03:13<00:48,  3.65it/s] 71%|███████   | 425/600 [03:14<00:47,  3.65it/s] 71%|███████   | 426/600 [03:14<00:47,  3.65it/s] 71%|███████   | 427/600 [03:14<00:47,  3.65it/s] 71%|███████▏  | 428/600 [03:15<00:47,  3.65it/s] 72%|███████▏  | 429/600 [03:15<00:46,  3.65it/s] 72%|███████▏  | 430/600 [03:15<00:46,  3.63it/s] 72%|███████▏  | 431/600 [03:15<00:46,  3.63it/s] 72%|███████▏  | 432/600 [03:16<00:46,  3.64it/s] 72%|███████▏  | 433/600 [03:16<00:45,  3.65it/s] 72%|███████▏  | 434/600 [03:16<00:45,  3.64it/s] 72%|███████▎  | 435/600 [03:17<00:45,  3.63it/s] 73%|███████▎  | 436/600 [03:17<00:45,  3.63it/s] 73%|███████▎  | 437/600 [03:17<00:44,  3.64it/s] 73%|███████▎  | 438/600 [03:17<00:44,  3.64it/s] 73%|███████▎  | 439/600 [03:18<00:44,  3.65it/s] 73%|███████▎  | 440/600 [03:18<00:43,  3.65it/s] 74%|███████▎  | 441/600 [03:18<00:45,  3.50it/s] 74%|███████▎  | 442/600 [03:18<00:44,  3.54it/s] 74%|███████▍  | 443/600 [03:19<00:43,  3.58it/s] 74%|███████▍  | 444/600 [03:19<00:43,  3.60it/s] 74%|███████▍  | 445/600 [03:19<00:43,  3.60it/s] 74%|███████▍  | 446/600 [03:20<00:42,  3.61it/s] 74%|███████▍  | 447/600 [03:20<00:42,  3.61it/s] 75%|███████▍  | 448/600 [03:20<00:42,  3.61it/s] 75%|███████▍  | 449/600 [03:20<00:41,  3.62it/s] 75%|███████▌  | 450/600 [03:21<00:41,  3.63it/s] 75%|███████▌  | 451/600 [03:21<00:40,  3.64it/s] 75%|███████▌  | 452/600 [03:21<00:43,  3.44it/s] 76%|███████▌  | 453/600 [03:22<00:41,  3.50it/s] 76%|███████▌  | 454/600 [03:22<00:41,  3.55it/s] 76%|███████▌  | 455/600 [03:22<00:40,  3.58it/s] 76%|███████▌  | 456/600 [03:22<00:39,  3.60it/s] 76%|███████▌  | 457/600 [03:23<00:39,  3.62it/s] 76%|███████▋  | 458/600 [03:23<00:39,  3.63it/s] 76%|███████▋  | 459/600 [03:23<00:38,  3.64it/s] 77%|███████▋  | 460/600 [03:23<00:38,  3.65it/s] 77%|███████▋  | 461/600 [03:24<00:38,  3.65it/s] 77%|███████▋  | 462/600 [03:24<00:37,  3.65it/s] 77%|███████▋  | 463/600 [03:24<00:39,  3.48it/s] 77%|███████▋  | 464/600 [03:25<00:39,  3.48it/s] 78%|███████▊  | 465/600 [03:25<00:38,  3.53it/s] 78%|███████▊  | 466/600 [03:25<00:37,  3.57it/s] 78%|███████▊  | 467/600 [03:25<00:37,  3.59it/s] 78%|███████▊  | 468/600 [03:26<00:36,  3.61it/s] 78%|███████▊  | 469/600 [03:26<00:36,  3.62it/s] 78%|███████▊  | 470/600 [03:26<00:35,  3.63it/s] 78%|███████▊  | 471/600 [03:27<00:35,  3.64it/s] 79%|███████▊  | 472/600 [03:27<00:35,  3.64it/s] 79%|███████▉  | 473/600 [03:27<00:34,  3.64it/s] 79%|███████▉  | 474/600 [03:27<00:34,  3.65it/s] 79%|███████▉  | 475/600 [03:28<00:34,  3.63it/s] 79%|███████▉  | 476/600 [03:28<00:34,  3.63it/s] 80%|███████▉  | 477/600 [03:28<00:33,  3.64it/s] 80%|███████▉  | 478/600 [03:28<00:33,  3.64it/s] 80%|███████▉  | 479/600 [03:29<00:33,  3.64it/s] 80%|████████  | 480/600 [03:29<00:32,  3.64it/s][INFO|trainer.py:2140] 2023-08-29 17:32:41,276 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 17:32:41,276 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 17:32:41,276 >>   Batch size = 8
{'eval_loss': 0.9968060255050659, 'eval_runtime': 23.0601, 'eval_samples_per_second': 371.551, 'eval_steps_per_second': 46.444, 'epoch': 3.0}

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 57.25it/s][A
  1%|          | 12/1071 [00:00<00:20, 50.49it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 48.77it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.03it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 47.60it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 47.31it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 47.02it/s][A
  4%|▍         | 43/1071 [00:00<00:22, 46.67it/s][A
  4%|▍         | 48/1071 [00:01<00:21, 46.68it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 46.67it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 46.71it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 46.71it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 46.69it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 46.74it/s][A
  7%|▋         | 78/1071 [00:01<00:21, 46.65it/s][A
  8%|▊         | 83/1071 [00:01<00:21, 46.55it/s][A
  8%|▊         | 88/1071 [00:01<00:21, 46.50it/s][A
  9%|▊         | 93/1071 [00:01<00:21, 46.49it/s][A
  9%|▉         | 98/1071 [00:02<00:20, 46.60it/s][A
 10%|▉         | 103/1071 [00:02<00:20, 46.64it/s][A
 10%|█         | 108/1071 [00:02<00:20, 46.64it/s][A
 11%|█         | 113/1071 [00:02<00:20, 46.71it/s][A
 11%|█         | 118/1071 [00:02<00:20, 46.70it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 46.63it/s][A
 12%|█▏        | 128/1071 [00:02<00:20, 46.57it/s][A
 12%|█▏        | 133/1071 [00:02<00:20, 46.45it/s][A
 13%|█▎        | 138/1071 [00:02<00:20, 46.15it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 46.64it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 46.66it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 46.68it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 46.70it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 46.66it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 46.63it/s][A
 16%|█▌        | 173/1071 [00:03<00:19, 46.58it/s][A
 17%|█▋        | 178/1071 [00:03<00:19, 46.49it/s][A
 17%|█▋        | 183/1071 [00:03<00:19, 46.47it/s][A
 18%|█▊        | 188/1071 [00:04<00:19, 46.46it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 46.58it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 46.63it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 46.65it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 46.70it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 46.63it/s][A
 20%|██        | 218/1071 [00:04<00:18, 46.58it/s][A
 21%|██        | 223/1071 [00:04<00:18, 46.55it/s][A
 21%|██▏       | 228/1071 [00:04<00:18, 46.51it/s][A
 22%|██▏       | 233/1071 [00:04<00:18, 46.48it/s][A
 22%|██▏       | 238/1071 [00:05<00:17, 46.49it/s][A
 23%|██▎       | 243/1071 [00:05<00:17, 46.48it/s][A
 23%|██▎       | 248/1071 [00:05<00:17, 46.59it/s][A
 24%|██▎       | 253/1071 [00:05<00:17, 46.64it/s][A
 24%|██▍       | 258/1071 [00:05<00:17, 46.58it/s][A
 25%|██▍       | 263/1071 [00:05<00:17, 46.56it/s][A
 25%|██▌       | 268/1071 [00:05<00:17, 46.51it/s][A
 25%|██▌       | 273/1071 [00:05<00:17, 46.50it/s][A
 26%|██▌       | 278/1071 [00:05<00:17, 46.49it/s][A
 26%|██▋       | 283/1071 [00:06<00:16, 46.48it/s][A
 27%|██▋       | 288/1071 [00:06<00:16, 46.54it/s][A
 27%|██▋       | 293/1071 [00:06<00:16, 46.59it/s][A
 28%|██▊       | 298/1071 [00:06<00:16, 46.61it/s][A
 28%|██▊       | 303/1071 [00:06<00:16, 46.68it/s][A
 29%|██▉       | 308/1071 [00:06<00:16, 46.62it/s][A
 29%|██▉       | 313/1071 [00:06<00:16, 46.59it/s][A
 30%|██▉       | 318/1071 [00:06<00:16, 46.53it/s][A
 30%|███       | 323/1071 [00:06<00:16, 46.48it/s][A
 31%|███       | 328/1071 [00:07<00:15, 46.58it/s][A
 31%|███       | 333/1071 [00:07<00:15, 46.54it/s][A
 32%|███▏      | 338/1071 [00:07<00:15, 46.52it/s][A
 32%|███▏      | 343/1071 [00:07<00:15, 46.62it/s][A
 32%|███▏      | 348/1071 [00:07<00:15, 46.66it/s][A
 33%|███▎      | 353/1071 [00:07<00:15, 46.65it/s][A
 33%|███▎      | 358/1071 [00:07<00:15, 46.61it/s][A
 34%|███▍      | 363/1071 [00:07<00:15, 46.55it/s][A
 34%|███▍      | 368/1071 [00:07<00:15, 46.47it/s][A
 35%|███▍      | 373/1071 [00:07<00:15, 46.46it/s][A
 35%|███▌      | 378/1071 [00:08<00:14, 46.47it/s][A
 36%|███▌      | 383/1071 [00:08<00:14, 46.54it/s][A
 36%|███▌      | 388/1071 [00:08<00:14, 46.51it/s][A
 37%|███▋      | 393/1071 [00:08<00:14, 46.58it/s][A
 37%|███▋      | 398/1071 [00:08<00:14, 46.65it/s][A
 38%|███▊      | 403/1071 [00:08<00:14, 46.64it/s][A
 38%|███▊      | 408/1071 [00:08<00:14, 46.61it/s][A
 39%|███▊      | 413/1071 [00:08<00:14, 46.56it/s][A
 39%|███▉      | 418/1071 [00:08<00:14, 46.52it/s][A
 39%|███▉      | 423/1071 [00:09<00:13, 46.56it/s][A
 40%|███▉      | 428/1071 [00:09<00:13, 46.52it/s][A
 40%|████      | 433/1071 [00:09<00:13, 46.54it/s][A
 41%|████      | 438/1071 [00:09<00:13, 46.62it/s][A
 41%|████▏     | 443/1071 [00:09<00:13, 46.65it/s][A
 42%|████▏     | 448/1071 [00:09<00:13, 46.63it/s][A
 42%|████▏     | 453/1071 [00:09<00:13, 46.57it/s][A
 43%|████▎     | 458/1071 [00:09<00:13, 46.53it/s][A
 43%|████▎     | 463/1071 [00:09<00:13, 46.54it/s][A
 44%|████▎     | 468/1071 [00:10<00:12, 46.51it/s][A
 44%|████▍     | 473/1071 [00:10<00:12, 46.51it/s][A
 45%|████▍     | 478/1071 [00:10<00:12, 46.58it/s][A
 45%|████▌     | 483/1071 [00:10<00:12, 46.58it/s][A
 46%|████▌     | 488/1071 [00:10<00:12, 46.62it/s][A
 46%|████▌     | 493/1071 [00:10<00:12, 46.60it/s][A
 46%|████▋     | 498/1071 [00:10<00:12, 46.55it/s][A
 47%|████▋     | 503/1071 [00:10<00:12, 46.57it/s][A
 47%|████▋     | 508/1071 [00:10<00:12, 46.53it/s][A
 48%|████▊     | 513/1071 [00:10<00:11, 46.51it/s][A
 48%|████▊     | 518/1071 [00:11<00:11, 46.52it/s][A
 49%|████▉     | 523/1071 [00:11<00:11, 46.49it/s][A
 49%|████▉     | 528/1071 [00:11<00:11, 46.57it/s][A
 50%|████▉     | 533/1071 [00:11<00:11, 46.63it/s][A
 50%|█████     | 538/1071 [00:11<00:11, 46.61it/s][A
 51%|█████     | 543/1071 [00:11<00:11, 46.61it/s][A
 51%|█████     | 548/1071 [00:11<00:11, 46.55it/s][A
 52%|█████▏    | 553/1071 [00:11<00:11, 46.53it/s][A
 52%|█████▏    | 558/1071 [00:11<00:11, 46.54it/s][A
 53%|█████▎    | 563/1071 [00:12<00:10, 46.48it/s][A
 53%|█████▎    | 568/1071 [00:12<00:10, 46.52it/s][A
 54%|█████▎    | 573/1071 [00:12<00:10, 46.63it/s][A
 54%|█████▍    | 578/1071 [00:12<00:10, 46.66it/s][A
 54%|█████▍    | 583/1071 [00:12<00:10, 46.67it/s][A
 55%|█████▍    | 588/1071 [00:12<00:10, 46.60it/s][A
 55%|█████▌    | 593/1071 [00:12<00:10, 46.55it/s][A
 56%|█████▌    | 598/1071 [00:12<00:10, 46.58it/s][A
 56%|█████▋    | 603/1071 [00:12<00:10, 46.54it/s][A
 57%|█████▋    | 608/1071 [00:13<00:09, 46.42it/s][A
 57%|█████▋    | 613/1071 [00:13<00:09, 46.44it/s][A
 58%|█████▊    | 618/1071 [00:13<00:09, 46.44it/s][A
 58%|█████▊    | 623/1071 [00:13<00:09, 46.57it/s][A
 59%|█████▊    | 628/1071 [00:13<00:09, 46.62it/s][A
 59%|█████▉    | 633/1071 [00:13<00:09, 46.61it/s][A
 60%|█████▉    | 638/1071 [00:13<00:09, 46.61it/s][A
 60%|██████    | 643/1071 [00:13<00:09, 46.56it/s][A
 61%|██████    | 648/1071 [00:13<00:09, 46.52it/s][A
 61%|██████    | 653/1071 [00:13<00:08, 46.50it/s][A
 61%|██████▏   | 658/1071 [00:14<00:08, 46.48it/s][A
 62%|██████▏   | 663/1071 [00:14<00:08, 46.52it/s][A
 62%|██████▏   | 668/1071 [00:14<00:08, 46.53it/s][A
 63%|██████▎   | 673/1071 [00:14<00:08, 46.50it/s][A
 63%|██████▎   | 678/1071 [00:14<00:08, 46.62it/s][A
 64%|██████▍   | 683/1071 [00:14<00:08, 46.62it/s][A
 64%|██████▍   | 688/1071 [00:14<00:08, 46.56it/s][A
 65%|██████▍   | 693/1071 [00:14<00:08, 46.55it/s][A
 65%|██████▌   | 698/1071 [00:14<00:08, 46.49it/s][A
 66%|██████▌   | 703/1071 [00:15<00:07, 46.56it/s][A
 66%|██████▌   | 708/1071 [00:15<00:07, 46.59it/s][A
 67%|██████▋   | 713/1071 [00:15<00:07, 46.55it/s][A
 67%|██████▋   | 718/1071 [00:15<00:07, 46.58it/s][A
 68%|██████▊   | 723/1071 [00:15<00:07, 45.31it/s][A
 68%|██████▊   | 728/1071 [00:15<00:07, 45.95it/s][A
 68%|██████▊   | 733/1071 [00:15<00:07, 46.12it/s][A
 69%|██████▉   | 738/1071 [00:15<00:07, 46.20it/s][A
 69%|██████▉   | 743/1071 [00:15<00:07, 46.29it/s][A
 70%|██████▉   | 748/1071 [00:16<00:06, 46.33it/s][A
 70%|███████   | 753/1071 [00:16<00:06, 46.46it/s][A
 71%|███████   | 758/1071 [00:16<00:06, 46.48it/s][A
 71%|███████   | 763/1071 [00:16<00:06, 46.48it/s][A
 72%|███████▏  | 768/1071 [00:16<00:06, 46.52it/s][A
 72%|███████▏  | 773/1071 [00:16<00:06, 46.50it/s][A
 73%|███████▎  | 778/1071 [00:16<00:06, 46.51it/s][A
 73%|███████▎  | 783/1071 [00:16<00:06, 46.54it/s][A
 74%|███████▎  | 788/1071 [00:16<00:06, 46.49it/s][A
 74%|███████▍  | 793/1071 [00:17<00:05, 46.58it/s][A
 75%|███████▍  | 798/1071 [00:17<00:05, 46.59it/s][A
 75%|███████▍  | 803/1071 [00:17<00:05, 46.55it/s][A
 75%|███████▌  | 808/1071 [00:17<00:05, 46.61it/s][A
 76%|███████▌  | 813/1071 [00:17<00:05, 46.56it/s][A
 76%|███████▋  | 818/1071 [00:17<00:05, 46.56it/s][A
 77%|███████▋  | 823/1071 [00:17<00:05, 46.54it/s][A
 77%|███████▋  | 828/1071 [00:17<00:05, 46.51it/s][A
 78%|███████▊  | 833/1071 [00:17<00:05, 46.53it/s][A
 78%|███████▊  | 838/1071 [00:17<00:05, 46.54it/s][A
 79%|███████▊  | 843/1071 [00:18<00:04, 46.51it/s][A
 79%|███████▉  | 848/1071 [00:18<00:04, 46.59it/s][A
 80%|███████▉  | 853/1071 [00:18<00:04, 46.29it/s][A
 80%|████████  | 858/1071 [00:18<00:04, 46.43it/s][A
 81%|████████  | 863/1071 [00:18<00:04, 46.43it/s][A
 81%|████████  | 868/1071 [00:18<00:04, 46.43it/s][A
 82%|████████▏ | 873/1071 [00:18<00:04, 46.46it/s][A
 82%|████████▏ | 878/1071 [00:18<00:04, 46.43it/s][A
 82%|████████▏ | 883/1071 [00:18<00:04, 46.48it/s][A
 83%|████████▎ | 888/1071 [00:19<00:03, 46.59it/s][A
 83%|████████▎ | 893/1071 [00:19<00:03, 46.61it/s][A
 84%|████████▍ | 898/1071 [00:19<00:03, 46.60it/s][A
 84%|████████▍ | 903/1071 [00:19<00:03, 46.02it/s][A
 85%|████████▍ | 908/1071 [00:19<00:03, 45.91it/s][A
 85%|████████▌ | 913/1071 [00:19<00:03, 46.11it/s][A
 86%|████████▌ | 918/1071 [00:19<00:03, 46.19it/s][A
 86%|████████▌ | 923/1071 [00:19<00:03, 46.31it/s][A
 87%|████████▋ | 928/1071 [00:19<00:03, 46.34it/s][A
 87%|████████▋ | 933/1071 [00:20<00:02, 46.42it/s][A
 88%|████████▊ | 938/1071 [00:20<00:02, 46.52it/s][A
 88%|████████▊ | 943/1071 [00:20<00:02, 46.50it/s][A
 89%|████████▊ | 948/1071 [00:20<00:02, 46.53it/s][A
 89%|████████▉ | 953/1071 [00:20<00:02, 46.51it/s][A
 89%|████████▉ | 958/1071 [00:20<00:02, 46.49it/s][A
 90%|████████▉ | 963/1071 [00:20<00:02, 46.54it/s][A
 90%|█████████ | 968/1071 [00:20<00:02, 46.51it/s][A
 91%|█████████ | 973/1071 [00:20<00:02, 46.51it/s][A
 91%|█████████▏| 978/1071 [00:20<00:01, 46.60it/s][A
 92%|█████████▏| 983/1071 [00:21<00:01, 46.56it/s][A
 92%|█████████▏| 988/1071 [00:21<00:01, 46.55it/s][A
 93%|█████████▎| 993/1071 [00:21<00:01, 46.54it/s][A
 93%|█████████▎| 998/1071 [00:21<00:01, 46.50it/s][A
 94%|█████████▎| 1003/1071 [00:21<00:01, 46.53it/s][A
 94%|█████████▍| 1008/1071 [00:21<00:01, 46.51it/s][A
 95%|█████████▍| 1013/1071 [00:21<00:01, 46.50it/s][A
 95%|█████████▌| 1018/1071 [00:21<00:01, 46.59it/s][A
 96%|█████████▌| 1023/1071 [00:21<00:01, 46.58it/s][A
 96%|█████████▌| 1028/1071 [00:22<00:00, 46.57it/s][A
 96%|█████████▋| 1033/1071 [00:22<00:00, 46.55it/s][A
 97%|█████████▋| 1038/1071 [00:22<00:00, 46.52it/s][A
 97%|█████████▋| 1043/1071 [00:22<00:00, 46.55it/s][A
 98%|█████████▊| 1048/1071 [00:22<00:00, 46.52it/s][A
 98%|█████████▊| 1053/1071 [00:22<00:00, 46.51it/s][A
 99%|█████████▉| 1058/1071 [00:22<00:00, 46.53it/s][A
 99%|█████████▉| 1063/1071 [00:22<00:00, 46.50it/s][A
100%|█████████▉| 1068/1071 [00:22<00:00, 46.57it/s][A                                                 
                                                   [A 80%|████████  | 480/600 [03:52<00:32,  3.64it/s]
100%|██████████| 1071/1071 [00:23<00:00, 46.57it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 17:33:04,357 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-480
[INFO|configuration_utils.py:351] 2023-08-29 17:33:04,372 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-480/config.json
[INFO|modeling_utils.py:886] 2023-08-29 17:33:06,923 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-480/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 17:33:06,940 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-480/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 17:33:06,950 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-480/special_tokens_map.json
 80%|████████  | 481/600 [03:55<16:01,  8.08s/it] 80%|████████  | 482/600 [03:56<11:16,  5.74s/it] 80%|████████  | 483/600 [03:56<07:59,  4.10s/it] 81%|████████  | 484/600 [03:56<05:42,  2.95s/it] 81%|████████  | 485/600 [03:56<04:06,  2.15s/it] 81%|████████  | 486/600 [03:57<03:00,  1.58s/it] 81%|████████  | 487/600 [03:57<02:14,  1.19s/it] 81%|████████▏ | 488/600 [03:57<01:42,  1.09it/s] 82%|████████▏ | 489/600 [03:57<01:20,  1.38it/s] 82%|████████▏ | 490/600 [03:58<01:04,  1.70it/s] 82%|████████▏ | 491/600 [03:58<00:53,  2.02it/s] 82%|████████▏ | 492/600 [03:58<00:46,  2.32it/s] 82%|████████▏ | 493/600 [03:59<00:41,  2.61it/s] 82%|████████▏ | 494/600 [03:59<00:37,  2.85it/s] 82%|████████▎ | 495/600 [03:59<00:34,  3.05it/s] 83%|████████▎ | 496/600 [03:59<00:32,  3.21it/s] 83%|████████▎ | 497/600 [04:00<00:30,  3.34it/s] 83%|████████▎ | 498/600 [04:00<00:29,  3.43it/s] 83%|████████▎ | 499/600 [04:00<00:28,  3.49it/s] 83%|████████▎ | 500/600 [04:00<00:28,  3.54it/s]                                                  83%|████████▎ | 500/600 [04:00<00:28,  3.54it/s] 84%|████████▎ | 501/600 [04:01<00:27,  3.57it/s] 84%|████████▎ | 502/600 [04:01<00:27,  3.60it/s] 84%|████████▍ | 503/600 [04:01<00:27,  3.59it/s] 84%|████████▍ | 504/600 [04:02<00:26,  3.61it/s] 84%|████████▍ | 505/600 [04:02<00:26,  3.63it/s] 84%|████████▍ | 506/600 [04:02<00:25,  3.64it/s] 84%|████████▍ | 507/600 [04:02<00:25,  3.64it/s] 85%|████████▍ | 508/600 [04:03<00:25,  3.65it/s] 85%|████████▍ | 509/600 [04:03<00:24,  3.65it/s] 85%|████████▌ | 510/600 [04:03<00:24,  3.65it/s] 85%|████████▌ | 511/600 [04:03<00:24,  3.65it/s] 85%|████████▌ | 512/600 [04:04<00:24,  3.65it/s] 86%|████████▌ | 513/600 [04:04<00:23,  3.66it/s] 86%|████████▌ | 514/600 [04:04<00:23,  3.63it/s] 86%|████████▌ | 515/600 [04:05<00:23,  3.64it/s] 86%|████████▌ | 516/600 [04:05<00:23,  3.64it/s] 86%|████████▌ | 517/600 [04:05<00:22,  3.64it/s] 86%|████████▋ | 518/600 [04:05<00:22,  3.65it/s] 86%|████████▋ | 519/600 [04:06<00:22,  3.65it/s] 87%|████████▋ | 520/600 [04:06<00:21,  3.65it/s] 87%|████████▋ | 521/600 [04:06<00:21,  3.65it/s] 87%|████████▋ | 522/600 [04:07<00:21,  3.65it/s] 87%|████████▋ | 523/600 [04:07<00:21,  3.65it/s] 87%|████████▋ | 524/600 [04:07<00:20,  3.62it/s] 88%|████████▊ | 525/600 [04:07<00:20,  3.60it/s] 88%|████████▊ | 526/600 [04:08<00:20,  3.62it/s] 88%|████████▊ | 527/600 [04:08<00:20,  3.63it/s] 88%|████████▊ | 528/600 [04:08<00:19,  3.63it/s] 88%|████████▊ | 529/600 [04:08<00:19,  3.64it/s] 88%|████████▊ | 530/600 [04:09<00:19,  3.64it/s] 88%|████████▊ | 531/600 [04:09<00:18,  3.65it/s] 89%|████████▊ | 532/600 [04:09<00:18,  3.65it/s] 89%|████████▉ | 533/600 [04:10<00:18,  3.65it/s] 89%|████████▉ | 534/600 [04:10<00:18,  3.65it/s] 89%|████████▉ | 535/600 [04:10<00:17,  3.65it/s] 89%|████████▉ | 536/600 [04:10<00:17,  3.64it/s] 90%|████████▉ | 537/600 [04:11<00:17,  3.64it/s] 90%|████████▉ | 538/600 [04:11<00:17,  3.65it/s] 90%|████████▉ | 539/600 [04:11<00:16,  3.65it/s] 90%|█████████ | 540/600 [04:11<00:16,  3.65it/s] 90%|█████████ | 541/600 [04:12<00:16,  3.65it/s] 90%|█████████ | 542/600 [04:12<00:15,  3.65it/s] 90%|█████████ | 543/600 [04:12<00:15,  3.65it/s] 91%|█████████ | 544/600 [04:13<00:15,  3.65it/s] 91%|█████████ | 545/600 [04:13<00:15,  3.65it/s] 91%|█████████ | 546/600 [04:13<00:14,  3.65it/s] 91%|█████████ | 547/600 [04:13<00:14,  3.64it/s] 91%|█████████▏| 548/600 [04:14<00:14,  3.64it/s] 92%|█████████▏| 549/600 [04:14<00:14,  3.64it/s] 92%|█████████▏| 550/600 [04:14<00:13,  3.64it/s] 92%|█████████▏| 551/600 [04:14<00:13,  3.65it/s] 92%|█████████▏| 552/600 [04:15<00:13,  3.65it/s] 92%|█████████▏| 553/600 [04:15<00:12,  3.65it/s] 92%|█████████▏| 554/600 [04:15<00:12,  3.65it/s] 92%|█████████▎| 555/600 [04:16<00:12,  3.65it/s] 93%|█████████▎| 556/600 [04:16<00:12,  3.65it/s] 93%|█████████▎| 557/600 [04:16<00:11,  3.65it/s] 93%|█████████▎| 558/600 [04:16<00:11,  3.63it/s] 93%|█████████▎| 559/600 [04:17<00:11,  3.64it/s] 93%|█████████▎| 560/600 [04:17<00:10,  3.64it/s] 94%|█████████▎| 561/600 [04:17<00:10,  3.64it/s] 94%|█████████▎| 562/600 [04:17<00:10,  3.64it/s] 94%|█████████▍| 563/600 [04:18<00:10,  3.65it/s] 94%|█████████▍| 564/600 [04:18<00:09,  3.65it/s] 94%|█████████▍| 565/600 [04:18<00:09,  3.65it/s] 94%|█████████▍| 566/600 [04:19<00:09,  3.65it/s] 94%|█████████▍| 567/600 [04:19<00:09,  3.65it/s] 95%|█████████▍| 568/600 [04:19<00:08,  3.65it/s] 95%|█████████▍| 569/600 [04:19<00:08,  3.63it/s] 95%|█████████▌| 570/600 [04:20<00:08,  3.64it/s] 95%|█████████▌| 571/600 [04:20<00:07,  3.64it/s] 95%|█████████▌| 572/600 [04:20<00:07,  3.64it/s] 96%|█████████▌| 573/600 [04:21<00:07,  3.65it/s] 96%|█████████▌| 574/600 [04:21<00:07,  3.65it/s] 96%|█████████▌| 575/600 [04:21<00:06,  3.65it/s] 96%|█████████▌| 576/600 [04:21<00:06,  3.65it/s] 96%|█████████▌| 577/600 [04:22<00:06,  3.65it/s] 96%|█████████▋| 578/600 [04:22<00:06,  3.65it/s] 96%|█████████▋| 579/600 [04:22<00:05,  3.65it/s] 97%|█████████▋| 580/600 [04:22<00:05,  3.63it/s] 97%|█████████▋| 581/600 [04:23<00:05,  3.64it/s] 97%|█████████▋| 582/600 [04:23<00:04,  3.64it/s] 97%|█████████▋| 583/600 [04:23<00:04,  3.64it/s] 97%|█████████▋| 584/600 [04:24<00:04,  3.65it/s] 98%|█████████▊| 585/600 [04:24<00:04,  3.65it/s] 98%|█████████▊| 586/600 [04:24<00:03,  3.65it/s] 98%|█████████▊| 587/600 [04:24<00:03,  3.65it/s] 98%|█████████▊| 588/600 [04:25<00:03,  3.65it/s] 98%|█████████▊| 589/600 [04:25<00:03,  3.65it/s] 98%|█████████▊| 590/600 [04:25<00:02,  3.65it/s] 98%|█████████▊| 591/600 [04:25<00:02,  3.63it/s] 99%|█████████▊| 592/600 [04:26<00:02,  3.64it/s] 99%|█████████▉| 593/600 [04:26<00:01,  3.64it/s] 99%|█████████▉| 594/600 [04:26<00:01,  3.64it/s] 99%|█████████▉| 595/600 [04:27<00:01,  3.64it/s] 99%|█████████▉| 596/600 [04:27<00:01,  3.65it/s]100%|█████████▉| 597/600 [04:27<00:00,  3.65it/s]100%|█████████▉| 598/600 [04:27<00:00,  3.65it/s]100%|█████████▉| 599/600 [04:28<00:00,  3.65it/s]100%|██████████| 600/600 [04:28<00:00,  3.65it/s][INFO|trainer.py:2140] 2023-08-29 17:33:40,161 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 17:33:40,161 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 17:33:40,161 >>   Batch size = 8
{'eval_loss': 0.9968060255050659, 'eval_runtime': 23.0603, 'eval_samples_per_second': 371.548, 'eval_steps_per_second': 46.444, 'epoch': 4.0}
{'loss': nan, 'learning_rate': 1.6625e-05, 'epoch': 4.17}

  0%|          | 0/1071 [00:00<?, ?it/s][A
  1%|          | 6/1071 [00:00<00:18, 57.24it/s][A
  1%|          | 12/1071 [00:00<00:20, 50.47it/s][A
  2%|▏         | 18/1071 [00:00<00:21, 48.72it/s][A
  2%|▏         | 23/1071 [00:00<00:21, 48.03it/s][A
  3%|▎         | 28/1071 [00:00<00:21, 47.62it/s][A
  3%|▎         | 33/1071 [00:00<00:21, 47.33it/s][A
  4%|▎         | 38/1071 [00:00<00:21, 47.03it/s][A
  4%|▍         | 43/1071 [00:00<00:21, 46.78it/s][A
  4%|▍         | 48/1071 [00:01<00:21, 46.64it/s][A
  5%|▍         | 53/1071 [00:01<00:21, 46.60it/s][A
  5%|▌         | 58/1071 [00:01<00:21, 46.65it/s][A
  6%|▌         | 63/1071 [00:01<00:21, 46.67it/s][A
  6%|▋         | 68/1071 [00:01<00:21, 46.71it/s][A
  7%|▋         | 73/1071 [00:01<00:21, 46.74it/s][A
  7%|▋         | 78/1071 [00:01<00:21, 46.73it/s][A
  8%|▊         | 83/1071 [00:01<00:21, 46.66it/s][A
  8%|▊         | 88/1071 [00:01<00:21, 46.58it/s][A
  9%|▊         | 93/1071 [00:01<00:21, 46.51it/s][A
  9%|▉         | 98/1071 [00:02<00:20, 46.53it/s][A
 10%|▉         | 103/1071 [00:02<00:20, 46.50it/s][A
 10%|█         | 108/1071 [00:02<00:20, 46.53it/s][A
 11%|█         | 113/1071 [00:02<00:20, 46.62it/s][A
 11%|█         | 118/1071 [00:02<00:20, 46.66it/s][A
 11%|█▏        | 123/1071 [00:02<00:20, 46.63it/s][A
 12%|█▏        | 128/1071 [00:02<00:20, 46.58it/s][A
 12%|█▏        | 133/1071 [00:02<00:20, 46.51it/s][A
 13%|█▎        | 138/1071 [00:02<00:20, 46.52it/s][A
 13%|█▎        | 143/1071 [00:03<00:19, 46.49it/s][A
 14%|█▍        | 148/1071 [00:03<00:19, 46.49it/s][A
 14%|█▍        | 153/1071 [00:03<00:19, 46.54it/s][A
 15%|█▍        | 158/1071 [00:03<00:19, 46.49it/s][A
 15%|█▌        | 163/1071 [00:03<00:19, 46.59it/s][A
 16%|█▌        | 168/1071 [00:03<00:19, 46.63it/s][A
 16%|█▌        | 173/1071 [00:03<00:19, 46.68it/s][A
 17%|█▋        | 178/1071 [00:03<00:19, 46.65it/s][A
 17%|█▋        | 183/1071 [00:03<00:19, 46.59it/s][A
 18%|█▊        | 188/1071 [00:04<00:18, 46.50it/s][A
 18%|█▊        | 193/1071 [00:04<00:18, 46.55it/s][A
 18%|█▊        | 198/1071 [00:04<00:18, 46.51it/s][A
 19%|█▉        | 203/1071 [00:04<00:18, 46.55it/s][A
 19%|█▉        | 208/1071 [00:04<00:18, 46.61it/s][A
 20%|█▉        | 213/1071 [00:04<00:18, 46.66it/s][A
 20%|██        | 218/1071 [00:04<00:18, 46.65it/s][A
 21%|██        | 223/1071 [00:04<00:18, 46.58it/s][A
 21%|██▏       | 228/1071 [00:04<00:18, 46.55it/s][A
 22%|██▏       | 233/1071 [00:04<00:18, 46.54it/s][A
 22%|██▏       | 238/1071 [00:05<00:17, 46.49it/s][A
 23%|██▎       | 243/1071 [00:05<00:17, 46.52it/s][A
 23%|██▎       | 248/1071 [00:05<00:17, 46.61it/s][A
 24%|██▎       | 253/1071 [00:05<00:17, 46.66it/s][A
 24%|██▍       | 258/1071 [00:05<00:17, 46.67it/s][A
 25%|██▍       | 263/1071 [00:05<00:17, 46.65it/s][A
 25%|██▌       | 268/1071 [00:05<00:17, 46.59it/s][A
 25%|██▌       | 273/1071 [00:05<00:17, 46.59it/s][A
 26%|██▌       | 278/1071 [00:05<00:17, 46.55it/s][A
 26%|██▋       | 283/1071 [00:06<00:16, 46.49it/s][A
 27%|██▋       | 288/1071 [00:06<00:16, 46.50it/s][A
 27%|██▋       | 293/1071 [00:06<00:16, 46.49it/s][A
 28%|██▊       | 298/1071 [00:06<00:16, 46.56it/s][A
 28%|██▊       | 303/1071 [00:06<00:16, 46.62it/s][A
 29%|██▉       | 308/1071 [00:06<00:16, 46.62it/s][A
 29%|██▉       | 313/1071 [00:06<00:16, 46.62it/s][A
 30%|██▉       | 318/1071 [00:06<00:16, 46.58it/s][A
 30%|███       | 323/1071 [00:06<00:16, 46.54it/s][A
 31%|███       | 328/1071 [00:07<00:15, 46.53it/s][A
 31%|███       | 333/1071 [00:07<00:15, 46.51it/s][A
 32%|███▏      | 338/1071 [00:07<00:15, 46.54it/s][A
 32%|███▏      | 343/1071 [00:07<00:15, 46.63it/s][A
 32%|███▏      | 348/1071 [00:07<00:15, 46.65it/s][A
 33%|███▎      | 353/1071 [00:07<00:15, 46.61it/s][A
 33%|███▎      | 358/1071 [00:07<00:15, 46.57it/s][A
 34%|███▍      | 363/1071 [00:07<00:15, 46.53it/s][A
 34%|███▍      | 368/1071 [00:07<00:15, 46.53it/s][A
 35%|███▍      | 373/1071 [00:07<00:15, 46.48it/s][A
 35%|███▌      | 378/1071 [00:08<00:14, 46.51it/s][A
 36%|███▌      | 383/1071 [00:08<00:14, 46.60it/s][A
 36%|███▌      | 388/1071 [00:08<00:14, 46.64it/s][A
 37%|███▋      | 393/1071 [00:08<00:14, 46.65it/s][A
 37%|███▋      | 398/1071 [00:08<00:14, 46.61it/s][A
 38%|███▊      | 403/1071 [00:08<00:14, 46.56it/s][A
 38%|███▊      | 408/1071 [00:08<00:14, 46.58it/s][A
 39%|███▊      | 413/1071 [00:08<00:14, 46.54it/s][A
 39%|███▉      | 418/1071 [00:08<00:14, 46.47it/s][A
 39%|███▉      | 423/1071 [00:09<00:13, 46.50it/s][A
 40%|███▉      | 428/1071 [00:09<00:13, 46.48it/s][A
 40%|████      | 433/1071 [00:09<00:13, 46.57it/s][A
 41%|████      | 438/1071 [00:09<00:13, 46.63it/s][A
 41%|████▏     | 443/1071 [00:09<00:13, 46.62it/s][A
 42%|████▏     | 448/1071 [00:09<00:13, 46.60it/s][A
 42%|████▏     | 453/1071 [00:09<00:13, 46.55it/s][A
 43%|████▎     | 458/1071 [00:09<00:13, 46.51it/s][A
 43%|████▎     | 463/1071 [00:09<00:13, 46.53it/s][A
 44%|████▎     | 468/1071 [00:10<00:12, 46.50it/s][A
 44%|████▍     | 473/1071 [00:10<00:12, 46.52it/s][A
 45%|████▍     | 478/1071 [00:10<00:12, 46.52it/s][A
 45%|████▌     | 483/1071 [00:10<00:12, 46.50it/s][A
 46%|████▌     | 488/1071 [00:10<00:12, 46.59it/s][A
 46%|████▌     | 493/1071 [00:10<00:12, 46.59it/s][A
 46%|████▋     | 498/1071 [00:10<00:12, 46.53it/s][A
 47%|████▋     | 503/1071 [00:10<00:12, 46.57it/s][A
 47%|████▋     | 508/1071 [00:10<00:12, 46.53it/s][A
 48%|████▊     | 513/1071 [00:10<00:11, 46.53it/s][A
 48%|████▊     | 518/1071 [00:11<00:11, 46.52it/s][A
 49%|████▉     | 523/1071 [00:11<00:11, 46.50it/s][A
 49%|████▉     | 528/1071 [00:11<00:11, 46.55it/s][A
 50%|████▉     | 533/1071 [00:11<00:11, 46.61it/s][A
 50%|█████     | 538/1071 [00:11<00:11, 46.53it/s][A
 51%|█████     | 543/1071 [00:11<00:11, 46.59it/s][A
 51%|█████     | 548/1071 [00:11<00:11, 46.54it/s][A
 52%|█████▏    | 553/1071 [00:11<00:11, 46.53it/s][A
 52%|█████▏    | 558/1071 [00:11<00:11, 46.54it/s][A
 53%|█████▎    | 563/1071 [00:12<00:10, 46.50it/s][A
 53%|█████▎    | 568/1071 [00:12<00:10, 46.55it/s][A
 54%|█████▎    | 573/1071 [00:12<00:10, 46.51it/s][A
 54%|█████▍    | 578/1071 [00:12<00:10, 46.50it/s][A
 54%|█████▍    | 583/1071 [00:12<00:10, 46.59it/s][A
 55%|█████▍    | 588/1071 [00:12<00:10, 45.36it/s][A
 55%|█████▌    | 593/1071 [00:12<00:10, 46.42it/s][A
 56%|█████▌    | 598/1071 [00:12<00:10, 46.50it/s][A
 56%|█████▋    | 603/1071 [00:12<00:10, 46.47it/s][A
 57%|█████▋    | 608/1071 [00:13<00:09, 46.54it/s][A
 57%|█████▋    | 613/1071 [00:13<00:09, 46.52it/s][A
 58%|█████▊    | 618/1071 [00:13<00:09, 46.55it/s][A
 58%|█████▊    | 623/1071 [00:13<00:09, 46.54it/s][A
 59%|█████▊    | 628/1071 [00:13<00:09, 46.51it/s][A
 59%|█████▉    | 633/1071 [00:13<00:09, 46.55it/s][A
 60%|█████▉    | 638/1071 [00:13<00:09, 46.53it/s][A
 60%|██████    | 643/1071 [00:13<00:09, 46.50it/s][A
 61%|██████    | 648/1071 [00:13<00:09, 46.57it/s][A
 61%|██████    | 653/1071 [00:14<00:08, 46.54it/s][A
 61%|██████▏   | 658/1071 [00:14<00:08, 46.55it/s][A
 62%|██████▏   | 663/1071 [00:14<00:08, 46.57it/s][A
 62%|██████▏   | 668/1071 [00:14<00:08, 46.54it/s][A
 63%|██████▎   | 673/1071 [00:14<00:08, 46.54it/s][A
 63%|██████▎   | 678/1071 [00:14<00:08, 46.52it/s][A
 64%|██████▍   | 683/1071 [00:14<00:08, 46.50it/s][A
 64%|██████▍   | 688/1071 [00:14<00:08, 46.55it/s][A
 65%|██████▍   | 693/1071 [00:14<00:08, 46.52it/s][A
 65%|██████▌   | 698/1071 [00:14<00:08, 46.53it/s][A
 66%|██████▌   | 703/1071 [00:15<00:07, 46.52it/s][A
 66%|██████▌   | 708/1071 [00:15<00:07, 46.51it/s][A
 67%|██████▋   | 713/1071 [00:15<00:07, 46.56it/s][A
 67%|██████▋   | 718/1071 [00:15<00:07, 46.50it/s][A
 68%|██████▊   | 723/1071 [00:15<00:07, 46.48it/s][A
 68%|██████▊   | 728/1071 [00:15<00:07, 46.52it/s][A
 68%|██████▊   | 733/1071 [00:15<00:07, 46.50it/s][A
 69%|██████▉   | 738/1071 [00:15<00:07, 46.53it/s][A
 69%|██████▉   | 743/1071 [00:15<00:07, 46.54it/s][A
 70%|██████▉   | 748/1071 [00:16<00:06, 46.51it/s][A
 70%|███████   | 753/1071 [00:16<00:06, 46.54it/s][A
 71%|███████   | 758/1071 [00:16<00:06, 46.56it/s][A
 71%|███████   | 763/1071 [00:16<00:06, 46.48it/s][A
 72%|███████▏  | 768/1071 [00:16<00:06, 46.59it/s][A
 72%|███████▏  | 773/1071 [00:16<00:06, 46.56it/s][A
 73%|███████▎  | 778/1071 [00:16<00:06, 46.57it/s][A
 73%|███████▎  | 783/1071 [00:16<00:06, 46.60it/s][A
 74%|███████▎  | 788/1071 [00:16<00:06, 46.56it/s][A
 74%|███████▍  | 793/1071 [00:17<00:05, 46.58it/s][A
 75%|███████▍  | 798/1071 [00:17<00:05, 46.54it/s][A
 75%|███████▍  | 803/1071 [00:17<00:05, 46.51it/s][A
 75%|███████▌  | 808/1071 [00:17<00:05, 46.53it/s][A
 76%|███████▌  | 813/1071 [00:17<00:05, 46.51it/s][A
 76%|███████▋  | 818/1071 [00:17<00:05, 46.51it/s][A
 77%|███████▋  | 823/1071 [00:17<00:05, 46.59it/s][A
 77%|███████▋  | 828/1071 [00:17<00:05, 46.55it/s][A
 78%|███████▊  | 833/1071 [00:17<00:05, 46.56it/s][A
 78%|███████▊  | 838/1071 [00:17<00:05, 46.46it/s][A
 79%|███████▊  | 843/1071 [00:18<00:04, 46.46it/s][A
 79%|███████▉  | 848/1071 [00:18<00:04, 46.51it/s][A
 80%|███████▉  | 853/1071 [00:18<00:04, 46.49it/s][A
 80%|████████  | 858/1071 [00:18<00:04, 46.50it/s][A
 81%|████████  | 863/1071 [00:18<00:04, 46.50it/s][A
 81%|████████  | 868/1071 [00:18<00:04, 46.49it/s][A
 82%|████████▏ | 873/1071 [00:18<00:04, 46.58it/s][A
 82%|████████▏ | 878/1071 [00:18<00:04, 46.59it/s][A
 82%|████████▏ | 883/1071 [00:18<00:04, 46.55it/s][A
 83%|████████▎ | 888/1071 [00:19<00:03, 46.56it/s][A
 83%|████████▎ | 893/1071 [00:19<00:03, 46.52it/s][A
 84%|████████▍ | 898/1071 [00:19<00:03, 46.52it/s][A
 84%|████████▍ | 903/1071 [00:19<00:03, 46.51it/s][A
 85%|████████▍ | 908/1071 [00:19<00:03, 46.50it/s][A
 85%|████████▌ | 913/1071 [00:19<00:03, 46.54it/s][A
 86%|████████▌ | 918/1071 [00:19<00:03, 46.60it/s][A
 86%|████████▌ | 923/1071 [00:19<00:03, 46.56it/s][A
 87%|████████▋ | 928/1071 [00:19<00:03, 46.56it/s][A
 87%|████████▋ | 933/1071 [00:20<00:02, 46.53it/s][A
 88%|████████▊ | 938/1071 [00:20<00:02, 46.53it/s][A
 88%|████████▊ | 943/1071 [00:20<00:02, 46.54it/s][A
 89%|████████▊ | 948/1071 [00:20<00:02, 46.51it/s][A
 89%|████████▉ | 953/1071 [00:20<00:02, 46.49it/s][A
 89%|████████▉ | 958/1071 [00:20<00:02, 44.73it/s][A
 90%|█████████ | 964/1071 [00:20<00:02, 46.38it/s][A
 90%|█████████ | 969/1071 [00:20<00:02, 46.49it/s][A
 91%|█████████ | 974/1071 [00:20<00:02, 46.49it/s][A
 91%|█████████▏| 979/1071 [00:21<00:01, 46.54it/s][A
 92%|█████████▏| 984/1071 [00:21<00:01, 46.52it/s][A
 92%|█████████▏| 989/1071 [00:21<00:01, 46.53it/s][A
 93%|█████████▎| 994/1071 [00:21<00:01, 46.52it/s][A
 93%|█████████▎| 999/1071 [00:21<00:01, 46.49it/s][A
 94%|█████████▎| 1004/1071 [00:21<00:01, 46.47it/s][A
 94%|█████████▍| 1009/1071 [00:21<00:01, 46.46it/s][A
 95%|█████████▍| 1014/1071 [00:21<00:01, 46.47it/s][A
 95%|█████████▌| 1019/1071 [00:21<00:01, 46.58it/s][A
 96%|█████████▌| 1024/1071 [00:21<00:01, 46.58it/s][A
 96%|█████████▌| 1029/1071 [00:22<00:00, 46.57it/s][A
 97%|█████████▋| 1034/1071 [00:22<00:00, 46.55it/s][A
 97%|█████████▋| 1039/1071 [00:22<00:00, 46.52it/s][A
 97%|█████████▋| 1044/1071 [00:22<00:00, 46.54it/s][A
 98%|█████████▊| 1049/1071 [00:22<00:00, 46.51it/s][A
 98%|█████████▊| 1054/1071 [00:22<00:00, 46.47it/s][A
 99%|█████████▉| 1059/1071 [00:22<00:00, 46.50it/s][A
 99%|█████████▉| 1064/1071 [00:22<00:00, 46.49it/s][A
100%|█████████▉| 1069/1071 [00:22<00:00, 46.28it/s][A                                                 
                                                   [A100%|██████████| 600/600 [04:51<00:00,  3.65it/s]
100%|██████████| 1071/1071 [00:23<00:00, 46.28it/s][A
                                                   [A[INFO|trainer.py:1894] 2023-08-29 17:34:03,201 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-600
[INFO|configuration_utils.py:351] 2023-08-29 17:34:03,219 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-600/config.json
[INFO|modeling_utils.py:886] 2023-08-29 17:34:05,309 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-600/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 17:34:05,333 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-600/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 17:34:05,343 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-600/special_tokens_map.json
[INFO|trainer.py:1343] 2023-08-29 17:34:05,613 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:1352] 2023-08-29 17:34:05,613 >> Loading best model from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-120 (score: 0.9968060255050659).
                                                 100%|██████████| 600/600 [04:56<00:00,  3.65it/s]100%|██████████| 600/600 [04:56<00:00,  2.03it/s]
[INFO|trainer.py:1894] 2023-08-29 17:34:07,920 >> Saving model checkpoint to outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model
[INFO|configuration_utils.py:351] 2023-08-29 17:34:07,940 >> Configuration saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/config.json
[INFO|modeling_utils.py:886] 2023-08-29 17:34:10,620 >> Model weights saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/pytorch_model.bin
[INFO|tokenization_utils_base.py:1925] 2023-08-29 17:34:10,633 >> tokenizer config file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/tokenizer_config.json
[INFO|tokenization_utils_base.py:1931] 2023-08-29 17:34:10,645 >> Special tokens file saved in outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/special_tokens_map.json
[INFO|trainer_pt_utils.py:908] 2023-08-29 17:34:10,831 >> ***** train metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:10,831 >>   epoch                    =        5.0
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:10,831 >>   train_loss               =        nan
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:10,831 >>   train_runtime            = 0:04:56.17
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:10,831 >>   train_samples            =       7700
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:10,831 >>   train_samples_per_second =    129.991
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:10,831 >>   train_steps_per_second   =      2.026
{'eval_loss': 0.9968060255050659, 'eval_runtime': 23.0184, 'eval_samples_per_second': 372.225, 'eval_steps_per_second': 46.528, 'epoch': 5.0}
{'train_runtime': 296.1736, 'train_samples_per_second': 129.991, 'train_steps_per_second': 2.026, 'train_loss': nan, 'epoch': 5.0}
08/29/2023 17:34:10 - INFO - transformer_base.run_clm_rl -   *** Evaluate ***
[INFO|trainer.py:2140] 2023-08-29 17:34:10,879 >> ***** Running Evaluation *****
[INFO|trainer.py:2142] 2023-08-29 17:34:10,879 >>   Num examples = 8568
[INFO|trainer.py:2145] 2023-08-29 17:34:10,879 >>   Batch size = 8
  0%|          | 0/1071 [00:00<?, ?it/s]  1%|          | 6/1071 [00:00<00:18, 58.34it/s]  1%|          | 12/1071 [00:00<00:20, 51.23it/s]  2%|▏         | 18/1071 [00:00<00:21, 49.31it/s]  2%|▏         | 23/1071 [00:00<00:21, 48.54it/s]  3%|▎         | 28/1071 [00:00<00:21, 48.08it/s]  3%|▎         | 33/1071 [00:00<00:21, 47.80it/s]  4%|▎         | 38/1071 [00:00<00:21, 47.56it/s]  4%|▍         | 43/1071 [00:00<00:21, 47.39it/s]  4%|▍         | 48/1071 [00:00<00:21, 47.08it/s]  5%|▍         | 53/1071 [00:01<00:21, 47.06it/s]  5%|▌         | 58/1071 [00:01<00:21, 47.08it/s]  6%|▌         | 63/1071 [00:01<00:21, 47.06it/s]  6%|▋         | 68/1071 [00:01<00:21, 47.02it/s]  7%|▋         | 73/1071 [00:01<00:21, 47.03it/s]  7%|▋         | 78/1071 [00:01<00:21, 47.00it/s]  8%|▊         | 83/1071 [00:01<00:21, 46.96it/s]  8%|▊         | 88/1071 [00:01<00:20, 46.94it/s]  9%|▊         | 93/1071 [00:01<00:20, 46.78it/s]  9%|▉         | 98/1071 [00:02<00:20, 46.76it/s] 10%|▉         | 103/1071 [00:02<00:20, 46.87it/s] 10%|█         | 108/1071 [00:02<00:20, 46.92it/s] 11%|█         | 113/1071 [00:02<00:20, 46.91it/s] 11%|█         | 118/1071 [00:02<00:20, 46.95it/s] 11%|█▏        | 123/1071 [00:02<00:20, 46.95it/s] 12%|█▏        | 128/1071 [00:02<00:20, 46.90it/s] 12%|█▏        | 133/1071 [00:02<00:20, 46.87it/s] 13%|█▎        | 138/1071 [00:02<00:19, 46.74it/s] 13%|█▎        | 143/1071 [00:03<00:19, 46.72it/s] 14%|█▍        | 148/1071 [00:03<00:19, 46.80it/s] 14%|█▍        | 153/1071 [00:03<00:19, 46.85it/s] 15%|█▍        | 158/1071 [00:03<00:19, 46.88it/s] 15%|█▌        | 163/1071 [00:03<00:19, 46.93it/s] 16%|█▌        | 168/1071 [00:03<00:19, 46.91it/s] 16%|█▌        | 173/1071 [00:03<00:19, 46.86it/s] 17%|█▋        | 178/1071 [00:03<00:19, 46.84it/s] 17%|█▋        | 183/1071 [00:03<00:18, 46.76it/s] 18%|█▊        | 188/1071 [00:03<00:18, 46.77it/s] 18%|█▊        | 193/1071 [00:04<00:18, 46.77it/s] 18%|█▊        | 198/1071 [00:04<00:18, 46.82it/s] 19%|█▉        | 203/1071 [00:04<00:18, 46.92it/s] 19%|█▉        | 208/1071 [00:04<00:18, 46.95it/s] 20%|█▉        | 213/1071 [00:04<00:18, 46.93it/s] 20%|██        | 218/1071 [00:04<00:18, 46.89it/s] 21%|██        | 223/1071 [00:04<00:18, 46.84it/s] 21%|██▏       | 228/1071 [00:04<00:18, 46.78it/s] 22%|██▏       | 233/1071 [00:04<00:17, 46.77it/s] 22%|██▏       | 238/1071 [00:05<00:17, 46.75it/s] 23%|██▎       | 243/1071 [00:05<00:17, 46.75it/s] 23%|██▎       | 248/1071 [00:05<00:17, 46.89it/s] 24%|██▎       | 253/1071 [00:05<00:17, 46.95it/s] 24%|██▍       | 258/1071 [00:05<00:17, 46.91it/s] 25%|██▍       | 263/1071 [00:05<00:17, 46.92it/s] 25%|██▌       | 268/1071 [00:05<00:17, 46.86it/s] 25%|██▌       | 273/1071 [00:05<00:17, 46.78it/s] 26%|██▌       | 278/1071 [00:05<00:16, 46.78it/s] 26%|██▋       | 283/1071 [00:06<00:16, 46.76it/s] 27%|██▋       | 288/1071 [00:06<00:16, 46.73it/s] 27%|██▋       | 293/1071 [00:06<00:16, 46.81it/s] 28%|██▊       | 298/1071 [00:06<00:16, 46.86it/s] 28%|██▊       | 303/1071 [00:06<00:16, 46.87it/s] 29%|██▉       | 308/1071 [00:06<00:16, 46.92it/s] 29%|██▉       | 313/1071 [00:06<00:16, 46.88it/s] 30%|██▉       | 318/1071 [00:06<00:16, 46.79it/s] 30%|███       | 323/1071 [00:06<00:15, 46.81it/s] 31%|███       | 328/1071 [00:06<00:15, 46.71it/s] 31%|███       | 333/1071 [00:07<00:15, 46.67it/s] 32%|███▏      | 338/1071 [00:07<00:15, 46.78it/s] 32%|███▏      | 343/1071 [00:07<00:15, 46.85it/s] 32%|███▏      | 348/1071 [00:07<00:15, 46.83it/s] 33%|███▎      | 353/1071 [00:07<00:15, 46.88it/s] 33%|███▎      | 358/1071 [00:07<00:15, 46.88it/s] 34%|███▍      | 363/1071 [00:07<00:15, 46.82it/s] 34%|███▍      | 368/1071 [00:07<00:15, 46.80it/s] 35%|███▍      | 373/1071 [00:07<00:14, 46.76it/s] 35%|███▌      | 378/1071 [00:08<00:14, 46.75it/s] 36%|███▌      | 383/1071 [00:08<00:14, 46.83it/s] 36%|███▌      | 388/1071 [00:08<00:14, 46.87it/s] 37%|███▋      | 393/1071 [00:08<00:14, 46.83it/s] 37%|███▋      | 398/1071 [00:08<00:14, 45.58it/s] 38%|███▊      | 403/1071 [00:08<00:14, 46.05it/s] 38%|███▊      | 408/1071 [00:08<00:14, 46.34it/s] 39%|███▊      | 413/1071 [00:08<00:14, 46.43it/s] 39%|███▉      | 418/1071 [00:08<00:14, 46.56it/s] 39%|███▉      | 423/1071 [00:09<00:13, 46.61it/s] 40%|███▉      | 428/1071 [00:09<00:13, 46.67it/s] 40%|████      | 433/1071 [00:09<00:13, 46.76it/s] 41%|████      | 438/1071 [00:09<00:13, 46.71it/s] 41%|████▏     | 443/1071 [00:09<00:13, 46.67it/s] 42%|████▏     | 448/1071 [00:09<00:13, 46.78it/s] 42%|████▏     | 453/1071 [00:09<00:13, 46.81it/s] 43%|████▎     | 458/1071 [00:09<00:13, 46.77it/s] 43%|████▎     | 463/1071 [00:09<00:12, 46.78it/s] 44%|████▎     | 468/1071 [00:09<00:12, 46.77it/s] 44%|████▍     | 473/1071 [00:10<00:12, 46.73it/s] 45%|████▍     | 478/1071 [00:10<00:12, 46.79it/s] 45%|████▌     | 483/1071 [00:10<00:12, 46.73it/s] 46%|████▌     | 488/1071 [00:10<00:12, 46.75it/s] 46%|████▌     | 493/1071 [00:10<00:12, 46.75it/s] 46%|████▋     | 498/1071 [00:10<00:12, 46.75it/s] 47%|████▋     | 503/1071 [00:10<00:12, 46.75it/s] 47%|████▋     | 508/1071 [00:10<00:12, 46.67it/s] 48%|████▊     | 513/1071 [00:10<00:11, 46.61it/s] 48%|████▊     | 518/1071 [00:11<00:11, 46.70it/s] 49%|████▉     | 523/1071 [00:11<00:11, 46.72it/s] 49%|████▉     | 528/1071 [00:11<00:11, 46.71it/s] 50%|████▉     | 533/1071 [00:11<00:11, 46.81it/s] 50%|█████     | 538/1071 [00:11<00:11, 46.87it/s] 51%|█████     | 543/1071 [00:11<00:11, 46.84it/s] 51%|█████     | 548/1071 [00:11<00:11, 46.85it/s] 52%|█████▏    | 553/1071 [00:11<00:11, 46.82it/s] 52%|█████▏    | 558/1071 [00:11<00:10, 46.71it/s] 53%|█████▎    | 563/1071 [00:12<00:10, 46.75it/s] 53%|█████▎    | 568/1071 [00:12<00:10, 46.75it/s] 54%|█████▎    | 573/1071 [00:12<00:10, 46.73it/s] 54%|█████▍    | 578/1071 [00:12<00:10, 46.78it/s] 54%|█████▍    | 583/1071 [00:12<00:10, 46.77it/s] 55%|█████▍    | 588/1071 [00:12<00:10, 46.81it/s] 55%|█████▌    | 593/1071 [00:12<00:10, 46.83it/s] 56%|█████▌    | 598/1071 [00:12<00:10, 46.83it/s] 56%|█████▋    | 603/1071 [00:12<00:10, 46.80it/s] 57%|█████▋    | 608/1071 [00:12<00:09, 46.78it/s] 57%|█████▋    | 613/1071 [00:13<00:09, 46.74it/s] 58%|█████▊    | 618/1071 [00:13<00:09, 46.71it/s] 58%|█████▊    | 623/1071 [00:13<00:09, 46.74it/s] 59%|█████▊    | 628/1071 [00:13<00:09, 46.73it/s] 59%|█████▉    | 633/1071 [00:13<00:09, 46.80it/s] 60%|█████▉    | 638/1071 [00:13<00:09, 46.86it/s] 60%|██████    | 643/1071 [00:13<00:09, 46.80it/s] 61%|██████    | 648/1071 [00:13<00:09, 46.81it/s] 61%|██████    | 653/1071 [00:13<00:08, 46.79it/s] 61%|██████▏   | 658/1071 [00:14<00:08, 46.73it/s] 62%|██████▏   | 663/1071 [00:14<00:08, 46.75it/s] 62%|██████▏   | 668/1071 [00:14<00:08, 46.73it/s] 63%|██████▎   | 673/1071 [00:14<00:08, 46.74it/s] 63%|██████▎   | 678/1071 [00:14<00:08, 46.83it/s] 64%|██████▍   | 683/1071 [00:14<00:08, 46.85it/s] 64%|██████▍   | 688/1071 [00:14<00:08, 46.78it/s] 65%|██████▍   | 693/1071 [00:14<00:08, 46.81it/s] 65%|██████▌   | 698/1071 [00:14<00:07, 46.78it/s] 66%|██████▌   | 703/1071 [00:14<00:07, 46.77it/s] 66%|██████▌   | 708/1071 [00:15<00:07, 46.76it/s] 67%|██████▋   | 713/1071 [00:15<00:07, 46.67it/s] 67%|██████▋   | 718/1071 [00:15<00:07, 46.67it/s] 68%|██████▊   | 723/1071 [00:15<00:07, 46.78it/s] 68%|██████▊   | 728/1071 [00:15<00:07, 46.79it/s] 68%|██████▊   | 733/1071 [00:15<00:07, 46.77it/s] 69%|██████▉   | 738/1071 [00:15<00:07, 46.75it/s] 69%|██████▉   | 743/1071 [00:15<00:07, 46.74it/s] 70%|██████▉   | 748/1071 [00:15<00:06, 46.76it/s] 70%|███████   | 753/1071 [00:16<00:06, 46.77it/s] 71%|███████   | 758/1071 [00:16<00:06, 46.75it/s] 71%|███████   | 763/1071 [00:16<00:06, 46.81it/s] 72%|███████▏  | 768/1071 [00:16<00:06, 46.81it/s] 72%|███████▏  | 773/1071 [00:16<00:06, 46.76it/s] 73%|███████▎  | 778/1071 [00:16<00:06, 46.80it/s] 73%|███████▎  | 783/1071 [00:16<00:06, 46.79it/s] 74%|███████▎  | 788/1071 [00:16<00:06, 46.76it/s] 74%|███████▍  | 793/1071 [00:16<00:05, 46.79it/s] 75%|███████▍  | 798/1071 [00:17<00:05, 46.77it/s] 75%|███████▍  | 803/1071 [00:17<00:05, 46.72it/s] 75%|███████▌  | 808/1071 [00:17<00:05, 46.76it/s] 76%|███████▌  | 813/1071 [00:17<00:05, 46.75it/s] 76%|███████▋  | 818/1071 [00:17<00:05, 46.73it/s] 77%|███████▋  | 823/1071 [00:17<00:05, 46.75it/s] 77%|███████▋  | 828/1071 [00:17<00:05, 46.75it/s] 78%|███████▊  | 833/1071 [00:17<00:05, 46.77it/s] 78%|███████▊  | 838/1071 [00:17<00:05, 46.60it/s] 79%|███████▊  | 843/1071 [00:17<00:04, 46.63it/s] 79%|███████▉  | 848/1071 [00:18<00:04, 46.68it/s] 80%|███████▉  | 853/1071 [00:18<00:04, 46.70it/s] 80%|████████  | 858/1071 [00:18<00:04, 46.69it/s] 81%|████████  | 863/1071 [00:18<00:04, 46.73it/s] 81%|████████  | 868/1071 [00:18<00:04, 46.73it/s] 82%|████████▏ | 873/1071 [00:18<00:04, 46.69it/s] 82%|████████▏ | 878/1071 [00:18<00:04, 46.70it/s] 82%|████████▏ | 883/1071 [00:18<00:04, 46.69it/s] 83%|████████▎ | 888/1071 [00:18<00:03, 46.70it/s] 83%|████████▎ | 893/1071 [00:19<00:03, 46.80it/s] 84%|████████▍ | 898/1071 [00:19<00:03, 46.79it/s] 84%|████████▍ | 903/1071 [00:19<00:03, 46.76it/s] 85%|████████▍ | 908/1071 [00:19<00:03, 46.79it/s] 85%|████████▌ | 913/1071 [00:19<00:03, 46.78it/s] 86%|████████▌ | 918/1071 [00:19<00:03, 46.73it/s] 86%|████████▌ | 923/1071 [00:19<00:03, 46.69it/s] 87%|████████▋ | 928/1071 [00:19<00:03, 46.62it/s] 87%|████████▋ | 933/1071 [00:19<00:02, 46.69it/s] 88%|████████▊ | 938/1071 [00:20<00:02, 46.76it/s] 88%|████████▊ | 943/1071 [00:20<00:02, 46.78it/s] 89%|████████▊ | 948/1071 [00:20<00:02, 46.78it/s] 89%|████████▉ | 953/1071 [00:20<00:02, 46.77it/s] 89%|████████▉ | 958/1071 [00:20<00:02, 46.74it/s] 90%|████████▉ | 963/1071 [00:20<00:02, 46.76it/s] 90%|█████████ | 968/1071 [00:20<00:02, 46.72it/s] 91%|█████████ | 973/1071 [00:20<00:02, 46.61it/s] 91%|█████████▏| 978/1071 [00:20<00:01, 46.68it/s] 92%|█████████▏| 983/1071 [00:20<00:01, 46.69it/s] 92%|█████████▏| 988/1071 [00:21<00:01, 46.68it/s] 93%|█████████▎| 993/1071 [00:21<00:01, 46.75it/s] 93%|█████████▎| 998/1071 [00:21<00:01, 46.81it/s] 94%|█████████▎| 1003/1071 [00:21<00:01, 46.77it/s] 94%|█████████▍| 1008/1071 [00:21<00:01, 46.81it/s] 95%|█████████▍| 1013/1071 [00:21<00:01, 46.77it/s] 95%|█████████▌| 1018/1071 [00:21<00:01, 46.74it/s] 96%|█████████▌| 1023/1071 [00:21<00:01, 46.71it/s] 96%|█████████▌| 1028/1071 [00:21<00:00, 46.67it/s] 96%|█████████▋| 1033/1071 [00:22<00:00, 46.68it/s] 97%|█████████▋| 1038/1071 [00:22<00:00, 46.70it/s] 97%|█████████▋| 1043/1071 [00:22<00:00, 46.68it/s] 98%|█████████▊| 1048/1071 [00:22<00:00, 46.74it/s] 98%|█████████▊| 1053/1071 [00:22<00:00, 46.80it/s] 99%|█████████▉| 1058/1071 [00:22<00:00, 46.73it/s] 99%|█████████▉| 1063/1071 [00:22<00:00, 46.75it/s]100%|█████████▉| 1068/1071 [00:22<00:00, 46.75it/s]100%|██████████| 1071/1071 [00:22<00:00, 46.81it/s]
[INFO|trainer_pt_utils.py:908] 2023-08-29 17:34:33,781 >> ***** eval metrics *****
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:33,781 >>   epoch                   =        5.0
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:33,781 >>   eval_loss               =     0.9968
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:33,782 >>   eval_runtime            = 0:00:22.90
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:33,782 >>   eval_samples            =       8568
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:33,782 >>   eval_samples_per_second =    374.106
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:33,782 >>   eval_steps_per_second   =     46.763
[INFO|trainer_pt_utils.py:913] 2023-08-29 17:34:33,782 >>   perplexity              =     2.7096
/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/torch/nn/modules/rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:41,718 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:41,720 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:41,720 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:41,720 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:41,720 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 17:34:42,339 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 17:34:42,340 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 17:34:42,967 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 17:34:44,192 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 17:34:44,192 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:47,155 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:47,194 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:47,194 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:47,194 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:34:47,194 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 17:34:48,210 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 17:34:48,211 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 17:34:48,866 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 17:34:49,115 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 17:34:49,115 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-240
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-480
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-360
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-600
outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/generator/iter5/model/checkpoint-120
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/dev.jsonl', 'labels': ['country', 'place of death', 'production company', 'screenwriter', 'subsidiary'], 'mode': 'all_single', 'model_size': 'large', 'is_eval': True, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_in_all_single_is_eval_True.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_out_filter_all_single_is_eval_True.jsonl'}}
predict vocab size: 21439
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 21539, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.44it/s]Extractor Predicting: 2it [00:01,  1.57it/s]Extractor Predicting: 3it [00:01,  1.61it/s]Extractor Predicting: 4it [00:02,  1.67it/s]Extractor Predicting: 5it [00:03,  1.66it/s]Extractor Predicting: 6it [00:03,  1.66it/s]Extractor Predicting: 7it [00:04,  1.63it/s]Extractor Predicting: 8it [00:05,  1.52it/s]Extractor Predicting: 9it [00:05,  1.53it/s]Extractor Predicting: 10it [00:06,  1.57it/s]Extractor Predicting: 11it [00:06,  1.59it/s]Extractor Predicting: 12it [00:07,  1.54it/s]Extractor Predicting: 13it [00:08,  1.62it/s]Extractor Predicting: 14it [00:08,  1.63it/s]Extractor Predicting: 15it [00:09,  1.58it/s]Extractor Predicting: 16it [00:10,  1.63it/s]Extractor Predicting: 17it [00:10,  1.63it/s]Extractor Predicting: 18it [00:11,  1.68it/s]Extractor Predicting: 19it [00:11,  1.68it/s]Extractor Predicting: 20it [00:12,  1.70it/s]Extractor Predicting: 21it [00:12,  1.69it/s]Extractor Predicting: 22it [00:13,  1.72it/s]Extractor Predicting: 23it [00:14,  1.77it/s]Extractor Predicting: 24it [00:14,  1.70it/s]Extractor Predicting: 25it [00:15,  1.59it/s]Extractor Predicting: 26it [00:16,  1.60it/s]Extractor Predicting: 27it [00:16,  1.62it/s]Extractor Predicting: 28it [00:17,  1.65it/s]Extractor Predicting: 29it [00:17,  1.68it/s]Extractor Predicting: 30it [00:18,  1.61it/s]Extractor Predicting: 31it [00:19,  1.62it/s]Extractor Predicting: 32it [00:19,  1.66it/s]Extractor Predicting: 33it [00:20,  1.69it/s]Extractor Predicting: 34it [00:20,  1.73it/s]Extractor Predicting: 35it [00:21,  1.78it/s]Extractor Predicting: 36it [00:21,  1.75it/s]Extractor Predicting: 37it [00:22,  1.81it/s]Extractor Predicting: 38it [00:22,  1.74it/s]Extractor Predicting: 39it [00:23,  1.72it/s]Extractor Predicting: 40it [00:24,  1.73it/s]Extractor Predicting: 41it [00:24,  1.75it/s]Extractor Predicting: 42it [00:25,  1.78it/s]Extractor Predicting: 43it [00:25,  1.77it/s]Extractor Predicting: 44it [00:26,  1.68it/s]Extractor Predicting: 45it [00:27,  1.73it/s]Extractor Predicting: 46it [00:27,  1.70it/s]Extractor Predicting: 47it [00:28,  1.70it/s]Extractor Predicting: 48it [00:28,  1.74it/s]Extractor Predicting: 49it [00:29,  1.75it/s]Extractor Predicting: 50it [00:29,  1.80it/s]Extractor Predicting: 51it [00:30,  1.81it/s]Extractor Predicting: 52it [00:30,  1.80it/s]Extractor Predicting: 53it [00:31,  1.83it/s]Extractor Predicting: 54it [00:32,  1.82it/s]Extractor Predicting: 55it [00:32,  1.83it/s]Extractor Predicting: 56it [00:33,  1.81it/s]Extractor Predicting: 57it [00:33,  1.85it/s]Extractor Predicting: 58it [00:34,  1.88it/s]Extractor Predicting: 59it [00:34,  1.77it/s]Extractor Predicting: 60it [00:35,  1.77it/s]Extractor Predicting: 61it [00:35,  1.75it/s]Extractor Predicting: 62it [00:36,  1.75it/s]Extractor Predicting: 63it [00:37,  1.73it/s]Extractor Predicting: 64it [00:37,  1.80it/s]Extractor Predicting: 65it [00:38,  1.85it/s]Extractor Predicting: 66it [00:38,  1.82it/s]Extractor Predicting: 67it [00:39,  1.80it/s]Extractor Predicting: 68it [00:39,  1.78it/s]Extractor Predicting: 69it [00:40,  1.81it/s]Extractor Predicting: 70it [00:40,  1.75it/s]Extractor Predicting: 71it [00:41,  1.79it/s]Extractor Predicting: 72it [00:42,  1.75it/s]Extractor Predicting: 73it [00:42,  1.73it/s]Extractor Predicting: 74it [00:43,  1.70it/s]Extractor Predicting: 75it [00:43,  1.70it/s]Extractor Predicting: 76it [00:44,  1.67it/s]Extractor Predicting: 77it [00:45,  1.63it/s]Extractor Predicting: 78it [00:45,  1.66it/s]Extractor Predicting: 79it [00:46,  1.61it/s]Extractor Predicting: 80it [00:47,  1.58it/s]Extractor Predicting: 81it [00:47,  1.56it/s]Extractor Predicting: 82it [00:48,  1.54it/s]Extractor Predicting: 83it [00:49,  1.54it/s]Extractor Predicting: 84it [00:49,  1.53it/s]Extractor Predicting: 85it [00:50,  1.53it/s]Extractor Predicting: 86it [00:51,  1.54it/s]Extractor Predicting: 87it [00:51,  1.54it/s]Extractor Predicting: 88it [00:52,  1.54it/s]Extractor Predicting: 89it [00:52,  1.56it/s]Extractor Predicting: 90it [00:53,  1.56it/s]Extractor Predicting: 91it [00:54,  1.53it/s]Extractor Predicting: 92it [00:54,  1.54it/s]Extractor Predicting: 93it [00:55,  1.53it/s]Extractor Predicting: 94it [00:56,  1.53it/s]Extractor Predicting: 95it [00:56,  1.54it/s]Extractor Predicting: 96it [00:57,  1.55it/s]Extractor Predicting: 97it [00:58,  1.58it/s]Extractor Predicting: 98it [00:58,  1.58it/s]Extractor Predicting: 99it [00:59,  1.59it/s]Extractor Predicting: 100it [01:00,  1.57it/s]Extractor Predicting: 101it [01:00,  1.57it/s]Extractor Predicting: 102it [01:01,  1.53it/s]Extractor Predicting: 103it [01:01,  1.55it/s]Extractor Predicting: 104it [01:02,  1.53it/s]Extractor Predicting: 105it [01:03,  1.54it/s]Extractor Predicting: 106it [01:03,  1.53it/s]Extractor Predicting: 107it [01:04,  1.53it/s]Extractor Predicting: 108it [01:05,  1.55it/s]Extractor Predicting: 109it [01:06,  1.40it/s]Extractor Predicting: 110it [01:06,  1.47it/s]Extractor Predicting: 111it [01:07,  1.50it/s]Extractor Predicting: 112it [01:07,  1.55it/s]Extractor Predicting: 113it [01:08,  1.57it/s]Extractor Predicting: 114it [01:09,  1.57it/s]Extractor Predicting: 115it [01:09,  1.51it/s]Extractor Predicting: 116it [01:10,  1.53it/s]Extractor Predicting: 117it [01:11,  1.54it/s]Extractor Predicting: 118it [01:11,  1.53it/s]Extractor Predicting: 119it [01:12,  1.52it/s]Extractor Predicting: 120it [01:13,  1.55it/s]Extractor Predicting: 121it [01:13,  1.57it/s]Extractor Predicting: 122it [01:14,  1.52it/s]Extractor Predicting: 123it [01:15,  1.55it/s]Extractor Predicting: 124it [01:15,  1.53it/s]Extractor Predicting: 125it [01:16,  1.55it/s]Extractor Predicting: 126it [01:16,  1.57it/s]Extractor Predicting: 127it [01:17,  1.64it/s]Extractor Predicting: 128it [01:18,  1.66it/s]Extractor Predicting: 129it [01:18,  1.67it/s]Extractor Predicting: 130it [01:19,  1.63it/s]Extractor Predicting: 131it [01:19,  1.64it/s]Extractor Predicting: 132it [01:20,  1.61it/s]Extractor Predicting: 133it [01:21,  1.60it/s]Extractor Predicting: 134it [01:21,  1.61it/s]Extractor Predicting: 135it [01:22,  1.63it/s]Extractor Predicting: 136it [01:23,  1.67it/s]Extractor Predicting: 137it [01:23,  1.68it/s]Extractor Predicting: 138it [01:24,  1.68it/s]Extractor Predicting: 139it [01:24,  1.68it/s]Extractor Predicting: 140it [01:25,  1.69it/s]Extractor Predicting: 141it [01:25,  1.71it/s]Extractor Predicting: 142it [01:26,  1.68it/s]Extractor Predicting: 143it [01:27,  1.64it/s]Extractor Predicting: 144it [01:27,  1.64it/s]Extractor Predicting: 145it [01:28,  1.70it/s]Extractor Predicting: 146it [01:28,  1.73it/s]Extractor Predicting: 147it [01:29,  1.72it/s]Extractor Predicting: 148it [01:30,  1.73it/s]Extractor Predicting: 149it [01:30,  1.70it/s]Extractor Predicting: 150it [01:31,  1.71it/s]Extractor Predicting: 151it [01:31,  1.67it/s]Extractor Predicting: 152it [01:32,  1.67it/s]Extractor Predicting: 153it [01:33,  1.67it/s]Extractor Predicting: 154it [01:33,  1.62it/s]Extractor Predicting: 155it [01:34,  1.60it/s]Extractor Predicting: 156it [01:35,  1.61it/s]Extractor Predicting: 157it [01:35,  1.63it/s]Extractor Predicting: 158it [01:36,  1.61it/s]Extractor Predicting: 159it [01:36,  1.62it/s]Extractor Predicting: 160it [01:37,  1.63it/s]Extractor Predicting: 161it [01:38,  1.63it/s]Extractor Predicting: 162it [01:38,  1.68it/s]Extractor Predicting: 163it [01:39,  1.83it/s]Extractor Predicting: 164it [01:39,  1.96it/s]Extractor Predicting: 165it [01:39,  1.97it/s]Extractor Predicting: 166it [01:40,  1.90it/s]Extractor Predicting: 167it [01:41,  1.81it/s]Extractor Predicting: 168it [01:41,  1.73it/s]Extractor Predicting: 169it [01:42,  1.67it/s]Extractor Predicting: 170it [01:43,  1.68it/s]Extractor Predicting: 171it [01:43,  1.68it/s]Extractor Predicting: 172it [01:44,  1.66it/s]Extractor Predicting: 173it [01:44,  1.66it/s]Extractor Predicting: 174it [01:45,  1.66it/s]Extractor Predicting: 175it [01:46,  1.63it/s]Extractor Predicting: 176it [01:46,  1.60it/s]Extractor Predicting: 177it [01:47,  1.61it/s]Extractor Predicting: 178it [01:47,  1.64it/s]Extractor Predicting: 179it [01:48,  1.59it/s]Extractor Predicting: 180it [01:49,  1.61it/s]Extractor Predicting: 181it [01:49,  1.64it/s]Extractor Predicting: 182it [01:50,  1.67it/s]Extractor Predicting: 183it [01:51,  1.63it/s]Extractor Predicting: 184it [01:51,  1.62it/s]Extractor Predicting: 185it [01:52,  1.60it/s]Extractor Predicting: 186it [01:52,  1.63it/s]Extractor Predicting: 187it [01:53,  1.64it/s]Extractor Predicting: 188it [01:54,  1.63it/s]Extractor Predicting: 189it [01:54,  1.64it/s]Extractor Predicting: 190it [01:55,  1.62it/s]Extractor Predicting: 191it [01:55,  1.65it/s]Extractor Predicting: 192it [01:56,  1.67it/s]Extractor Predicting: 193it [01:57,  1.67it/s]Extractor Predicting: 194it [01:57,  1.68it/s]Extractor Predicting: 195it [01:58,  1.64it/s]Extractor Predicting: 196it [01:58,  1.65it/s]Extractor Predicting: 197it [01:59,  1.63it/s]Extractor Predicting: 198it [02:00,  1.63it/s]Extractor Predicting: 199it [02:00,  1.62it/s]Extractor Predicting: 200it [02:01,  1.61it/s]Extractor Predicting: 201it [02:02,  1.57it/s]Extractor Predicting: 202it [02:02,  1.59it/s]Extractor Predicting: 203it [02:03,  1.59it/s]Extractor Predicting: 204it [02:03,  1.58it/s]Extractor Predicting: 205it [02:04,  1.60it/s]Extractor Predicting: 206it [02:05,  1.60it/s]Extractor Predicting: 207it [02:05,  1.65it/s]Extractor Predicting: 208it [02:06,  1.67it/s]Extractor Predicting: 209it [02:06,  1.65it/s]Extractor Predicting: 210it [02:07,  1.64it/s]Extractor Predicting: 211it [02:08,  1.65it/s]Extractor Predicting: 212it [02:08,  1.61it/s]Extractor Predicting: 213it [02:09,  1.58it/s]Extractor Predicting: 214it [02:10,  1.62it/s]Extractor Predicting: 215it [02:10,  1.64it/s]Extractor Predicting: 216it [02:11,  1.63it/s]Extractor Predicting: 217it [02:11,  1.61it/s]Extractor Predicting: 218it [02:12,  1.59it/s]Extractor Predicting: 219it [02:13,  1.60it/s]Extractor Predicting: 220it [02:13,  1.61it/s]Extractor Predicting: 221it [02:14,  1.64it/s]Extractor Predicting: 222it [02:15,  1.62it/s]Extractor Predicting: 223it [02:15,  1.64it/s]Extractor Predicting: 224it [02:16,  1.67it/s]Extractor Predicting: 225it [02:16,  1.71it/s]Extractor Predicting: 226it [02:17,  1.68it/s]Extractor Predicting: 227it [02:17,  1.66it/s]Extractor Predicting: 228it [02:18,  1.67it/s]Extractor Predicting: 229it [02:19,  1.58it/s]Extractor Predicting: 230it [02:19,  1.65it/s]Extractor Predicting: 231it [02:20,  1.65it/s]Extractor Predicting: 232it [02:21,  1.63it/s]Extractor Predicting: 233it [02:21,  1.61it/s]Extractor Predicting: 234it [02:22,  1.57it/s]Extractor Predicting: 235it [02:23,  1.43it/s]Extractor Predicting: 236it [02:23,  1.45it/s]Extractor Predicting: 237it [02:24,  1.44it/s]Extractor Predicting: 238it [02:25,  1.45it/s]Extractor Predicting: 239it [02:25,  1.43it/s]Extractor Predicting: 240it [02:26,  1.46it/s]Extractor Predicting: 241it [02:27,  1.50it/s]Extractor Predicting: 242it [02:27,  1.50it/s]Extractor Predicting: 243it [02:28,  1.55it/s]Extractor Predicting: 244it [02:29,  1.56it/s]Extractor Predicting: 245it [02:29,  1.61it/s]Extractor Predicting: 246it [02:30,  1.63it/s]Extractor Predicting: 247it [02:30,  1.66it/s]Extractor Predicting: 248it [02:31,  1.69it/s]Extractor Predicting: 249it [02:32,  1.73it/s]Extractor Predicting: 250it [02:32,  1.68it/s]Extractor Predicting: 251it [02:33,  1.72it/s]Extractor Predicting: 252it [02:33,  1.69it/s]Extractor Predicting: 253it [02:34,  1.69it/s]Extractor Predicting: 254it [02:35,  1.69it/s]Extractor Predicting: 255it [02:35,  1.70it/s]Extractor Predicting: 256it [02:36,  1.67it/s]Extractor Predicting: 257it [02:36,  1.69it/s]Extractor Predicting: 258it [02:37,  1.70it/s]Extractor Predicting: 259it [02:37,  1.67it/s]Extractor Predicting: 260it [02:38,  1.67it/s]Extractor Predicting: 261it [02:39,  1.65it/s]Extractor Predicting: 262it [02:39,  1.64it/s]Extractor Predicting: 263it [02:40,  1.64it/s]Extractor Predicting: 264it [02:41,  1.65it/s]Extractor Predicting: 265it [02:41,  1.66it/s]Extractor Predicting: 266it [02:42,  1.63it/s]Extractor Predicting: 267it [02:42,  1.63it/s]Extractor Predicting: 268it [02:43,  1.62it/s]Extractor Predicting: 269it [02:44,  1.59it/s]Extractor Predicting: 270it [02:44,  1.63it/s]Extractor Predicting: 271it [02:45,  1.65it/s]Extractor Predicting: 272it [02:45,  1.71it/s]Extractor Predicting: 273it [02:46,  1.71it/s]Extractor Predicting: 274it [02:47,  1.71it/s]Extractor Predicting: 275it [02:47,  1.67it/s]Extractor Predicting: 276it [02:48,  1.67it/s]Extractor Predicting: 277it [02:48,  1.68it/s]Extractor Predicting: 278it [02:49,  1.65it/s]Extractor Predicting: 279it [02:50,  1.67it/s]Extractor Predicting: 280it [02:50,  1.73it/s]Extractor Predicting: 281it [02:51,  1.72it/s]Extractor Predicting: 282it [02:51,  1.68it/s]Extractor Predicting: 283it [02:52,  1.65it/s]Extractor Predicting: 284it [02:53,  1.63it/s]Extractor Predicting: 285it [02:53,  1.59it/s]Extractor Predicting: 286it [02:54,  1.61it/s]Extractor Predicting: 287it [02:54,  1.60it/s]Extractor Predicting: 288it [02:55,  1.59it/s]Extractor Predicting: 289it [02:56,  1.57it/s]Extractor Predicting: 290it [02:56,  1.57it/s]Extractor Predicting: 291it [02:57,  1.61it/s]Extractor Predicting: 292it [02:58,  1.62it/s]Extractor Predicting: 293it [02:58,  1.62it/s]Extractor Predicting: 294it [02:59,  1.57it/s]Extractor Predicting: 295it [03:00,  1.58it/s]Extractor Predicting: 296it [03:00,  1.56it/s]Extractor Predicting: 297it [03:01,  1.53it/s]Extractor Predicting: 298it [03:02,  1.51it/s]Extractor Predicting: 299it [03:02,  1.50it/s]Extractor Predicting: 300it [03:03,  1.50it/s]Extractor Predicting: 301it [03:04,  1.47it/s]Extractor Predicting: 302it [03:04,  1.47it/s]Extractor Predicting: 303it [03:05,  1.48it/s]Extractor Predicting: 303it [03:05,  1.63it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:05,626 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:05,633 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:05,633 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:05,633 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:05,633 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 17:38:06,254 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 17:38:06,255 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 17:38:06,814 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 17:38:07,879 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 17:38:07,879 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:10,719 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:10,723 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:10,724 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:10,724 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:38:10,724 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 17:38:11,589 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 17:38:11,590 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 17:38:12,175 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 17:38:12,344 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 17:38:12,344 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_out_filter_all_single_is_eval_True.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_in_all_single_is_eval_True.jsonl",
  "precision": 0,
  "recall": 0,
  "score": 0,
  "mode": "all_single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/results_all_single_is_eval_True.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'single', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_in_single_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_out_filter_single_is_eval_False.jsonl'}}
predict vocab size: 20815
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 20915, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.68it/s]Extractor Predicting: 2it [00:01,  1.62it/s]Extractor Predicting: 3it [00:01,  1.65it/s]Extractor Predicting: 4it [00:02,  1.66it/s]Extractor Predicting: 5it [00:02,  1.69it/s]Extractor Predicting: 6it [00:03,  1.65it/s]Extractor Predicting: 7it [00:04,  1.65it/s]Extractor Predicting: 8it [00:04,  1.65it/s]Extractor Predicting: 9it [00:05,  1.63it/s]Extractor Predicting: 10it [00:06,  1.63it/s]Extractor Predicting: 11it [00:06,  1.66it/s]Extractor Predicting: 12it [00:07,  1.68it/s]Extractor Predicting: 13it [00:07,  1.68it/s]Extractor Predicting: 14it [00:08,  1.56it/s]Extractor Predicting: 15it [00:09,  1.62it/s]Extractor Predicting: 16it [00:09,  1.63it/s]Extractor Predicting: 17it [00:10,  1.64it/s]Extractor Predicting: 18it [00:11,  1.60it/s]Extractor Predicting: 19it [00:11,  1.61it/s]Extractor Predicting: 20it [00:12,  1.62it/s]Extractor Predicting: 21it [00:12,  1.62it/s]Extractor Predicting: 22it [00:13,  1.60it/s]Extractor Predicting: 23it [00:14,  1.62it/s]Extractor Predicting: 24it [00:14,  1.63it/s]Extractor Predicting: 25it [00:15,  1.65it/s]Extractor Predicting: 26it [00:15,  1.65it/s]Extractor Predicting: 27it [00:16,  1.64it/s]Extractor Predicting: 28it [00:17,  1.66it/s]Extractor Predicting: 29it [00:17,  1.62it/s]Extractor Predicting: 30it [00:18,  1.65it/s]Extractor Predicting: 31it [00:18,  1.67it/s]Extractor Predicting: 32it [00:19,  1.65it/s]Extractor Predicting: 33it [00:20,  1.66it/s]Extractor Predicting: 34it [00:20,  1.64it/s]Extractor Predicting: 35it [00:21,  1.61it/s]Extractor Predicting: 36it [00:21,  1.65it/s]Extractor Predicting: 37it [00:22,  1.64it/s]Extractor Predicting: 38it [00:23,  1.64it/s]Extractor Predicting: 39it [00:23,  1.68it/s]Extractor Predicting: 40it [00:24,  1.68it/s]Extractor Predicting: 41it [00:24,  1.67it/s]Extractor Predicting: 42it [00:25,  1.68it/s]Extractor Predicting: 43it [00:26,  1.65it/s]Extractor Predicting: 44it [00:26,  1.60it/s]Extractor Predicting: 45it [00:27,  1.58it/s]Extractor Predicting: 46it [00:28,  1.57it/s]Extractor Predicting: 47it [00:28,  1.59it/s]Extractor Predicting: 48it [00:29,  1.60it/s]Extractor Predicting: 49it [00:29,  1.61it/s]Extractor Predicting: 50it [00:30,  1.65it/s]Extractor Predicting: 51it [00:31,  1.67it/s]Extractor Predicting: 52it [00:31,  1.67it/s]Extractor Predicting: 53it [00:32,  1.68it/s]Extractor Predicting: 54it [00:32,  1.63it/s]Extractor Predicting: 55it [00:33,  1.67it/s]Extractor Predicting: 56it [00:34,  1.66it/s]Extractor Predicting: 57it [00:34,  1.68it/s]Extractor Predicting: 58it [00:35,  1.63it/s]Extractor Predicting: 59it [00:35,  1.64it/s]Extractor Predicting: 60it [00:36,  1.64it/s]Extractor Predicting: 61it [00:37,  1.63it/s]Extractor Predicting: 62it [00:37,  1.64it/s]Extractor Predicting: 63it [00:38,  1.66it/s]Extractor Predicting: 64it [00:38,  1.68it/s]Extractor Predicting: 65it [00:39,  1.57it/s]Extractor Predicting: 66it [00:40,  1.60it/s]Extractor Predicting: 67it [00:40,  1.64it/s]Extractor Predicting: 68it [00:41,  1.61it/s]Extractor Predicting: 69it [00:42,  1.62it/s]Extractor Predicting: 70it [00:42,  1.62it/s]Extractor Predicting: 71it [00:43,  1.63it/s]Extractor Predicting: 72it [00:43,  1.66it/s]Extractor Predicting: 73it [00:44,  1.67it/s]Extractor Predicting: 74it [00:45,  1.66it/s]Extractor Predicting: 75it [00:45,  1.64it/s]Extractor Predicting: 76it [00:46,  1.67it/s]Extractor Predicting: 77it [00:46,  1.66it/s]Extractor Predicting: 78it [00:47,  1.67it/s]Extractor Predicting: 79it [00:48,  1.66it/s]Extractor Predicting: 80it [00:48,  1.66it/s]Extractor Predicting: 81it [00:49,  1.67it/s]Extractor Predicting: 82it [00:49,  1.69it/s]Extractor Predicting: 83it [00:50,  1.51it/s]Extractor Predicting: 84it [00:51,  1.55it/s]Extractor Predicting: 85it [00:51,  1.57it/s]Extractor Predicting: 86it [00:52,  1.62it/s]Extractor Predicting: 87it [00:53,  1.61it/s]Extractor Predicting: 88it [00:53,  1.60it/s]Extractor Predicting: 89it [00:54,  1.61it/s]Extractor Predicting: 90it [00:55,  1.62it/s]Extractor Predicting: 91it [00:55,  1.64it/s]Extractor Predicting: 92it [00:56,  1.66it/s]Extractor Predicting: 93it [00:56,  1.64it/s]Extractor Predicting: 94it [00:57,  1.65it/s]Extractor Predicting: 95it [00:58,  1.65it/s]Extractor Predicting: 96it [00:58,  1.66it/s]Extractor Predicting: 97it [00:59,  1.62it/s]Extractor Predicting: 98it [00:59,  1.67it/s]Extractor Predicting: 99it [01:00,  1.67it/s]Extractor Predicting: 100it [01:01,  1.62it/s]Extractor Predicting: 101it [01:01,  1.65it/s]Extractor Predicting: 102it [01:02,  1.64it/s]Extractor Predicting: 103it [01:02,  1.63it/s]Extractor Predicting: 104it [01:03,  1.64it/s]Extractor Predicting: 105it [01:04,  1.63it/s]Extractor Predicting: 106it [01:04,  1.62it/s]Extractor Predicting: 107it [01:05,  1.65it/s]Extractor Predicting: 108it [01:05,  1.62it/s]Extractor Predicting: 109it [01:06,  1.61it/s]Extractor Predicting: 110it [01:07,  1.63it/s]Extractor Predicting: 111it [01:07,  1.68it/s]Extractor Predicting: 112it [01:08,  1.69it/s]Extractor Predicting: 113it [01:08,  1.70it/s]Extractor Predicting: 114it [01:09,  1.66it/s]Extractor Predicting: 115it [01:10,  1.67it/s]Extractor Predicting: 116it [01:10,  1.68it/s]Extractor Predicting: 117it [01:11,  1.65it/s]Extractor Predicting: 118it [01:11,  1.65it/s]Extractor Predicting: 119it [01:12,  1.64it/s]Extractor Predicting: 120it [01:13,  1.64it/s]Extractor Predicting: 121it [01:13,  1.66it/s]Extractor Predicting: 122it [01:14,  1.65it/s]Extractor Predicting: 123it [01:14,  1.66it/s]Extractor Predicting: 124it [01:15,  1.66it/s]Extractor Predicting: 125it [01:16,  1.68it/s]Extractor Predicting: 126it [01:16,  1.65it/s]Extractor Predicting: 127it [01:17,  1.64it/s]Extractor Predicting: 128it [01:18,  1.64it/s]Extractor Predicting: 129it [01:18,  1.70it/s]Extractor Predicting: 130it [01:19,  1.73it/s]Extractor Predicting: 131it [01:19,  1.70it/s]Extractor Predicting: 132it [01:20,  1.66it/s]Extractor Predicting: 133it [01:21,  1.59it/s]Extractor Predicting: 134it [01:21,  1.58it/s]Extractor Predicting: 135it [01:22,  1.60it/s]Extractor Predicting: 136it [01:22,  1.59it/s]Extractor Predicting: 137it [01:23,  1.59it/s]Extractor Predicting: 138it [01:24,  1.58it/s]Extractor Predicting: 139it [01:24,  1.58it/s]Extractor Predicting: 140it [01:25,  1.59it/s]Extractor Predicting: 141it [01:26,  1.57it/s]Extractor Predicting: 142it [01:26,  1.57it/s]Extractor Predicting: 143it [01:27,  1.58it/s]Extractor Predicting: 144it [01:28,  1.58it/s]Extractor Predicting: 145it [01:28,  1.59it/s]Extractor Predicting: 146it [01:29,  1.59it/s]Extractor Predicting: 147it [01:29,  1.57it/s]Extractor Predicting: 148it [01:30,  1.62it/s]Extractor Predicting: 149it [01:31,  1.60it/s]Extractor Predicting: 150it [01:31,  1.60it/s]Extractor Predicting: 151it [01:32,  1.57it/s]Extractor Predicting: 152it [01:33,  1.63it/s]Extractor Predicting: 153it [01:33,  1.66it/s]Extractor Predicting: 154it [01:34,  1.65it/s]Extractor Predicting: 155it [01:34,  1.65it/s]Extractor Predicting: 156it [01:35,  1.65it/s]Extractor Predicting: 157it [01:35,  1.67it/s]Extractor Predicting: 158it [01:36,  1.65it/s]Extractor Predicting: 159it [01:37,  1.64it/s]Extractor Predicting: 160it [01:37,  1.65it/s]Extractor Predicting: 161it [01:38,  1.64it/s]Extractor Predicting: 162it [01:39,  1.63it/s]Extractor Predicting: 163it [01:39,  1.65it/s]Extractor Predicting: 164it [01:40,  1.64it/s]Extractor Predicting: 165it [01:40,  1.68it/s]Extractor Predicting: 166it [01:41,  1.69it/s]Extractor Predicting: 167it [01:42,  1.67it/s]Extractor Predicting: 168it [01:42,  1.68it/s]Extractor Predicting: 169it [01:43,  1.68it/s]Extractor Predicting: 170it [01:43,  1.65it/s]Extractor Predicting: 171it [01:44,  1.62it/s]Extractor Predicting: 172it [01:45,  1.62it/s]Extractor Predicting: 173it [01:45,  1.63it/s]Extractor Predicting: 174it [01:46,  1.66it/s]Extractor Predicting: 175it [01:47,  1.52it/s]Extractor Predicting: 176it [01:47,  1.52it/s]Extractor Predicting: 177it [01:48,  1.57it/s]Extractor Predicting: 178it [01:48,  1.57it/s]Extractor Predicting: 179it [01:49,  1.58it/s]Extractor Predicting: 180it [01:50,  1.64it/s]Extractor Predicting: 181it [01:50,  1.66it/s]Extractor Predicting: 182it [01:51,  1.64it/s]Extractor Predicting: 183it [01:51,  1.67it/s]Extractor Predicting: 184it [01:52,  1.70it/s]Extractor Predicting: 185it [01:53,  1.69it/s]Extractor Predicting: 186it [01:53,  1.70it/s]Extractor Predicting: 187it [01:54,  1.70it/s]Extractor Predicting: 188it [01:54,  1.67it/s]Extractor Predicting: 189it [01:55,  1.63it/s]Extractor Predicting: 190it [01:56,  1.61it/s]Extractor Predicting: 191it [01:56,  1.62it/s]Extractor Predicting: 192it [01:57,  1.66it/s]Extractor Predicting: 193it [01:57,  1.64it/s]Extractor Predicting: 194it [01:58,  1.63it/s]Extractor Predicting: 195it [01:59,  1.66it/s]Extractor Predicting: 196it [01:59,  1.70it/s]Extractor Predicting: 197it [02:00,  1.69it/s]Extractor Predicting: 198it [02:00,  1.71it/s]Extractor Predicting: 199it [02:01,  1.70it/s]Extractor Predicting: 200it [02:02,  1.66it/s]Extractor Predicting: 201it [02:02,  1.67it/s]Extractor Predicting: 202it [02:03,  1.66it/s]Extractor Predicting: 203it [02:03,  1.67it/s]Extractor Predicting: 204it [02:04,  1.68it/s]Extractor Predicting: 205it [02:05,  1.71it/s]Extractor Predicting: 206it [02:05,  1.69it/s]Extractor Predicting: 207it [02:06,  1.70it/s]Extractor Predicting: 208it [02:06,  1.73it/s]Extractor Predicting: 209it [02:07,  1.73it/s]Extractor Predicting: 210it [02:07,  1.70it/s]Extractor Predicting: 211it [02:08,  1.70it/s]Extractor Predicting: 212it [02:09,  1.67it/s]Extractor Predicting: 213it [02:09,  1.66it/s]Extractor Predicting: 214it [02:10,  1.64it/s]Extractor Predicting: 215it [02:11,  1.64it/s]Extractor Predicting: 216it [02:11,  1.65it/s]Extractor Predicting: 217it [02:12,  1.62it/s]Extractor Predicting: 218it [02:12,  1.69it/s]Extractor Predicting: 219it [02:13,  1.69it/s]Extractor Predicting: 220it [02:14,  1.66it/s]Extractor Predicting: 221it [02:14,  1.63it/s]Extractor Predicting: 222it [02:15,  1.65it/s]Extractor Predicting: 223it [02:15,  1.67it/s]Extractor Predicting: 224it [02:16,  1.66it/s]Extractor Predicting: 225it [02:17,  1.69it/s]Extractor Predicting: 226it [02:17,  1.69it/s]Extractor Predicting: 227it [02:18,  1.70it/s]Extractor Predicting: 228it [02:18,  1.68it/s]Extractor Predicting: 229it [02:19,  1.70it/s]Extractor Predicting: 230it [02:20,  1.66it/s]Extractor Predicting: 231it [02:20,  1.70it/s]Extractor Predicting: 232it [02:21,  1.67it/s]Extractor Predicting: 233it [02:21,  1.66it/s]Extractor Predicting: 234it [02:22,  1.65it/s]Extractor Predicting: 235it [02:23,  1.67it/s]Extractor Predicting: 236it [02:23,  1.65it/s]Extractor Predicting: 237it [02:24,  1.62it/s]Extractor Predicting: 238it [02:24,  1.62it/s]Extractor Predicting: 239it [02:25,  1.68it/s]Extractor Predicting: 240it [02:26,  1.65it/s]Extractor Predicting: 241it [02:26,  1.63it/s]Extractor Predicting: 242it [02:27,  1.61it/s]Extractor Predicting: 243it [02:27,  1.67it/s]Extractor Predicting: 244it [02:28,  1.70it/s]Extractor Predicting: 245it [02:29,  1.73it/s]Extractor Predicting: 246it [02:29,  1.78it/s]Extractor Predicting: 247it [02:30,  1.75it/s]Extractor Predicting: 248it [02:30,  1.76it/s]Extractor Predicting: 249it [02:31,  1.75it/s]Extractor Predicting: 250it [02:31,  1.75it/s]Extractor Predicting: 251it [02:32,  1.74it/s]Extractor Predicting: 252it [02:32,  1.76it/s]Extractor Predicting: 253it [02:33,  1.76it/s]Extractor Predicting: 254it [02:34,  1.75it/s]Extractor Predicting: 255it [02:34,  1.79it/s]Extractor Predicting: 256it [02:35,  1.76it/s]Extractor Predicting: 257it [02:35,  1.75it/s]Extractor Predicting: 258it [02:36,  1.74it/s]Extractor Predicting: 259it [02:36,  1.73it/s]Extractor Predicting: 260it [02:37,  1.72it/s]Extractor Predicting: 261it [02:38,  1.74it/s]Extractor Predicting: 262it [02:38,  1.76it/s]Extractor Predicting: 263it [02:39,  1.79it/s]Extractor Predicting: 264it [02:39,  1.72it/s]Extractor Predicting: 265it [02:40,  1.68it/s]Extractor Predicting: 266it [02:41,  1.66it/s]Extractor Predicting: 267it [02:41,  1.64it/s]Extractor Predicting: 268it [02:42,  1.67it/s]Extractor Predicting: 269it [02:42,  1.70it/s]Extractor Predicting: 270it [02:43,  1.70it/s]Extractor Predicting: 271it [02:44,  1.69it/s]Extractor Predicting: 272it [02:44,  1.68it/s]Extractor Predicting: 273it [02:45,  1.71it/s]Extractor Predicting: 274it [02:45,  1.71it/s]Extractor Predicting: 275it [02:46,  1.75it/s]Extractor Predicting: 276it [02:47,  1.53it/s]Extractor Predicting: 277it [02:47,  1.53it/s]Extractor Predicting: 278it [02:48,  1.59it/s]Extractor Predicting: 279it [02:48,  1.67it/s]Extractor Predicting: 280it [02:49,  1.70it/s]Extractor Predicting: 281it [02:50,  1.74it/s]Extractor Predicting: 282it [02:50,  1.75it/s]Extractor Predicting: 283it [02:51,  1.76it/s]Extractor Predicting: 284it [02:51,  1.75it/s]Extractor Predicting: 285it [02:52,  1.70it/s]Extractor Predicting: 286it [02:52,  1.76it/s]Extractor Predicting: 287it [02:53,  1.74it/s]Extractor Predicting: 288it [02:54,  1.73it/s]Extractor Predicting: 289it [02:54,  1.72it/s]Extractor Predicting: 290it [02:55,  1.74it/s]Extractor Predicting: 291it [02:55,  1.75it/s]Extractor Predicting: 292it [02:56,  1.70it/s]Extractor Predicting: 293it [02:57,  1.69it/s]Extractor Predicting: 294it [02:57,  1.69it/s]Extractor Predicting: 295it [02:58,  1.69it/s]Extractor Predicting: 296it [02:58,  1.71it/s]Extractor Predicting: 297it [02:59,  1.68it/s]Extractor Predicting: 298it [02:59,  1.73it/s]Extractor Predicting: 299it [03:00,  1.67it/s]Extractor Predicting: 300it [03:01,  1.64it/s]Extractor Predicting: 301it [03:01,  1.56it/s]Extractor Predicting: 302it [03:02,  1.59it/s]Extractor Predicting: 303it [03:03,  1.58it/s]Extractor Predicting: 304it [03:03,  1.59it/s]Extractor Predicting: 305it [03:04,  1.56it/s]Extractor Predicting: 306it [03:05,  1.54it/s]Extractor Predicting: 306it [03:05,  1.65it/s]
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:24,164 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/xuting/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:24,169 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:24,169 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:24,169 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/xuting/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:24,169 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|configuration_utils.py:517] 2023-08-29 17:41:24,480 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:553] 2023-08-29 17:41:24,481 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1152] 2023-08-29 17:41:24,764 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1328] 2023-08-29 17:41:25,832 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 17:41:25,832 >> All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:28,726 >> loading file https://huggingface.co/albert-large-v2/resolve/main/spiece.model from cache at /home/xuting/.cache/huggingface/transformers/b4bd5194827ca5bc0342e0421aace72462c676f37679a440862cf3ee46f95f48.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:28,730 >> loading file https://huggingface.co/albert-large-v2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:28,730 >> loading file https://huggingface.co/albert-large-v2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:28,730 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer_config.json from cache at None
[INFO|tokenization_utils_base.py:1717] 2023-08-29 17:41:28,731 >> loading file https://huggingface.co/albert-large-v2/resolve/main/tokenizer.json from cache at /home/xuting/.cache/huggingface/transformers/8f1144987c0a5fcedc8808300dc830a4a00787ceaccb85e9f913ef047103bd89.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74
[INFO|configuration_utils.py:517] 2023-08-29 17:41:29,371 >> loading configuration file https://huggingface.co/albert-large-v2/resolve/main/config.json from cache at /home/xuting/.cache/huggingface/transformers/b2da41a68a8020e0d5923bb74adfb48c33df97683e143ca33ad6e52a3e05d70d.06fa0ad0d486db01b65880587686cbf167e4c2d52e242d574fac416eda16c32d
[INFO|configuration_utils.py:553] 2023-08-29 17:41:29,372 >> Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 16,
  "num_hidden_groups": 1,
  "num_hidden_layers": 24,
  "num_memory_blocks": 0,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.7.0",
  "type_vocab_size": 2,
  "vocab_size": 30000
}

[INFO|modeling_utils.py:1152] 2023-08-29 17:41:29,946 >> loading weights file https://huggingface.co/albert-large-v2/resolve/main/pytorch_model.bin from cache at /home/xuting/.cache/huggingface/transformers/4552fda677d63af6d9acdc968e0a4bfb09ef6994bbb37c065ea6533cf8dc0977.4ffe1a3c3f6feb9b16e8d8811a495b5ca957bb71b1215ae0960c2b06f2e7d9bd
[WARNING|modeling_utils.py:1328] 2023-08-29 17:41:30,112 >> Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:1345] 2023-08-29 17:41:30,112 >> All the weights of AlbertModel were initialized from the model checkpoint at albert-large-v2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertModel for predictions without further training.
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_out_filter_single_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_in_single_is_eval_False.jsonl",
  "precision": 0,
  "recall": 0,
  "score": 0,
  "mode": "single",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/results_single_is_eval_False.json"
}
{'run_eval': {'path_model': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5', 'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'mode': 'multi', 'model_size': 'large', 'is_eval': False, 'limit': 0}}
{'predict': {'path_in': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_in_multi_is_eval_False.jsonl', 'path_out': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_out_filter_multi_is_eval_False.jsonl'}}
predict vocab size: 6322
{'get_model': {'config': {'cased': False, 'token_emb_dim': 100, 'char_encoder': 'lstm', 'char_emb_dim': 30, 'tag_emb_dim': 50, 'hidden_dim': 200, 'num_layers': 3, 'max_depth': None, 'crf': None, 'loss_reduction': 'sum', 'dropout': 0.5, 'lr': 0.001, 'optimizer': 'adam', 'maxlen': None, 'vocab_size': 6422, 'vocab_file': None, 'ner_tag_vocab_size': 64, 're_tag_vocab_size': 250, 'tag_form': 'iob2', 'device': 'cuda', 'lm_emb_dim': 1024, 'lm_emb_path': 'albert-large-v2', 'pos_emb_dim': 0, 'head_emb_dim': 384, 'warm_steps': 1000, 'grad_period': 1}}}
albert-large-v2 is not file, try load as bert model.
albert-large-v2 loaded successfully.
Note it only supports default options now, i.e.: 
  layers='-1,-2,-3,-4', use_scalar_mix=True, pooling_operation="mean"
reading pretrained wv from outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/data/predict.txt
Extractor Predicting: 0it [00:00, ?it/s]Extractor Predicting: 1it [00:00,  1.57it/s]Extractor Predicting: 2it [00:01,  1.54it/s]Extractor Predicting: 3it [00:01,  1.55it/s]Extractor Predicting: 4it [00:02,  1.60it/s]Extractor Predicting: 5it [00:03,  1.58it/s]Extractor Predicting: 6it [00:03,  1.54it/s]Extractor Predicting: 7it [00:04,  1.58it/s]Extractor Predicting: 8it [00:05,  1.60it/s]Extractor Predicting: 9it [00:05,  1.59it/s]Extractor Predicting: 10it [00:06,  1.63it/s]Extractor Predicting: 11it [00:06,  1.59it/s]Extractor Predicting: 12it [00:07,  1.60it/s]Extractor Predicting: 13it [00:08,  1.60it/s]Extractor Predicting: 14it [00:08,  1.58it/s]Extractor Predicting: 15it [00:09,  1.60it/s]Extractor Predicting: 16it [00:10,  1.57it/s]Extractor Predicting: 17it [00:10,  1.55it/s]Extractor Predicting: 18it [00:11,  1.57it/s]Extractor Predicting: 19it [00:11,  1.60it/s]Extractor Predicting: 20it [00:12,  1.58it/s]Extractor Predicting: 21it [00:13,  1.57it/s]Extractor Predicting: 22it [00:13,  1.58it/s]Extractor Predicting: 23it [00:14,  1.63it/s]Extractor Predicting: 24it [00:15,  1.65it/s]Extractor Predicting: 25it [00:15,  1.67it/s]Extractor Predicting: 26it [00:16,  1.68it/s]Extractor Predicting: 27it [00:16,  1.67it/s]Extractor Predicting: 28it [00:17,  1.67it/s]Extractor Predicting: 29it [00:18,  1.64it/s]Extractor Predicting: 30it [00:18,  1.67it/s]Extractor Predicting: 31it [00:19,  1.66it/s]Extractor Predicting: 32it [00:19,  1.56it/s]Extractor Predicting: 33it [00:20,  1.58it/s]Extractor Predicting: 34it [00:21,  1.62it/s]Extractor Predicting: 35it [00:21,  1.64it/s]Extractor Predicting: 36it [00:22,  1.68it/s]Extractor Predicting: 37it [00:22,  1.68it/s]Extractor Predicting: 38it [00:23,  1.72it/s]Extractor Predicting: 39it [00:24,  1.69it/s]Extractor Predicting: 40it [00:24,  1.67it/s]Extractor Predicting: 41it [00:25,  1.67it/s]Extractor Predicting: 42it [00:25,  1.64it/s]Extractor Predicting: 43it [00:26,  1.61it/s]Extractor Predicting: 44it [00:27,  1.62it/s]Extractor Predicting: 45it [00:27,  1.62it/s]Extractor Predicting: 46it [00:28,  1.57it/s]Extractor Predicting: 47it [00:29,  1.59it/s]Extractor Predicting: 48it [00:29,  1.62it/s]Extractor Predicting: 49it [00:30,  1.63it/s]Extractor Predicting: 50it [00:30,  1.63it/s]Extractor Predicting: 51it [00:31,  1.64it/s]Extractor Predicting: 52it [00:32,  1.62it/s]Extractor Predicting: 53it [00:32,  1.63it/s]Extractor Predicting: 54it [00:33,  1.64it/s]Extractor Predicting: 55it [00:33,  1.64it/s]Extractor Predicting: 56it [00:34,  1.64it/s]Extractor Predicting: 57it [00:35,  1.59it/s]Extractor Predicting: 58it [00:35,  1.59it/s]Extractor Predicting: 59it [00:36,  1.57it/s]Extractor Predicting: 60it [00:36,  1.97it/s]Extractor Predicting: 60it [00:36,  1.63it/s]
{
  "path_pred": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_out_filter_multi_is_eval_False.jsonl",
  "path_gold": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/pred_in_multi_is_eval_False.jsonl",
  "precision": 0,
  "recall": 0,
  "score": 0,
  "mode": "multi",
  "limit": 0,
  "path_results": "outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter5/results_multi_is_eval_False.json"
}
{'eval_best': {'path_test': 'zero_rte/wiki/unseen_10_seed_3/test.jsonl', 'save_dir': 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/', 'labels': ['continent', 'field of this occupation', 'field of work', 'founded by', 'movement', 'owned by', 'performer', 'producer', 'record label', 'replaces'], 'num_iter': 5, 'limit': 5000}}
Traceback (most recent call last):
  File "wrapper.py", line 811, in <module>
    Fire()
  File "/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/fire/core.py", line 471, in _Fire
    target=component.__name__)
  File "/cto_studio/xuting/miniconda3/envs/table_v1/lib/python3.7/site-packages/fire/core.py", line 681, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "wrapper.py", line 654, in main_dual
    eval_best(path_test=path_test, save_dir=save_dir, labels=labels_test, num_iter=num_iter, limit=limit)
  File "wrapper.py", line 711, in eval_best
    with open(path_results) as f:
FileNotFoundError: [Errno 2] No such file or directory: 'outputs/wrapper/wiki_rl_all_rsFalse_nbrel_train_large/unseen_10_seed_3/extractor/iter1/results_single_is_eval_True_limit5000.json'
